save path : ./save/2019-11-22/cifar10_quan_resnet20_200_i2r2o2_adam0.75_3bit
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.75, 'input_grain_size': [1, 2], 'input_num_bits': 3, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.75, 'output_grain_size': [1, 2], 'output_num_bits': 3, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.75, 'res_grain_size': [1, 2], 'res_num_bits': 3, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-22/cifar10_quan_resnet20_200_i2r2o2_adam0.75_3bit', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-23 14:35:45] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.668 (1.668)   Data 0.172 (0.172)   Loss 4.0454 (4.0454)   Prec@1 10.156 (10.156)   Prec@5 50.781 (50.781)   [2019-11-23 14:35:47]
  Epoch: [000][100/391]   Time 0.043 (0.064)   Data 0.000 (0.002)   Loss 1.7640 (2.0051)   Prec@1 32.812 (26.091)   Prec@5 86.719 (79.881)   [2019-11-23 14:35:52]
  Epoch: [000][200/391]   Time 0.044 (0.057)   Data 0.000 (0.001)   Loss 1.5531 (1.8085)   Prec@1 42.969 (33.085)   Prec@5 92.188 (85.032)   [2019-11-23 14:35:57]
  Epoch: [000][300/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 1.3195 (1.6687)   Prec@1 51.562 (38.458)   Prec@5 95.312 (87.596)   [2019-11-23 14:36:02]
  **Train** Prec@1 41.930 Prec@5 89.112 Error@1 58.070
  **Test** Prec@1 52.930 Prec@5 94.640 Error@1 47.070
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:36:08] [Epoch=001/200] [Need: 01:14:33] [LR=0.0100][M=0.90] [Best : Accuracy=52.93, Error=47.07]
  Epoch: [001][000/391]   Time 0.270 (0.270)   Data 0.202 (0.202)   Loss 1.2349 (1.2349)   Prec@1 53.906 (53.906)   Prec@5 95.312 (95.312)   [2019-11-23 14:36:09]
  Epoch: [001][100/391]   Time 0.042 (0.048)   Data 0.000 (0.002)   Loss 1.1779 (1.1651)   Prec@1 60.156 (57.534)   Prec@5 99.219 (95.506)   [2019-11-23 14:36:13]
  Epoch: [001][200/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 1.0629 (1.1198)   Prec@1 58.594 (59.324)   Prec@5 97.656 (95.845)   [2019-11-23 14:36:18]
  Epoch: [001][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.9306 (1.0958)   Prec@1 64.844 (60.341)   Prec@5 95.312 (96.063)   [2019-11-23 14:36:23]
  **Train** Prec@1 61.466 Prec@5 96.284 Error@1 38.534
  **Test** Prec@1 57.330 Prec@5 95.520 Error@1 42.670
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:36:30] [Epoch=002/200] [Need: 01:12:27] [LR=0.0100][M=0.90] [Best : Accuracy=57.33, Error=42.67]
  Epoch: [002][000/391]   Time 0.250 (0.250)   Data 0.188 (0.188)   Loss 0.9669 (0.9669)   Prec@1 66.406 (66.406)   Prec@5 94.531 (94.531)   [2019-11-23 14:36:30]
  Epoch: [002][100/391]   Time 0.080 (0.054)   Data 0.000 (0.002)   Loss 0.9857 (0.9287)   Prec@1 65.625 (67.064)   Prec@5 98.438 (97.123)   [2019-11-23 14:36:35]
  Epoch: [002][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 1.0186 (0.8986)   Prec@1 64.844 (67.930)   Prec@5 96.875 (97.458)   [2019-11-23 14:36:40]
  Epoch: [002][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.8944 (0.8813)   Prec@1 69.531 (68.716)   Prec@5 96.094 (97.612)   [2019-11-23 14:36:45]
  **Train** Prec@1 69.520 Prec@5 97.682 Error@1 30.480
  **Test** Prec@1 69.520 Prec@5 97.880 Error@1 30.480
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:36:51] [Epoch=003/200] [Need: 01:11:16] [LR=0.0100][M=0.90] [Best : Accuracy=69.52, Error=30.48]
  Epoch: [003][000/391]   Time 0.265 (0.265)   Data 0.195 (0.195)   Loss 0.9153 (0.9153)   Prec@1 64.844 (64.844)   Prec@5 95.312 (95.312)   [2019-11-23 14:36:51]
  Epoch: [003][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.6948 (0.7728)   Prec@1 73.438 (72.981)   Prec@5 99.219 (98.136)   [2019-11-23 14:36:56]
  Epoch: [003][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.7130 (0.7611)   Prec@1 71.875 (73.441)   Prec@5 98.438 (98.169)   [2019-11-23 14:37:01]
  Epoch: [003][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.5005 (0.7513)   Prec@1 83.594 (73.741)   Prec@5 99.219 (98.181)   [2019-11-23 14:37:06]
  **Train** Prec@1 74.108 Prec@5 98.194 Error@1 25.892
  **Test** Prec@1 73.400 Prec@5 98.140 Error@1 26.600
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:37:13] [Epoch=004/200] [Need: 01:11:11] [LR=0.0100][M=0.90] [Best : Accuracy=73.40, Error=26.60]
  Epoch: [004][000/391]   Time 0.272 (0.272)   Data 0.213 (0.213)   Loss 0.6272 (0.6272)   Prec@1 78.125 (78.125)   Prec@5 99.219 (99.219)   [2019-11-23 14:37:13]
  Epoch: [004][100/391]   Time 0.047 (0.051)   Data 0.000 (0.002)   Loss 0.6253 (0.7013)   Prec@1 79.688 (75.774)   Prec@5 98.438 (98.128)   [2019-11-23 14:37:18]
  Epoch: [004][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.5502 (0.6873)   Prec@1 80.469 (76.182)   Prec@5 100.000 (98.368)   [2019-11-23 14:37:23]
  Epoch: [004][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.5481 (0.6804)   Prec@1 82.031 (76.466)   Prec@5 100.000 (98.432)   [2019-11-23 14:37:28]
  **Train** Prec@1 76.778 Prec@5 98.500 Error@1 23.222
  **Test** Prec@1 71.910 Prec@5 98.060 Error@1 28.090

==>>[2019-11-23 14:37:34] [Epoch=005/200] [Need: 01:10:26] [LR=0.0100][M=0.90] [Best : Accuracy=73.40, Error=26.60]
  Epoch: [005][000/391]   Time 0.261 (0.261)   Data 0.201 (0.201)   Loss 0.6322 (0.6322)   Prec@1 79.688 (79.688)   Prec@5 97.656 (97.656)   [2019-11-23 14:37:34]
  Epoch: [005][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.4818 (0.6291)   Prec@1 85.938 (78.195)   Prec@5 99.219 (98.948)   [2019-11-23 14:37:39]
  Epoch: [005][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.6346 (0.6285)   Prec@1 80.469 (78.055)   Prec@5 96.875 (98.861)   [2019-11-23 14:37:44]
  Epoch: [005][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.6946 (0.6264)   Prec@1 78.906 (78.296)   Prec@5 97.656 (98.837)   [2019-11-23 14:37:50]
  **Train** Prec@1 78.688 Prec@5 98.816 Error@1 21.312
  **Test** Prec@1 75.600 Prec@5 98.180 Error@1 24.400
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:37:56] [Epoch=006/200] [Need: 01:10:13] [LR=0.0100][M=0.90] [Best : Accuracy=75.60, Error=24.40]
  Epoch: [006][000/391]   Time 0.274 (0.274)   Data 0.188 (0.188)   Loss 0.4670 (0.4670)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-23 14:37:56]
  Epoch: [006][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.5724 (0.5856)   Prec@1 82.031 (79.587)   Prec@5 97.656 (98.902)   [2019-11-23 14:38:01]
  Epoch: [006][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.6568 (0.5847)   Prec@1 78.125 (79.711)   Prec@5 100.000 (98.869)   [2019-11-23 14:38:06]
  Epoch: [006][300/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.5225 (0.5855)   Prec@1 80.469 (79.685)   Prec@5 99.219 (98.884)   [2019-11-23 14:38:11]
  **Train** Prec@1 79.814 Prec@5 98.898 Error@1 20.186
  **Test** Prec@1 75.860 Prec@5 98.740 Error@1 24.140
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:38:18] [Epoch=007/200] [Need: 01:09:47] [LR=0.0100][M=0.90] [Best : Accuracy=75.86, Error=24.14]
  Epoch: [007][000/391]   Time 0.266 (0.266)   Data 0.210 (0.210)   Loss 0.6055 (0.6055)   Prec@1 79.688 (79.688)   Prec@5 97.656 (97.656)   [2019-11-23 14:38:18]
  Epoch: [007][100/391]   Time 0.074 (0.052)   Data 0.000 (0.002)   Loss 0.7075 (0.5613)   Prec@1 77.344 (80.910)   Prec@5 99.219 (98.878)   [2019-11-23 14:38:23]
  Epoch: [007][200/391]   Time 0.038 (0.050)   Data 0.000 (0.001)   Loss 0.6445 (0.5534)   Prec@1 75.000 (80.993)   Prec@5 99.219 (98.951)   [2019-11-23 14:38:28]
  Epoch: [007][300/391]   Time 0.081 (0.050)   Data 0.000 (0.001)   Loss 0.5502 (0.5515)   Prec@1 81.250 (81.074)   Prec@5 98.438 (98.977)   [2019-11-23 14:38:33]
  **Train** Prec@1 80.982 Prec@5 98.996 Error@1 19.018
  **Test** Prec@1 76.100 Prec@5 98.470 Error@1 23.900
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:38:39] [Epoch=008/200] [Need: 01:09:21] [LR=0.0100][M=0.90] [Best : Accuracy=76.10, Error=23.90]
  Epoch: [008][000/391]   Time 0.270 (0.270)   Data 0.217 (0.217)   Loss 0.6061 (0.6061)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-23 14:38:39]
  Epoch: [008][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.4294 (0.5517)   Prec@1 86.719 (80.631)   Prec@5 100.000 (99.095)   [2019-11-23 14:38:44]
  Epoch: [008][200/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.5084 (0.5363)   Prec@1 82.031 (81.530)   Prec@5 100.000 (99.149)   [2019-11-23 14:38:49]
  Epoch: [008][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.5416 (0.5332)   Prec@1 82.812 (81.585)   Prec@5 100.000 (99.131)   [2019-11-23 14:38:54]
  **Train** Prec@1 81.642 Prec@5 99.150 Error@1 18.358
  **Test** Prec@1 78.170 Prec@5 98.670 Error@1 21.830
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:39:01] [Epoch=009/200] [Need: 01:09:01] [LR=0.0100][M=0.90] [Best : Accuracy=78.17, Error=21.83]
  Epoch: [009][000/391]   Time 0.273 (0.273)   Data 0.205 (0.205)   Loss 0.6725 (0.6725)   Prec@1 76.562 (76.562)   Prec@5 98.438 (98.438)   [2019-11-23 14:39:01]
  Epoch: [009][100/391]   Time 0.038 (0.054)   Data 0.000 (0.002)   Loss 0.4910 (0.4994)   Prec@1 85.156 (82.696)   Prec@5 99.219 (99.188)   [2019-11-23 14:39:06]
  Epoch: [009][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5266 (0.5045)   Prec@1 82.031 (82.435)   Prec@5 96.875 (99.172)   [2019-11-23 14:39:11]
  Epoch: [009][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.6462 (0.5059)   Prec@1 80.469 (82.444)   Prec@5 99.219 (99.159)   [2019-11-23 14:39:16]
  **Train** Prec@1 82.334 Prec@5 99.148 Error@1 17.666
  **Test** Prec@1 80.010 Prec@5 99.040 Error@1 19.990
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:39:23] [Epoch=010/200] [Need: 01:08:41] [LR=0.0100][M=0.90] [Best : Accuracy=80.01, Error=19.99]
  Epoch: [010][000/391]   Time 0.271 (0.271)   Data 0.195 (0.195)   Loss 0.4565 (0.4565)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-23 14:39:23]
  Epoch: [010][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.3331 (0.4758)   Prec@1 89.062 (82.944)   Prec@5 98.438 (99.219)   [2019-11-23 14:39:28]
  Epoch: [010][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3932 (0.4958)   Prec@1 88.281 (82.696)   Prec@5 99.219 (99.149)   [2019-11-23 14:39:33]
  Epoch: [010][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.2933 (0.4985)   Prec@1 91.406 (82.644)   Prec@5 99.219 (99.180)   [2019-11-23 14:39:38]
  **Train** Prec@1 82.652 Prec@5 99.180 Error@1 17.348
  **Test** Prec@1 80.900 Prec@5 99.010 Error@1 19.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:39:45] [Epoch=011/200] [Need: 01:08:25] [LR=0.0100][M=0.90] [Best : Accuracy=80.90, Error=19.10]
  Epoch: [011][000/391]   Time 0.277 (0.277)   Data 0.208 (0.208)   Loss 0.3709 (0.3709)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:39:45]
  Epoch: [011][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.6491 (0.4746)   Prec@1 78.125 (83.911)   Prec@5 97.656 (99.180)   [2019-11-23 14:39:50]
  Epoch: [011][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5609 (0.4791)   Prec@1 83.594 (83.625)   Prec@5 100.000 (99.203)   [2019-11-23 14:39:55]
  Epoch: [011][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4386 (0.4832)   Prec@1 85.938 (83.394)   Prec@5 97.656 (99.195)   [2019-11-23 14:40:00]
  **Train** Prec@1 83.442 Prec@5 99.188 Error@1 16.558
  **Test** Prec@1 77.550 Prec@5 98.600 Error@1 22.450

==>>[2019-11-23 14:40:07] [Epoch=012/200] [Need: 01:08:06] [LR=0.0100][M=0.90] [Best : Accuracy=80.90, Error=19.10]
  Epoch: [012][000/391]   Time 0.290 (0.290)   Data 0.219 (0.219)   Loss 0.3779 (0.3779)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 14:40:07]
  Epoch: [012][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.5764 (0.4646)   Prec@1 78.906 (84.112)   Prec@5 96.094 (99.226)   [2019-11-23 14:40:12]
  Epoch: [012][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4909 (0.4663)   Prec@1 83.594 (84.037)   Prec@5 99.219 (99.242)   [2019-11-23 14:40:17]
  Epoch: [012][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3515 (0.4682)   Prec@1 86.719 (83.955)   Prec@5 99.219 (99.237)   [2019-11-23 14:40:22]
  **Train** Prec@1 83.856 Prec@5 99.238 Error@1 16.144
  **Test** Prec@1 74.410 Prec@5 98.560 Error@1 25.590

==>>[2019-11-23 14:40:29] [Epoch=013/200] [Need: 01:07:48] [LR=0.0100][M=0.90] [Best : Accuracy=80.90, Error=19.10]
  Epoch: [013][000/391]   Time 0.263 (0.263)   Data 0.188 (0.188)   Loss 0.5981 (0.5981)   Prec@1 79.688 (79.688)   Prec@5 98.438 (98.438)   [2019-11-23 14:40:29]
  Epoch: [013][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.4606 (0.4443)   Prec@1 82.812 (84.684)   Prec@5 100.000 (99.319)   [2019-11-23 14:40:34]
  Epoch: [013][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4132 (0.4464)   Prec@1 85.938 (84.492)   Prec@5 100.000 (99.359)   [2019-11-23 14:40:39]
  Epoch: [013][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5365 (0.4557)   Prec@1 79.688 (84.235)   Prec@5 99.219 (99.276)   [2019-11-23 14:40:44]
  **Train** Prec@1 84.288 Prec@5 99.266 Error@1 15.712
  **Test** Prec@1 76.150 Prec@5 98.620 Error@1 23.850

==>>[2019-11-23 14:40:50] [Epoch=014/200] [Need: 01:07:21] [LR=0.0100][M=0.90] [Best : Accuracy=80.90, Error=19.10]
  Epoch: [014][000/391]   Time 0.258 (0.258)   Data 0.187 (0.187)   Loss 0.4773 (0.4773)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 14:40:50]
  Epoch: [014][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.4846 (0.4329)   Prec@1 84.375 (84.901)   Prec@5 100.000 (99.373)   [2019-11-23 14:40:56]
  Epoch: [014][200/391]   Time 0.079 (0.055)   Data 0.000 (0.001)   Loss 0.5191 (0.4423)   Prec@1 81.250 (84.542)   Prec@5 98.438 (99.359)   [2019-11-23 14:41:01]
  Epoch: [014][300/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.5204 (0.4507)   Prec@1 80.469 (84.440)   Prec@5 99.219 (99.299)   [2019-11-23 14:41:06]
  **Train** Prec@1 84.414 Prec@5 99.314 Error@1 15.586
  **Test** Prec@1 79.310 Prec@5 98.870 Error@1 20.690

==>>[2019-11-23 14:41:13] [Epoch=015/200] [Need: 01:07:10] [LR=0.0100][M=0.90] [Best : Accuracy=80.90, Error=19.10]
  Epoch: [015][000/391]   Time 0.254 (0.254)   Data 0.192 (0.192)   Loss 0.5718 (0.5718)   Prec@1 79.688 (79.688)   Prec@5 100.000 (100.000)   [2019-11-23 14:41:13]
  Epoch: [015][100/391]   Time 0.044 (0.048)   Data 0.000 (0.002)   Loss 0.3485 (0.4253)   Prec@1 89.062 (85.388)   Prec@5 99.219 (99.435)   [2019-11-23 14:41:17]
  Epoch: [015][200/391]   Time 0.047 (0.048)   Data 0.000 (0.001)   Loss 0.5478 (0.4362)   Prec@1 82.812 (85.001)   Prec@5 100.000 (99.409)   [2019-11-23 14:41:22]
  Epoch: [015][300/391]   Time 0.049 (0.049)   Data 0.000 (0.001)   Loss 0.4634 (0.4406)   Prec@1 87.500 (84.788)   Prec@5 99.219 (99.408)   [2019-11-23 14:41:27]
  **Train** Prec@1 84.690 Prec@5 99.378 Error@1 15.310
  **Test** Prec@1 81.820 Prec@5 99.170 Error@1 18.180
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:41:33] [Epoch=016/200] [Need: 01:06:37] [LR=0.0100][M=0.90] [Best : Accuracy=81.82, Error=18.18]
  Epoch: [016][000/391]   Time 0.282 (0.282)   Data 0.208 (0.208)   Loss 0.4526 (0.4526)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 14:41:34]
  Epoch: [016][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.4027 (0.4232)   Prec@1 84.375 (85.179)   Prec@5 99.219 (99.435)   [2019-11-23 14:41:39]
  Epoch: [016][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5163 (0.4308)   Prec@1 81.250 (84.865)   Prec@5 99.219 (99.390)   [2019-11-23 14:41:44]
  Epoch: [016][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3987 (0.4371)   Prec@1 88.281 (84.718)   Prec@5 99.219 (99.377)   [2019-11-23 14:41:49]
  **Train** Prec@1 84.904 Prec@5 99.352 Error@1 15.096
  **Test** Prec@1 81.940 Prec@5 98.830 Error@1 18.060
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:41:56] [Epoch=017/200] [Need: 01:06:21] [LR=0.0100][M=0.90] [Best : Accuracy=81.94, Error=18.06]
  Epoch: [017][000/391]   Time 0.258 (0.258)   Data 0.198 (0.198)   Loss 0.3391 (0.3391)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 14:41:56]
  Epoch: [017][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.4633 (0.4134)   Prec@1 85.938 (85.876)   Prec@5 99.219 (99.435)   [2019-11-23 14:42:01]
  Epoch: [017][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.6089 (0.4211)   Prec@1 77.344 (85.370)   Prec@5 97.656 (99.382)   [2019-11-23 14:42:06]
  Epoch: [017][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.4761 (0.4271)   Prec@1 83.594 (85.177)   Prec@5 99.219 (99.393)   [2019-11-23 14:42:11]
  **Train** Prec@1 85.240 Prec@5 99.418 Error@1 14.760
  **Test** Prec@1 81.640 Prec@5 99.240 Error@1 18.360

==>>[2019-11-23 14:42:18] [Epoch=018/200] [Need: 01:06:01] [LR=0.0100][M=0.90] [Best : Accuracy=81.94, Error=18.06]
  Epoch: [018][000/391]   Time 0.264 (0.264)   Data 0.200 (0.200)   Loss 0.3245 (0.3245)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 14:42:18]
  Epoch: [018][100/391]   Time 0.075 (0.056)   Data 0.000 (0.002)   Loss 0.4153 (0.4066)   Prec@1 85.938 (86.185)   Prec@5 99.219 (99.420)   [2019-11-23 14:42:23]
  Epoch: [018][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.5261 (0.4134)   Prec@1 86.719 (85.801)   Prec@5 99.219 (99.405)   [2019-11-23 14:42:28]
  Epoch: [018][300/391]   Time 0.039 (0.052)   Data 0.001 (0.001)   Loss 0.4303 (0.4148)   Prec@1 84.375 (85.681)   Prec@5 100.000 (99.398)   [2019-11-23 14:42:33]
  **Train** Prec@1 85.612 Prec@5 99.390 Error@1 14.388
  **Test** Prec@1 79.630 Prec@5 98.670 Error@1 20.370

==>>[2019-11-23 14:42:39] [Epoch=019/200] [Need: 01:05:40] [LR=0.0100][M=0.90] [Best : Accuracy=81.94, Error=18.06]
  Epoch: [019][000/391]   Time 0.266 (0.266)   Data 0.193 (0.193)   Loss 0.4722 (0.4722)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 14:42:40]
  Epoch: [019][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3112 (0.4095)   Prec@1 88.281 (85.860)   Prec@5 100.000 (99.335)   [2019-11-23 14:42:45]
  Epoch: [019][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.4727 (0.4105)   Prec@1 84.375 (85.778)   Prec@5 99.219 (99.382)   [2019-11-23 14:42:50]
  Epoch: [019][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.3409 (0.4118)   Prec@1 88.281 (85.751)   Prec@5 100.000 (99.408)   [2019-11-23 14:42:55]
  **Train** Prec@1 85.602 Prec@5 99.398 Error@1 14.398
  **Test** Prec@1 82.370 Prec@5 99.070 Error@1 17.630
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:43:02] [Epoch=020/200] [Need: 01:05:23] [LR=0.0100][M=0.90] [Best : Accuracy=82.37, Error=17.63]
  Epoch: [020][000/391]   Time 0.292 (0.292)   Data 0.231 (0.231)   Loss 0.4088 (0.4088)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 14:43:02]
  Epoch: [020][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.4048 (0.4036)   Prec@1 87.500 (86.595)   Prec@5 100.000 (99.466)   [2019-11-23 14:43:07]
  Epoch: [020][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.4988 (0.4040)   Prec@1 77.344 (86.221)   Prec@5 100.000 (99.491)   [2019-11-23 14:43:12]
  Epoch: [020][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.4774 (0.4051)   Prec@1 85.156 (86.210)   Prec@5 97.656 (99.450)   [2019-11-23 14:43:17]
  **Train** Prec@1 86.028 Prec@5 99.460 Error@1 13.972
  **Test** Prec@1 82.950 Prec@5 98.960 Error@1 17.050
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:43:24] [Epoch=021/200] [Need: 01:05:04] [LR=0.0100][M=0.90] [Best : Accuracy=82.95, Error=17.05]
  Epoch: [021][000/391]   Time 0.266 (0.266)   Data 0.206 (0.206)   Loss 0.4299 (0.4299)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 14:43:24]
  Epoch: [021][100/391]   Time 0.039 (0.054)   Data 0.000 (0.002)   Loss 0.4880 (0.3905)   Prec@1 83.594 (86.115)   Prec@5 99.219 (99.451)   [2019-11-23 14:43:29]
  Epoch: [021][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.4784 (0.3932)   Prec@1 84.375 (86.318)   Prec@5 99.219 (99.499)   [2019-11-23 14:43:35]
  Epoch: [021][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4692 (0.3979)   Prec@1 82.812 (86.319)   Prec@5 100.000 (99.437)   [2019-11-23 14:43:40]
  **Train** Prec@1 86.172 Prec@5 99.448 Error@1 13.828
  **Test** Prec@1 83.060 Prec@5 99.250 Error@1 16.940
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:43:46] [Epoch=022/200] [Need: 01:04:48] [LR=0.0100][M=0.90] [Best : Accuracy=83.06, Error=16.94]
  Epoch: [022][000/391]   Time 0.272 (0.272)   Data 0.188 (0.188)   Loss 0.3266 (0.3266)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:43:47]
  Epoch: [022][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.5264 (0.3956)   Prec@1 81.250 (86.580)   Prec@5 99.219 (99.412)   [2019-11-23 14:43:51]
  Epoch: [022][200/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.4843 (0.3905)   Prec@1 79.688 (86.618)   Prec@5 100.000 (99.487)   [2019-11-23 14:43:57]
  Epoch: [022][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3429 (0.3947)   Prec@1 86.719 (86.410)   Prec@5 100.000 (99.494)   [2019-11-23 14:44:02]
  **Train** Prec@1 86.336 Prec@5 99.476 Error@1 13.664
  **Test** Prec@1 80.770 Prec@5 98.750 Error@1 19.230

==>>[2019-11-23 14:44:08] [Epoch=023/200] [Need: 01:04:26] [LR=0.0100][M=0.90] [Best : Accuracy=83.06, Error=16.94]
  Epoch: [023][000/391]   Time 0.293 (0.293)   Data 0.234 (0.234)   Loss 0.4094 (0.4094)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2019-11-23 14:44:08]
  Epoch: [023][100/391]   Time 0.073 (0.056)   Data 0.000 (0.002)   Loss 0.3702 (0.3642)   Prec@1 86.719 (87.392)   Prec@5 100.000 (99.544)   [2019-11-23 14:44:14]
  Epoch: [023][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.3396 (0.3775)   Prec@1 88.281 (86.948)   Prec@5 100.000 (99.510)   [2019-11-23 14:44:19]
  Epoch: [023][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.3832 (0.3846)   Prec@1 89.062 (86.708)   Prec@5 98.438 (99.491)   [2019-11-23 14:44:24]
  **Train** Prec@1 86.560 Prec@5 99.504 Error@1 13.440
  **Test** Prec@1 83.320 Prec@5 99.020 Error@1 16.680
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:44:30] [Epoch=024/200] [Need: 01:04:08] [LR=0.0100][M=0.90] [Best : Accuracy=83.32, Error=16.68]
  Epoch: [024][000/391]   Time 0.260 (0.260)   Data 0.199 (0.199)   Loss 0.3620 (0.3620)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 14:44:31]
  Epoch: [024][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.3437 (0.3824)   Prec@1 90.625 (86.719)   Prec@5 98.438 (99.482)   [2019-11-23 14:44:36]
  Epoch: [024][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.4941 (0.3883)   Prec@1 83.594 (86.377)   Prec@5 98.438 (99.502)   [2019-11-23 14:44:41]
  Epoch: [024][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.5544 (0.3892)   Prec@1 81.250 (86.236)   Prec@5 100.000 (99.525)   [2019-11-23 14:44:46]
  **Train** Prec@1 86.238 Prec@5 99.532 Error@1 13.762
  **Test** Prec@1 81.110 Prec@5 99.050 Error@1 18.890

==>>[2019-11-23 14:44:53] [Epoch=025/200] [Need: 01:03:48] [LR=0.0100][M=0.90] [Best : Accuracy=83.32, Error=16.68]
  Epoch: [025][000/391]   Time 0.272 (0.272)   Data 0.203 (0.203)   Loss 0.3730 (0.3730)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 14:44:53]
  Epoch: [025][100/391]   Time 0.081 (0.049)   Data 0.000 (0.002)   Loss 0.3148 (0.3673)   Prec@1 89.062 (87.407)   Prec@5 100.000 (99.536)   [2019-11-23 14:44:58]
  Epoch: [025][200/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.4112 (0.3780)   Prec@1 85.156 (86.995)   Prec@5 100.000 (99.506)   [2019-11-23 14:45:03]
  Epoch: [025][300/391]   Time 0.054 (0.049)   Data 0.000 (0.001)   Loss 0.3442 (0.3848)   Prec@1 87.500 (86.727)   Prec@5 100.000 (99.525)   [2019-11-23 14:45:08]
  **Train** Prec@1 86.586 Prec@5 99.508 Error@1 13.414
  **Test** Prec@1 80.570 Prec@5 99.050 Error@1 19.430

==>>[2019-11-23 14:45:14] [Epoch=026/200] [Need: 01:03:22] [LR=0.0100][M=0.90] [Best : Accuracy=83.32, Error=16.68]
  Epoch: [026][000/391]   Time 0.266 (0.266)   Data 0.194 (0.194)   Loss 0.2716 (0.2716)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 14:45:14]
  Epoch: [026][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.3379 (0.3700)   Prec@1 89.062 (87.407)   Prec@5 99.219 (99.528)   [2019-11-23 14:45:19]
  Epoch: [026][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4968 (0.3808)   Prec@1 83.594 (86.987)   Prec@5 100.000 (99.522)   [2019-11-23 14:45:24]
  Epoch: [026][300/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.3640 (0.3816)   Prec@1 88.281 (86.880)   Prec@5 100.000 (99.504)   [2019-11-23 14:45:29]
  **Train** Prec@1 86.820 Prec@5 99.484 Error@1 13.180
  **Test** Prec@1 82.070 Prec@5 98.870 Error@1 17.930

==>>[2019-11-23 14:45:36] [Epoch=027/200] [Need: 01:02:59] [LR=0.0100][M=0.90] [Best : Accuracy=83.32, Error=16.68]
  Epoch: [027][000/391]   Time 0.273 (0.273)   Data 0.185 (0.185)   Loss 0.2914 (0.2914)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 14:45:36]
  Epoch: [027][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.3428 (0.3633)   Prec@1 90.625 (87.399)   Prec@5 100.000 (99.621)   [2019-11-23 14:45:41]
  Epoch: [027][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.5409 (0.3765)   Prec@1 78.906 (86.878)   Prec@5 98.438 (99.518)   [2019-11-23 14:45:46]
  Epoch: [027][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3394 (0.3789)   Prec@1 91.406 (86.926)   Prec@5 100.000 (99.491)   [2019-11-23 14:45:51]
  **Train** Prec@1 86.886 Prec@5 99.480 Error@1 13.114
  **Test** Prec@1 82.890 Prec@5 99.150 Error@1 17.110

==>>[2019-11-23 14:45:58] [Epoch=028/200] [Need: 01:02:40] [LR=0.0100][M=0.90] [Best : Accuracy=83.32, Error=16.68]
  Epoch: [028][000/391]   Time 0.246 (0.246)   Data 0.174 (0.174)   Loss 0.4736 (0.4736)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 14:45:58]
  Epoch: [028][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.3059 (0.3632)   Prec@1 87.500 (87.461)   Prec@5 100.000 (99.621)   [2019-11-23 14:46:03]
  Epoch: [028][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.4280 (0.3723)   Prec@1 84.375 (87.076)   Prec@5 99.219 (99.557)   [2019-11-23 14:46:08]
  Epoch: [028][300/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.3805 (0.3770)   Prec@1 86.719 (86.942)   Prec@5 100.000 (99.502)   [2019-11-23 14:46:13]
  **Train** Prec@1 86.814 Prec@5 99.510 Error@1 13.186
  **Test** Prec@1 84.040 Prec@5 99.120 Error@1 15.960
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:46:20] [Epoch=029/200] [Need: 01:02:16] [LR=0.0100][M=0.90] [Best : Accuracy=84.04, Error=15.96]
  Epoch: [029][000/391]   Time 0.264 (0.264)   Data 0.187 (0.187)   Loss 0.3869 (0.3869)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-23 14:46:20]
  Epoch: [029][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3390 (0.3562)   Prec@1 89.062 (87.740)   Prec@5 100.000 (99.582)   [2019-11-23 14:46:25]
  Epoch: [029][200/391]   Time 0.068 (0.053)   Data 0.000 (0.001)   Loss 0.4783 (0.3657)   Prec@1 82.031 (87.380)   Prec@5 99.219 (99.569)   [2019-11-23 14:46:30]
  Epoch: [029][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.3540 (0.3696)   Prec@1 88.281 (87.121)   Prec@5 99.219 (99.572)   [2019-11-23 14:46:35]
  **Train** Prec@1 87.054 Prec@5 99.566 Error@1 12.946
  **Test** Prec@1 84.360 Prec@5 99.270 Error@1 15.640
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:46:42] [Epoch=030/200] [Need: 01:01:56] [LR=0.0100][M=0.90] [Best : Accuracy=84.36, Error=15.64]
  Epoch: [030][000/391]   Time 0.260 (0.260)   Data 0.198 (0.198)   Loss 0.4104 (0.4104)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 14:46:42]
  Epoch: [030][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.3184 (0.3528)   Prec@1 89.062 (87.871)   Prec@5 100.000 (99.474)   [2019-11-23 14:46:47]
  Epoch: [030][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.3742 (0.3689)   Prec@1 89.844 (87.321)   Prec@5 99.219 (99.479)   [2019-11-23 14:46:52]
  Epoch: [030][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3334 (0.3688)   Prec@1 86.719 (87.274)   Prec@5 100.000 (99.504)   [2019-11-23 14:46:57]
  **Train** Prec@1 87.222 Prec@5 99.528 Error@1 12.778
  **Test** Prec@1 83.690 Prec@5 99.280 Error@1 16.310

==>>[2019-11-23 14:47:04] [Epoch=031/200] [Need: 01:01:35] [LR=0.0100][M=0.90] [Best : Accuracy=84.36, Error=15.64]
  Epoch: [031][000/391]   Time 0.259 (0.259)   Data 0.208 (0.208)   Loss 0.4493 (0.4493)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-23 14:47:04]
  Epoch: [031][100/391]   Time 0.050 (0.055)   Data 0.000 (0.002)   Loss 0.2975 (0.3438)   Prec@1 92.969 (88.204)   Prec@5 100.000 (99.575)   [2019-11-23 14:47:09]
  Epoch: [031][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2934 (0.3594)   Prec@1 87.500 (87.543)   Prec@5 100.000 (99.553)   [2019-11-23 14:47:14]
  Epoch: [031][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4707 (0.3619)   Prec@1 83.594 (87.368)   Prec@5 98.438 (99.538)   [2019-11-23 14:47:19]
  **Train** Prec@1 87.266 Prec@5 99.526 Error@1 12.734
  **Test** Prec@1 83.780 Prec@5 99.370 Error@1 16.220

==>>[2019-11-23 14:47:26] [Epoch=032/200] [Need: 01:01:15] [LR=0.0100][M=0.90] [Best : Accuracy=84.36, Error=15.64]
  Epoch: [032][000/391]   Time 0.256 (0.256)   Data 0.189 (0.189)   Loss 0.4442 (0.4442)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-23 14:47:26]
  Epoch: [032][100/391]   Time 0.049 (0.049)   Data 0.000 (0.002)   Loss 0.3895 (0.3436)   Prec@1 88.281 (88.181)   Prec@5 100.000 (99.528)   [2019-11-23 14:47:31]
  Epoch: [032][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.3265 (0.3495)   Prec@1 92.969 (87.986)   Prec@5 99.219 (99.588)   [2019-11-23 14:47:36]
  Epoch: [032][300/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.3677 (0.3603)   Prec@1 86.719 (87.648)   Prec@5 98.438 (99.530)   [2019-11-23 14:47:41]
  **Train** Prec@1 87.546 Prec@5 99.552 Error@1 12.454
  **Test** Prec@1 85.180 Prec@5 99.340 Error@1 14.820
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:47:48] [Epoch=033/200] [Need: 01:00:53] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [033][000/391]   Time 0.275 (0.275)   Data 0.201 (0.201)   Loss 0.2871 (0.2871)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 14:47:48]
  Epoch: [033][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.2648 (0.3423)   Prec@1 92.188 (87.918)   Prec@5 100.000 (99.636)   [2019-11-23 14:47:53]
  Epoch: [033][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.4554 (0.3526)   Prec@1 82.812 (87.648)   Prec@5 97.656 (99.592)   [2019-11-23 14:47:58]
  Epoch: [033][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2573 (0.3554)   Prec@1 90.625 (87.651)   Prec@5 100.000 (99.590)   [2019-11-23 14:48:03]
  **Train** Prec@1 87.428 Prec@5 99.570 Error@1 12.572
  **Test** Prec@1 82.600 Prec@5 98.880 Error@1 17.400

==>>[2019-11-23 14:48:10] [Epoch=034/200] [Need: 01:00:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [034][000/391]   Time 0.262 (0.262)   Data 0.198 (0.198)   Loss 0.2884 (0.2884)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 14:48:10]
  Epoch: [034][100/391]   Time 0.072 (0.052)   Data 0.000 (0.002)   Loss 0.3688 (0.3554)   Prec@1 85.938 (87.546)   Prec@5 99.219 (99.613)   [2019-11-23 14:48:15]
  Epoch: [034][200/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.4280 (0.3583)   Prec@1 85.156 (87.558)   Prec@5 100.000 (99.569)   [2019-11-23 14:48:20]
  Epoch: [034][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.4637 (0.3599)   Prec@1 85.156 (87.409)   Prec@5 100.000 (99.598)   [2019-11-23 14:48:25]
  **Train** Prec@1 87.400 Prec@5 99.584 Error@1 12.600
  **Test** Prec@1 82.730 Prec@5 99.180 Error@1 17.270

==>>[2019-11-23 14:48:32] [Epoch=035/200] [Need: 01:00:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [035][000/391]   Time 0.270 (0.270)   Data 0.216 (0.216)   Loss 0.3631 (0.3631)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 14:48:32]
  Epoch: [035][100/391]   Time 0.075 (0.052)   Data 0.000 (0.002)   Loss 0.3735 (0.3403)   Prec@1 89.062 (88.444)   Prec@5 100.000 (99.683)   [2019-11-23 14:48:37]
  Epoch: [035][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2517 (0.3440)   Prec@1 92.969 (88.165)   Prec@5 98.438 (99.646)   [2019-11-23 14:48:42]
  Epoch: [035][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4431 (0.3471)   Prec@1 85.156 (88.144)   Prec@5 98.438 (99.603)   [2019-11-23 14:48:47]
  **Train** Prec@1 87.922 Prec@5 99.556 Error@1 12.078
  **Test** Prec@1 83.660 Prec@5 99.170 Error@1 16.340

==>>[2019-11-23 14:48:54] [Epoch=036/200] [Need: 00:59:51] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [036][000/391]   Time 0.252 (0.252)   Data 0.191 (0.191)   Loss 0.3364 (0.3364)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 14:48:54]
  Epoch: [036][100/391]   Time 0.079 (0.052)   Data 0.000 (0.002)   Loss 0.5271 (0.3464)   Prec@1 82.031 (88.127)   Prec@5 97.656 (99.613)   [2019-11-23 14:48:59]
  Epoch: [036][200/391]   Time 0.084 (0.051)   Data 0.000 (0.001)   Loss 0.3646 (0.3377)   Prec@1 85.156 (88.301)   Prec@5 100.000 (99.631)   [2019-11-23 14:49:04]
  Epoch: [036][300/391]   Time 0.072 (0.051)   Data 0.000 (0.001)   Loss 0.3731 (0.3481)   Prec@1 86.719 (87.900)   Prec@5 100.000 (99.603)   [2019-11-23 14:49:10]
  **Train** Prec@1 87.768 Prec@5 99.578 Error@1 12.232
  **Test** Prec@1 84.960 Prec@5 99.250 Error@1 15.040

==>>[2019-11-23 14:49:16] [Epoch=037/200] [Need: 00:59:30] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [037][000/391]   Time 0.262 (0.262)   Data 0.189 (0.189)   Loss 0.2695 (0.2695)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 14:49:17]
  Epoch: [037][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.2955 (0.3317)   Prec@1 87.500 (88.328)   Prec@5 100.000 (99.613)   [2019-11-23 14:49:22]
  Epoch: [037][200/391]   Time 0.047 (0.055)   Data 0.000 (0.001)   Loss 0.2480 (0.3458)   Prec@1 91.406 (87.881)   Prec@5 100.000 (99.576)   [2019-11-23 14:49:27]
  Epoch: [037][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3014 (0.3485)   Prec@1 89.844 (87.817)   Prec@5 100.000 (99.569)   [2019-11-23 14:49:32]
  **Train** Prec@1 87.768 Prec@5 99.568 Error@1 12.232
  **Test** Prec@1 84.830 Prec@5 99.300 Error@1 15.170

==>>[2019-11-23 14:49:38] [Epoch=038/200] [Need: 00:59:09] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [038][000/391]   Time 0.267 (0.267)   Data 0.209 (0.209)   Loss 0.2860 (0.2860)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 14:49:39]
  Epoch: [038][100/391]   Time 0.079 (0.050)   Data 0.000 (0.002)   Loss 0.3066 (0.3372)   Prec@1 87.500 (88.552)   Prec@5 100.000 (99.636)   [2019-11-23 14:49:44]
  Epoch: [038][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.2723 (0.3446)   Prec@1 92.969 (88.036)   Prec@5 100.000 (99.662)   [2019-11-23 14:49:49]
  Epoch: [038][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3889 (0.3500)   Prec@1 86.719 (87.850)   Prec@5 99.219 (99.634)   [2019-11-23 14:49:53]
  **Train** Prec@1 87.866 Prec@5 99.608 Error@1 12.134
  **Test** Prec@1 80.450 Prec@5 99.020 Error@1 19.550

==>>[2019-11-23 14:50:00] [Epoch=039/200] [Need: 00:58:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [039][000/391]   Time 0.275 (0.275)   Data 0.191 (0.191)   Loss 0.3191 (0.3191)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 14:50:00]
  Epoch: [039][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.3422 (0.3394)   Prec@1 83.594 (88.274)   Prec@5 100.000 (99.544)   [2019-11-23 14:50:05]
  Epoch: [039][200/391]   Time 0.080 (0.054)   Data 0.000 (0.001)   Loss 0.2286 (0.3484)   Prec@1 92.969 (88.126)   Prec@5 100.000 (99.572)   [2019-11-23 14:50:11]
  Epoch: [039][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3495 (0.3480)   Prec@1 85.938 (88.105)   Prec@5 99.219 (99.603)   [2019-11-23 14:50:16]
  **Train** Prec@1 88.114 Prec@5 99.602 Error@1 11.886
  **Test** Prec@1 83.600 Prec@5 99.230 Error@1 16.400

==>>[2019-11-23 14:50:22] [Epoch=040/200] [Need: 00:58:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [040][000/391]   Time 0.274 (0.274)   Data 0.201 (0.201)   Loss 0.3424 (0.3424)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 14:50:23]
  Epoch: [040][100/391]   Time 0.072 (0.055)   Data 0.000 (0.002)   Loss 0.2044 (0.3336)   Prec@1 93.750 (88.444)   Prec@5 100.000 (99.629)   [2019-11-23 14:50:28]
  Epoch: [040][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.3682 (0.3457)   Prec@1 85.156 (88.095)   Prec@5 100.000 (99.588)   [2019-11-23 14:50:33]
  Epoch: [040][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.3752 (0.3477)   Prec@1 86.719 (87.996)   Prec@5 99.219 (99.593)   [2019-11-23 14:50:38]
  **Train** Prec@1 88.200 Prec@5 99.588 Error@1 11.800
  **Test** Prec@1 84.490 Prec@5 99.290 Error@1 15.510

==>>[2019-11-23 14:50:44] [Epoch=041/200] [Need: 00:58:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [041][000/391]   Time 0.259 (0.259)   Data 0.190 (0.190)   Loss 0.3632 (0.3632)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 14:50:45]
  Epoch: [041][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3880 (0.3344)   Prec@1 85.156 (88.382)   Prec@5 100.000 (99.698)   [2019-11-23 14:50:50]
  Epoch: [041][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.2687 (0.3391)   Prec@1 91.406 (88.219)   Prec@5 100.000 (99.674)   [2019-11-23 14:50:55]
  Epoch: [041][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3213 (0.3392)   Prec@1 87.500 (88.250)   Prec@5 100.000 (99.663)   [2019-11-23 14:51:00]
  **Train** Prec@1 88.188 Prec@5 99.628 Error@1 11.812
  **Test** Prec@1 81.540 Prec@5 99.100 Error@1 18.460

==>>[2019-11-23 14:51:07] [Epoch=042/200] [Need: 00:57:44] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [042][000/391]   Time 0.262 (0.262)   Data 0.190 (0.190)   Loss 0.3200 (0.3200)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 14:51:07]
  Epoch: [042][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.4393 (0.3318)   Prec@1 83.594 (88.699)   Prec@5 100.000 (99.590)   [2019-11-23 14:51:12]
  Epoch: [042][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3356 (0.3340)   Prec@1 91.406 (88.491)   Prec@5 100.000 (99.607)   [2019-11-23 14:51:17]
  Epoch: [042][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.3583 (0.3379)   Prec@1 92.188 (88.424)   Prec@5 100.000 (99.595)   [2019-11-23 14:51:22]
  **Train** Prec@1 88.268 Prec@5 99.610 Error@1 11.732
  **Test** Prec@1 82.960 Prec@5 99.010 Error@1 17.040

==>>[2019-11-23 14:51:28] [Epoch=043/200] [Need: 00:57:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [043][000/391]   Time 0.261 (0.261)   Data 0.206 (0.206)   Loss 0.3498 (0.3498)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 14:51:28]
  Epoch: [043][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.2105 (0.3190)   Prec@1 92.188 (88.916)   Prec@5 100.000 (99.760)   [2019-11-23 14:51:33]
  Epoch: [043][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3688 (0.3302)   Prec@1 87.500 (88.460)   Prec@5 100.000 (99.681)   [2019-11-23 14:51:38]
  Epoch: [043][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2944 (0.3331)   Prec@1 92.188 (88.458)   Prec@5 100.000 (99.624)   [2019-11-23 14:51:44]
  **Train** Prec@1 88.362 Prec@5 99.618 Error@1 11.638
  **Test** Prec@1 84.170 Prec@5 99.490 Error@1 15.830

==>>[2019-11-23 14:51:51] [Epoch=044/200] [Need: 00:57:00] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [044][000/391]   Time 0.262 (0.262)   Data 0.201 (0.201)   Loss 0.3512 (0.3512)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:51:51]
  Epoch: [044][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3857 (0.3327)   Prec@1 85.938 (88.513)   Prec@5 99.219 (99.582)   [2019-11-23 14:51:56]
  Epoch: [044][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.2904 (0.3391)   Prec@1 89.844 (88.270)   Prec@5 100.000 (99.600)   [2019-11-23 14:52:01]
  Epoch: [044][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.3596 (0.3389)   Prec@1 88.281 (88.203)   Prec@5 100.000 (99.621)   [2019-11-23 14:52:05]
  **Train** Prec@1 88.226 Prec@5 99.626 Error@1 11.774
  **Test** Prec@1 84.380 Prec@5 99.330 Error@1 15.620

==>>[2019-11-23 14:52:12] [Epoch=045/200] [Need: 00:56:36] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [045][000/391]   Time 0.273 (0.273)   Data 0.190 (0.190)   Loss 0.3323 (0.3323)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 14:52:12]
  Epoch: [045][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5216 (0.3284)   Prec@1 80.469 (88.606)   Prec@5 100.000 (99.706)   [2019-11-23 14:52:17]
  Epoch: [045][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3129 (0.3352)   Prec@1 88.281 (88.425)   Prec@5 99.219 (99.689)   [2019-11-23 14:52:22]
  Epoch: [045][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3375 (0.3367)   Prec@1 87.500 (88.281)   Prec@5 99.219 (99.681)   [2019-11-23 14:52:28]
  **Train** Prec@1 88.232 Prec@5 99.646 Error@1 11.768
  **Test** Prec@1 81.470 Prec@5 99.270 Error@1 18.530

==>>[2019-11-23 14:52:34] [Epoch=046/200] [Need: 00:56:15] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [046][000/391]   Time 0.273 (0.273)   Data 0.215 (0.215)   Loss 0.3789 (0.3789)   Prec@1 87.500 (87.500)   Prec@5 98.438 (98.438)   [2019-11-23 14:52:34]
  Epoch: [046][100/391]   Time 0.047 (0.051)   Data 0.000 (0.002)   Loss 0.2692 (0.3272)   Prec@1 92.188 (88.475)   Prec@5 100.000 (99.683)   [2019-11-23 14:52:39]
  Epoch: [046][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3603 (0.3313)   Prec@1 85.938 (88.359)   Prec@5 99.219 (99.666)   [2019-11-23 14:52:44]
  Epoch: [046][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4206 (0.3339)   Prec@1 86.719 (88.235)   Prec@5 99.219 (99.629)   [2019-11-23 14:52:50]
  **Train** Prec@1 88.314 Prec@5 99.630 Error@1 11.686
  **Test** Prec@1 83.280 Prec@5 99.110 Error@1 16.720

==>>[2019-11-23 14:52:56] [Epoch=047/200] [Need: 00:55:53] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [047][000/391]   Time 0.257 (0.257)   Data 0.190 (0.190)   Loss 0.1379 (0.1379)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 14:52:56]
  Epoch: [047][100/391]   Time 0.049 (0.055)   Data 0.000 (0.002)   Loss 0.2866 (0.3206)   Prec@1 89.062 (88.784)   Prec@5 100.000 (99.652)   [2019-11-23 14:53:01]
  Epoch: [047][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3571 (0.3322)   Prec@1 89.062 (88.530)   Prec@5 100.000 (99.674)   [2019-11-23 14:53:07]
  Epoch: [047][300/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.3594 (0.3369)   Prec@1 85.156 (88.341)   Prec@5 100.000 (99.650)   [2019-11-23 14:53:12]
  **Train** Prec@1 88.166 Prec@5 99.636 Error@1 11.834
  **Test** Prec@1 84.090 Prec@5 98.970 Error@1 15.910

==>>[2019-11-23 14:53:18] [Epoch=048/200] [Need: 00:55:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.18, Error=14.82]
  Epoch: [048][000/391]   Time 0.257 (0.257)   Data 0.189 (0.189)   Loss 0.3076 (0.3076)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 14:53:19]
  Epoch: [048][100/391]   Time 0.080 (0.055)   Data 0.000 (0.002)   Loss 0.4243 (0.3164)   Prec@1 84.375 (88.792)   Prec@5 98.438 (99.660)   [2019-11-23 14:53:24]
  Epoch: [048][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.3913 (0.3255)   Prec@1 85.156 (88.437)   Prec@5 99.219 (99.677)   [2019-11-23 14:53:29]
  Epoch: [048][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.4031 (0.3323)   Prec@1 85.938 (88.281)   Prec@5 100.000 (99.624)   [2019-11-23 14:53:34]
  **Train** Prec@1 88.238 Prec@5 99.616 Error@1 11.762
  **Test** Prec@1 85.360 Prec@5 99.300 Error@1 14.640
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:53:41] [Epoch=049/200] [Need: 00:55:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [049][000/391]   Time 0.253 (0.253)   Data 0.195 (0.195)   Loss 0.3086 (0.3086)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-23 14:53:41]
  Epoch: [049][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.3136 (0.3321)   Prec@1 85.156 (88.451)   Prec@5 99.219 (99.683)   [2019-11-23 14:53:47]
  Epoch: [049][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.5131 (0.3296)   Prec@1 82.812 (88.526)   Prec@5 99.219 (99.642)   [2019-11-23 14:53:51]
  Epoch: [049][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2797 (0.3328)   Prec@1 89.844 (88.414)   Prec@5 100.000 (99.655)   [2019-11-23 14:53:56]
  **Train** Prec@1 88.312 Prec@5 99.658 Error@1 11.688
  **Test** Prec@1 84.300 Prec@5 99.320 Error@1 15.700

==>>[2019-11-23 14:54:02] [Epoch=050/200] [Need: 00:54:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [050][000/391]   Time 0.259 (0.259)   Data 0.204 (0.204)   Loss 0.2925 (0.2925)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 14:54:03]
  Epoch: [050][100/391]   Time 0.058 (0.055)   Data 0.000 (0.002)   Loss 0.1746 (0.3299)   Prec@1 94.531 (88.583)   Prec@5 100.000 (99.636)   [2019-11-23 14:54:08]
  Epoch: [050][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3086 (0.3307)   Prec@1 89.844 (88.619)   Prec@5 99.219 (99.607)   [2019-11-23 14:54:13]
  Epoch: [050][300/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.3854 (0.3310)   Prec@1 89.062 (88.595)   Prec@5 99.219 (99.621)   [2019-11-23 14:54:18]
  **Train** Prec@1 88.554 Prec@5 99.636 Error@1 11.446
  **Test** Prec@1 84.190 Prec@5 99.250 Error@1 15.810

==>>[2019-11-23 14:54:24] [Epoch=051/200] [Need: 00:54:28] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [051][000/391]   Time 0.279 (0.279)   Data 0.201 (0.201)   Loss 0.2891 (0.2891)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:54:25]
  Epoch: [051][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3081 (0.3151)   Prec@1 92.188 (89.039)   Prec@5 100.000 (99.722)   [2019-11-23 14:54:30]
  Epoch: [051][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.2204 (0.3232)   Prec@1 90.625 (88.650)   Prec@5 100.000 (99.685)   [2019-11-23 14:54:35]
  Epoch: [051][300/391]   Time 0.080 (0.052)   Data 0.000 (0.001)   Loss 0.3116 (0.3300)   Prec@1 92.188 (88.502)   Prec@5 99.219 (99.644)   [2019-11-23 14:54:40]
  **Train** Prec@1 88.406 Prec@5 99.620 Error@1 11.594
  **Test** Prec@1 83.170 Prec@5 98.920 Error@1 16.830

==>>[2019-11-23 14:54:46] [Epoch=052/200] [Need: 00:54:06] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [052][000/391]   Time 0.274 (0.274)   Data 0.209 (0.209)   Loss 0.4199 (0.4199)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 14:54:47]
  Epoch: [052][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.3079 (0.3115)   Prec@1 89.844 (89.186)   Prec@5 99.219 (99.667)   [2019-11-23 14:54:52]
  Epoch: [052][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3245 (0.3318)   Prec@1 89.062 (88.460)   Prec@5 99.219 (99.607)   [2019-11-23 14:54:57]
  Epoch: [052][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4277 (0.3287)   Prec@1 85.156 (88.562)   Prec@5 99.219 (99.618)   [2019-11-23 14:55:02]
  **Train** Prec@1 88.534 Prec@5 99.602 Error@1 11.466
  **Test** Prec@1 84.390 Prec@5 99.210 Error@1 15.610

==>>[2019-11-23 14:55:09] [Epoch=053/200] [Need: 00:53:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [053][000/391]   Time 0.273 (0.273)   Data 0.216 (0.216)   Loss 0.2758 (0.2758)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 14:55:09]
  Epoch: [053][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.2030 (0.3217)   Prec@1 91.406 (88.923)   Prec@5 100.000 (99.606)   [2019-11-23 14:55:14]
  Epoch: [053][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.3034 (0.3254)   Prec@1 88.281 (88.810)   Prec@5 100.000 (99.619)   [2019-11-23 14:55:19]
  Epoch: [053][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4519 (0.3294)   Prec@1 90.625 (88.671)   Prec@5 100.000 (99.634)   [2019-11-23 14:55:24]
  **Train** Prec@1 88.572 Prec@5 99.634 Error@1 11.428
  **Test** Prec@1 82.190 Prec@5 99.250 Error@1 17.810

==>>[2019-11-23 14:55:31] [Epoch=054/200] [Need: 00:53:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [054][000/391]   Time 0.264 (0.264)   Data 0.210 (0.210)   Loss 0.2143 (0.2143)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 14:55:31]
  Epoch: [054][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.2519 (0.3175)   Prec@1 92.969 (89.086)   Prec@5 100.000 (99.714)   [2019-11-23 14:55:36]
  Epoch: [054][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.2724 (0.3175)   Prec@1 88.281 (89.028)   Prec@5 100.000 (99.712)   [2019-11-23 14:55:41]
  Epoch: [054][300/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.3738 (0.3304)   Prec@1 83.594 (88.619)   Prec@5 99.219 (99.650)   [2019-11-23 14:55:46]
  **Train** Prec@1 88.716 Prec@5 99.646 Error@1 11.284
  **Test** Prec@1 84.210 Prec@5 99.450 Error@1 15.790

==>>[2019-11-23 14:55:53] [Epoch=055/200] [Need: 00:53:02] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [055][000/391]   Time 0.248 (0.248)   Data 0.189 (0.189)   Loss 0.3729 (0.3729)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 14:55:53]
  Epoch: [055][100/391]   Time 0.049 (0.054)   Data 0.000 (0.002)   Loss 0.4638 (0.3177)   Prec@1 85.938 (89.117)   Prec@5 99.219 (99.675)   [2019-11-23 14:55:58]
  Epoch: [055][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.2956 (0.3191)   Prec@1 89.062 (89.047)   Prec@5 100.000 (99.670)   [2019-11-23 14:56:03]
  Epoch: [055][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.3039 (0.3240)   Prec@1 91.406 (88.847)   Prec@5 100.000 (99.676)   [2019-11-23 14:56:08]
  **Train** Prec@1 88.786 Prec@5 99.670 Error@1 11.214
  **Test** Prec@1 84.690 Prec@5 99.330 Error@1 15.310

==>>[2019-11-23 14:56:15] [Epoch=056/200] [Need: 00:52:40] [LR=0.0100][M=0.90] [Best : Accuracy=85.36, Error=14.64]
  Epoch: [056][000/391]   Time 0.265 (0.265)   Data 0.208 (0.208)   Loss 0.3435 (0.3435)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-23 14:56:15]
  Epoch: [056][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.2953 (0.3079)   Prec@1 89.062 (89.163)   Prec@5 100.000 (99.714)   [2019-11-23 14:56:20]
  Epoch: [056][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.2752 (0.3201)   Prec@1 89.062 (88.860)   Prec@5 100.000 (99.627)   [2019-11-23 14:56:25]
  Epoch: [056][300/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.3185 (0.3266)   Prec@1 89.062 (88.671)   Prec@5 100.000 (99.644)   [2019-11-23 14:56:30]
  **Train** Prec@1 88.594 Prec@5 99.626 Error@1 11.406
  **Test** Prec@1 85.500 Prec@5 99.350 Error@1 14.500
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 14:56:37] [Epoch=057/200] [Need: 00:52:18] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [057][000/391]   Time 0.275 (0.275)   Data 0.183 (0.183)   Loss 0.3186 (0.3186)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:56:37]
  Epoch: [057][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.4758 (0.3141)   Prec@1 84.375 (88.830)   Prec@5 99.219 (99.660)   [2019-11-23 14:56:42]
  Epoch: [057][200/391]   Time 0.080 (0.052)   Data 0.000 (0.001)   Loss 0.3075 (0.3164)   Prec@1 89.844 (88.950)   Prec@5 99.219 (99.642)   [2019-11-23 14:56:47]
  Epoch: [057][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2540 (0.3225)   Prec@1 89.844 (88.717)   Prec@5 100.000 (99.611)   [2019-11-23 14:56:52]
  **Train** Prec@1 88.594 Prec@5 99.614 Error@1 11.406
  **Test** Prec@1 82.320 Prec@5 99.060 Error@1 17.680

==>>[2019-11-23 14:56:59] [Epoch=058/200] [Need: 00:51:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [058][000/391]   Time 0.259 (0.259)   Data 0.203 (0.203)   Loss 0.3263 (0.3263)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 14:56:59]
  Epoch: [058][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.3381 (0.2994)   Prec@1 91.406 (89.643)   Prec@5 98.438 (99.737)   [2019-11-23 14:57:04]
  Epoch: [058][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3312 (0.3106)   Prec@1 87.500 (89.315)   Prec@5 100.000 (99.701)   [2019-11-23 14:57:09]
  Epoch: [058][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.2538 (0.3147)   Prec@1 93.750 (89.117)   Prec@5 98.438 (99.665)   [2019-11-23 14:57:14]
  **Train** Prec@1 88.914 Prec@5 99.646 Error@1 11.086
  **Test** Prec@1 84.590 Prec@5 99.430 Error@1 15.410

==>>[2019-11-23 14:57:20] [Epoch=059/200] [Need: 00:51:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [059][000/391]   Time 0.270 (0.270)   Data 0.210 (0.210)   Loss 0.3850 (0.3850)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 14:57:21]
  Epoch: [059][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.3155 (0.3099)   Prec@1 89.844 (89.062)   Prec@5 100.000 (99.752)   [2019-11-23 14:57:26]
  Epoch: [059][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.3726 (0.3098)   Prec@1 83.594 (88.977)   Prec@5 100.000 (99.716)   [2019-11-23 14:57:31]
  Epoch: [059][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3360 (0.3271)   Prec@1 88.281 (88.541)   Prec@5 99.219 (99.665)   [2019-11-23 14:57:36]
  **Train** Prec@1 88.664 Prec@5 99.652 Error@1 11.336
  **Test** Prec@1 82.280 Prec@5 99.170 Error@1 17.720

==>>[2019-11-23 14:57:42] [Epoch=060/200] [Need: 00:51:11] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [060][000/391]   Time 0.256 (0.256)   Data 0.201 (0.201)   Loss 0.2217 (0.2217)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 14:57:42]
  Epoch: [060][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.4523 (0.3108)   Prec@1 83.594 (88.923)   Prec@5 100.000 (99.799)   [2019-11-23 14:57:47]
  Epoch: [060][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.3005 (0.3133)   Prec@1 90.625 (88.989)   Prec@5 100.000 (99.724)   [2019-11-23 14:57:52]
  Epoch: [060][300/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.3023 (0.3162)   Prec@1 88.281 (88.902)   Prec@5 100.000 (99.681)   [2019-11-23 14:57:57]
  **Train** Prec@1 88.878 Prec@5 99.674 Error@1 11.122
  **Test** Prec@1 84.450 Prec@5 99.280 Error@1 15.550

==>>[2019-11-23 14:58:04] [Epoch=061/200] [Need: 00:50:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [061][000/391]   Time 0.283 (0.283)   Data 0.228 (0.228)   Loss 0.3819 (0.3819)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-23 14:58:04]
  Epoch: [061][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.2725 (0.3181)   Prec@1 89.062 (88.699)   Prec@5 100.000 (99.691)   [2019-11-23 14:58:09]
  Epoch: [061][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4336 (0.3180)   Prec@1 88.281 (88.934)   Prec@5 99.219 (99.666)   [2019-11-23 14:58:14]
  Epoch: [061][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3029 (0.3208)   Prec@1 92.188 (88.886)   Prec@5 100.000 (99.670)   [2019-11-23 14:58:19]
  **Train** Prec@1 88.932 Prec@5 99.668 Error@1 11.068
  **Test** Prec@1 85.440 Prec@5 99.400 Error@1 14.560

==>>[2019-11-23 14:58:25] [Epoch=062/200] [Need: 00:50:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [062][000/391]   Time 0.256 (0.256)   Data 0.189 (0.189)   Loss 0.2772 (0.2772)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 14:58:26]
  Epoch: [062][100/391]   Time 0.059 (0.056)   Data 0.000 (0.002)   Loss 0.4386 (0.3085)   Prec@1 83.594 (89.271)   Prec@5 100.000 (99.660)   [2019-11-23 14:58:31]
  Epoch: [062][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3557 (0.3195)   Prec@1 86.719 (88.888)   Prec@5 100.000 (99.689)   [2019-11-23 14:58:36]
  Epoch: [062][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.3188 (0.3208)   Prec@1 88.281 (88.860)   Prec@5 100.000 (99.689)   [2019-11-23 14:58:41]
  **Train** Prec@1 88.898 Prec@5 99.684 Error@1 11.102
  **Test** Prec@1 84.600 Prec@5 99.360 Error@1 15.400

==>>[2019-11-23 14:58:47] [Epoch=063/200] [Need: 00:50:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [063][000/391]   Time 0.261 (0.261)   Data 0.204 (0.204)   Loss 0.2038 (0.2038)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 14:58:48]
  Epoch: [063][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.3771 (0.2966)   Prec@1 85.156 (89.612)   Prec@5 99.219 (99.644)   [2019-11-23 14:58:52]
  Epoch: [063][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.4618 (0.3121)   Prec@1 82.812 (89.171)   Prec@5 100.000 (99.674)   [2019-11-23 14:58:57]
  Epoch: [063][300/391]   Time 0.059 (0.050)   Data 0.000 (0.001)   Loss 0.4220 (0.3153)   Prec@1 84.375 (89.062)   Prec@5 100.000 (99.676)   [2019-11-23 14:59:02]
  **Train** Prec@1 88.942 Prec@5 99.662 Error@1 11.058
  **Test** Prec@1 84.450 Prec@5 99.240 Error@1 15.550

==>>[2019-11-23 14:59:09] [Epoch=064/200] [Need: 00:49:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [064][000/391]   Time 0.273 (0.273)   Data 0.191 (0.191)   Loss 0.2774 (0.2774)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 14:59:09]
  Epoch: [064][100/391]   Time 0.037 (0.053)   Data 0.000 (0.002)   Loss 0.4088 (0.3024)   Prec@1 89.844 (89.233)   Prec@5 100.000 (99.745)   [2019-11-23 14:59:14]
  Epoch: [064][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2807 (0.3081)   Prec@1 90.625 (89.140)   Prec@5 100.000 (99.732)   [2019-11-23 14:59:19]
  Epoch: [064][300/391]   Time 0.085 (0.051)   Data 0.000 (0.001)   Loss 0.4301 (0.3160)   Prec@1 85.938 (88.831)   Prec@5 100.000 (99.699)   [2019-11-23 14:59:24]
  **Train** Prec@1 88.896 Prec@5 99.690 Error@1 11.104
  **Test** Prec@1 84.620 Prec@5 99.210 Error@1 15.380

==>>[2019-11-23 14:59:31] [Epoch=065/200] [Need: 00:49:19] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [065][000/391]   Time 0.253 (0.253)   Data 0.196 (0.196)   Loss 0.3893 (0.3893)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 14:59:31]
  Epoch: [065][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.2771 (0.3195)   Prec@1 91.406 (89.132)   Prec@5 99.219 (99.636)   [2019-11-23 14:59:36]
  Epoch: [065][200/391]   Time 0.071 (0.051)   Data 0.000 (0.001)   Loss 0.2452 (0.3180)   Prec@1 89.844 (89.004)   Prec@5 100.000 (99.662)   [2019-11-23 14:59:41]
  Epoch: [065][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.4069 (0.3191)   Prec@1 88.281 (89.034)   Prec@5 99.219 (99.647)   [2019-11-23 14:59:46]
  **Train** Prec@1 89.004 Prec@5 99.638 Error@1 10.996
  **Test** Prec@1 83.050 Prec@5 99.230 Error@1 16.950

==>>[2019-11-23 14:59:53] [Epoch=066/200] [Need: 00:48:57] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [066][000/391]   Time 0.255 (0.255)   Data 0.190 (0.190)   Loss 0.3935 (0.3935)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 14:59:53]
  Epoch: [066][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.2813 (0.2966)   Prec@1 91.406 (89.643)   Prec@5 100.000 (99.698)   [2019-11-23 14:59:58]
  Epoch: [066][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3286 (0.3114)   Prec@1 86.719 (89.214)   Prec@5 99.219 (99.642)   [2019-11-23 15:00:03]
  Epoch: [066][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.1826 (0.3144)   Prec@1 90.625 (89.068)   Prec@5 100.000 (99.676)   [2019-11-23 15:00:08]
  **Train** Prec@1 88.930 Prec@5 99.662 Error@1 11.070
  **Test** Prec@1 85.350 Prec@5 99.400 Error@1 14.650

==>>[2019-11-23 15:00:15] [Epoch=067/200] [Need: 00:48:36] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [067][000/391]   Time 0.263 (0.263)   Data 0.190 (0.190)   Loss 0.3332 (0.3332)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 15:00:15]
  Epoch: [067][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.2893 (0.3005)   Prec@1 89.844 (89.828)   Prec@5 100.000 (99.706)   [2019-11-23 15:00:20]
  Epoch: [067][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.2247 (0.3126)   Prec@1 90.625 (89.323)   Prec@5 100.000 (99.685)   [2019-11-23 15:00:26]
  Epoch: [067][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.3667 (0.3125)   Prec@1 85.156 (89.288)   Prec@5 100.000 (99.673)   [2019-11-23 15:00:31]
  **Train** Prec@1 89.136 Prec@5 99.654 Error@1 10.864
  **Test** Prec@1 85.060 Prec@5 99.210 Error@1 14.940

==>>[2019-11-23 15:00:37] [Epoch=068/200] [Need: 00:48:15] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [068][000/391]   Time 0.288 (0.288)   Data 0.217 (0.217)   Loss 0.2830 (0.2830)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 15:00:37]
  Epoch: [068][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.2996 (0.3131)   Prec@1 92.188 (89.202)   Prec@5 98.438 (99.714)   [2019-11-23 15:00:42]
  Epoch: [068][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.3733 (0.3142)   Prec@1 89.062 (89.265)   Prec@5 98.438 (99.650)   [2019-11-23 15:00:47]
  Epoch: [068][300/391]   Time 0.059 (0.050)   Data 0.000 (0.001)   Loss 0.1762 (0.3175)   Prec@1 96.094 (89.120)   Prec@5 99.219 (99.650)   [2019-11-23 15:00:52]
  **Train** Prec@1 89.168 Prec@5 99.656 Error@1 10.832
  **Test** Prec@1 84.170 Prec@5 99.360 Error@1 15.830

==>>[2019-11-23 15:00:59] [Epoch=069/200] [Need: 00:47:52] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [069][000/391]   Time 0.257 (0.257)   Data 0.187 (0.187)   Loss 0.1814 (0.1814)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 15:00:59]
  Epoch: [069][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.2858 (0.2971)   Prec@1 87.500 (89.650)   Prec@5 100.000 (99.621)   [2019-11-23 15:01:04]
  Epoch: [069][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.2643 (0.3005)   Prec@1 91.406 (89.572)   Prec@5 99.219 (99.666)   [2019-11-23 15:01:09]
  Epoch: [069][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2524 (0.3063)   Prec@1 92.188 (89.335)   Prec@5 99.219 (99.644)   [2019-11-23 15:01:14]
  **Train** Prec@1 89.138 Prec@5 99.624 Error@1 10.862
  **Test** Prec@1 85.030 Prec@5 99.300 Error@1 14.970

==>>[2019-11-23 15:01:20] [Epoch=070/200] [Need: 00:47:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [070][000/391]   Time 0.263 (0.263)   Data 0.200 (0.200)   Loss 0.2405 (0.2405)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 15:01:21]
  Epoch: [070][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.2205 (0.2941)   Prec@1 90.625 (89.898)   Prec@5 100.000 (99.683)   [2019-11-23 15:01:26]
  Epoch: [070][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3235 (0.3138)   Prec@1 87.500 (89.202)   Prec@5 100.000 (99.658)   [2019-11-23 15:01:31]
  Epoch: [070][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.4368 (0.3128)   Prec@1 86.719 (89.184)   Prec@5 100.000 (99.720)   [2019-11-23 15:01:36]
  **Train** Prec@1 89.080 Prec@5 99.716 Error@1 10.920
  **Test** Prec@1 85.070 Prec@5 99.350 Error@1 14.930

==>>[2019-11-23 15:01:43] [Epoch=071/200] [Need: 00:47:09] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [071][000/391]   Time 0.253 (0.253)   Data 0.194 (0.194)   Loss 0.2789 (0.2789)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-23 15:01:43]
  Epoch: [071][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.3516 (0.3046)   Prec@1 85.156 (89.349)   Prec@5 99.219 (99.737)   [2019-11-23 15:01:48]
  Epoch: [071][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.2465 (0.3028)   Prec@1 91.406 (89.373)   Prec@5 98.438 (99.716)   [2019-11-23 15:01:54]
  Epoch: [071][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2331 (0.3078)   Prec@1 90.625 (89.309)   Prec@5 100.000 (99.714)   [2019-11-23 15:01:59]
  **Train** Prec@1 89.336 Prec@5 99.704 Error@1 10.664
  **Test** Prec@1 83.050 Prec@5 98.700 Error@1 16.950

==>>[2019-11-23 15:02:05] [Epoch=072/200] [Need: 00:46:47] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [072][000/391]   Time 0.267 (0.267)   Data 0.209 (0.209)   Loss 0.2047 (0.2047)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 15:02:05]
  Epoch: [072][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.2657 (0.2909)   Prec@1 89.844 (89.851)   Prec@5 100.000 (99.783)   [2019-11-23 15:02:10]
  Epoch: [072][200/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.3606 (0.2995)   Prec@1 88.281 (89.661)   Prec@5 98.438 (99.697)   [2019-11-23 15:02:15]
  Epoch: [072][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.4252 (0.3063)   Prec@1 80.469 (89.460)   Prec@5 99.219 (99.717)   [2019-11-23 15:02:20]
  **Train** Prec@1 89.274 Prec@5 99.710 Error@1 10.726
  **Test** Prec@1 85.850 Prec@5 99.330 Error@1 14.150
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:02:27] [Epoch=073/200] [Need: 00:46:25] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [073][000/391]   Time 0.266 (0.266)   Data 0.189 (0.189)   Loss 0.2951 (0.2951)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 15:02:27]
  Epoch: [073][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.2903 (0.3053)   Prec@1 89.062 (89.349)   Prec@5 100.000 (99.729)   [2019-11-23 15:02:32]
  Epoch: [073][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.2867 (0.3121)   Prec@1 91.406 (89.082)   Prec@5 100.000 (99.670)   [2019-11-23 15:02:37]
  Epoch: [073][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.3308 (0.3135)   Prec@1 85.938 (89.088)   Prec@5 100.000 (99.673)   [2019-11-23 15:02:42]
  **Train** Prec@1 89.184 Prec@5 99.686 Error@1 10.816
  **Test** Prec@1 85.660 Prec@5 99.360 Error@1 14.340

==>>[2019-11-23 15:02:49] [Epoch=074/200] [Need: 00:46:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [074][000/391]   Time 0.262 (0.262)   Data 0.207 (0.207)   Loss 0.4157 (0.4157)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 15:02:49]
  Epoch: [074][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.3698 (0.3018)   Prec@1 89.062 (89.759)   Prec@5 100.000 (99.675)   [2019-11-23 15:02:54]
  Epoch: [074][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.3580 (0.3032)   Prec@1 87.500 (89.478)   Prec@5 99.219 (99.728)   [2019-11-23 15:02:59]
  Epoch: [074][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3127 (0.3110)   Prec@1 89.844 (89.317)   Prec@5 100.000 (99.707)   [2019-11-23 15:03:04]
  **Train** Prec@1 89.368 Prec@5 99.672 Error@1 10.632
  **Test** Prec@1 82.610 Prec@5 99.150 Error@1 17.390

==>>[2019-11-23 15:03:11] [Epoch=075/200] [Need: 00:45:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [075][000/391]   Time 0.252 (0.252)   Data 0.187 (0.187)   Loss 0.2869 (0.2869)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 15:03:11]
  Epoch: [075][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.4393 (0.2815)   Prec@1 85.156 (90.331)   Prec@5 100.000 (99.752)   [2019-11-23 15:03:16]
  Epoch: [075][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.2630 (0.3011)   Prec@1 94.531 (89.544)   Prec@5 100.000 (99.685)   [2019-11-23 15:03:21]
  Epoch: [075][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.3110 (0.3084)   Prec@1 89.062 (89.242)   Prec@5 98.438 (99.626)   [2019-11-23 15:03:26]
  **Train** Prec@1 89.060 Prec@5 99.628 Error@1 10.940
  **Test** Prec@1 85.480 Prec@5 99.000 Error@1 14.520

==>>[2019-11-23 15:03:32] [Epoch=076/200] [Need: 00:45:18] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [076][000/391]   Time 0.271 (0.271)   Data 0.213 (0.213)   Loss 0.4089 (0.4089)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 15:03:32]
  Epoch: [076][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.2603 (0.3060)   Prec@1 89.062 (89.325)   Prec@5 100.000 (99.629)   [2019-11-23 15:03:37]
  Epoch: [076][200/391]   Time 0.080 (0.051)   Data 0.000 (0.001)   Loss 0.2609 (0.3098)   Prec@1 91.406 (89.164)   Prec@5 100.000 (99.681)   [2019-11-23 15:03:42]
  Epoch: [076][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.3908 (0.3089)   Prec@1 84.375 (89.242)   Prec@5 98.438 (99.683)   [2019-11-23 15:03:47]
  **Train** Prec@1 89.088 Prec@5 99.684 Error@1 10.912
  **Test** Prec@1 84.120 Prec@5 99.160 Error@1 15.880

==>>[2019-11-23 15:03:54] [Epoch=077/200] [Need: 00:44:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [077][000/391]   Time 0.268 (0.268)   Data 0.194 (0.194)   Loss 0.1929 (0.1929)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:03:54]
  Epoch: [077][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3908 (0.3050)   Prec@1 86.719 (89.457)   Prec@5 100.000 (99.636)   [2019-11-23 15:03:59]
  Epoch: [077][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.3442 (0.3059)   Prec@1 90.625 (89.397)   Prec@5 100.000 (99.650)   [2019-11-23 15:04:04]
  Epoch: [077][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2964 (0.3062)   Prec@1 88.281 (89.410)   Prec@5 100.000 (99.702)   [2019-11-23 15:04:09]
  **Train** Prec@1 89.370 Prec@5 99.678 Error@1 10.630
  **Test** Prec@1 83.390 Prec@5 99.180 Error@1 16.610

==>>[2019-11-23 15:04:15] [Epoch=078/200] [Need: 00:44:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [078][000/391]   Time 0.274 (0.274)   Data 0.201 (0.201)   Loss 0.3273 (0.3273)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-23 15:04:16]
  Epoch: [078][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.3253 (0.2921)   Prec@1 89.062 (90.207)   Prec@5 100.000 (99.706)   [2019-11-23 15:04:21]
  Epoch: [078][200/391]   Time 0.069 (0.053)   Data 0.000 (0.001)   Loss 0.3640 (0.3047)   Prec@1 87.500 (89.696)   Prec@5 98.438 (99.674)   [2019-11-23 15:04:26]
  Epoch: [078][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.2171 (0.3056)   Prec@1 91.406 (89.582)   Prec@5 100.000 (99.686)   [2019-11-23 15:04:31]
  **Train** Prec@1 89.476 Prec@5 99.660 Error@1 10.524
  **Test** Prec@1 85.030 Prec@5 99.280 Error@1 14.970

==>>[2019-11-23 15:04:38] [Epoch=079/200] [Need: 00:44:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [079][000/391]   Time 0.264 (0.264)   Data 0.204 (0.204)   Loss 0.3026 (0.3026)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 15:04:38]
  Epoch: [079][100/391]   Time 0.040 (0.054)   Data 0.000 (0.002)   Loss 0.4162 (0.2955)   Prec@1 87.500 (89.411)   Prec@5 99.219 (99.675)   [2019-11-23 15:04:43]
  Epoch: [079][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.2763 (0.2977)   Prec@1 88.281 (89.494)   Prec@5 100.000 (99.708)   [2019-11-23 15:04:49]
  Epoch: [079][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2410 (0.3038)   Prec@1 89.062 (89.384)   Prec@5 100.000 (99.709)   [2019-11-23 15:04:54]
  **Train** Prec@1 89.222 Prec@5 99.680 Error@1 10.778
  **Test** Prec@1 85.740 Prec@5 99.330 Error@1 14.260

==>>[2019-11-23 15:05:00] [Epoch=080/200] [Need: 00:43:51] [LR=0.0010][M=0.90] [Best : Accuracy=85.85, Error=14.15]
  Epoch: [080][000/391]   Time 0.268 (0.268)   Data 0.186 (0.186)   Loss 0.3095 (0.3095)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 15:05:01]
  Epoch: [080][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.2792 (0.2383)   Prec@1 90.625 (91.963)   Prec@5 100.000 (99.745)   [2019-11-23 15:05:06]
  Epoch: [080][200/391]   Time 0.082 (0.052)   Data 0.000 (0.001)   Loss 0.2181 (0.2277)   Prec@1 93.750 (92.242)   Prec@5 100.000 (99.786)   [2019-11-23 15:05:11]
  Epoch: [080][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.2405 (0.2201)   Prec@1 93.750 (92.489)   Prec@5 100.000 (99.811)   [2019-11-23 15:05:16]
  **Train** Prec@1 92.610 Prec@5 99.808 Error@1 7.390
  **Test** Prec@1 89.750 Prec@5 99.640 Error@1 10.250
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:05:22] [Epoch=081/200] [Need: 00:43:29] [LR=0.0010][M=0.90] [Best : Accuracy=89.75, Error=10.25]
  Epoch: [081][000/391]   Time 0.265 (0.265)   Data 0.206 (0.206)   Loss 0.2297 (0.2297)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-23 15:05:22]
  Epoch: [081][100/391]   Time 0.080 (0.053)   Data 0.000 (0.002)   Loss 0.1834 (0.1876)   Prec@1 95.312 (93.750)   Prec@5 99.219 (99.822)   [2019-11-23 15:05:27]
  Epoch: [081][200/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.2358 (0.1864)   Prec@1 92.188 (93.750)   Prec@5 100.000 (99.829)   [2019-11-23 15:05:32]
  Epoch: [081][300/391]   Time 0.071 (0.051)   Data 0.000 (0.001)   Loss 0.1905 (0.1847)   Prec@1 95.312 (93.670)   Prec@5 100.000 (99.855)   [2019-11-23 15:05:38]
  **Train** Prec@1 93.572 Prec@5 99.874 Error@1 6.428
  **Test** Prec@1 90.090 Prec@5 99.660 Error@1 9.910
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:05:44] [Epoch=082/200] [Need: 00:43:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.09, Error=9.91]
  Epoch: [082][000/391]   Time 0.253 (0.253)   Data 0.187 (0.187)   Loss 0.1886 (0.1886)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 15:05:44]
  Epoch: [082][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.2907 (0.1737)   Prec@1 89.062 (94.129)   Prec@5 99.219 (99.884)   [2019-11-23 15:05:50]
  Epoch: [082][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.1602 (0.1752)   Prec@1 95.312 (94.014)   Prec@5 99.219 (99.880)   [2019-11-23 15:05:55]
  Epoch: [082][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1334 (0.1770)   Prec@1 95.312 (93.882)   Prec@5 100.000 (99.878)   [2019-11-23 15:05:59]
  **Train** Prec@1 93.908 Prec@5 99.886 Error@1 6.092
  **Test** Prec@1 89.670 Prec@5 99.690 Error@1 10.330

==>>[2019-11-23 15:06:06] [Epoch=083/200] [Need: 00:42:46] [LR=0.0010][M=0.90] [Best : Accuracy=90.09, Error=9.91]
  Epoch: [083][000/391]   Time 0.268 (0.268)   Data 0.208 (0.208)   Loss 0.1736 (0.1736)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:06:06]
  Epoch: [083][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.1220 (0.1658)   Prec@1 96.875 (94.400)   Prec@5 100.000 (99.907)   [2019-11-23 15:06:12]
  Epoch: [083][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.2473 (0.1660)   Prec@1 94.531 (94.333)   Prec@5 99.219 (99.891)   [2019-11-23 15:06:16]
  Epoch: [083][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1873 (0.1634)   Prec@1 93.750 (94.503)   Prec@5 99.219 (99.901)   [2019-11-23 15:06:21]
  **Train** Prec@1 94.478 Prec@5 99.896 Error@1 5.522
  **Test** Prec@1 90.100 Prec@5 99.720 Error@1 9.900
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:06:28] [Epoch=084/200] [Need: 00:42:23] [LR=0.0010][M=0.90] [Best : Accuracy=90.10, Error=9.90]
  Epoch: [084][000/391]   Time 0.287 (0.287)   Data 0.231 (0.231)   Loss 0.1250 (0.1250)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:06:28]
  Epoch: [084][100/391]   Time 0.083 (0.050)   Data 0.000 (0.002)   Loss 0.0878 (0.1609)   Prec@1 96.875 (94.338)   Prec@5 100.000 (99.899)   [2019-11-23 15:06:33]
  Epoch: [084][200/391]   Time 0.073 (0.052)   Data 0.000 (0.001)   Loss 0.1602 (0.1602)   Prec@1 94.531 (94.364)   Prec@5 100.000 (99.883)   [2019-11-23 15:06:38]
  Epoch: [084][300/391]   Time 0.071 (0.052)   Data 0.000 (0.001)   Loss 0.2269 (0.1585)   Prec@1 92.188 (94.427)   Prec@5 100.000 (99.886)   [2019-11-23 15:06:43]
  **Train** Prec@1 94.398 Prec@5 99.894 Error@1 5.602
  **Test** Prec@1 90.120 Prec@5 99.720 Error@1 9.880
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:06:49] [Epoch=085/200] [Need: 00:42:01] [LR=0.0010][M=0.90] [Best : Accuracy=90.12, Error=9.88]
  Epoch: [085][000/391]   Time 0.274 (0.274)   Data 0.219 (0.219)   Loss 0.1561 (0.1561)   Prec@1 93.750 (93.750)   Prec@5 98.438 (98.438)   [2019-11-23 15:06:50]
  Epoch: [085][100/391]   Time 0.041 (0.054)   Data 0.000 (0.002)   Loss 0.1129 (0.1587)   Prec@1 96.094 (94.524)   Prec@5 100.000 (99.946)   [2019-11-23 15:06:55]
  Epoch: [085][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0848 (0.1550)   Prec@1 97.656 (94.625)   Prec@5 100.000 (99.926)   [2019-11-23 15:07:00]
  Epoch: [085][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0913 (0.1562)   Prec@1 96.094 (94.560)   Prec@5 100.000 (99.920)   [2019-11-23 15:07:05]
  **Train** Prec@1 94.572 Prec@5 99.918 Error@1 5.428
  **Test** Prec@1 89.990 Prec@5 99.740 Error@1 10.010

==>>[2019-11-23 15:07:12] [Epoch=086/200] [Need: 00:41:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.12, Error=9.88]
  Epoch: [086][000/391]   Time 0.277 (0.277)   Data 0.200 (0.200)   Loss 0.1789 (0.1789)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 15:07:12]
  Epoch: [086][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.1183 (0.1427)   Prec@1 95.312 (95.142)   Prec@5 100.000 (99.938)   [2019-11-23 15:07:17]
  Epoch: [086][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1119 (0.1464)   Prec@1 94.531 (94.978)   Prec@5 100.000 (99.930)   [2019-11-23 15:07:22]
  Epoch: [086][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1928 (0.1501)   Prec@1 91.406 (94.822)   Prec@5 100.000 (99.930)   [2019-11-23 15:07:27]
  **Train** Prec@1 94.776 Prec@5 99.922 Error@1 5.224
  **Test** Prec@1 90.060 Prec@5 99.740 Error@1 9.940

==>>[2019-11-23 15:07:34] [Epoch=087/200] [Need: 00:41:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.12, Error=9.88]
  Epoch: [087][000/391]   Time 0.282 (0.282)   Data 0.219 (0.219)   Loss 0.0529 (0.0529)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:07:34]
  Epoch: [087][100/391]   Time 0.081 (0.051)   Data 0.000 (0.002)   Loss 0.1132 (0.1413)   Prec@1 96.094 (95.080)   Prec@5 100.000 (99.899)   [2019-11-23 15:07:39]
  Epoch: [087][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1679 (0.1426)   Prec@1 92.188 (95.048)   Prec@5 100.000 (99.914)   [2019-11-23 15:07:44]
  Epoch: [087][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0883 (0.1426)   Prec@1 96.094 (95.056)   Prec@5 100.000 (99.927)   [2019-11-23 15:07:49]
  **Train** Prec@1 95.034 Prec@5 99.918 Error@1 4.966
  **Test** Prec@1 90.140 Prec@5 99.730 Error@1 9.860
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:07:55] [Epoch=088/200] [Need: 00:40:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.14, Error=9.86]
  Epoch: [088][000/391]   Time 0.270 (0.270)   Data 0.200 (0.200)   Loss 0.1335 (0.1335)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:07:56]
  Epoch: [088][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.1689 (0.1408)   Prec@1 93.750 (95.359)   Prec@5 99.219 (99.938)   [2019-11-23 15:08:01]
  Epoch: [088][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.1331 (0.1375)   Prec@1 92.969 (95.297)   Prec@5 100.000 (99.930)   [2019-11-23 15:08:06]
  Epoch: [088][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1355 (0.1387)   Prec@1 96.875 (95.268)   Prec@5 100.000 (99.922)   [2019-11-23 15:08:11]
  **Train** Prec@1 95.158 Prec@5 99.932 Error@1 4.842
  **Test** Prec@1 90.200 Prec@5 99.710 Error@1 9.800
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:08:17] [Epoch=089/200] [Need: 00:40:33] [LR=0.0010][M=0.90] [Best : Accuracy=90.20, Error=9.80]
  Epoch: [089][000/391]   Time 0.270 (0.270)   Data 0.198 (0.198)   Loss 0.1173 (0.1173)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:08:17]
  Epoch: [089][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0820 (0.1368)   Prec@1 96.094 (95.274)   Prec@5 100.000 (99.938)   [2019-11-23 15:08:22]
  Epoch: [089][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1440 (0.1379)   Prec@1 95.312 (95.196)   Prec@5 99.219 (99.934)   [2019-11-23 15:08:27]
  Epoch: [089][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.1394 (0.1354)   Prec@1 96.094 (95.315)   Prec@5 100.000 (99.943)   [2019-11-23 15:08:32]
  **Train** Prec@1 95.214 Prec@5 99.944 Error@1 4.786
  **Test** Prec@1 90.090 Prec@5 99.660 Error@1 9.910

==>>[2019-11-23 15:08:39] [Epoch=090/200] [Need: 00:40:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.20, Error=9.80]
  Epoch: [090][000/391]   Time 0.285 (0.285)   Data 0.210 (0.210)   Loss 0.2371 (0.2371)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 15:08:39]
  Epoch: [090][100/391]   Time 0.072 (0.057)   Data 0.000 (0.002)   Loss 0.1170 (0.1333)   Prec@1 96.094 (95.251)   Prec@5 100.000 (99.946)   [2019-11-23 15:08:44]
  Epoch: [090][200/391]   Time 0.081 (0.054)   Data 0.000 (0.001)   Loss 0.1709 (0.1317)   Prec@1 93.750 (95.320)   Prec@5 100.000 (99.942)   [2019-11-23 15:08:50]
  Epoch: [090][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1774 (0.1341)   Prec@1 93.750 (95.266)   Prec@5 100.000 (99.930)   [2019-11-23 15:08:54]
  **Train** Prec@1 95.298 Prec@5 99.936 Error@1 4.702
  **Test** Prec@1 90.280 Prec@5 99.710 Error@1 9.720
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:09:01] [Epoch=091/200] [Need: 00:39:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.28, Error=9.72]
  Epoch: [091][000/391]   Time 0.293 (0.293)   Data 0.228 (0.228)   Loss 0.1034 (0.1034)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:09:01]
  Epoch: [091][100/391]   Time 0.049 (0.055)   Data 0.000 (0.002)   Loss 0.1303 (0.1344)   Prec@1 96.875 (95.274)   Prec@5 100.000 (99.938)   [2019-11-23 15:09:06]
  Epoch: [091][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1343 (0.1317)   Prec@1 92.969 (95.332)   Prec@5 100.000 (99.938)   [2019-11-23 15:09:11]
  Epoch: [091][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2103 (0.1309)   Prec@1 95.312 (95.385)   Prec@5 98.438 (99.920)   [2019-11-23 15:09:16]
  **Train** Prec@1 95.412 Prec@5 99.928 Error@1 4.588
  **Test** Prec@1 90.260 Prec@5 99.730 Error@1 9.740

==>>[2019-11-23 15:09:23] [Epoch=092/200] [Need: 00:39:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.28, Error=9.72]
  Epoch: [092][000/391]   Time 0.268 (0.268)   Data 0.213 (0.213)   Loss 0.1294 (0.1294)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:09:23]
  Epoch: [092][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1205 (0.1247)   Prec@1 93.750 (95.684)   Prec@5 100.000 (99.961)   [2019-11-23 15:09:28]
  Epoch: [092][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1210 (0.1279)   Prec@1 94.531 (95.414)   Prec@5 100.000 (99.957)   [2019-11-23 15:09:33]
  Epoch: [092][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.1689 (0.1254)   Prec@1 95.312 (95.512)   Prec@5 100.000 (99.961)   [2019-11-23 15:09:38]
  **Train** Prec@1 95.470 Prec@5 99.958 Error@1 4.530
  **Test** Prec@1 90.440 Prec@5 99.740 Error@1 9.560
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:09:45] [Epoch=093/200] [Need: 00:39:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [093][000/391]   Time 0.251 (0.251)   Data 0.195 (0.195)   Loss 0.1173 (0.1173)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:09:45]
  Epoch: [093][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0864 (0.1213)   Prec@1 97.656 (95.753)   Prec@5 100.000 (99.938)   [2019-11-23 15:09:50]
  Epoch: [093][200/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.1757 (0.1239)   Prec@1 92.969 (95.616)   Prec@5 100.000 (99.946)   [2019-11-23 15:09:55]
  Epoch: [093][300/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.1260 (0.1266)   Prec@1 96.094 (95.541)   Prec@5 100.000 (99.938)   [2019-11-23 15:10:00]
  **Train** Prec@1 95.614 Prec@5 99.936 Error@1 4.386
  **Test** Prec@1 89.790 Prec@5 99.720 Error@1 10.210

==>>[2019-11-23 15:10:06] [Epoch=094/200] [Need: 00:38:43] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [094][000/391]   Time 0.271 (0.271)   Data 0.191 (0.191)   Loss 0.1132 (0.1132)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:10:06]
  Epoch: [094][100/391]   Time 0.083 (0.053)   Data 0.000 (0.002)   Loss 0.0948 (0.1204)   Prec@1 95.312 (95.784)   Prec@5 100.000 (99.930)   [2019-11-23 15:10:11]
  Epoch: [094][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.1252 (0.1214)   Prec@1 96.094 (95.588)   Prec@5 100.000 (99.953)   [2019-11-23 15:10:16]
  Epoch: [094][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0934 (0.1215)   Prec@1 96.094 (95.611)   Prec@5 100.000 (99.948)   [2019-11-23 15:10:21]
  **Train** Prec@1 95.614 Prec@5 99.946 Error@1 4.386
  **Test** Prec@1 90.250 Prec@5 99.680 Error@1 9.750

==>>[2019-11-23 15:10:28] [Epoch=095/200] [Need: 00:38:21] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [095][000/391]   Time 0.268 (0.268)   Data 0.210 (0.210)   Loss 0.0469 (0.0469)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:10:28]
  Epoch: [095][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.1194 (0.1075)   Prec@1 95.312 (96.225)   Prec@5 100.000 (99.977)   [2019-11-23 15:10:33]
  Epoch: [095][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.0815 (0.1125)   Prec@1 97.656 (96.070)   Prec@5 100.000 (99.961)   [2019-11-23 15:10:39]
  Epoch: [095][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1669 (0.1158)   Prec@1 93.750 (95.915)   Prec@5 100.000 (99.956)   [2019-11-23 15:10:43]
  **Train** Prec@1 95.866 Prec@5 99.960 Error@1 4.134
  **Test** Prec@1 89.790 Prec@5 99.750 Error@1 10.210

==>>[2019-11-23 15:10:50] [Epoch=096/200] [Need: 00:37:59] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [096][000/391]   Time 0.265 (0.265)   Data 0.201 (0.201)   Loss 0.0947 (0.0947)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:10:50]
  Epoch: [096][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.0283 (0.1185)   Prec@1 99.219 (95.908)   Prec@5 100.000 (99.969)   [2019-11-23 15:10:55]
  Epoch: [096][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.0927 (0.1174)   Prec@1 96.094 (95.915)   Prec@5 100.000 (99.965)   [2019-11-23 15:11:00]
  Epoch: [096][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1473 (0.1184)   Prec@1 91.406 (95.832)   Prec@5 100.000 (99.964)   [2019-11-23 15:11:05]
  **Train** Prec@1 95.822 Prec@5 99.966 Error@1 4.178
  **Test** Prec@1 90.250 Prec@5 99.750 Error@1 9.750

==>>[2019-11-23 15:11:11] [Epoch=097/200] [Need: 00:37:37] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [097][000/391]   Time 0.266 (0.266)   Data 0.201 (0.201)   Loss 0.1127 (0.1127)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:11:12]
  Epoch: [097][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.1078 (0.1100)   Prec@1 96.875 (96.279)   Prec@5 100.000 (99.977)   [2019-11-23 15:11:17]
  Epoch: [097][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1079 (0.1124)   Prec@1 96.094 (96.098)   Prec@5 100.000 (99.973)   [2019-11-23 15:11:22]
  Epoch: [097][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1172 (0.1149)   Prec@1 96.875 (95.990)   Prec@5 100.000 (99.956)   [2019-11-23 15:11:27]
  **Train** Prec@1 95.920 Prec@5 99.954 Error@1 4.080
  **Test** Prec@1 89.800 Prec@5 99.640 Error@1 10.200

==>>[2019-11-23 15:11:33] [Epoch=098/200] [Need: 00:37:15] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [098][000/391]   Time 0.278 (0.278)   Data 0.215 (0.215)   Loss 0.1168 (0.1168)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:11:34]
  Epoch: [098][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.1338 (0.1123)   Prec@1 93.750 (96.086)   Prec@5 100.000 (99.930)   [2019-11-23 15:11:39]
  Epoch: [098][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1459 (0.1097)   Prec@1 93.750 (96.035)   Prec@5 100.000 (99.961)   [2019-11-23 15:11:44]
  Epoch: [098][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0995 (0.1120)   Prec@1 96.875 (95.902)   Prec@5 100.000 (99.953)   [2019-11-23 15:11:49]
  **Train** Prec@1 95.974 Prec@5 99.960 Error@1 4.026
  **Test** Prec@1 90.260 Prec@5 99.780 Error@1 9.740

==>>[2019-11-23 15:11:55] [Epoch=099/200] [Need: 00:36:53] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [099][000/391]   Time 0.257 (0.257)   Data 0.192 (0.192)   Loss 0.1185 (0.1185)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:11:56]
  Epoch: [099][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.1782 (0.1120)   Prec@1 93.750 (96.117)   Prec@5 100.000 (99.930)   [2019-11-23 15:12:01]
  Epoch: [099][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1341 (0.1106)   Prec@1 95.312 (96.117)   Prec@5 100.000 (99.946)   [2019-11-23 15:12:06]
  Epoch: [099][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1324 (0.1124)   Prec@1 95.312 (96.026)   Prec@5 100.000 (99.953)   [2019-11-23 15:12:11]
  **Train** Prec@1 96.056 Prec@5 99.948 Error@1 3.944
  **Test** Prec@1 90.100 Prec@5 99.750 Error@1 9.900

==>>[2019-11-23 15:12:18] [Epoch=100/200] [Need: 00:36:31] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [100][000/391]   Time 0.269 (0.269)   Data 0.194 (0.194)   Loss 0.0896 (0.0896)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:12:18]
  Epoch: [100][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1745 (0.1037)   Prec@1 94.531 (96.264)   Prec@5 100.000 (99.946)   [2019-11-23 15:12:23]
  Epoch: [100][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1032 (0.1048)   Prec@1 95.312 (96.238)   Prec@5 100.000 (99.957)   [2019-11-23 15:12:28]
  Epoch: [100][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1081 (0.1066)   Prec@1 96.094 (96.224)   Prec@5 100.000 (99.948)   [2019-11-23 15:12:33]
  **Train** Prec@1 96.122 Prec@5 99.946 Error@1 3.878
  **Test** Prec@1 90.270 Prec@5 99.690 Error@1 9.730

==>>[2019-11-23 15:12:40] [Epoch=101/200] [Need: 00:36:10] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [101][000/391]   Time 0.275 (0.275)   Data 0.193 (0.193)   Loss 0.1010 (0.1010)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:12:40]
  Epoch: [101][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0538 (0.1038)   Prec@1 98.438 (96.264)   Prec@5 100.000 (99.969)   [2019-11-23 15:12:45]
  Epoch: [101][200/391]   Time 0.070 (0.053)   Data 0.000 (0.001)   Loss 0.1366 (0.1056)   Prec@1 95.312 (96.148)   Prec@5 100.000 (99.953)   [2019-11-23 15:12:51]
  Epoch: [101][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1602 (0.1059)   Prec@1 94.531 (96.195)   Prec@5 100.000 (99.964)   [2019-11-23 15:12:56]
  **Train** Prec@1 96.118 Prec@5 99.960 Error@1 3.882
  **Test** Prec@1 90.740 Prec@5 99.740 Error@1 9.260
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:13:02] [Epoch=102/200] [Need: 00:35:48] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [102][000/391]   Time 0.260 (0.260)   Data 0.180 (0.180)   Loss 0.1086 (0.1086)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:13:02]
  Epoch: [102][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.1247 (0.0991)   Prec@1 95.312 (96.380)   Prec@5 100.000 (99.969)   [2019-11-23 15:13:07]
  Epoch: [102][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.1109 (0.1022)   Prec@1 96.094 (96.253)   Prec@5 100.000 (99.977)   [2019-11-23 15:13:12]
  Epoch: [102][300/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0729 (0.1037)   Prec@1 96.094 (96.249)   Prec@5 100.000 (99.971)   [2019-11-23 15:13:18]
  **Train** Prec@1 96.304 Prec@5 99.966 Error@1 3.696
  **Test** Prec@1 90.420 Prec@5 99.690 Error@1 9.580

==>>[2019-11-23 15:13:24] [Epoch=103/200] [Need: 00:35:26] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [103][000/391]   Time 0.256 (0.256)   Data 0.195 (0.195)   Loss 0.0828 (0.0828)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:13:24]
  Epoch: [103][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.1404 (0.1004)   Prec@1 96.094 (96.597)   Prec@5 100.000 (99.969)   [2019-11-23 15:13:29]
  Epoch: [103][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0671 (0.0984)   Prec@1 98.438 (96.580)   Prec@5 100.000 (99.969)   [2019-11-23 15:13:34]
  Epoch: [103][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1664 (0.1003)   Prec@1 92.969 (96.501)   Prec@5 100.000 (99.958)   [2019-11-23 15:13:39]
  **Train** Prec@1 96.548 Prec@5 99.962 Error@1 3.452
  **Test** Prec@1 90.150 Prec@5 99.720 Error@1 9.850

==>>[2019-11-23 15:13:45] [Epoch=104/200] [Need: 00:35:04] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [104][000/391]   Time 0.266 (0.266)   Data 0.199 (0.199)   Loss 0.0347 (0.0347)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:13:46]
  Epoch: [104][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0597 (0.0937)   Prec@1 96.875 (96.898)   Prec@5 100.000 (99.969)   [2019-11-23 15:13:51]
  Epoch: [104][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0464 (0.0955)   Prec@1 98.438 (96.716)   Prec@5 100.000 (99.977)   [2019-11-23 15:13:56]
  Epoch: [104][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.1297 (0.0972)   Prec@1 96.094 (96.579)   Prec@5 100.000 (99.982)   [2019-11-23 15:14:01]
  **Train** Prec@1 96.542 Prec@5 99.976 Error@1 3.458
  **Test** Prec@1 90.120 Prec@5 99.700 Error@1 9.880

==>>[2019-11-23 15:14:07] [Epoch=105/200] [Need: 00:34:42] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [105][000/391]   Time 0.263 (0.263)   Data 0.204 (0.204)   Loss 0.0994 (0.0994)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:14:08]
  Epoch: [105][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0853 (0.0995)   Prec@1 96.094 (96.442)   Prec@5 100.000 (99.977)   [2019-11-23 15:14:13]
  Epoch: [105][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.1460 (0.0993)   Prec@1 94.531 (96.467)   Prec@5 100.000 (99.981)   [2019-11-23 15:14:18]
  Epoch: [105][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.1095 (0.0996)   Prec@1 96.875 (96.462)   Prec@5 100.000 (99.984)   [2019-11-23 15:14:22]
  **Train** Prec@1 96.420 Prec@5 99.980 Error@1 3.580
  **Test** Prec@1 90.280 Prec@5 99.760 Error@1 9.720

==>>[2019-11-23 15:14:29] [Epoch=106/200] [Need: 00:34:20] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [106][000/391]   Time 0.269 (0.269)   Data 0.216 (0.216)   Loss 0.0837 (0.0837)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:14:29]
  Epoch: [106][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0789 (0.0915)   Prec@1 96.094 (96.666)   Prec@5 100.000 (99.977)   [2019-11-23 15:14:34]
  Epoch: [106][200/391]   Time 0.074 (0.052)   Data 0.000 (0.001)   Loss 0.0973 (0.0958)   Prec@1 95.312 (96.533)   Prec@5 100.000 (99.973)   [2019-11-23 15:14:39]
  Epoch: [106][300/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.1047 (0.0962)   Prec@1 96.875 (96.566)   Prec@5 100.000 (99.974)   [2019-11-23 15:14:44]
  **Train** Prec@1 96.502 Prec@5 99.972 Error@1 3.498
  **Test** Prec@1 90.360 Prec@5 99.730 Error@1 9.640

==>>[2019-11-23 15:14:50] [Epoch=107/200] [Need: 00:33:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [107][000/391]   Time 0.263 (0.263)   Data 0.199 (0.199)   Loss 0.0777 (0.0777)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:14:51]
  Epoch: [107][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.0981 (0.0884)   Prec@1 96.875 (96.836)   Prec@5 100.000 (99.977)   [2019-11-23 15:14:56]
  Epoch: [107][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.1048 (0.0922)   Prec@1 97.656 (96.708)   Prec@5 100.000 (99.977)   [2019-11-23 15:15:01]
  Epoch: [107][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.1160 (0.0970)   Prec@1 95.312 (96.522)   Prec@5 100.000 (99.977)   [2019-11-23 15:15:06]
  **Train** Prec@1 96.430 Prec@5 99.980 Error@1 3.570
  **Test** Prec@1 89.710 Prec@5 99.720 Error@1 10.290

==>>[2019-11-23 15:15:12] [Epoch=108/200] [Need: 00:33:35] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [108][000/391]   Time 0.280 (0.280)   Data 0.221 (0.221)   Loss 0.0999 (0.0999)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:15:13]
  Epoch: [108][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.1177 (0.0894)   Prec@1 96.875 (96.829)   Prec@5 100.000 (99.992)   [2019-11-23 15:15:18]
  Epoch: [108][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.1280 (0.0935)   Prec@1 93.750 (96.650)   Prec@5 100.000 (99.992)   [2019-11-23 15:15:23]
  Epoch: [108][300/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.1161 (0.0957)   Prec@1 96.094 (96.564)   Prec@5 99.219 (99.984)   [2019-11-23 15:15:28]
  **Train** Prec@1 96.558 Prec@5 99.982 Error@1 3.442
  **Test** Prec@1 90.260 Prec@5 99.710 Error@1 9.740

==>>[2019-11-23 15:15:34] [Epoch=109/200] [Need: 00:33:14] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [109][000/391]   Time 0.264 (0.264)   Data 0.194 (0.194)   Loss 0.1495 (0.1495)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:15:35]
  Epoch: [109][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0553 (0.0896)   Prec@1 98.438 (96.805)   Prec@5 100.000 (99.977)   [2019-11-23 15:15:40]
  Epoch: [109][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0483 (0.0932)   Prec@1 98.438 (96.720)   Prec@5 100.000 (99.973)   [2019-11-23 15:15:45]
  Epoch: [109][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1664 (0.0937)   Prec@1 96.875 (96.714)   Prec@5 100.000 (99.977)   [2019-11-23 15:15:49]
  **Train** Prec@1 96.658 Prec@5 99.976 Error@1 3.342
  **Test** Prec@1 90.310 Prec@5 99.660 Error@1 9.690

==>>[2019-11-23 15:15:56] [Epoch=110/200] [Need: 00:32:52] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [110][000/391]   Time 0.278 (0.278)   Data 0.206 (0.206)   Loss 0.0501 (0.0501)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:15:56]
  Epoch: [110][100/391]   Time 0.073 (0.059)   Data 0.000 (0.002)   Loss 0.0776 (0.0884)   Prec@1 96.875 (96.875)   Prec@5 100.000 (99.969)   [2019-11-23 15:16:02]
  Epoch: [110][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.0594 (0.0923)   Prec@1 96.875 (96.793)   Prec@5 100.000 (99.977)   [2019-11-23 15:16:07]
  Epoch: [110][300/391]   Time 0.037 (0.053)   Data 0.000 (0.001)   Loss 0.0549 (0.0913)   Prec@1 98.438 (96.800)   Prec@5 100.000 (99.982)   [2019-11-23 15:16:12]
  **Train** Prec@1 96.732 Prec@5 99.982 Error@1 3.268
  **Test** Prec@1 89.750 Prec@5 99.730 Error@1 10.250

==>>[2019-11-23 15:16:19] [Epoch=111/200] [Need: 00:32:30] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [111][000/391]   Time 0.260 (0.260)   Data 0.190 (0.190)   Loss 0.0527 (0.0527)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:16:19]
  Epoch: [111][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0756 (0.0926)   Prec@1 97.656 (96.744)   Prec@5 100.000 (99.969)   [2019-11-23 15:16:24]
  Epoch: [111][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.1853 (0.0885)   Prec@1 92.188 (96.840)   Prec@5 100.000 (99.977)   [2019-11-23 15:16:29]
  Epoch: [111][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0728 (0.0904)   Prec@1 98.438 (96.758)   Prec@5 100.000 (99.977)   [2019-11-23 15:16:34]
  **Train** Prec@1 96.678 Prec@5 99.974 Error@1 3.322
  **Test** Prec@1 90.070 Prec@5 99.710 Error@1 9.930

==>>[2019-11-23 15:16:40] [Epoch=112/200] [Need: 00:32:08] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [112][000/391]   Time 0.269 (0.269)   Data 0.203 (0.203)   Loss 0.0539 (0.0539)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:16:41]
  Epoch: [112][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.0910 (0.0817)   Prec@1 95.312 (97.123)   Prec@5 100.000 (99.977)   [2019-11-23 15:16:46]
  Epoch: [112][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0713 (0.0847)   Prec@1 96.875 (97.015)   Prec@5 100.000 (99.973)   [2019-11-23 15:16:50]
  Epoch: [112][300/391]   Time 0.071 (0.050)   Data 0.000 (0.001)   Loss 0.0925 (0.0883)   Prec@1 96.875 (96.891)   Prec@5 100.000 (99.971)   [2019-11-23 15:16:55]
  **Train** Prec@1 96.766 Prec@5 99.970 Error@1 3.234
  **Test** Prec@1 90.200 Prec@5 99.690 Error@1 9.800

==>>[2019-11-23 15:17:02] [Epoch=113/200] [Need: 00:31:46] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [113][000/391]   Time 0.245 (0.245)   Data 0.194 (0.194)   Loss 0.1286 (0.1286)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 15:17:02]
  Epoch: [113][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.1144 (0.0866)   Prec@1 96.094 (96.883)   Prec@5 100.000 (99.977)   [2019-11-23 15:17:07]
  Epoch: [113][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0310 (0.0888)   Prec@1 98.438 (96.867)   Prec@5 100.000 (99.969)   [2019-11-23 15:17:13]
  Epoch: [113][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0688 (0.0890)   Prec@1 97.656 (96.865)   Prec@5 100.000 (99.974)   [2019-11-23 15:17:18]
  **Train** Prec@1 96.832 Prec@5 99.976 Error@1 3.168
  **Test** Prec@1 90.610 Prec@5 99.740 Error@1 9.390

==>>[2019-11-23 15:17:24] [Epoch=114/200] [Need: 00:31:24] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [114][000/391]   Time 0.273 (0.273)   Data 0.197 (0.197)   Loss 0.1244 (0.1244)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:17:24]
  Epoch: [114][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0891 (0.0923)   Prec@1 95.312 (96.751)   Prec@5 100.000 (99.969)   [2019-11-23 15:17:30]
  Epoch: [114][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.1046 (0.0923)   Prec@1 95.312 (96.735)   Prec@5 100.000 (99.981)   [2019-11-23 15:17:35]
  Epoch: [114][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0810 (0.0912)   Prec@1 96.875 (96.766)   Prec@5 100.000 (99.977)   [2019-11-23 15:17:40]
  **Train** Prec@1 96.796 Prec@5 99.978 Error@1 3.204
  **Test** Prec@1 90.430 Prec@5 99.730 Error@1 9.570

==>>[2019-11-23 15:17:47] [Epoch=115/200] [Need: 00:31:03] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [115][000/391]   Time 0.254 (0.254)   Data 0.191 (0.191)   Loss 0.0850 (0.0850)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:17:47]
  Epoch: [115][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0584 (0.0840)   Prec@1 98.438 (96.968)   Prec@5 100.000 (99.977)   [2019-11-23 15:17:52]
  Epoch: [115][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0617 (0.0854)   Prec@1 97.656 (96.910)   Prec@5 100.000 (99.977)   [2019-11-23 15:17:57]
  Epoch: [115][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.1117 (0.0858)   Prec@1 95.312 (96.909)   Prec@5 100.000 (99.971)   [2019-11-23 15:18:02]
  **Train** Prec@1 96.950 Prec@5 99.976 Error@1 3.050
  **Test** Prec@1 90.150 Prec@5 99.700 Error@1 9.850

==>>[2019-11-23 15:18:09] [Epoch=116/200] [Need: 00:30:41] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [116][000/391]   Time 0.256 (0.256)   Data 0.198 (0.198)   Loss 0.1711 (0.1711)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 15:18:09]
  Epoch: [116][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.1042 (0.0858)   Prec@1 96.094 (96.952)   Prec@5 100.000 (99.977)   [2019-11-23 15:18:14]
  Epoch: [116][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.1025 (0.0860)   Prec@1 96.094 (96.976)   Prec@5 100.000 (99.984)   [2019-11-23 15:18:19]
  Epoch: [116][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0660 (0.0839)   Prec@1 96.875 (96.966)   Prec@5 100.000 (99.990)   [2019-11-23 15:18:24]
  **Train** Prec@1 96.930 Prec@5 99.990 Error@1 3.070
  **Test** Prec@1 90.350 Prec@5 99.780 Error@1 9.650

==>>[2019-11-23 15:18:30] [Epoch=117/200] [Need: 00:30:19] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [117][000/391]   Time 0.256 (0.256)   Data 0.194 (0.194)   Loss 0.1547 (0.1547)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 15:18:31]
  Epoch: [117][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0603 (0.0877)   Prec@1 97.656 (96.689)   Prec@5 100.000 (99.992)   [2019-11-23 15:18:36]
  Epoch: [117][200/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.1156 (0.0864)   Prec@1 94.531 (96.852)   Prec@5 100.000 (99.988)   [2019-11-23 15:18:41]
  Epoch: [117][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0795 (0.0855)   Prec@1 97.656 (96.891)   Prec@5 100.000 (99.984)   [2019-11-23 15:18:46]
  **Train** Prec@1 96.894 Prec@5 99.976 Error@1 3.106
  **Test** Prec@1 89.940 Prec@5 99.690 Error@1 10.060

==>>[2019-11-23 15:18:52] [Epoch=118/200] [Need: 00:29:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [118][000/391]   Time 0.252 (0.252)   Data 0.198 (0.198)   Loss 0.1085 (0.1085)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:18:52]
  Epoch: [118][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.1599 (0.0815)   Prec@1 93.750 (97.076)   Prec@5 100.000 (99.985)   [2019-11-23 15:18:57]
  Epoch: [118][200/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0974 (0.0843)   Prec@1 97.656 (97.003)   Prec@5 100.000 (99.984)   [2019-11-23 15:19:02]
  Epoch: [118][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0435 (0.0861)   Prec@1 97.656 (96.911)   Prec@5 100.000 (99.971)   [2019-11-23 15:19:08]
  **Train** Prec@1 96.946 Prec@5 99.976 Error@1 3.054
  **Test** Prec@1 90.140 Prec@5 99.750 Error@1 9.860

==>>[2019-11-23 15:19:14] [Epoch=119/200] [Need: 00:29:35] [LR=0.0010][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [119][000/391]   Time 0.255 (0.255)   Data 0.199 (0.199)   Loss 0.0207 (0.0207)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:19:15]
  Epoch: [119][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0885 (0.0737)   Prec@1 96.875 (97.223)   Prec@5 100.000 (99.992)   [2019-11-23 15:19:20]
  Epoch: [119][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1141 (0.0788)   Prec@1 96.094 (97.124)   Prec@5 100.000 (99.992)   [2019-11-23 15:19:25]
  Epoch: [119][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1019 (0.0811)   Prec@1 96.094 (97.007)   Prec@5 100.000 (99.992)   [2019-11-23 15:19:30]
  **Train** Prec@1 97.052 Prec@5 99.990 Error@1 2.948
  **Test** Prec@1 90.220 Prec@5 99.750 Error@1 9.780

==>>[2019-11-23 15:19:36] [Epoch=120/200] [Need: 00:29:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [120][000/391]   Time 0.267 (0.267)   Data 0.211 (0.211)   Loss 0.0573 (0.0573)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:19:36]
  Epoch: [120][100/391]   Time 0.057 (0.054)   Data 0.000 (0.002)   Loss 0.0490 (0.0787)   Prec@1 98.438 (97.045)   Prec@5 100.000 (99.992)   [2019-11-23 15:19:41]
  Epoch: [120][200/391]   Time 0.047 (0.054)   Data 0.000 (0.001)   Loss 0.0511 (0.0743)   Prec@1 97.656 (97.213)   Prec@5 100.000 (99.996)   [2019-11-23 15:19:47]
  Epoch: [120][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0450 (0.0744)   Prec@1 99.219 (97.277)   Prec@5 100.000 (99.987)   [2019-11-23 15:19:52]
  **Train** Prec@1 97.366 Prec@5 99.986 Error@1 2.634
  **Test** Prec@1 90.710 Prec@5 99.730 Error@1 9.290

==>>[2019-11-23 15:19:58] [Epoch=121/200] [Need: 00:28:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [121][000/391]   Time 0.278 (0.278)   Data 0.188 (0.188)   Loss 0.0476 (0.0476)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:19:58]
  Epoch: [121][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0517 (0.0634)   Prec@1 98.438 (97.780)   Prec@5 100.000 (99.985)   [2019-11-23 15:20:04]
  Epoch: [121][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0777 (0.0636)   Prec@1 97.656 (97.804)   Prec@5 100.000 (99.984)   [2019-11-23 15:20:09]
  Epoch: [121][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1168 (0.0647)   Prec@1 95.312 (97.763)   Prec@5 99.219 (99.982)   [2019-11-23 15:20:14]
  **Train** Prec@1 97.760 Prec@5 99.982 Error@1 2.240
  **Test** Prec@1 90.800 Prec@5 99.740 Error@1 9.200
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:20:20] [Epoch=122/200] [Need: 00:28:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [122][000/391]   Time 0.261 (0.261)   Data 0.197 (0.197)   Loss 0.0482 (0.0482)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:20:20]
  Epoch: [122][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0475 (0.0639)   Prec@1 98.438 (97.826)   Prec@5 100.000 (100.000)   [2019-11-23 15:20:26]
  Epoch: [122][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0811 (0.0639)   Prec@1 97.656 (97.854)   Prec@5 100.000 (100.000)   [2019-11-23 15:20:31]
  Epoch: [122][300/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.0424 (0.0619)   Prec@1 97.656 (97.918)   Prec@5 100.000 (100.000)   [2019-11-23 15:20:36]
  **Train** Prec@1 97.864 Prec@5 99.998 Error@1 2.136
  **Test** Prec@1 90.780 Prec@5 99.750 Error@1 9.220

==>>[2019-11-23 15:20:42] [Epoch=123/200] [Need: 00:28:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [123][000/391]   Time 0.265 (0.265)   Data 0.195 (0.195)   Loss 0.0249 (0.0249)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:20:43]
  Epoch: [123][100/391]   Time 0.053 (0.050)   Data 0.000 (0.002)   Loss 0.0626 (0.0610)   Prec@1 97.656 (97.888)   Prec@5 100.000 (99.992)   [2019-11-23 15:20:47]
  Epoch: [123][200/391]   Time 0.053 (0.049)   Data 0.000 (0.001)   Loss 0.0415 (0.0622)   Prec@1 99.219 (97.870)   Prec@5 100.000 (99.992)   [2019-11-23 15:20:52]
  Epoch: [123][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0240 (0.0618)   Prec@1 99.219 (97.913)   Prec@5 100.000 (99.995)   [2019-11-23 15:20:57]
  **Train** Prec@1 97.880 Prec@5 99.992 Error@1 2.120
  **Test** Prec@1 90.780 Prec@5 99.770 Error@1 9.220

==>>[2019-11-23 15:21:04] [Epoch=124/200] [Need: 00:27:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [124][000/391]   Time 0.262 (0.262)   Data 0.198 (0.198)   Loss 0.0360 (0.0360)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:21:04]
  Epoch: [124][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0476 (0.0544)   Prec@1 98.438 (98.120)   Prec@5 100.000 (99.985)   [2019-11-23 15:21:09]
  Epoch: [124][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0312 (0.0572)   Prec@1 99.219 (98.002)   Prec@5 100.000 (99.981)   [2019-11-23 15:21:14]
  Epoch: [124][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0334 (0.0592)   Prec@1 99.219 (97.978)   Prec@5 100.000 (99.987)   [2019-11-23 15:21:19]
  **Train** Prec@1 97.996 Prec@5 99.988 Error@1 2.004
  **Test** Prec@1 90.900 Prec@5 99.690 Error@1 9.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:21:26] [Epoch=125/200] [Need: 00:27:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [125][000/391]   Time 0.274 (0.274)   Data 0.216 (0.216)   Loss 0.0290 (0.0290)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:21:26]
  Epoch: [125][100/391]   Time 0.047 (0.052)   Data 0.000 (0.002)   Loss 0.0374 (0.0523)   Prec@1 100.000 (98.275)   Prec@5 100.000 (99.992)   [2019-11-23 15:21:31]
  Epoch: [125][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0684 (0.0566)   Prec@1 98.438 (98.119)   Prec@5 100.000 (99.996)   [2019-11-23 15:21:36]
  Epoch: [125][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0596 (0.0584)   Prec@1 97.656 (98.027)   Prec@5 100.000 (99.995)   [2019-11-23 15:21:42]
  **Train** Prec@1 98.012 Prec@5 99.992 Error@1 1.988
  **Test** Prec@1 91.010 Prec@5 99.730 Error@1 8.990
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:21:48] [Epoch=126/200] [Need: 00:27:02] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [126][000/391]   Time 0.278 (0.278)   Data 0.196 (0.196)   Loss 0.0647 (0.0647)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:21:49]
  Epoch: [126][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0467 (0.0590)   Prec@1 98.438 (97.904)   Prec@5 100.000 (100.000)   [2019-11-23 15:21:54]
  Epoch: [126][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0474 (0.0582)   Prec@1 97.656 (97.994)   Prec@5 100.000 (99.996)   [2019-11-23 15:21:59]
  Epoch: [126][300/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.0497 (0.0594)   Prec@1 97.656 (97.916)   Prec@5 100.000 (99.992)   [2019-11-23 15:22:04]
  **Train** Prec@1 97.984 Prec@5 99.994 Error@1 2.016
  **Test** Prec@1 90.810 Prec@5 99.790 Error@1 9.190

==>>[2019-11-23 15:22:10] [Epoch=127/200] [Need: 00:26:40] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [127][000/391]   Time 0.274 (0.274)   Data 0.218 (0.218)   Loss 0.0886 (0.0886)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 15:22:10]
  Epoch: [127][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0489 (0.0586)   Prec@1 97.656 (97.981)   Prec@5 100.000 (99.985)   [2019-11-23 15:22:15]
  Epoch: [127][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0806 (0.0596)   Prec@1 97.656 (98.010)   Prec@5 100.000 (99.977)   [2019-11-23 15:22:20]
  Epoch: [127][300/391]   Time 0.053 (0.049)   Data 0.000 (0.001)   Loss 0.0608 (0.0574)   Prec@1 98.438 (98.085)   Prec@5 100.000 (99.984)   [2019-11-23 15:22:25]
  **Train** Prec@1 98.112 Prec@5 99.988 Error@1 1.888
  **Test** Prec@1 90.780 Prec@5 99.760 Error@1 9.220

==>>[2019-11-23 15:22:31] [Epoch=128/200] [Need: 00:26:18] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [128][000/391]   Time 0.273 (0.273)   Data 0.215 (0.215)   Loss 0.0652 (0.0652)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:22:32]
  Epoch: [128][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0580 (0.0548)   Prec@1 98.438 (98.252)   Prec@5 100.000 (99.985)   [2019-11-23 15:22:37]
  Epoch: [128][200/391]   Time 0.064 (0.052)   Data 0.000 (0.001)   Loss 0.1430 (0.0569)   Prec@1 96.875 (98.103)   Prec@5 100.000 (99.988)   [2019-11-23 15:22:42]
  Epoch: [128][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0388 (0.0568)   Prec@1 98.438 (98.092)   Prec@5 100.000 (99.992)   [2019-11-23 15:22:47]
  **Train** Prec@1 98.092 Prec@5 99.994 Error@1 1.908
  **Test** Prec@1 90.750 Prec@5 99.750 Error@1 9.250

==>>[2019-11-23 15:22:53] [Epoch=129/200] [Need: 00:25:56] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [129][000/391]   Time 0.259 (0.259)   Data 0.200 (0.200)   Loss 0.0332 (0.0332)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:22:54]
  Epoch: [129][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0547 (0.0539)   Prec@1 98.438 (98.190)   Prec@5 100.000 (100.000)   [2019-11-23 15:22:59]
  Epoch: [129][200/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.0740 (0.0550)   Prec@1 97.656 (98.095)   Prec@5 100.000 (100.000)   [2019-11-23 15:23:04]
  Epoch: [129][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.0279 (0.0566)   Prec@1 99.219 (98.009)   Prec@5 100.000 (100.000)   [2019-11-23 15:23:08]
  **Train** Prec@1 97.970 Prec@5 100.000 Error@1 2.030
  **Test** Prec@1 90.740 Prec@5 99.710 Error@1 9.260

==>>[2019-11-23 15:23:15] [Epoch=130/200] [Need: 00:25:34] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [130][000/391]   Time 0.266 (0.266)   Data 0.199 (0.199)   Loss 0.0716 (0.0716)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:23:15]
  Epoch: [130][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0789 (0.0545)   Prec@1 97.656 (98.144)   Prec@5 100.000 (99.992)   [2019-11-23 15:23:20]
  Epoch: [130][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.0299 (0.0547)   Prec@1 99.219 (98.142)   Prec@5 100.000 (99.996)   [2019-11-23 15:23:26]
  Epoch: [130][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0451 (0.0550)   Prec@1 98.438 (98.129)   Prec@5 100.000 (99.997)   [2019-11-23 15:23:30]
  **Train** Prec@1 98.118 Prec@5 99.994 Error@1 1.882
  **Test** Prec@1 90.820 Prec@5 99.720 Error@1 9.180

==>>[2019-11-23 15:23:37] [Epoch=131/200] [Need: 00:25:12] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [131][000/391]   Time 0.278 (0.278)   Data 0.191 (0.191)   Loss 0.0532 (0.0532)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:23:37]
  Epoch: [131][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.1180 (0.0554)   Prec@1 96.094 (98.089)   Prec@5 99.219 (99.961)   [2019-11-23 15:23:42]
  Epoch: [131][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0518 (0.0551)   Prec@1 98.438 (98.107)   Prec@5 100.000 (99.981)   [2019-11-23 15:23:47]
  Epoch: [131][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0471 (0.0556)   Prec@1 98.438 (98.123)   Prec@5 100.000 (99.982)   [2019-11-23 15:23:52]
  **Train** Prec@1 98.168 Prec@5 99.984 Error@1 1.832
  **Test** Prec@1 90.620 Prec@5 99.740 Error@1 9.380

==>>[2019-11-23 15:23:59] [Epoch=132/200] [Need: 00:24:50] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [132][000/391]   Time 0.269 (0.269)   Data 0.201 (0.201)   Loss 0.0395 (0.0395)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:23:59]
  Epoch: [132][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0637 (0.0570)   Prec@1 99.219 (98.113)   Prec@5 100.000 (99.977)   [2019-11-23 15:24:04]
  Epoch: [132][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1176 (0.0575)   Prec@1 96.094 (98.076)   Prec@5 100.000 (99.984)   [2019-11-23 15:24:10]
  Epoch: [132][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0346 (0.0556)   Prec@1 99.219 (98.160)   Prec@5 100.000 (99.990)   [2019-11-23 15:24:15]
  **Train** Prec@1 98.158 Prec@5 99.992 Error@1 1.842
  **Test** Prec@1 90.890 Prec@5 99.740 Error@1 9.110

==>>[2019-11-23 15:24:21] [Epoch=133/200] [Need: 00:24:28] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [133][000/391]   Time 0.267 (0.267)   Data 0.200 (0.200)   Loss 0.0299 (0.0299)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:24:21]
  Epoch: [133][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0397 (0.0537)   Prec@1 99.219 (98.159)   Prec@5 100.000 (100.000)   [2019-11-23 15:24:26]
  Epoch: [133][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0310 (0.0546)   Prec@1 98.438 (98.092)   Prec@5 100.000 (99.992)   [2019-11-23 15:24:31]
  Epoch: [133][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0432 (0.0548)   Prec@1 99.219 (98.110)   Prec@5 100.000 (99.995)   [2019-11-23 15:24:36]
  **Train** Prec@1 98.088 Prec@5 99.994 Error@1 1.912
  **Test** Prec@1 90.960 Prec@5 99.790 Error@1 9.040

==>>[2019-11-23 15:24:43] [Epoch=134/200] [Need: 00:24:06] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [134][000/391]   Time 0.284 (0.284)   Data 0.224 (0.224)   Loss 0.0348 (0.0348)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:24:43]
  Epoch: [134][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0552 (0.0545)   Prec@1 98.438 (98.128)   Prec@5 100.000 (99.985)   [2019-11-23 15:24:48]
  Epoch: [134][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0516 (0.0531)   Prec@1 97.656 (98.228)   Prec@5 100.000 (99.988)   [2019-11-23 15:24:53]
  Epoch: [134][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0596 (0.0534)   Prec@1 97.656 (98.209)   Prec@5 100.000 (99.992)   [2019-11-23 15:24:58]
  **Train** Prec@1 98.160 Prec@5 99.986 Error@1 1.840
  **Test** Prec@1 90.850 Prec@5 99.720 Error@1 9.150

==>>[2019-11-23 15:25:05] [Epoch=135/200] [Need: 00:23:44] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [135][000/391]   Time 0.261 (0.261)   Data 0.206 (0.206)   Loss 0.0759 (0.0759)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:25:05]
  Epoch: [135][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0591 (0.0518)   Prec@1 97.656 (98.306)   Prec@5 100.000 (100.000)   [2019-11-23 15:25:10]
  Epoch: [135][200/391]   Time 0.047 (0.048)   Data 0.000 (0.001)   Loss 0.0300 (0.0522)   Prec@1 100.000 (98.286)   Prec@5 100.000 (99.996)   [2019-11-23 15:25:15]
  Epoch: [135][300/391]   Time 0.047 (0.048)   Data 0.000 (0.001)   Loss 0.0303 (0.0530)   Prec@1 99.219 (98.235)   Prec@5 100.000 (99.990)   [2019-11-23 15:25:19]
  **Train** Prec@1 98.212 Prec@5 99.992 Error@1 1.788
  **Test** Prec@1 90.970 Prec@5 99.760 Error@1 9.030

==>>[2019-11-23 15:25:26] [Epoch=136/200] [Need: 00:23:22] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [136][000/391]   Time 0.263 (0.263)   Data 0.193 (0.193)   Loss 0.0552 (0.0552)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:25:26]
  Epoch: [136][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0249 (0.0517)   Prec@1 99.219 (98.291)   Prec@5 100.000 (100.000)   [2019-11-23 15:25:31]
  Epoch: [136][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0452 (0.0510)   Prec@1 98.438 (98.309)   Prec@5 100.000 (99.996)   [2019-11-23 15:25:36]
  Epoch: [136][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0127 (0.0515)   Prec@1 100.000 (98.313)   Prec@5 100.000 (99.995)   [2019-11-23 15:25:41]
  **Train** Prec@1 98.314 Prec@5 99.996 Error@1 1.686
  **Test** Prec@1 90.980 Prec@5 99.750 Error@1 9.020

==>>[2019-11-23 15:25:47] [Epoch=137/200] [Need: 00:23:00] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [137][000/391]   Time 0.270 (0.270)   Data 0.200 (0.200)   Loss 0.0279 (0.0279)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:25:48]
  Epoch: [137][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.0222 (0.0513)   Prec@1 99.219 (98.221)   Prec@5 100.000 (99.977)   [2019-11-23 15:25:53]
  Epoch: [137][200/391]   Time 0.060 (0.054)   Data 0.000 (0.001)   Loss 0.0372 (0.0523)   Prec@1 97.656 (98.259)   Prec@5 100.000 (99.984)   [2019-11-23 15:25:58]
  Epoch: [137][300/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.0274 (0.0531)   Prec@1 100.000 (98.178)   Prec@5 100.000 (99.987)   [2019-11-23 15:26:03]
  **Train** Prec@1 98.178 Prec@5 99.990 Error@1 1.822
  **Test** Prec@1 90.800 Prec@5 99.720 Error@1 9.200

==>>[2019-11-23 15:26:10] [Epoch=138/200] [Need: 00:22:38] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [138][000/391]   Time 0.271 (0.271)   Data 0.203 (0.203)   Loss 0.0484 (0.0484)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:10]
  Epoch: [138][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0367 (0.0524)   Prec@1 98.438 (98.213)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:15]
  Epoch: [138][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0121 (0.0532)   Prec@1 100.000 (98.212)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:21]
  Epoch: [138][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0733 (0.0524)   Prec@1 98.438 (98.209)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:26]
  **Train** Prec@1 98.214 Prec@5 100.000 Error@1 1.786
  **Test** Prec@1 90.750 Prec@5 99.760 Error@1 9.250

==>>[2019-11-23 15:26:32] [Epoch=139/200] [Need: 00:22:16] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [139][000/391]   Time 0.264 (0.264)   Data 0.201 (0.201)   Loss 0.0368 (0.0368)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:32]
  Epoch: [139][100/391]   Time 0.047 (0.051)   Data 0.000 (0.002)   Loss 0.0400 (0.0488)   Prec@1 99.219 (98.484)   Prec@5 100.000 (99.985)   [2019-11-23 15:26:37]
  Epoch: [139][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0365 (0.0524)   Prec@1 98.438 (98.301)   Prec@5 100.000 (99.992)   [2019-11-23 15:26:42]
  Epoch: [139][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.0571 (0.0518)   Prec@1 97.656 (98.305)   Prec@5 100.000 (99.995)   [2019-11-23 15:26:47]
  **Train** Prec@1 98.318 Prec@5 99.996 Error@1 1.682
  **Test** Prec@1 90.830 Prec@5 99.750 Error@1 9.170

==>>[2019-11-23 15:26:53] [Epoch=140/200] [Need: 00:21:54] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [140][000/391]   Time 0.266 (0.266)   Data 0.208 (0.208)   Loss 0.0556 (0.0556)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:54]
  Epoch: [140][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0509 (0.0532)   Prec@1 98.438 (98.136)   Prec@5 100.000 (100.000)   [2019-11-23 15:26:59]
  Epoch: [140][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0349 (0.0513)   Prec@1 98.438 (98.208)   Prec@5 100.000 (100.000)   [2019-11-23 15:27:04]
  Epoch: [140][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0583 (0.0520)   Prec@1 97.656 (98.212)   Prec@5 100.000 (100.000)   [2019-11-23 15:27:09]
  **Train** Prec@1 98.222 Prec@5 100.000 Error@1 1.778
  **Test** Prec@1 90.770 Prec@5 99.740 Error@1 9.230

==>>[2019-11-23 15:27:15] [Epoch=141/200] [Need: 00:21:32] [LR=0.0001][M=0.90] [Best : Accuracy=91.01, Error=8.99]
  Epoch: [141][000/391]   Time 0.246 (0.246)   Data 0.182 (0.182)   Loss 0.0506 (0.0506)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:27:16]
  Epoch: [141][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0513 (0.0523)   Prec@1 98.438 (98.213)   Prec@5 100.000 (99.992)   [2019-11-23 15:27:21]
  Epoch: [141][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0737 (0.0525)   Prec@1 98.438 (98.204)   Prec@5 100.000 (99.992)   [2019-11-23 15:27:26]
  Epoch: [141][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0133 (0.0533)   Prec@1 100.000 (98.165)   Prec@5 100.000 (99.992)   [2019-11-23 15:27:31]
  **Train** Prec@1 98.146 Prec@5 99.990 Error@1 1.854
  **Test** Prec@1 91.120 Prec@5 99.750 Error@1 8.880
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 15:27:37] [Epoch=142/200] [Need: 00:21:10] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [142][000/391]   Time 0.273 (0.273)   Data 0.217 (0.217)   Loss 0.0629 (0.0629)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:27:37]
  Epoch: [142][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.0539 (0.0540)   Prec@1 99.219 (98.113)   Prec@5 100.000 (99.992)   [2019-11-23 15:27:42]
  Epoch: [142][200/391]   Time 0.080 (0.053)   Data 0.000 (0.001)   Loss 0.0480 (0.0518)   Prec@1 98.438 (98.239)   Prec@5 100.000 (99.996)   [2019-11-23 15:27:48]
  Epoch: [142][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0445 (0.0510)   Prec@1 98.438 (98.225)   Prec@5 100.000 (99.997)   [2019-11-23 15:27:53]
  **Train** Prec@1 98.178 Prec@5 99.996 Error@1 1.822
  **Test** Prec@1 90.810 Prec@5 99.730 Error@1 9.190

==>>[2019-11-23 15:27:59] [Epoch=143/200] [Need: 00:20:48] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [143][000/391]   Time 0.278 (0.278)   Data 0.217 (0.217)   Loss 0.0114 (0.0114)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:27:59]
  Epoch: [143][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0730 (0.0510)   Prec@1 96.875 (98.321)   Prec@5 100.000 (99.977)   [2019-11-23 15:28:04]
  Epoch: [143][200/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0406 (0.0512)   Prec@1 98.438 (98.263)   Prec@5 100.000 (99.984)   [2019-11-23 15:28:09]
  Epoch: [143][300/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.0765 (0.0510)   Prec@1 95.312 (98.277)   Prec@5 100.000 (99.987)   [2019-11-23 15:28:14]
  **Train** Prec@1 98.242 Prec@5 99.988 Error@1 1.758
  **Test** Prec@1 90.740 Prec@5 99.720 Error@1 9.260

==>>[2019-11-23 15:28:20] [Epoch=144/200] [Need: 00:20:26] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [144][000/391]   Time 0.262 (0.262)   Data 0.194 (0.194)   Loss 0.0400 (0.0400)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:28:20]
  Epoch: [144][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0298 (0.0483)   Prec@1 98.438 (98.298)   Prec@5 100.000 (99.977)   [2019-11-23 15:28:25]
  Epoch: [144][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0300 (0.0484)   Prec@1 98.438 (98.259)   Prec@5 100.000 (99.988)   [2019-11-23 15:28:30]
  Epoch: [144][300/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.0189 (0.0496)   Prec@1 100.000 (98.258)   Prec@5 100.000 (99.990)   [2019-11-23 15:28:35]
  **Train** Prec@1 98.312 Prec@5 99.992 Error@1 1.688
  **Test** Prec@1 91.040 Prec@5 99.770 Error@1 8.960

==>>[2019-11-23 15:28:42] [Epoch=145/200] [Need: 00:20:04] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [145][000/391]   Time 0.258 (0.258)   Data 0.193 (0.193)   Loss 0.0401 (0.0401)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:28:42]
  Epoch: [145][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0659 (0.0487)   Prec@1 99.219 (98.476)   Prec@5 100.000 (99.969)   [2019-11-23 15:28:47]
  Epoch: [145][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0433 (0.0487)   Prec@1 98.438 (98.406)   Prec@5 100.000 (99.984)   [2019-11-23 15:28:52]
  Epoch: [145][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0270 (0.0504)   Prec@1 99.219 (98.284)   Prec@5 100.000 (99.990)   [2019-11-23 15:28:57]
  **Train** Prec@1 98.208 Prec@5 99.992 Error@1 1.792
  **Test** Prec@1 90.820 Prec@5 99.780 Error@1 9.180

==>>[2019-11-23 15:29:04] [Epoch=146/200] [Need: 00:19:42] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [146][000/391]   Time 0.266 (0.266)   Data 0.207 (0.207)   Loss 0.0254 (0.0254)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:04]
  Epoch: [146][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.0512 (0.0476)   Prec@1 99.219 (98.383)   Prec@5 100.000 (99.992)   [2019-11-23 15:29:09]
  Epoch: [146][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0536 (0.0494)   Prec@1 98.438 (98.333)   Prec@5 100.000 (99.992)   [2019-11-23 15:29:14]
  Epoch: [146][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0560 (0.0502)   Prec@1 97.656 (98.266)   Prec@5 100.000 (99.992)   [2019-11-23 15:29:19]
  **Train** Prec@1 98.262 Prec@5 99.994 Error@1 1.738
  **Test** Prec@1 90.920 Prec@5 99.790 Error@1 9.080

==>>[2019-11-23 15:29:25] [Epoch=147/200] [Need: 00:19:20] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [147][000/391]   Time 0.260 (0.260)   Data 0.200 (0.200)   Loss 0.0907 (0.0907)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:26]
  Epoch: [147][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.0603 (0.0499)   Prec@1 97.656 (98.159)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:30]
  Epoch: [147][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0526 (0.0493)   Prec@1 96.875 (98.251)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:35]
  Epoch: [147][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0819 (0.0488)   Prec@1 96.875 (98.297)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:40]
  **Train** Prec@1 98.372 Prec@5 100.000 Error@1 1.628
  **Test** Prec@1 90.840 Prec@5 99.710 Error@1 9.160

==>>[2019-11-23 15:29:47] [Epoch=148/200] [Need: 00:18:58] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [148][000/391]   Time 0.266 (0.266)   Data 0.194 (0.194)   Loss 0.0380 (0.0380)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:47]
  Epoch: [148][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0754 (0.0464)   Prec@1 97.656 (98.430)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:52]
  Epoch: [148][200/391]   Time 0.037 (0.053)   Data 0.000 (0.001)   Loss 0.0182 (0.0491)   Prec@1 99.219 (98.294)   Prec@5 100.000 (100.000)   [2019-11-23 15:29:57]
  Epoch: [148][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.0878 (0.0496)   Prec@1 96.094 (98.284)   Prec@5 100.000 (99.992)   [2019-11-23 15:30:02]
  **Train** Prec@1 98.336 Prec@5 99.992 Error@1 1.664
  **Test** Prec@1 90.840 Prec@5 99.750 Error@1 9.160

==>>[2019-11-23 15:30:09] [Epoch=149/200] [Need: 00:18:36] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [149][000/391]   Time 0.259 (0.259)   Data 0.203 (0.203)   Loss 0.0573 (0.0573)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:30:09]
  Epoch: [149][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.0549 (0.0539)   Prec@1 99.219 (98.105)   Prec@5 100.000 (99.992)   [2019-11-23 15:30:15]
  Epoch: [149][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0368 (0.0520)   Prec@1 98.438 (98.200)   Prec@5 100.000 (99.992)   [2019-11-23 15:30:20]
  Epoch: [149][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0504 (0.0518)   Prec@1 97.656 (98.238)   Prec@5 100.000 (99.992)   [2019-11-23 15:30:25]
  **Train** Prec@1 98.258 Prec@5 99.994 Error@1 1.742
  **Test** Prec@1 90.950 Prec@5 99.750 Error@1 9.050

==>>[2019-11-23 15:30:31] [Epoch=150/200] [Need: 00:18:15] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [150][000/391]   Time 0.257 (0.257)   Data 0.192 (0.192)   Loss 0.0224 (0.0224)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:30:31]
  Epoch: [150][100/391]   Time 0.051 (0.057)   Data 0.000 (0.002)   Loss 0.0388 (0.0525)   Prec@1 98.438 (98.151)   Prec@5 100.000 (99.985)   [2019-11-23 15:30:37]
  Epoch: [150][200/391]   Time 0.040 (0.053)   Data 0.000 (0.001)   Loss 0.0422 (0.0505)   Prec@1 98.438 (98.243)   Prec@5 100.000 (99.984)   [2019-11-23 15:30:42]
  Epoch: [150][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0431 (0.0512)   Prec@1 98.438 (98.245)   Prec@5 100.000 (99.990)   [2019-11-23 15:30:47]
  **Train** Prec@1 98.242 Prec@5 99.992 Error@1 1.758
  **Test** Prec@1 90.810 Prec@5 99.740 Error@1 9.190

==>>[2019-11-23 15:30:54] [Epoch=151/200] [Need: 00:17:53] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [151][000/391]   Time 0.262 (0.262)   Data 0.204 (0.204)   Loss 0.0701 (0.0701)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:30:54]
  Epoch: [151][100/391]   Time 0.074 (0.057)   Data 0.000 (0.002)   Loss 0.0229 (0.0458)   Prec@1 99.219 (98.608)   Prec@5 100.000 (99.985)   [2019-11-23 15:30:59]
  Epoch: [151][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0129 (0.0453)   Prec@1 100.000 (98.554)   Prec@5 100.000 (99.988)   [2019-11-23 15:31:04]
  Epoch: [151][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0247 (0.0475)   Prec@1 99.219 (98.445)   Prec@5 100.000 (99.982)   [2019-11-23 15:31:09]
  **Train** Prec@1 98.410 Prec@5 99.984 Error@1 1.590
  **Test** Prec@1 90.820 Prec@5 99.790 Error@1 9.180

==>>[2019-11-23 15:31:16] [Epoch=152/200] [Need: 00:17:31] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [152][000/391]   Time 0.261 (0.261)   Data 0.189 (0.189)   Loss 0.0560 (0.0560)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:31:16]
  Epoch: [152][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0492 (0.0466)   Prec@1 99.219 (98.445)   Prec@5 100.000 (99.992)   [2019-11-23 15:31:21]
  Epoch: [152][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0371 (0.0472)   Prec@1 99.219 (98.406)   Prec@5 100.000 (99.996)   [2019-11-23 15:31:26]
  Epoch: [152][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0833 (0.0477)   Prec@1 96.094 (98.375)   Prec@5 100.000 (99.997)   [2019-11-23 15:31:31]
  **Train** Prec@1 98.308 Prec@5 99.998 Error@1 1.692
  **Test** Prec@1 90.820 Prec@5 99.810 Error@1 9.180

==>>[2019-11-23 15:31:37] [Epoch=153/200] [Need: 00:17:09] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [153][000/391]   Time 0.278 (0.278)   Data 0.222 (0.222)   Loss 0.0305 (0.0305)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:31:38]
  Epoch: [153][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0393 (0.0415)   Prec@1 97.656 (98.724)   Prec@5 100.000 (100.000)   [2019-11-23 15:31:43]
  Epoch: [153][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0572 (0.0435)   Prec@1 99.219 (98.593)   Prec@5 100.000 (100.000)   [2019-11-23 15:31:48]
  Epoch: [153][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.0421 (0.0468)   Prec@1 96.875 (98.484)   Prec@5 100.000 (99.997)   [2019-11-23 15:31:52]
  **Train** Prec@1 98.480 Prec@5 99.994 Error@1 1.520
  **Test** Prec@1 90.730 Prec@5 99.740 Error@1 9.270

==>>[2019-11-23 15:31:59] [Epoch=154/200] [Need: 00:16:47] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [154][000/391]   Time 0.279 (0.279)   Data 0.209 (0.209)   Loss 0.0136 (0.0136)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:31:59]
  Epoch: [154][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.0474 (0.0443)   Prec@1 99.219 (98.546)   Prec@5 100.000 (100.000)   [2019-11-23 15:32:04]
  Epoch: [154][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0504 (0.0466)   Prec@1 98.438 (98.375)   Prec@5 100.000 (100.000)   [2019-11-23 15:32:09]
  Epoch: [154][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0862 (0.0483)   Prec@1 96.094 (98.305)   Prec@5 100.000 (99.997)   [2019-11-23 15:32:14]
  **Train** Prec@1 98.348 Prec@5 99.998 Error@1 1.652
  **Test** Prec@1 90.950 Prec@5 99.790 Error@1 9.050

==>>[2019-11-23 15:32:21] [Epoch=155/200] [Need: 00:16:25] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [155][000/391]   Time 0.261 (0.261)   Data 0.205 (0.205)   Loss 0.0310 (0.0310)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:32:21]
  Epoch: [155][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.0716 (0.0468)   Prec@1 97.656 (98.337)   Prec@5 100.000 (99.985)   [2019-11-23 15:32:26]
  Epoch: [155][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.0620 (0.0486)   Prec@1 97.656 (98.336)   Prec@5 100.000 (99.992)   [2019-11-23 15:32:32]
  Epoch: [155][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0572 (0.0483)   Prec@1 96.875 (98.339)   Prec@5 100.000 (99.995)   [2019-11-23 15:32:37]
  **Train** Prec@1 98.320 Prec@5 99.992 Error@1 1.680
  **Test** Prec@1 90.610 Prec@5 99.740 Error@1 9.390

==>>[2019-11-23 15:32:43] [Epoch=156/200] [Need: 00:16:03] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [156][000/391]   Time 0.263 (0.263)   Data 0.196 (0.196)   Loss 0.0413 (0.0413)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:32:44]
  Epoch: [156][100/391]   Time 0.058 (0.052)   Data 0.000 (0.002)   Loss 0.0392 (0.0470)   Prec@1 99.219 (98.298)   Prec@5 100.000 (99.977)   [2019-11-23 15:32:48]
  Epoch: [156][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0216 (0.0458)   Prec@1 99.219 (98.418)   Prec@5 100.000 (99.984)   [2019-11-23 15:32:53]
  Epoch: [156][300/391]   Time 0.057 (0.050)   Data 0.000 (0.001)   Loss 0.0290 (0.0457)   Prec@1 99.219 (98.456)   Prec@5 100.000 (99.987)   [2019-11-23 15:32:58]
  **Train** Prec@1 98.446 Prec@5 99.988 Error@1 1.554
  **Test** Prec@1 90.880 Prec@5 99.740 Error@1 9.120

==>>[2019-11-23 15:33:05] [Epoch=157/200] [Need: 00:15:41] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [157][000/391]   Time 0.269 (0.269)   Data 0.212 (0.212)   Loss 0.0888 (0.0888)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:05]
  Epoch: [157][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.0416 (0.0482)   Prec@1 98.438 (98.298)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:10]
  Epoch: [157][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0593 (0.0488)   Prec@1 97.656 (98.321)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:15]
  Epoch: [157][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0268 (0.0479)   Prec@1 99.219 (98.328)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:20]
  **Train** Prec@1 98.354 Prec@5 100.000 Error@1 1.646
  **Test** Prec@1 90.830 Prec@5 99.770 Error@1 9.170

==>>[2019-11-23 15:33:26] [Epoch=158/200] [Need: 00:15:19] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [158][000/391]   Time 0.261 (0.261)   Data 0.204 (0.204)   Loss 0.0792 (0.0792)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:26]
  Epoch: [158][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.1231 (0.0498)   Prec@1 94.531 (98.229)   Prec@5 100.000 (99.992)   [2019-11-23 15:33:31]
  Epoch: [158][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0445 (0.0475)   Prec@1 98.438 (98.368)   Prec@5 100.000 (99.992)   [2019-11-23 15:33:36]
  Epoch: [158][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0669 (0.0470)   Prec@1 96.875 (98.339)   Prec@5 100.000 (99.995)   [2019-11-23 15:33:41]
  **Train** Prec@1 98.310 Prec@5 99.994 Error@1 1.690
  **Test** Prec@1 90.720 Prec@5 99.740 Error@1 9.280

==>>[2019-11-23 15:33:48] [Epoch=159/200] [Need: 00:14:57] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [159][000/391]   Time 0.277 (0.277)   Data 0.189 (0.189)   Loss 0.0500 (0.0500)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:48]
  Epoch: [159][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0868 (0.0505)   Prec@1 96.875 (98.182)   Prec@5 100.000 (100.000)   [2019-11-23 15:33:53]
  Epoch: [159][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.0449 (0.0497)   Prec@1 97.656 (98.282)   Prec@5 100.000 (99.996)   [2019-11-23 15:33:59]
  Epoch: [159][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0460 (0.0492)   Prec@1 99.219 (98.316)   Prec@5 100.000 (99.992)   [2019-11-23 15:34:03]
  **Train** Prec@1 98.326 Prec@5 99.994 Error@1 1.674
  **Test** Prec@1 90.650 Prec@5 99.770 Error@1 9.350

==>>[2019-11-23 15:34:09] [Epoch=160/200] [Need: 00:14:35] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [160][000/391]   Time 0.277 (0.277)   Data 0.219 (0.219)   Loss 0.0789 (0.0789)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:34:10]
  Epoch: [160][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0369 (0.0460)   Prec@1 99.219 (98.368)   Prec@5 100.000 (100.000)   [2019-11-23 15:34:15]
  Epoch: [160][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.0380 (0.0458)   Prec@1 100.000 (98.403)   Prec@5 100.000 (99.996)   [2019-11-23 15:34:20]
  Epoch: [160][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0243 (0.0453)   Prec@1 99.219 (98.456)   Prec@5 100.000 (99.997)   [2019-11-23 15:34:25]
  **Train** Prec@1 98.414 Prec@5 99.998 Error@1 1.586
  **Test** Prec@1 90.850 Prec@5 99.720 Error@1 9.150

==>>[2019-11-23 15:34:32] [Epoch=161/200] [Need: 00:14:14] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [161][000/391]   Time 0.273 (0.273)   Data 0.207 (0.207)   Loss 0.0439 (0.0439)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:34:32]
  Epoch: [161][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.0295 (0.0445)   Prec@1 99.219 (98.414)   Prec@5 100.000 (99.992)   [2019-11-23 15:34:37]
  Epoch: [161][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0160 (0.0449)   Prec@1 100.000 (98.430)   Prec@5 100.000 (99.992)   [2019-11-23 15:34:42]
  Epoch: [161][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0476 (0.0445)   Prec@1 99.219 (98.453)   Prec@5 100.000 (99.995)   [2019-11-23 15:34:47]
  **Train** Prec@1 98.460 Prec@5 99.992 Error@1 1.540
  **Test** Prec@1 91.110 Prec@5 99.780 Error@1 8.890

==>>[2019-11-23 15:34:53] [Epoch=162/200] [Need: 00:13:52] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [162][000/391]   Time 0.260 (0.260)   Data 0.205 (0.205)   Loss 0.0315 (0.0315)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:34:54]
  Epoch: [162][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.0473 (0.0438)   Prec@1 98.438 (98.554)   Prec@5 100.000 (100.000)   [2019-11-23 15:34:59]
  Epoch: [162][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0551 (0.0427)   Prec@1 97.656 (98.601)   Prec@5 100.000 (99.996)   [2019-11-23 15:35:04]
  Epoch: [162][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0587 (0.0445)   Prec@1 97.656 (98.482)   Prec@5 100.000 (99.997)   [2019-11-23 15:35:09]
  **Train** Prec@1 98.472 Prec@5 99.998 Error@1 1.528
  **Test** Prec@1 90.820 Prec@5 99.710 Error@1 9.180

==>>[2019-11-23 15:35:15] [Epoch=163/200] [Need: 00:13:30] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [163][000/391]   Time 0.262 (0.262)   Data 0.203 (0.203)   Loss 0.0262 (0.0262)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:15]
  Epoch: [163][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.0249 (0.0454)   Prec@1 99.219 (98.476)   Prec@5 100.000 (99.992)   [2019-11-23 15:35:20]
  Epoch: [163][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.1059 (0.0466)   Prec@1 96.875 (98.383)   Prec@5 100.000 (99.992)   [2019-11-23 15:35:25]
  Epoch: [163][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0566 (0.0460)   Prec@1 96.875 (98.404)   Prec@5 100.000 (99.992)   [2019-11-23 15:35:30]
  **Train** Prec@1 98.428 Prec@5 99.994 Error@1 1.572
  **Test** Prec@1 90.870 Prec@5 99.750 Error@1 9.130

==>>[2019-11-23 15:35:36] [Epoch=164/200] [Need: 00:13:08] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [164][000/391]   Time 0.269 (0.269)   Data 0.200 (0.200)   Loss 0.0315 (0.0315)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:36]
  Epoch: [164][100/391]   Time 0.080 (0.053)   Data 0.000 (0.002)   Loss 0.0364 (0.0454)   Prec@1 97.656 (98.453)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:41]
  Epoch: [164][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0260 (0.0444)   Prec@1 99.219 (98.496)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:47]
  Epoch: [164][300/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.0753 (0.0439)   Prec@1 98.438 (98.526)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:52]
  **Train** Prec@1 98.530 Prec@5 100.000 Error@1 1.470
  **Test** Prec@1 90.910 Prec@5 99.720 Error@1 9.090

==>>[2019-11-23 15:35:58] [Epoch=165/200] [Need: 00:12:46] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [165][000/391]   Time 0.261 (0.261)   Data 0.190 (0.190)   Loss 0.0549 (0.0549)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:35:59]
  Epoch: [165][100/391]   Time 0.041 (0.055)   Data 0.000 (0.002)   Loss 0.0448 (0.0424)   Prec@1 99.219 (98.646)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:04]
  Epoch: [165][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0483 (0.0434)   Prec@1 99.219 (98.531)   Prec@5 100.000 (99.996)   [2019-11-23 15:36:09]
  Epoch: [165][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0142 (0.0442)   Prec@1 100.000 (98.474)   Prec@5 100.000 (99.997)   [2019-11-23 15:36:14]
  **Train** Prec@1 98.442 Prec@5 99.994 Error@1 1.558
  **Test** Prec@1 91.100 Prec@5 99.760 Error@1 8.900

==>>[2019-11-23 15:36:20] [Epoch=166/200] [Need: 00:12:24] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [166][000/391]   Time 0.256 (0.256)   Data 0.207 (0.207)   Loss 0.0176 (0.0176)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:20]
  Epoch: [166][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0291 (0.0438)   Prec@1 99.219 (98.492)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:25]
  Epoch: [166][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0381 (0.0442)   Prec@1 98.438 (98.492)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:30]
  Epoch: [166][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0223 (0.0453)   Prec@1 99.219 (98.479)   Prec@5 100.000 (99.995)   [2019-11-23 15:36:35]
  **Train** Prec@1 98.502 Prec@5 99.996 Error@1 1.498
  **Test** Prec@1 90.980 Prec@5 99.740 Error@1 9.020

==>>[2019-11-23 15:36:41] [Epoch=167/200] [Need: 00:12:02] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [167][000/391]   Time 0.256 (0.256)   Data 0.200 (0.200)   Loss 0.0368 (0.0368)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:42]
  Epoch: [167][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.0390 (0.0465)   Prec@1 97.656 (98.337)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:47]
  Epoch: [167][200/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.0547 (0.0441)   Prec@1 96.875 (98.461)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:52]
  Epoch: [167][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0756 (0.0447)   Prec@1 97.656 (98.456)   Prec@5 100.000 (100.000)   [2019-11-23 15:36:57]
  **Train** Prec@1 98.450 Prec@5 100.000 Error@1 1.550
  **Test** Prec@1 90.930 Prec@5 99.730 Error@1 9.070

==>>[2019-11-23 15:37:03] [Epoch=168/200] [Need: 00:11:40] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [168][000/391]   Time 0.263 (0.263)   Data 0.203 (0.203)   Loss 0.0319 (0.0319)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:03]
  Epoch: [168][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0316 (0.0389)   Prec@1 99.219 (98.670)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:08]
  Epoch: [168][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0206 (0.0412)   Prec@1 100.000 (98.507)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:13]
  Epoch: [168][300/391]   Time 0.065 (0.050)   Data 0.000 (0.001)   Loss 0.0734 (0.0422)   Prec@1 96.875 (98.500)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:18]
  **Train** Prec@1 98.476 Prec@5 100.000 Error@1 1.524
  **Test** Prec@1 91.040 Prec@5 99.740 Error@1 8.960

==>>[2019-11-23 15:37:25] [Epoch=169/200] [Need: 00:11:18] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [169][000/391]   Time 0.260 (0.260)   Data 0.205 (0.205)   Loss 0.1168 (0.1168)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:25]
  Epoch: [169][100/391]   Time 0.054 (0.050)   Data 0.000 (0.002)   Loss 0.0116 (0.0453)   Prec@1 100.000 (98.492)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:30]
  Epoch: [169][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0410 (0.0461)   Prec@1 97.656 (98.441)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:35]
  Epoch: [169][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0412 (0.0470)   Prec@1 97.656 (98.409)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:40]
  **Train** Prec@1 98.432 Prec@5 100.000 Error@1 1.568
  **Test** Prec@1 90.910 Prec@5 99.690 Error@1 9.090

==>>[2019-11-23 15:37:46] [Epoch=170/200] [Need: 00:10:56] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [170][000/391]   Time 0.278 (0.278)   Data 0.212 (0.212)   Loss 0.0931 (0.0931)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:37:46]
  Epoch: [170][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0317 (0.0387)   Prec@1 98.438 (98.778)   Prec@5 100.000 (99.992)   [2019-11-23 15:37:51]
  Epoch: [170][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0452 (0.0407)   Prec@1 98.438 (98.678)   Prec@5 100.000 (99.992)   [2019-11-23 15:37:56]
  Epoch: [170][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0077 (0.0425)   Prec@1 100.000 (98.562)   Prec@5 100.000 (99.995)   [2019-11-23 15:38:01]
  **Train** Prec@1 98.536 Prec@5 99.994 Error@1 1.464
  **Test** Prec@1 90.780 Prec@5 99.740 Error@1 9.220

==>>[2019-11-23 15:38:07] [Epoch=171/200] [Need: 00:10:34] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [171][000/391]   Time 0.275 (0.275)   Data 0.192 (0.192)   Loss 0.0346 (0.0346)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:38:07]
  Epoch: [171][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0534 (0.0461)   Prec@1 96.875 (98.337)   Prec@5 100.000 (99.992)   [2019-11-23 15:38:13]
  Epoch: [171][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0537 (0.0461)   Prec@1 97.656 (98.387)   Prec@5 100.000 (99.996)   [2019-11-23 15:38:17]
  Epoch: [171][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0287 (0.0444)   Prec@1 100.000 (98.492)   Prec@5 100.000 (99.997)   [2019-11-23 15:38:22]
  **Train** Prec@1 98.484 Prec@5 99.998 Error@1 1.516
  **Test** Prec@1 90.720 Prec@5 99.830 Error@1 9.280

==>>[2019-11-23 15:38:29] [Epoch=172/200] [Need: 00:10:12] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [172][000/391]   Time 0.278 (0.278)   Data 0.217 (0.217)   Loss 0.0204 (0.0204)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:38:29]
  Epoch: [172][100/391]   Time 0.055 (0.052)   Data 0.001 (0.002)   Loss 0.0435 (0.0442)   Prec@1 97.656 (98.530)   Prec@5 100.000 (99.985)   [2019-11-23 15:38:34]
  Epoch: [172][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0617 (0.0458)   Prec@1 97.656 (98.476)   Prec@5 100.000 (99.988)   [2019-11-23 15:38:39]
  Epoch: [172][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0311 (0.0441)   Prec@1 99.219 (98.539)   Prec@5 100.000 (99.990)   [2019-11-23 15:38:44]
  **Train** Prec@1 98.526 Prec@5 99.990 Error@1 1.474
  **Test** Prec@1 90.910 Prec@5 99.760 Error@1 9.090

==>>[2019-11-23 15:38:51] [Epoch=173/200] [Need: 00:09:50] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [173][000/391]   Time 0.260 (0.260)   Data 0.203 (0.203)   Loss 0.0302 (0.0302)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:38:51]
  Epoch: [173][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0129 (0.0403)   Prec@1 100.000 (98.592)   Prec@5 100.000 (100.000)   [2019-11-23 15:38:57]
  Epoch: [173][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0739 (0.0429)   Prec@1 98.438 (98.531)   Prec@5 100.000 (99.996)   [2019-11-23 15:39:01]
  Epoch: [173][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0421 (0.0436)   Prec@1 98.438 (98.531)   Prec@5 100.000 (99.995)   [2019-11-23 15:39:06]
  **Train** Prec@1 98.488 Prec@5 99.996 Error@1 1.512
  **Test** Prec@1 90.920 Prec@5 99.760 Error@1 9.080

==>>[2019-11-23 15:39:13] [Epoch=174/200] [Need: 00:09:28] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [174][000/391]   Time 0.272 (0.272)   Data 0.195 (0.195)   Loss 0.0414 (0.0414)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:39:13]
  Epoch: [174][100/391]   Time 0.058 (0.054)   Data 0.000 (0.002)   Loss 0.0217 (0.0396)   Prec@1 100.000 (98.793)   Prec@5 100.000 (99.992)   [2019-11-23 15:39:18]
  Epoch: [174][200/391]   Time 0.044 (0.055)   Data 0.000 (0.001)   Loss 0.0839 (0.0406)   Prec@1 96.875 (98.702)   Prec@5 100.000 (99.996)   [2019-11-23 15:39:24]
  Epoch: [174][300/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.0200 (0.0414)   Prec@1 99.219 (98.637)   Prec@5 100.000 (99.995)   [2019-11-23 15:39:29]
  **Train** Prec@1 98.592 Prec@5 99.996 Error@1 1.408
  **Test** Prec@1 90.710 Prec@5 99.770 Error@1 9.290

==>>[2019-11-23 15:39:36] [Epoch=175/200] [Need: 00:09:07] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [175][000/391]   Time 0.275 (0.275)   Data 0.197 (0.197)   Loss 0.0404 (0.0404)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:39:36]
  Epoch: [175][100/391]   Time 0.040 (0.054)   Data 0.000 (0.002)   Loss 0.0352 (0.0396)   Prec@1 99.219 (98.747)   Prec@5 100.000 (99.977)   [2019-11-23 15:39:41]
  Epoch: [175][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0255 (0.0438)   Prec@1 100.000 (98.581)   Prec@5 100.000 (99.988)   [2019-11-23 15:39:46]
  Epoch: [175][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0407 (0.0431)   Prec@1 99.219 (98.591)   Prec@5 100.000 (99.992)   [2019-11-23 15:39:51]
  **Train** Prec@1 98.562 Prec@5 99.994 Error@1 1.438
  **Test** Prec@1 90.850 Prec@5 99.750 Error@1 9.150

==>>[2019-11-23 15:39:58] [Epoch=176/200] [Need: 00:08:45] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [176][000/391]   Time 0.273 (0.273)   Data 0.216 (0.216)   Loss 0.0501 (0.0501)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:39:58]
  Epoch: [176][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0376 (0.0445)   Prec@1 99.219 (98.561)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:03]
  Epoch: [176][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0366 (0.0447)   Prec@1 98.438 (98.445)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:08]
  Epoch: [176][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0548 (0.0445)   Prec@1 97.656 (98.500)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:13]
  **Train** Prec@1 98.518 Prec@5 100.000 Error@1 1.482
  **Test** Prec@1 90.750 Prec@5 99.740 Error@1 9.250

==>>[2019-11-23 15:40:20] [Epoch=177/200] [Need: 00:08:23] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [177][000/391]   Time 0.265 (0.265)   Data 0.202 (0.202)   Loss 0.0201 (0.0201)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:20]
  Epoch: [177][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0237 (0.0448)   Prec@1 99.219 (98.430)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:25]
  Epoch: [177][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0650 (0.0436)   Prec@1 97.656 (98.562)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:30]
  Epoch: [177][300/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0400 (0.0438)   Prec@1 99.219 (98.531)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:35]
  **Train** Prec@1 98.530 Prec@5 100.000 Error@1 1.470
  **Test** Prec@1 90.730 Prec@5 99.790 Error@1 9.270

==>>[2019-11-23 15:40:41] [Epoch=178/200] [Need: 00:08:01] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [178][000/391]   Time 0.257 (0.257)   Data 0.188 (0.188)   Loss 0.0453 (0.0453)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:42]
  Epoch: [178][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.0654 (0.0435)   Prec@1 96.875 (98.693)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:47]
  Epoch: [178][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0381 (0.0417)   Prec@1 98.438 (98.671)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:52]
  Epoch: [178][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0238 (0.0429)   Prec@1 100.000 (98.596)   Prec@5 100.000 (100.000)   [2019-11-23 15:40:57]
  **Train** Prec@1 98.562 Prec@5 99.992 Error@1 1.438
  **Test** Prec@1 90.890 Prec@5 99.790 Error@1 9.110

==>>[2019-11-23 15:41:03] [Epoch=179/200] [Need: 00:07:39] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [179][000/391]   Time 0.273 (0.273)   Data 0.203 (0.203)   Loss 0.0527 (0.0527)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:41:03]
  Epoch: [179][100/391]   Time 0.041 (0.055)   Data 0.000 (0.002)   Loss 0.0160 (0.0442)   Prec@1 100.000 (98.476)   Prec@5 100.000 (100.000)   [2019-11-23 15:41:08]
  Epoch: [179][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0310 (0.0415)   Prec@1 99.219 (98.632)   Prec@5 100.000 (99.988)   [2019-11-23 15:41:13]
  Epoch: [179][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0722 (0.0429)   Prec@1 96.875 (98.549)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:18]
  **Train** Prec@1 98.572 Prec@5 99.994 Error@1 1.428
  **Test** Prec@1 90.860 Prec@5 99.760 Error@1 9.140

==>>[2019-11-23 15:41:25] [Epoch=180/200] [Need: 00:07:17] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [180][000/391]   Time 0.275 (0.275)   Data 0.206 (0.206)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:41:25]
  Epoch: [180][100/391]   Time 0.081 (0.052)   Data 0.000 (0.002)   Loss 0.0285 (0.0395)   Prec@1 98.438 (98.639)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:30]
  Epoch: [180][200/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.0392 (0.0410)   Prec@1 98.438 (98.605)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:35]
  Epoch: [180][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0597 (0.0420)   Prec@1 98.438 (98.554)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:40]
  **Train** Prec@1 98.562 Prec@5 99.994 Error@1 1.438
  **Test** Prec@1 90.890 Prec@5 99.770 Error@1 9.110

==>>[2019-11-23 15:41:46] [Epoch=181/200] [Need: 00:06:55] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [181][000/391]   Time 0.268 (0.268)   Data 0.205 (0.205)   Loss 0.0601 (0.0601)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:41:46]
  Epoch: [181][100/391]   Time 0.077 (0.054)   Data 0.000 (0.002)   Loss 0.0520 (0.0408)   Prec@1 98.438 (98.631)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:52]
  Epoch: [181][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0252 (0.0397)   Prec@1 99.219 (98.690)   Prec@5 100.000 (99.992)   [2019-11-23 15:41:57]
  Epoch: [181][300/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.0190 (0.0412)   Prec@1 100.000 (98.624)   Prec@5 100.000 (99.992)   [2019-11-23 15:42:02]
  **Train** Prec@1 98.614 Prec@5 99.992 Error@1 1.386
  **Test** Prec@1 90.770 Prec@5 99.750 Error@1 9.230

==>>[2019-11-23 15:42:08] [Epoch=182/200] [Need: 00:06:33] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [182][000/391]   Time 0.250 (0.250)   Data 0.183 (0.183)   Loss 0.0704 (0.0704)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:42:08]
  Epoch: [182][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.0184 (0.0438)   Prec@1 100.000 (98.476)   Prec@5 100.000 (99.992)   [2019-11-23 15:42:13]
  Epoch: [182][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0206 (0.0439)   Prec@1 98.438 (98.488)   Prec@5 100.000 (99.996)   [2019-11-23 15:42:18]
  Epoch: [182][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0638 (0.0452)   Prec@1 98.438 (98.463)   Prec@5 99.219 (99.992)   [2019-11-23 15:42:23]
  **Train** Prec@1 98.446 Prec@5 99.994 Error@1 1.554
  **Test** Prec@1 90.930 Prec@5 99.750 Error@1 9.070

==>>[2019-11-23 15:42:30] [Epoch=183/200] [Need: 00:06:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [183][000/391]   Time 0.266 (0.266)   Data 0.197 (0.197)   Loss 0.0440 (0.0440)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:42:30]
  Epoch: [183][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.0445 (0.0410)   Prec@1 98.438 (98.600)   Prec@5 100.000 (100.000)   [2019-11-23 15:42:35]
  Epoch: [183][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0284 (0.0439)   Prec@1 99.219 (98.469)   Prec@5 100.000 (99.996)   [2019-11-23 15:42:40]
  Epoch: [183][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0272 (0.0432)   Prec@1 98.438 (98.492)   Prec@5 100.000 (99.997)   [2019-11-23 15:42:45]
  **Train** Prec@1 98.536 Prec@5 99.994 Error@1 1.464
  **Test** Prec@1 90.720 Prec@5 99.700 Error@1 9.280

==>>[2019-11-23 15:42:51] [Epoch=184/200] [Need: 00:05:50] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [184][000/391]   Time 0.269 (0.269)   Data 0.209 (0.209)   Loss 0.0448 (0.0448)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:42:51]
  Epoch: [184][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0540 (0.0401)   Prec@1 98.438 (98.623)   Prec@5 100.000 (100.000)   [2019-11-23 15:42:56]
  Epoch: [184][200/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0166 (0.0407)   Prec@1 100.000 (98.628)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:01]
  Epoch: [184][300/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0393 (0.0430)   Prec@1 99.219 (98.534)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:06]
  **Train** Prec@1 98.540 Prec@5 99.998 Error@1 1.460
  **Test** Prec@1 91.100 Prec@5 99.780 Error@1 8.900

==>>[2019-11-23 15:43:12] [Epoch=185/200] [Need: 00:05:28] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [185][000/391]   Time 0.266 (0.266)   Data 0.192 (0.192)   Loss 0.0524 (0.0524)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:13]
  Epoch: [185][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0238 (0.0397)   Prec@1 99.219 (98.716)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:18]
  Epoch: [185][200/391]   Time 0.071 (0.053)   Data 0.000 (0.001)   Loss 0.0471 (0.0421)   Prec@1 97.656 (98.612)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:23]
  Epoch: [185][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0690 (0.0425)   Prec@1 96.875 (98.611)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:28]
  **Train** Prec@1 98.610 Prec@5 99.998 Error@1 1.390
  **Test** Prec@1 90.740 Prec@5 99.750 Error@1 9.260

==>>[2019-11-23 15:43:34] [Epoch=186/200] [Need: 00:05:06] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [186][000/391]   Time 0.261 (0.261)   Data 0.203 (0.203)   Loss 0.0518 (0.0518)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:35]
  Epoch: [186][100/391]   Time 0.051 (0.054)   Data 0.000 (0.002)   Loss 0.0473 (0.0404)   Prec@1 97.656 (98.615)   Prec@5 100.000 (99.992)   [2019-11-23 15:43:40]
  Epoch: [186][200/391]   Time 0.080 (0.053)   Data 0.000 (0.001)   Loss 0.0139 (0.0427)   Prec@1 100.000 (98.605)   Prec@5 100.000 (99.992)   [2019-11-23 15:43:45]
  Epoch: [186][300/391]   Time 0.069 (0.053)   Data 0.000 (0.001)   Loss 0.0524 (0.0417)   Prec@1 98.438 (98.624)   Prec@5 100.000 (99.995)   [2019-11-23 15:43:50]
  **Train** Prec@1 98.614 Prec@5 99.994 Error@1 1.386
  **Test** Prec@1 90.980 Prec@5 99.750 Error@1 9.020

==>>[2019-11-23 15:43:57] [Epoch=187/200] [Need: 00:04:44] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [187][000/391]   Time 0.253 (0.253)   Data 0.187 (0.187)   Loss 0.0442 (0.0442)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:43:57]
  Epoch: [187][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.0591 (0.0401)   Prec@1 99.219 (98.615)   Prec@5 100.000 (100.000)   [2019-11-23 15:44:02]
  Epoch: [187][200/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.0241 (0.0405)   Prec@1 99.219 (98.601)   Prec@5 100.000 (100.000)   [2019-11-23 15:44:07]
  Epoch: [187][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0453 (0.0411)   Prec@1 98.438 (98.575)   Prec@5 100.000 (100.000)   [2019-11-23 15:44:12]
  **Train** Prec@1 98.600 Prec@5 99.998 Error@1 1.400
  **Test** Prec@1 90.840 Prec@5 99.740 Error@1 9.160

==>>[2019-11-23 15:44:18] [Epoch=188/200] [Need: 00:04:22] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [188][000/391]   Time 0.254 (0.254)   Data 0.182 (0.182)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:44:18]
  Epoch: [188][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0171 (0.0411)   Prec@1 99.219 (98.662)   Prec@5 100.000 (99.992)   [2019-11-23 15:44:23]
  Epoch: [188][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0235 (0.0433)   Prec@1 100.000 (98.496)   Prec@5 100.000 (99.992)   [2019-11-23 15:44:29]
  Epoch: [188][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0270 (0.0422)   Prec@1 99.219 (98.580)   Prec@5 100.000 (99.992)   [2019-11-23 15:44:34]
  **Train** Prec@1 98.554 Prec@5 99.994 Error@1 1.446
  **Test** Prec@1 91.090 Prec@5 99.760 Error@1 8.910

==>>[2019-11-23 15:44:40] [Epoch=189/200] [Need: 00:04:00] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [189][000/391]   Time 0.262 (0.262)   Data 0.203 (0.203)   Loss 0.0215 (0.0215)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:44:41]
  Epoch: [189][100/391]   Time 0.080 (0.055)   Data 0.000 (0.002)   Loss 0.0517 (0.0440)   Prec@1 98.438 (98.492)   Prec@5 100.000 (99.992)   [2019-11-23 15:44:46]
  Epoch: [189][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0449 (0.0461)   Prec@1 98.438 (98.371)   Prec@5 100.000 (99.996)   [2019-11-23 15:44:51]
  Epoch: [189][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0494 (0.0442)   Prec@1 98.438 (98.461)   Prec@5 100.000 (99.997)   [2019-11-23 15:44:55]
  **Train** Prec@1 98.472 Prec@5 99.996 Error@1 1.528
  **Test** Prec@1 90.800 Prec@5 99.760 Error@1 9.200

==>>[2019-11-23 15:45:02] [Epoch=190/200] [Need: 00:03:38] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [190][000/391]   Time 0.272 (0.272)   Data 0.208 (0.208)   Loss 0.0388 (0.0388)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:02]
  Epoch: [190][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.0466 (0.0414)   Prec@1 98.438 (98.677)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:08]
  Epoch: [190][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.0361 (0.0404)   Prec@1 99.219 (98.682)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:13]
  Epoch: [190][300/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.0591 (0.0398)   Prec@1 97.656 (98.713)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:18]
  **Train** Prec@1 98.692 Prec@5 100.000 Error@1 1.308
  **Test** Prec@1 90.870 Prec@5 99.770 Error@1 9.130

==>>[2019-11-23 15:45:24] [Epoch=191/200] [Need: 00:03:16] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [191][000/391]   Time 0.262 (0.262)   Data 0.192 (0.192)   Loss 0.0297 (0.0297)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:25]
  Epoch: [191][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0535 (0.0401)   Prec@1 98.438 (98.716)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:30]
  Epoch: [191][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0398 (0.0383)   Prec@1 98.438 (98.787)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:34]
  Epoch: [191][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0224 (0.0397)   Prec@1 99.219 (98.713)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:39]
  **Train** Prec@1 98.668 Prec@5 100.000 Error@1 1.332
  **Test** Prec@1 90.830 Prec@5 99.770 Error@1 9.170

==>>[2019-11-23 15:45:46] [Epoch=192/200] [Need: 00:02:54] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [192][000/391]   Time 0.269 (0.269)   Data 0.213 (0.213)   Loss 0.0573 (0.0573)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:46]
  Epoch: [192][100/391]   Time 0.054 (0.057)   Data 0.000 (0.002)   Loss 0.0414 (0.0434)   Prec@1 98.438 (98.461)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:51]
  Epoch: [192][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.0470 (0.0435)   Prec@1 98.438 (98.480)   Prec@5 100.000 (100.000)   [2019-11-23 15:45:56]
  Epoch: [192][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0417 (0.0435)   Prec@1 99.219 (98.521)   Prec@5 100.000 (99.997)   [2019-11-23 15:46:01]
  **Train** Prec@1 98.558 Prec@5 99.994 Error@1 1.442
  **Test** Prec@1 90.770 Prec@5 99.760 Error@1 9.230

==>>[2019-11-23 15:46:08] [Epoch=193/200] [Need: 00:02:33] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [193][000/391]   Time 0.272 (0.272)   Data 0.202 (0.202)   Loss 0.0480 (0.0480)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:46:08]
  Epoch: [193][100/391]   Time 0.050 (0.056)   Data 0.000 (0.002)   Loss 0.0804 (0.0434)   Prec@1 97.656 (98.468)   Prec@5 100.000 (99.992)   [2019-11-23 15:46:13]
  Epoch: [193][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0762 (0.0424)   Prec@1 96.875 (98.507)   Prec@5 100.000 (99.996)   [2019-11-23 15:46:18]
  Epoch: [193][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0724 (0.0422)   Prec@1 96.875 (98.541)   Prec@5 100.000 (99.997)   [2019-11-23 15:46:23]
  **Train** Prec@1 98.514 Prec@5 99.998 Error@1 1.486
  **Test** Prec@1 90.710 Prec@5 99.740 Error@1 9.290

==>>[2019-11-23 15:46:29] [Epoch=194/200] [Need: 00:02:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [194][000/391]   Time 0.268 (0.268)   Data 0.208 (0.208)   Loss 0.0158 (0.0158)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:46:29]
  Epoch: [194][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0503 (0.0412)   Prec@1 98.438 (98.654)   Prec@5 100.000 (99.992)   [2019-11-23 15:46:34]
  Epoch: [194][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0494 (0.0419)   Prec@1 99.219 (98.624)   Prec@5 100.000 (99.996)   [2019-11-23 15:46:40]
  Epoch: [194][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0279 (0.0424)   Prec@1 99.219 (98.583)   Prec@5 100.000 (99.995)   [2019-11-23 15:46:45]
  **Train** Prec@1 98.594 Prec@5 99.994 Error@1 1.406
  **Test** Prec@1 90.770 Prec@5 99.760 Error@1 9.230

==>>[2019-11-23 15:46:52] [Epoch=195/200] [Need: 00:01:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [195][000/391]   Time 0.273 (0.273)   Data 0.196 (0.196)   Loss 0.0537 (0.0537)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:46:52]
  Epoch: [195][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0575 (0.0427)   Prec@1 98.438 (98.430)   Prec@5 100.000 (100.000)   [2019-11-23 15:46:57]
  Epoch: [195][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0638 (0.0418)   Prec@1 97.656 (98.496)   Prec@5 100.000 (100.000)   [2019-11-23 15:47:02]
  Epoch: [195][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0606 (0.0416)   Prec@1 97.656 (98.531)   Prec@5 100.000 (99.995)   [2019-11-23 15:47:07]
  **Train** Prec@1 98.520 Prec@5 99.996 Error@1 1.480
  **Test** Prec@1 90.690 Prec@5 99.770 Error@1 9.310

==>>[2019-11-23 15:47:13] [Epoch=196/200] [Need: 00:01:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [196][000/391]   Time 0.247 (0.247)   Data 0.204 (0.204)   Loss 0.0655 (0.0655)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:47:14]
  Epoch: [196][100/391]   Time 0.041 (0.054)   Data 0.000 (0.002)   Loss 0.0493 (0.0422)   Prec@1 98.438 (98.523)   Prec@5 100.000 (100.000)   [2019-11-23 15:47:19]
  Epoch: [196][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0560 (0.0421)   Prec@1 97.656 (98.562)   Prec@5 100.000 (99.996)   [2019-11-23 15:47:24]
  Epoch: [196][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0474 (0.0433)   Prec@1 97.656 (98.495)   Prec@5 100.000 (99.997)   [2019-11-23 15:47:28]
  **Train** Prec@1 98.508 Prec@5 99.998 Error@1 1.492
  **Test** Prec@1 91.060 Prec@5 99.780 Error@1 8.940

==>>[2019-11-23 15:47:35] [Epoch=197/200] [Need: 00:01:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [197][000/391]   Time 0.264 (0.264)   Data 0.192 (0.192)   Loss 0.0497 (0.0497)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 15:47:35]
  Epoch: [197][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0293 (0.0420)   Prec@1 99.219 (98.538)   Prec@5 100.000 (99.985)   [2019-11-23 15:47:40]
  Epoch: [197][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0377 (0.0409)   Prec@1 97.656 (98.605)   Prec@5 100.000 (99.984)   [2019-11-23 15:47:45]
  Epoch: [197][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0182 (0.0415)   Prec@1 99.219 (98.570)   Prec@5 100.000 (99.987)   [2019-11-23 15:47:50]
  **Train** Prec@1 98.532 Prec@5 99.990 Error@1 1.468
  **Test** Prec@1 90.870 Prec@5 99.770 Error@1 9.130

==>>[2019-11-23 15:47:56] [Epoch=198/200] [Need: 00:00:43] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [198][000/391]   Time 0.260 (0.260)   Data 0.190 (0.190)   Loss 0.0243 (0.0243)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 15:47:57]
  Epoch: [198][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0978 (0.0385)   Prec@1 98.438 (98.894)   Prec@5 100.000 (100.000)   [2019-11-23 15:48:02]
  Epoch: [198][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0225 (0.0400)   Prec@1 98.438 (98.752)   Prec@5 100.000 (100.000)   [2019-11-23 15:48:07]
  Epoch: [198][300/391]   Time 0.082 (0.050)   Data 0.000 (0.001)   Loss 0.0303 (0.0415)   Prec@1 99.219 (98.669)   Prec@5 100.000 (99.997)   [2019-11-23 15:48:11]
  **Train** Prec@1 98.620 Prec@5 99.994 Error@1 1.380
  **Test** Prec@1 90.590 Prec@5 99.740 Error@1 9.410

==>>[2019-11-23 15:48:18] [Epoch=199/200] [Need: 00:00:21] [LR=0.0001][M=0.90] [Best : Accuracy=91.12, Error=8.88]
  Epoch: [199][000/391]   Time 0.267 (0.267)   Data 0.189 (0.189)   Loss 0.0781 (0.0781)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 15:48:18]
  Epoch: [199][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.0085 (0.0383)   Prec@1 100.000 (98.801)   Prec@5 100.000 (99.992)   [2019-11-23 15:48:24]
  Epoch: [199][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0351 (0.0396)   Prec@1 99.219 (98.748)   Prec@5 100.000 (99.992)   [2019-11-23 15:48:29]
  Epoch: [199][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0498 (0.0398)   Prec@1 98.438 (98.728)   Prec@5 100.000 (99.992)   [2019-11-23 15:48:33]
  **Train** Prec@1 98.688 Prec@5 99.994 Error@1 1.312
  **Test** Prec@1 90.880 Prec@5 99.770 Error@1 9.120
