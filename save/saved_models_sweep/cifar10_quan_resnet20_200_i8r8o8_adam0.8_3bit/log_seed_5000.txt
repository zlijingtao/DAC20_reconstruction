save path : ./save/2019-11-17/cifar10_quan_resnet20_200_i8r8o8_adam0.8clip
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 8], 'input_num_bits': 3, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.8, 'output_grain_size': [1, 8], 'output_num_bits': 3, 'print_freq': 100, 'res_M2D': 0.8, 'res_grain_size': [1, 8], 'res_num_bits': 3, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-17/cifar10_quan_resnet20_200_i8r8o8_adam0.8clip', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-18 05:24:52] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.649 (1.649)   Data 0.161 (0.161)   Loss 4.3827 (4.3827)   Prec@1 13.281 (13.281)   Prec@5 49.219 (49.219)   [2019-11-18 05:24:53]
  Epoch: [000][100/391]   Time 0.047 (0.058)   Data 0.000 (0.002)   Loss 1.7622 (2.0232)   Prec@1 37.500 (25.619)   Prec@5 83.594 (78.829)   [2019-11-18 05:24:58]
  Epoch: [000][200/391]   Time 0.037 (0.050)   Data 0.000 (0.001)   Loss 1.6243 (1.8431)   Prec@1 35.938 (31.611)   Prec@5 92.188 (84.006)   [2019-11-18 05:25:02]
  Epoch: [000][300/391]   Time 0.037 (0.048)   Data 0.000 (0.001)   Loss 1.3443 (1.7287)   Prec@1 46.094 (35.992)   Prec@5 95.312 (86.607)   [2019-11-18 05:25:06]
  **Train** Prec@1 38.910 Prec@5 88.052 Error@1 61.090
  **Test** Prec@1 43.580 Prec@5 91.980 Error@1 56.420
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:25:12] [Epoch=001/200] [Need: 01:07:13] [LR=0.0100][M=0.90] [Best : Accuracy=43.58, Error=56.42]
  Epoch: [001][000/391]   Time 0.299 (0.299)   Data 0.234 (0.234)   Loss 1.3035 (1.3035)   Prec@1 51.562 (51.562)   Prec@5 95.312 (95.312)   [2019-11-18 05:25:13]
  Epoch: [001][100/391]   Time 0.038 (0.043)   Data 0.000 (0.002)   Loss 1.3161 (1.2841)   Prec@1 53.906 (53.295)   Prec@5 93.750 (94.353)   [2019-11-18 05:25:17]
  Epoch: [001][200/391]   Time 0.035 (0.043)   Data 0.000 (0.001)   Loss 1.0960 (1.2270)   Prec@1 56.250 (55.624)   Prec@5 96.094 (94.761)   [2019-11-18 05:25:21]
  Epoch: [001][300/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 1.1063 (1.1965)   Prec@1 61.719 (57.086)   Prec@5 93.750 (95.024)   [2019-11-18 05:25:25]
  **Train** Prec@1 58.254 Prec@5 95.286 Error@1 41.746
  **Test** Prec@1 60.350 Prec@5 96.160 Error@1 39.650
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:25:31] [Epoch=002/200] [Need: 01:05:02] [LR=0.0100][M=0.90] [Best : Accuracy=60.35, Error=39.65]
  Epoch: [002][000/391]   Time 0.273 (0.273)   Data 0.209 (0.209)   Loss 0.9885 (0.9885)   Prec@1 65.625 (65.625)   Prec@5 95.312 (95.312)   [2019-11-18 05:25:32]
  Epoch: [002][100/391]   Time 0.073 (0.047)   Data 0.000 (0.002)   Loss 1.0571 (1.0388)   Prec@1 60.156 (62.949)   Prec@5 98.438 (96.334)   [2019-11-18 05:25:36]
  Epoch: [002][200/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 1.0794 (1.0024)   Prec@1 60.938 (64.210)   Prec@5 96.875 (96.661)   [2019-11-18 05:25:40]
  Epoch: [002][300/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.9768 (0.9873)   Prec@1 64.844 (65.028)   Prec@5 99.219 (96.758)   [2019-11-18 05:25:45]
  **Train** Prec@1 65.592 Prec@5 96.856 Error@1 34.408
  **Test** Prec@1 68.020 Prec@5 97.450 Error@1 31.980
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:25:50] [Epoch=003/200] [Need: 01:03:54] [LR=0.0100][M=0.90] [Best : Accuracy=68.02, Error=31.98]
  Epoch: [003][000/391]   Time 0.272 (0.272)   Data 0.223 (0.223)   Loss 1.0979 (1.0979)   Prec@1 60.938 (60.938)   Prec@5 93.750 (93.750)   [2019-11-18 05:25:51]
  Epoch: [003][100/391]   Time 0.045 (0.044)   Data 0.000 (0.002)   Loss 0.8882 (0.8860)   Prec@1 67.188 (68.843)   Prec@5 98.438 (97.393)   [2019-11-18 05:25:55]
  Epoch: [003][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.8683 (0.8819)   Prec@1 67.969 (69.088)   Prec@5 96.094 (97.466)   [2019-11-18 05:25:59]
  Epoch: [003][300/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.6669 (0.8743)   Prec@1 77.344 (69.456)   Prec@5 97.656 (97.519)   [2019-11-18 05:26:03]
  **Train** Prec@1 69.892 Prec@5 97.608 Error@1 30.108
  **Test** Prec@1 64.130 Prec@5 96.930 Error@1 35.870

==>>[2019-11-18 05:26:09] [Epoch=004/200] [Need: 01:02:49] [LR=0.0100][M=0.90] [Best : Accuracy=68.02, Error=31.98]
  Epoch: [004][000/391]   Time 0.273 (0.273)   Data 0.212 (0.212)   Loss 0.6816 (0.6816)   Prec@1 76.562 (76.562)   Prec@5 99.219 (99.219)   [2019-11-18 05:26:09]
  Epoch: [004][100/391]   Time 0.043 (0.047)   Data 0.000 (0.002)   Loss 0.6264 (0.7826)   Prec@1 77.344 (73.058)   Prec@5 99.219 (97.942)   [2019-11-18 05:26:14]
  Epoch: [004][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.7196 (0.7840)   Prec@1 75.000 (72.893)   Prec@5 100.000 (97.998)   [2019-11-18 05:26:18]
  Epoch: [004][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.6417 (0.7733)   Prec@1 77.344 (73.149)   Prec@5 99.219 (98.056)   [2019-11-18 05:26:22]
  **Train** Prec@1 73.450 Prec@5 98.158 Error@1 26.550
  **Test** Prec@1 72.970 Prec@5 98.270 Error@1 27.030
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:26:28] [Epoch=005/200] [Need: 01:02:39] [LR=0.0100][M=0.90] [Best : Accuracy=72.97, Error=27.03]
  Epoch: [005][000/391]   Time 0.293 (0.293)   Data 0.200 (0.200)   Loss 0.6512 (0.6512)   Prec@1 79.688 (79.688)   Prec@5 98.438 (98.438)   [2019-11-18 05:26:29]
  Epoch: [005][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.6126 (0.7320)   Prec@1 78.125 (74.381)   Prec@5 98.438 (98.445)   [2019-11-18 05:26:33]
  Epoch: [005][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.8128 (0.7238)   Prec@1 72.656 (75.101)   Prec@5 96.875 (98.403)   [2019-11-18 05:26:38]
  Epoch: [005][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.7991 (0.7231)   Prec@1 72.656 (75.055)   Prec@5 96.875 (98.360)   [2019-11-18 05:26:42]
  **Train** Prec@1 75.496 Prec@5 98.340 Error@1 24.504
  **Test** Prec@1 72.470 Prec@5 97.320 Error@1 27.530

==>>[2019-11-18 05:26:48] [Epoch=006/200] [Need: 01:02:45] [LR=0.0100][M=0.90] [Best : Accuracy=72.97, Error=27.03]
  Epoch: [006][000/391]   Time 0.283 (0.283)   Data 0.228 (0.228)   Loss 0.6098 (0.6098)   Prec@1 78.125 (78.125)   Prec@5 99.219 (99.219)   [2019-11-18 05:26:49]
  Epoch: [006][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.5753 (0.6753)   Prec@1 80.469 (77.174)   Prec@5 98.438 (98.275)   [2019-11-18 05:26:53]
  Epoch: [006][200/391]   Time 0.037 (0.048)   Data 0.000 (0.001)   Loss 0.7863 (0.6737)   Prec@1 71.875 (76.877)   Prec@5 98.438 (98.422)   [2019-11-18 05:26:58]
  Epoch: [006][300/391]   Time 0.067 (0.047)   Data 0.000 (0.001)   Loss 0.7621 (0.6763)   Prec@1 71.875 (76.742)   Prec@5 99.219 (98.471)   [2019-11-18 05:27:03]
  **Train** Prec@1 77.096 Prec@5 98.494 Error@1 22.904
  **Test** Prec@1 73.790 Prec@5 98.150 Error@1 26.210
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:27:09] [Epoch=007/200] [Need: 01:02:44] [LR=0.0100][M=0.90] [Best : Accuracy=73.79, Error=26.21]
  Epoch: [007][000/391]   Time 0.278 (0.278)   Data 0.228 (0.228)   Loss 0.7203 (0.7203)   Prec@1 75.781 (75.781)   Prec@5 97.656 (97.656)   [2019-11-18 05:27:09]
  Epoch: [007][100/391]   Time 0.037 (0.049)   Data 0.000 (0.002)   Loss 0.9133 (0.6447)   Prec@1 67.969 (77.839)   Prec@5 96.094 (98.770)   [2019-11-18 05:27:13]
  Epoch: [007][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.7536 (0.6399)   Prec@1 72.656 (77.962)   Prec@5 97.656 (98.741)   [2019-11-18 05:27:18]
  Epoch: [007][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.6868 (0.6385)   Prec@1 75.000 (78.096)   Prec@5 99.219 (98.681)   [2019-11-18 05:27:22]
  **Train** Prec@1 78.084 Prec@5 98.674 Error@1 21.916
  **Test** Prec@1 75.390 Prec@5 98.750 Error@1 24.610
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:27:28] [Epoch=008/200] [Need: 01:02:19] [LR=0.0100][M=0.90] [Best : Accuracy=75.39, Error=24.61]
  Epoch: [008][000/391]   Time 0.279 (0.279)   Data 0.227 (0.227)   Loss 0.7193 (0.7193)   Prec@1 72.656 (72.656)   Prec@5 100.000 (100.000)   [2019-11-18 05:27:28]
  Epoch: [008][100/391]   Time 0.045 (0.043)   Data 0.000 (0.002)   Loss 0.5775 (0.6204)   Prec@1 77.344 (78.968)   Prec@5 100.000 (98.824)   [2019-11-18 05:27:32]
  Epoch: [008][200/391]   Time 0.066 (0.043)   Data 0.000 (0.001)   Loss 0.6084 (0.6150)   Prec@1 79.688 (78.871)   Prec@5 98.438 (98.857)   [2019-11-18 05:27:36]
  Epoch: [008][300/391]   Time 0.057 (0.043)   Data 0.000 (0.001)   Loss 0.7182 (0.6101)   Prec@1 73.438 (79.137)   Prec@5 99.219 (98.824)   [2019-11-18 05:27:41]
  **Train** Prec@1 79.082 Prec@5 98.790 Error@1 20.918
  **Test** Prec@1 75.270 Prec@5 97.900 Error@1 24.730

==>>[2019-11-18 05:27:47] [Epoch=009/200] [Need: 01:01:45] [LR=0.0100][M=0.90] [Best : Accuracy=75.39, Error=24.61]
  Epoch: [009][000/391]   Time 0.282 (0.282)   Data 0.220 (0.220)   Loss 0.7100 (0.7100)   Prec@1 76.562 (76.562)   Prec@5 97.656 (97.656)   [2019-11-18 05:27:47]
  Epoch: [009][100/391]   Time 0.035 (0.044)   Data 0.000 (0.002)   Loss 0.5345 (0.5842)   Prec@1 79.688 (79.796)   Prec@5 100.000 (98.902)   [2019-11-18 05:27:51]
  Epoch: [009][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.6631 (0.5801)   Prec@1 78.125 (80.142)   Prec@5 97.656 (98.912)   [2019-11-18 05:27:56]
  Epoch: [009][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.6453 (0.5804)   Prec@1 81.250 (80.111)   Prec@5 97.656 (98.900)   [2019-11-18 05:28:00]
  **Train** Prec@1 80.068 Prec@5 98.850 Error@1 19.932
  **Test** Prec@1 72.330 Prec@5 98.020 Error@1 27.670

==>>[2019-11-18 05:28:06] [Epoch=010/200] [Need: 01:01:18] [LR=0.0100][M=0.90] [Best : Accuracy=75.39, Error=24.61]
  Epoch: [010][000/391]   Time 0.288 (0.288)   Data 0.237 (0.237)   Loss 0.6674 (0.6674)   Prec@1 75.781 (75.781)   Prec@5 99.219 (99.219)   [2019-11-18 05:28:06]
  Epoch: [010][100/391]   Time 0.047 (0.045)   Data 0.000 (0.003)   Loss 0.4685 (0.5599)   Prec@1 82.812 (80.593)   Prec@5 99.219 (99.033)   [2019-11-18 05:28:10]
  Epoch: [010][200/391]   Time 0.060 (0.046)   Data 0.000 (0.001)   Loss 0.5014 (0.5729)   Prec@1 83.594 (80.212)   Prec@5 99.219 (98.951)   [2019-11-18 05:28:15]
  Epoch: [010][300/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 0.3382 (0.5750)   Prec@1 89.062 (80.181)   Prec@5 100.000 (98.931)   [2019-11-18 05:28:19]
  **Train** Prec@1 80.290 Prec@5 98.946 Error@1 19.710
  **Test** Prec@1 77.820 Prec@5 98.550 Error@1 22.180
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:28:25] [Epoch=011/200] [Need: 01:01:02] [LR=0.0100][M=0.90] [Best : Accuracy=77.82, Error=22.18]
  Epoch: [011][000/391]   Time 0.272 (0.272)   Data 0.212 (0.212)   Loss 0.4558 (0.4558)   Prec@1 87.500 (87.500)   Prec@5 98.438 (98.438)   [2019-11-18 05:28:25]
  Epoch: [011][100/391]   Time 0.037 (0.046)   Data 0.000 (0.002)   Loss 0.6166 (0.5382)   Prec@1 78.125 (81.691)   Prec@5 100.000 (98.948)   [2019-11-18 05:28:30]
  Epoch: [011][200/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.6305 (0.5457)   Prec@1 79.688 (81.219)   Prec@5 99.219 (98.978)   [2019-11-18 05:28:34]
  Epoch: [011][300/391]   Time 0.042 (0.044)   Data 0.000 (0.001)   Loss 0.4401 (0.5473)   Prec@1 83.594 (81.055)   Prec@5 99.219 (98.967)   [2019-11-18 05:28:39]
  **Train** Prec@1 81.012 Prec@5 98.968 Error@1 18.988
  **Test** Prec@1 79.070 Prec@5 98.550 Error@1 20.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:28:45] [Epoch=012/200] [Need: 01:00:44] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [012][000/391]   Time 0.291 (0.291)   Data 0.237 (0.237)   Loss 0.4989 (0.4989)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-18 05:28:45]
  Epoch: [012][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.6984 (0.5410)   Prec@1 74.219 (81.436)   Prec@5 96.875 (98.855)   [2019-11-18 05:28:49]
  Epoch: [012][200/391]   Time 0.074 (0.047)   Data 0.000 (0.001)   Loss 0.5902 (0.5371)   Prec@1 80.469 (81.569)   Prec@5 99.219 (98.962)   [2019-11-18 05:28:54]
  Epoch: [012][300/391]   Time 0.056 (0.047)   Data 0.000 (0.001)   Loss 0.4108 (0.5453)   Prec@1 84.375 (81.364)   Prec@5 100.000 (98.951)   [2019-11-18 05:28:59]
  **Train** Prec@1 81.364 Prec@5 98.926 Error@1 18.636
  **Test** Prec@1 75.940 Prec@5 97.880 Error@1 24.060

==>>[2019-11-18 05:29:05] [Epoch=013/200] [Need: 01:00:41] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [013][000/391]   Time 0.275 (0.275)   Data 0.212 (0.212)   Loss 0.5396 (0.5396)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-18 05:29:05]
  Epoch: [013][100/391]   Time 0.045 (0.046)   Data 0.000 (0.002)   Loss 0.5457 (0.5194)   Prec@1 82.031 (82.186)   Prec@5 99.219 (99.103)   [2019-11-18 05:29:10]
  Epoch: [013][200/391]   Time 0.049 (0.044)   Data 0.002 (0.001)   Loss 0.4577 (0.5165)   Prec@1 82.812 (82.140)   Prec@5 100.000 (99.087)   [2019-11-18 05:29:14]
  Epoch: [013][300/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.6408 (0.5269)   Prec@1 78.906 (81.837)   Prec@5 98.438 (99.068)   [2019-11-18 05:29:18]
  **Train** Prec@1 81.932 Prec@5 99.024 Error@1 18.068
  **Test** Prec@1 75.120 Prec@5 98.250 Error@1 24.880

==>>[2019-11-18 05:29:24] [Epoch=014/200] [Need: 01:00:08] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [014][000/391]   Time 0.273 (0.273)   Data 0.212 (0.212)   Loss 0.6247 (0.6247)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-18 05:29:24]
  Epoch: [014][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.5133 (0.5183)   Prec@1 79.688 (82.170)   Prec@5 99.219 (99.072)   [2019-11-18 05:29:29]
  Epoch: [014][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.5629 (0.5236)   Prec@1 82.031 (81.954)   Prec@5 99.219 (99.079)   [2019-11-18 05:29:33]
  Epoch: [014][300/391]   Time 0.046 (0.047)   Data 0.000 (0.001)   Loss 0.6213 (0.5207)   Prec@1 79.688 (82.065)   Prec@5 99.219 (99.084)   [2019-11-18 05:29:38]
  **Train** Prec@1 82.088 Prec@5 99.108 Error@1 17.912
  **Test** Prec@1 78.660 Prec@5 98.720 Error@1 21.340

==>>[2019-11-18 05:29:44] [Epoch=015/200] [Need: 01:00:01] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [015][000/391]   Time 0.301 (0.301)   Data 0.249 (0.249)   Loss 0.6449 (0.6449)   Prec@1 75.781 (75.781)   Prec@5 100.000 (100.000)   [2019-11-18 05:29:44]
  Epoch: [015][100/391]   Time 0.037 (0.045)   Data 0.000 (0.003)   Loss 0.3577 (0.4850)   Prec@1 86.719 (83.346)   Prec@5 98.438 (99.172)   [2019-11-18 05:29:49]
  Epoch: [015][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.5026 (0.4983)   Prec@1 79.688 (82.910)   Prec@5 99.219 (99.098)   [2019-11-18 05:29:53]
  Epoch: [015][300/391]   Time 0.051 (0.045)   Data 0.000 (0.001)   Loss 0.4258 (0.5021)   Prec@1 85.156 (82.802)   Prec@5 100.000 (99.110)   [2019-11-18 05:29:57]
  **Train** Prec@1 82.742 Prec@5 99.086 Error@1 17.258
  **Test** Prec@1 77.990 Prec@5 98.010 Error@1 22.010

==>>[2019-11-18 05:30:03] [Epoch=016/200] [Need: 00:59:40] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [016][000/391]   Time 0.273 (0.273)   Data 0.210 (0.210)   Loss 0.4772 (0.4772)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-18 05:30:04]
  Epoch: [016][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.4141 (0.4765)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.180)   [2019-11-18 05:30:08]
  Epoch: [016][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.5763 (0.4872)   Prec@1 76.562 (83.170)   Prec@5 99.219 (99.145)   [2019-11-18 05:30:12]
  Epoch: [016][300/391]   Time 0.036 (0.042)   Data 0.000 (0.001)   Loss 0.4088 (0.4907)   Prec@1 84.375 (83.155)   Prec@5 99.219 (99.164)   [2019-11-18 05:30:16]
  **Train** Prec@1 83.238 Prec@5 99.138 Error@1 16.762
  **Test** Prec@1 78.960 Prec@5 98.770 Error@1 21.040

==>>[2019-11-18 05:30:22] [Epoch=017/200] [Need: 00:59:09] [LR=0.0100][M=0.90] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [017][000/391]   Time 0.292 (0.292)   Data 0.239 (0.239)   Loss 0.3156 (0.3156)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-18 05:30:22]
  Epoch: [017][100/391]   Time 0.036 (0.047)   Data 0.000 (0.002)   Loss 0.5350 (0.4737)   Prec@1 80.469 (83.694)   Prec@5 98.438 (99.188)   [2019-11-18 05:30:26]
  Epoch: [017][200/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.5837 (0.4802)   Prec@1 82.031 (83.570)   Prec@5 99.219 (99.176)   [2019-11-18 05:30:31]
  Epoch: [017][300/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.6162 (0.4867)   Prec@1 82.812 (83.287)   Prec@5 99.219 (99.164)   [2019-11-18 05:30:35]
  **Train** Prec@1 83.222 Prec@5 99.184 Error@1 16.778
  **Test** Prec@1 80.550 Prec@5 99.140 Error@1 19.450
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:30:40] [Epoch=018/200] [Need: 00:58:43] [LR=0.0100][M=0.90] [Best : Accuracy=80.55, Error=19.45]
  Epoch: [018][000/391]   Time 0.280 (0.280)   Data 0.216 (0.216)   Loss 0.3469 (0.3469)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-18 05:30:41]
  Epoch: [018][100/391]   Time 0.072 (0.046)   Data 0.000 (0.002)   Loss 0.3961 (0.4721)   Prec@1 89.062 (84.236)   Prec@5 98.438 (99.064)   [2019-11-18 05:30:45]
  Epoch: [018][200/391]   Time 0.045 (0.045)   Data 0.000 (0.001)   Loss 0.4413 (0.4836)   Prec@1 82.812 (83.590)   Prec@5 100.000 (99.133)   [2019-11-18 05:30:50]
  Epoch: [018][300/391]   Time 0.047 (0.046)   Data 0.000 (0.001)   Loss 0.5803 (0.4859)   Prec@1 78.125 (83.438)   Prec@5 100.000 (99.131)   [2019-11-18 05:30:54]
  **Train** Prec@1 83.286 Prec@5 99.148 Error@1 16.714
  **Test** Prec@1 81.060 Prec@5 98.850 Error@1 18.940
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:31:00] [Epoch=019/200] [Need: 00:58:25] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [019][000/391]   Time 0.279 (0.279)   Data 0.212 (0.212)   Loss 0.5972 (0.5972)   Prec@1 75.781 (75.781)   Prec@5 100.000 (100.000)   [2019-11-18 05:31:00]
  Epoch: [019][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.4540 (0.4827)   Prec@1 84.375 (83.222)   Prec@5 100.000 (99.188)   [2019-11-18 05:31:05]
  Epoch: [019][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.5000 (0.4757)   Prec@1 84.375 (83.403)   Prec@5 100.000 (99.277)   [2019-11-18 05:31:09]
  Epoch: [019][300/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.4885 (0.4755)   Prec@1 85.938 (83.576)   Prec@5 100.000 (99.247)   [2019-11-18 05:31:13]
  **Train** Prec@1 83.332 Prec@5 99.234 Error@1 16.668
  **Test** Prec@1 80.700 Prec@5 98.980 Error@1 19.300

==>>[2019-11-18 05:31:20] [Epoch=020/200] [Need: 00:58:07] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [020][000/391]   Time 0.277 (0.277)   Data 0.221 (0.221)   Loss 0.5188 (0.5188)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-18 05:31:20]
  Epoch: [020][100/391]   Time 0.053 (0.047)   Data 0.000 (0.002)   Loss 0.4614 (0.4744)   Prec@1 85.156 (83.625)   Prec@5 100.000 (99.203)   [2019-11-18 05:31:24]
  Epoch: [020][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.4790 (0.4686)   Prec@1 82.812 (83.784)   Prec@5 98.438 (99.242)   [2019-11-18 05:31:29]
  Epoch: [020][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.5739 (0.4688)   Prec@1 79.688 (83.864)   Prec@5 99.219 (99.227)   [2019-11-18 05:31:33]
  **Train** Prec@1 83.782 Prec@5 99.232 Error@1 16.218
  **Test** Prec@1 75.850 Prec@5 99.020 Error@1 24.150

==>>[2019-11-18 05:31:39] [Epoch=021/200] [Need: 00:57:49] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [021][000/391]   Time 0.274 (0.274)   Data 0.208 (0.208)   Loss 0.5507 (0.5507)   Prec@1 80.469 (80.469)   Prec@5 100.000 (100.000)   [2019-11-18 05:31:39]
  Epoch: [021][100/391]   Time 0.037 (0.045)   Data 0.000 (0.002)   Loss 0.7071 (0.4616)   Prec@1 78.125 (84.584)   Prec@5 98.438 (99.273)   [2019-11-18 05:31:44]
  Epoch: [021][200/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.4529 (0.4585)   Prec@1 83.594 (84.530)   Prec@5 100.000 (99.262)   [2019-11-18 05:31:48]
  Epoch: [021][300/391]   Time 0.054 (0.044)   Data 0.000 (0.001)   Loss 0.5708 (0.4609)   Prec@1 78.906 (84.406)   Prec@5 100.000 (99.237)   [2019-11-18 05:31:52]
  **Train** Prec@1 84.280 Prec@5 99.250 Error@1 15.720
  **Test** Prec@1 80.360 Prec@5 98.870 Error@1 19.640

==>>[2019-11-18 05:31:58] [Epoch=022/200] [Need: 00:57:27] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [022][000/391]   Time 0.283 (0.283)   Data 0.235 (0.235)   Loss 0.4559 (0.4559)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-18 05:31:58]
  Epoch: [022][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.3900 (0.4515)   Prec@1 88.281 (84.661)   Prec@5 100.000 (99.134)   [2019-11-18 05:32:03]
  Epoch: [022][200/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.4652 (0.4529)   Prec@1 82.031 (84.554)   Prec@5 99.219 (99.230)   [2019-11-18 05:32:07]
  Epoch: [022][300/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.4278 (0.4542)   Prec@1 83.594 (84.497)   Prec@5 100.000 (99.242)   [2019-11-18 05:32:12]
  **Train** Prec@1 84.498 Prec@5 99.242 Error@1 15.502
  **Test** Prec@1 78.870 Prec@5 98.930 Error@1 21.130

==>>[2019-11-18 05:32:18] [Epoch=023/200] [Need: 00:57:12] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [023][000/391]   Time 0.281 (0.281)   Data 0.233 (0.233)   Loss 0.4354 (0.4354)   Prec@1 87.500 (87.500)   Prec@5 98.438 (98.438)   [2019-11-18 05:32:18]
  Epoch: [023][100/391]   Time 0.038 (0.043)   Data 0.000 (0.002)   Loss 0.4612 (0.4347)   Prec@1 86.719 (85.350)   Prec@5 99.219 (99.273)   [2019-11-18 05:32:22]
  Epoch: [023][200/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.3983 (0.4453)   Prec@1 89.062 (84.740)   Prec@5 100.000 (99.312)   [2019-11-18 05:32:27]
  Epoch: [023][300/391]   Time 0.056 (0.045)   Data 0.000 (0.001)   Loss 0.4926 (0.4477)   Prec@1 86.719 (84.720)   Prec@5 98.438 (99.271)   [2019-11-18 05:32:31]
  **Train** Prec@1 84.552 Prec@5 99.294 Error@1 15.448
  **Test** Prec@1 79.600 Prec@5 98.730 Error@1 20.400

==>>[2019-11-18 05:32:37] [Epoch=024/200] [Need: 00:56:52] [LR=0.0100][M=0.90] [Best : Accuracy=81.06, Error=18.94]
  Epoch: [024][000/391]   Time 0.276 (0.276)   Data 0.223 (0.223)   Loss 0.4151 (0.4151)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2019-11-18 05:32:38]
  Epoch: [024][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.5097 (0.4341)   Prec@1 85.156 (85.466)   Prec@5 100.000 (99.203)   [2019-11-18 05:32:42]
  Epoch: [024][200/391]   Time 0.043 (0.043)   Data 0.000 (0.001)   Loss 0.4215 (0.4383)   Prec@1 88.281 (85.164)   Prec@5 99.219 (99.285)   [2019-11-18 05:32:46]
  Epoch: [024][300/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.6300 (0.4404)   Prec@1 79.688 (85.076)   Prec@5 98.438 (99.325)   [2019-11-18 05:32:50]
  **Train** Prec@1 84.944 Prec@5 99.346 Error@1 15.056
  **Test** Prec@1 82.230 Prec@5 99.180 Error@1 17.770
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:32:56] [Epoch=025/200] [Need: 00:56:25] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [025][000/391]   Time 0.281 (0.281)   Data 0.226 (0.226)   Loss 0.2850 (0.2850)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:32:56]
  Epoch: [025][100/391]   Time 0.036 (0.050)   Data 0.000 (0.002)   Loss 0.4436 (0.4176)   Prec@1 85.938 (85.783)   Prec@5 99.219 (99.242)   [2019-11-18 05:33:01]
  Epoch: [025][200/391]   Time 0.039 (0.048)   Data 0.000 (0.001)   Loss 0.4105 (0.4345)   Prec@1 84.375 (85.113)   Prec@5 100.000 (99.265)   [2019-11-18 05:33:05]
  Epoch: [025][300/391]   Time 0.046 (0.046)   Data 0.000 (0.001)   Loss 0.3816 (0.4404)   Prec@1 85.938 (84.990)   Prec@5 100.000 (99.278)   [2019-11-18 05:33:09]
  **Train** Prec@1 84.966 Prec@5 99.264 Error@1 15.034
  **Test** Prec@1 82.060 Prec@5 99.000 Error@1 17.940

==>>[2019-11-18 05:33:15] [Epoch=026/200] [Need: 00:56:06] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [026][000/391]   Time 0.280 (0.280)   Data 0.229 (0.229)   Loss 0.2951 (0.2951)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:33:15]
  Epoch: [026][100/391]   Time 0.034 (0.050)   Data 0.000 (0.002)   Loss 0.3493 (0.4214)   Prec@1 88.281 (85.605)   Prec@5 98.438 (99.428)   [2019-11-18 05:33:20]
  Epoch: [026][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.3973 (0.4266)   Prec@1 87.500 (85.409)   Prec@5 98.438 (99.378)   [2019-11-18 05:33:24]
  Epoch: [026][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.3671 (0.4319)   Prec@1 82.812 (85.299)   Prec@5 100.000 (99.362)   [2019-11-18 05:33:29]
  **Train** Prec@1 85.106 Prec@5 99.338 Error@1 14.894
  **Test** Prec@1 77.600 Prec@5 97.230 Error@1 22.400

==>>[2019-11-18 05:33:35] [Epoch=027/200] [Need: 00:55:50] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [027][000/391]   Time 0.302 (0.302)   Data 0.249 (0.249)   Loss 0.3855 (0.3855)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:33:35]
  Epoch: [027][100/391]   Time 0.040 (0.048)   Data 0.000 (0.003)   Loss 0.3594 (0.4132)   Prec@1 87.500 (85.558)   Prec@5 99.219 (99.412)   [2019-11-18 05:33:40]
  Epoch: [027][200/391]   Time 0.038 (0.046)   Data 0.000 (0.001)   Loss 0.4468 (0.4250)   Prec@1 84.375 (85.285)   Prec@5 99.219 (99.401)   [2019-11-18 05:33:44]
  Epoch: [027][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.3196 (0.4316)   Prec@1 89.844 (85.211)   Prec@5 100.000 (99.333)   [2019-11-18 05:33:48]
  **Train** Prec@1 85.142 Prec@5 99.348 Error@1 14.858
  **Test** Prec@1 82.000 Prec@5 99.040 Error@1 18.000

==>>[2019-11-18 05:33:54] [Epoch=028/200] [Need: 00:55:29] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [028][000/391]   Time 0.285 (0.285)   Data 0.230 (0.230)   Loss 0.5279 (0.5279)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-18 05:33:54]
  Epoch: [028][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.3307 (0.4097)   Prec@1 91.406 (86.108)   Prec@5 100.000 (99.389)   [2019-11-18 05:33:59]
  Epoch: [028][200/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.4824 (0.4247)   Prec@1 84.375 (85.343)   Prec@5 99.219 (99.378)   [2019-11-18 05:34:03]
  Epoch: [028][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.4267 (0.4302)   Prec@1 86.719 (85.224)   Prec@5 99.219 (99.343)   [2019-11-18 05:34:07]
  **Train** Prec@1 85.156 Prec@5 99.334 Error@1 14.844
  **Test** Prec@1 81.140 Prec@5 98.850 Error@1 18.860

==>>[2019-11-18 05:34:13] [Epoch=029/200] [Need: 00:55:08] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [029][000/391]   Time 0.291 (0.291)   Data 0.244 (0.244)   Loss 0.4360 (0.4360)   Prec@1 85.938 (85.938)   Prec@5 97.656 (97.656)   [2019-11-18 05:34:13]
  Epoch: [029][100/391]   Time 0.058 (0.046)   Data 0.000 (0.003)   Loss 0.4698 (0.4236)   Prec@1 85.156 (85.280)   Prec@5 99.219 (99.350)   [2019-11-18 05:34:18]
  Epoch: [029][200/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.5432 (0.4267)   Prec@1 82.031 (85.288)   Prec@5 100.000 (99.320)   [2019-11-18 05:34:22]
  Epoch: [029][300/391]   Time 0.051 (0.043)   Data 0.000 (0.001)   Loss 0.4716 (0.4286)   Prec@1 85.156 (85.250)   Prec@5 98.438 (99.315)   [2019-11-18 05:34:26]
  **Train** Prec@1 85.316 Prec@5 99.320 Error@1 14.684
  **Test** Prec@1 80.750 Prec@5 98.950 Error@1 19.250

==>>[2019-11-18 05:34:32] [Epoch=030/200] [Need: 00:54:46] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [030][000/391]   Time 0.273 (0.273)   Data 0.221 (0.221)   Loss 0.4435 (0.4435)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-18 05:34:32]
  Epoch: [030][100/391]   Time 0.042 (0.046)   Data 0.000 (0.002)   Loss 0.3931 (0.4206)   Prec@1 82.031 (85.721)   Prec@5 99.219 (99.296)   [2019-11-18 05:34:37]
  Epoch: [030][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3923 (0.4328)   Prec@1 88.281 (85.234)   Prec@5 100.000 (99.289)   [2019-11-18 05:34:41]
  Epoch: [030][300/391]   Time 0.035 (0.044)   Data 0.000 (0.001)   Loss 0.5191 (0.4296)   Prec@1 81.250 (85.315)   Prec@5 100.000 (99.330)   [2019-11-18 05:34:45]
  **Train** Prec@1 85.362 Prec@5 99.364 Error@1 14.638
  **Test** Prec@1 82.090 Prec@5 99.220 Error@1 17.910

==>>[2019-11-18 05:34:51] [Epoch=031/200] [Need: 00:54:23] [LR=0.0100][M=0.90] [Best : Accuracy=82.23, Error=17.77]
  Epoch: [031][000/391]   Time 0.280 (0.280)   Data 0.229 (0.229)   Loss 0.4702 (0.4702)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-18 05:34:51]
  Epoch: [031][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.3753 (0.4089)   Prec@1 88.281 (85.961)   Prec@5 100.000 (99.435)   [2019-11-18 05:34:55]
  Epoch: [031][200/391]   Time 0.037 (0.047)   Data 0.000 (0.001)   Loss 0.3816 (0.4211)   Prec@1 89.062 (85.595)   Prec@5 99.219 (99.363)   [2019-11-18 05:35:00]
  Epoch: [031][300/391]   Time 0.068 (0.047)   Data 0.000 (0.001)   Loss 0.3897 (0.4246)   Prec@1 88.281 (85.501)   Prec@5 100.000 (99.346)   [2019-11-18 05:35:05]
  **Train** Prec@1 85.396 Prec@5 99.350 Error@1 14.604
  **Test** Prec@1 83.880 Prec@5 99.000 Error@1 16.120
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:35:11] [Epoch=032/200] [Need: 00:54:07] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [032][000/391]   Time 0.277 (0.277)   Data 0.224 (0.224)   Loss 0.4827 (0.4827)   Prec@1 82.812 (82.812)   Prec@5 98.438 (98.438)   [2019-11-18 05:35:11]
  Epoch: [032][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.4782 (0.4080)   Prec@1 85.938 (85.845)   Prec@5 99.219 (99.404)   [2019-11-18 05:35:15]
  Epoch: [032][200/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.3806 (0.4093)   Prec@1 89.844 (85.949)   Prec@5 100.000 (99.370)   [2019-11-18 05:35:20]
  Epoch: [032][300/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.5039 (0.4128)   Prec@1 81.250 (85.805)   Prec@5 100.000 (99.374)   [2019-11-18 05:35:24]
  **Train** Prec@1 85.672 Prec@5 99.372 Error@1 14.328
  **Test** Prec@1 83.610 Prec@5 99.080 Error@1 16.390

==>>[2019-11-18 05:35:30] [Epoch=033/200] [Need: 00:53:48] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [033][000/391]   Time 0.290 (0.290)   Data 0.230 (0.230)   Loss 0.3708 (0.3708)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-18 05:35:30]
  Epoch: [033][100/391]   Time 0.063 (0.047)   Data 0.000 (0.003)   Loss 0.3952 (0.3981)   Prec@1 86.719 (86.255)   Prec@5 99.219 (99.420)   [2019-11-18 05:35:35]
  Epoch: [033][200/391]   Time 0.058 (0.045)   Data 0.000 (0.001)   Loss 0.4173 (0.4106)   Prec@1 85.938 (85.953)   Prec@5 98.438 (99.405)   [2019-11-18 05:35:39]
  Epoch: [033][300/391]   Time 0.041 (0.044)   Data 0.000 (0.001)   Loss 0.3224 (0.4107)   Prec@1 89.844 (86.034)   Prec@5 99.219 (99.393)   [2019-11-18 05:35:43]
  **Train** Prec@1 85.928 Prec@5 99.390 Error@1 14.072
  **Test** Prec@1 79.170 Prec@5 98.690 Error@1 20.830

==>>[2019-11-18 05:35:49] [Epoch=034/200] [Need: 00:53:29] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [034][000/391]   Time 0.284 (0.284)   Data 0.216 (0.216)   Loss 0.3379 (0.3379)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:35:50]
  Epoch: [034][100/391]   Time 0.043 (0.046)   Data 0.000 (0.002)   Loss 0.4806 (0.4042)   Prec@1 85.156 (86.139)   Prec@5 100.000 (99.451)   [2019-11-18 05:35:54]
  Epoch: [034][200/391]   Time 0.054 (0.046)   Data 0.000 (0.001)   Loss 0.3091 (0.4088)   Prec@1 91.406 (86.147)   Prec@5 100.000 (99.382)   [2019-11-18 05:35:59]
  Epoch: [034][300/391]   Time 0.032 (0.046)   Data 0.000 (0.001)   Loss 0.3893 (0.4057)   Prec@1 88.281 (86.278)   Prec@5 100.000 (99.387)   [2019-11-18 05:36:03]
  **Train** Prec@1 86.214 Prec@5 99.418 Error@1 13.786
  **Test** Prec@1 80.240 Prec@5 98.370 Error@1 19.760

==>>[2019-11-18 05:36:09] [Epoch=035/200] [Need: 00:53:13] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [035][000/391]   Time 0.278 (0.278)   Data 0.218 (0.218)   Loss 0.2764 (0.2764)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-18 05:36:10]
  Epoch: [035][100/391]   Time 0.047 (0.049)   Data 0.000 (0.002)   Loss 0.3406 (0.3912)   Prec@1 88.281 (86.525)   Prec@5 100.000 (99.466)   [2019-11-18 05:36:14]
  Epoch: [035][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.4119 (0.3956)   Prec@1 87.500 (86.462)   Prec@5 99.219 (99.475)   [2019-11-18 05:36:19]
  Epoch: [035][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.4768 (0.3970)   Prec@1 83.594 (86.358)   Prec@5 97.656 (99.473)   [2019-11-18 05:36:23]
  **Train** Prec@1 86.054 Prec@5 99.446 Error@1 13.946
  **Test** Prec@1 79.210 Prec@5 98.640 Error@1 20.790

==>>[2019-11-18 05:36:29] [Epoch=036/200] [Need: 00:52:54] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [036][000/391]   Time 0.280 (0.280)   Data 0.220 (0.220)   Loss 0.3644 (0.3644)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:36:29]
  Epoch: [036][100/391]   Time 0.038 (0.045)   Data 0.000 (0.002)   Loss 0.5210 (0.4030)   Prec@1 82.031 (86.108)   Prec@5 98.438 (99.482)   [2019-11-18 05:36:33]
  Epoch: [036][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.3490 (0.3899)   Prec@1 89.844 (86.598)   Prec@5 100.000 (99.522)   [2019-11-18 05:36:38]
  Epoch: [036][300/391]   Time 0.056 (0.043)   Data 0.000 (0.001)   Loss 0.3597 (0.4014)   Prec@1 89.844 (86.319)   Prec@5 99.219 (99.437)   [2019-11-18 05:36:42]
  **Train** Prec@1 86.242 Prec@5 99.394 Error@1 13.758
  **Test** Prec@1 82.460 Prec@5 99.070 Error@1 17.540

==>>[2019-11-18 05:36:48] [Epoch=037/200] [Need: 00:52:33] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [037][000/391]   Time 0.281 (0.281)   Data 0.228 (0.228)   Loss 0.3546 (0.3546)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2019-11-18 05:36:48]
  Epoch: [037][100/391]   Time 0.045 (0.045)   Data 0.000 (0.002)   Loss 0.3869 (0.3994)   Prec@1 88.281 (86.100)   Prec@5 98.438 (99.435)   [2019-11-18 05:36:52]
  Epoch: [037][200/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.4156 (0.4051)   Prec@1 85.938 (86.178)   Prec@5 100.000 (99.409)   [2019-11-18 05:36:56]
  Epoch: [037][300/391]   Time 0.037 (0.042)   Data 0.000 (0.001)   Loss 0.5053 (0.4109)   Prec@1 82.031 (86.008)   Prec@5 99.219 (99.406)   [2019-11-18 05:37:00]
  **Train** Prec@1 85.876 Prec@5 99.426 Error@1 14.124
  **Test** Prec@1 81.870 Prec@5 98.810 Error@1 18.130

==>>[2019-11-18 05:37:07] [Epoch=038/200] [Need: 00:52:13] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [038][000/391]   Time 0.275 (0.275)   Data 0.214 (0.214)   Loss 0.3953 (0.3953)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-18 05:37:07]
  Epoch: [038][100/391]   Time 0.036 (0.043)   Data 0.000 (0.002)   Loss 0.4548 (0.3807)   Prec@1 82.031 (87.098)   Prec@5 100.000 (99.459)   [2019-11-18 05:37:11]
  Epoch: [038][200/391]   Time 0.036 (0.042)   Data 0.000 (0.001)   Loss 0.3429 (0.3951)   Prec@1 90.625 (86.505)   Prec@5 100.000 (99.405)   [2019-11-18 05:37:15]
  Epoch: [038][300/391]   Time 0.045 (0.043)   Data 0.000 (0.001)   Loss 0.4736 (0.3996)   Prec@1 85.156 (86.345)   Prec@5 100.000 (99.398)   [2019-11-18 05:37:20]
  **Train** Prec@1 86.158 Prec@5 99.394 Error@1 13.842
  **Test** Prec@1 79.400 Prec@5 99.030 Error@1 20.600

==>>[2019-11-18 05:37:26] [Epoch=039/200] [Need: 00:51:52] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [039][000/391]   Time 0.296 (0.296)   Data 0.216 (0.216)   Loss 0.4862 (0.4862)   Prec@1 82.031 (82.031)   Prec@5 97.656 (97.656)   [2019-11-18 05:37:26]
  Epoch: [039][100/391]   Time 0.049 (0.049)   Data 0.000 (0.002)   Loss 0.3416 (0.3922)   Prec@1 88.281 (86.533)   Prec@5 99.219 (99.319)   [2019-11-18 05:37:31]
  Epoch: [039][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.3577 (0.4016)   Prec@1 85.156 (86.206)   Prec@5 99.219 (99.413)   [2019-11-18 05:37:35]
  Epoch: [039][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.4128 (0.3997)   Prec@1 85.938 (86.228)   Prec@5 100.000 (99.411)   [2019-11-18 05:37:40]
  **Train** Prec@1 86.188 Prec@5 99.410 Error@1 13.812
  **Test** Prec@1 82.910 Prec@5 99.140 Error@1 17.090

==>>[2019-11-18 05:37:46] [Epoch=040/200] [Need: 00:51:34] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [040][000/391]   Time 0.286 (0.286)   Data 0.233 (0.233)   Loss 0.3728 (0.3728)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-18 05:37:46]
  Epoch: [040][100/391]   Time 0.035 (0.045)   Data 0.000 (0.002)   Loss 0.3079 (0.3828)   Prec@1 89.062 (86.974)   Prec@5 100.000 (99.482)   [2019-11-18 05:37:50]
  Epoch: [040][200/391]   Time 0.045 (0.045)   Data 0.000 (0.001)   Loss 0.4737 (0.4004)   Prec@1 82.812 (86.237)   Prec@5 97.656 (99.401)   [2019-11-18 05:37:55]
  Epoch: [040][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.4484 (0.4012)   Prec@1 84.375 (86.158)   Prec@5 99.219 (99.416)   [2019-11-18 05:37:59]
  **Train** Prec@1 86.170 Prec@5 99.428 Error@1 13.830
  **Test** Prec@1 80.360 Prec@5 98.940 Error@1 19.640

==>>[2019-11-18 05:38:05] [Epoch=041/200] [Need: 00:51:15] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [041][000/391]   Time 0.269 (0.269)   Data 0.219 (0.219)   Loss 0.3997 (0.3997)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-18 05:38:05]
  Epoch: [041][100/391]   Time 0.044 (0.046)   Data 0.000 (0.002)   Loss 0.3717 (0.3916)   Prec@1 85.938 (86.556)   Prec@5 99.219 (99.482)   [2019-11-18 05:38:10]
  Epoch: [041][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.4361 (0.3961)   Prec@1 85.156 (86.400)   Prec@5 99.219 (99.483)   [2019-11-18 05:38:14]
  Epoch: [041][300/391]   Time 0.053 (0.045)   Data 0.000 (0.001)   Loss 0.4679 (0.3950)   Prec@1 85.938 (86.514)   Prec@5 98.438 (99.489)   [2019-11-18 05:38:19]
  **Train** Prec@1 86.464 Prec@5 99.462 Error@1 13.536
  **Test** Prec@1 76.740 Prec@5 97.500 Error@1 23.260

==>>[2019-11-18 05:38:25] [Epoch=042/200] [Need: 00:50:57] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [042][000/391]   Time 0.283 (0.283)   Data 0.227 (0.227)   Loss 0.4000 (0.4000)   Prec@1 89.062 (89.062)   Prec@5 98.438 (98.438)   [2019-11-18 05:38:25]
  Epoch: [042][100/391]   Time 0.036 (0.043)   Data 0.000 (0.002)   Loss 0.4278 (0.3862)   Prec@1 86.719 (87.013)   Prec@5 100.000 (99.343)   [2019-11-18 05:38:29]
  Epoch: [042][200/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.3829 (0.3880)   Prec@1 90.625 (86.886)   Prec@5 99.219 (99.394)   [2019-11-18 05:38:34]
  Epoch: [042][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.3799 (0.3928)   Prec@1 85.938 (86.675)   Prec@5 100.000 (99.416)   [2019-11-18 05:38:38]
  **Train** Prec@1 86.376 Prec@5 99.416 Error@1 13.624
  **Test** Prec@1 83.200 Prec@5 99.160 Error@1 16.800

==>>[2019-11-18 05:38:44] [Epoch=043/200] [Need: 00:50:36] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [043][000/391]   Time 0.283 (0.283)   Data 0.226 (0.226)   Loss 0.4176 (0.4176)   Prec@1 82.812 (82.812)   Prec@5 98.438 (98.438)   [2019-11-18 05:38:44]
  Epoch: [043][100/391]   Time 0.062 (0.049)   Data 0.000 (0.002)   Loss 0.2373 (0.3861)   Prec@1 91.406 (86.556)   Prec@5 100.000 (99.567)   [2019-11-18 05:38:49]
  Epoch: [043][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.4012 (0.3883)   Prec@1 85.938 (86.583)   Prec@5 99.219 (99.518)   [2019-11-18 05:38:53]
  Epoch: [043][300/391]   Time 0.067 (0.045)   Data 0.000 (0.001)   Loss 0.3192 (0.3918)   Prec@1 90.625 (86.490)   Prec@5 100.000 (99.471)   [2019-11-18 05:38:57]
  **Train** Prec@1 86.416 Prec@5 99.456 Error@1 13.584
  **Test** Prec@1 81.290 Prec@5 98.970 Error@1 18.710

==>>[2019-11-18 05:39:03] [Epoch=044/200] [Need: 00:50:18] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [044][000/391]   Time 0.283 (0.283)   Data 0.222 (0.222)   Loss 0.3151 (0.3151)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:39:04]
  Epoch: [044][100/391]   Time 0.036 (0.047)   Data 0.000 (0.002)   Loss 0.5278 (0.3838)   Prec@1 85.156 (86.897)   Prec@5 99.219 (99.474)   [2019-11-18 05:39:08]
  Epoch: [044][200/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.2304 (0.3983)   Prec@1 92.969 (86.361)   Prec@5 100.000 (99.374)   [2019-11-18 05:39:12]
  Epoch: [044][300/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.6644 (0.4000)   Prec@1 80.469 (86.368)   Prec@5 99.219 (99.419)   [2019-11-18 05:39:17]
  **Train** Prec@1 86.380 Prec@5 99.422 Error@1 13.620
  **Test** Prec@1 83.460 Prec@5 99.200 Error@1 16.540

==>>[2019-11-18 05:39:22] [Epoch=045/200] [Need: 00:49:58] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [045][000/391]   Time 0.281 (0.281)   Data 0.217 (0.217)   Loss 0.3628 (0.3628)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-18 05:39:23]
  Epoch: [045][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.4352 (0.3812)   Prec@1 89.062 (86.982)   Prec@5 99.219 (99.482)   [2019-11-18 05:39:27]
  Epoch: [045][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.4896 (0.3942)   Prec@1 79.688 (86.594)   Prec@5 99.219 (99.398)   [2019-11-18 05:39:31]
  Epoch: [045][300/391]   Time 0.069 (0.045)   Data 0.000 (0.001)   Loss 0.4685 (0.3951)   Prec@1 78.125 (86.524)   Prec@5 98.438 (99.395)   [2019-11-18 05:39:36]
  **Train** Prec@1 86.582 Prec@5 99.400 Error@1 13.418
  **Test** Prec@1 83.290 Prec@5 99.140 Error@1 16.710

==>>[2019-11-18 05:39:42] [Epoch=046/200] [Need: 00:49:39] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [046][000/391]   Time 0.292 (0.292)   Data 0.243 (0.243)   Loss 0.4249 (0.4249)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-18 05:39:42]
  Epoch: [046][100/391]   Time 0.044 (0.049)   Data 0.000 (0.003)   Loss 0.4042 (0.3975)   Prec@1 85.156 (86.463)   Prec@5 100.000 (99.567)   [2019-11-18 05:39:47]
  Epoch: [046][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.4120 (0.3963)   Prec@1 86.719 (86.579)   Prec@5 96.094 (99.506)   [2019-11-18 05:39:51]
  Epoch: [046][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.5055 (0.3894)   Prec@1 82.812 (86.820)   Prec@5 99.219 (99.515)   [2019-11-18 05:39:55]
  **Train** Prec@1 86.820 Prec@5 99.512 Error@1 13.180
  **Test** Prec@1 71.770 Prec@5 97.550 Error@1 28.230

==>>[2019-11-18 05:40:01] [Epoch=047/200] [Need: 00:49:19] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [047][000/391]   Time 0.265 (0.265)   Data 0.211 (0.211)   Loss 0.2443 (0.2443)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 05:40:01]
  Epoch: [047][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.2341 (0.3729)   Prec@1 90.625 (87.222)   Prec@5 100.000 (99.559)   [2019-11-18 05:40:06]
  Epoch: [047][200/391]   Time 0.057 (0.045)   Data 0.000 (0.001)   Loss 0.3941 (0.3833)   Prec@1 86.719 (86.901)   Prec@5 100.000 (99.526)   [2019-11-18 05:40:10]
  Epoch: [047][300/391]   Time 0.032 (0.044)   Data 0.000 (0.001)   Loss 0.3989 (0.3873)   Prec@1 87.500 (86.768)   Prec@5 99.219 (99.494)   [2019-11-18 05:40:14]
  **Train** Prec@1 86.690 Prec@5 99.498 Error@1 13.310
  **Test** Prec@1 82.220 Prec@5 99.470 Error@1 17.780

==>>[2019-11-18 05:40:20] [Epoch=048/200] [Need: 00:48:59] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [048][000/391]   Time 0.287 (0.287)   Data 0.225 (0.225)   Loss 0.3019 (0.3019)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-18 05:40:21]
  Epoch: [048][100/391]   Time 0.039 (0.047)   Data 0.000 (0.002)   Loss 0.3544 (0.3869)   Prec@1 89.062 (86.649)   Prec@5 98.438 (99.327)   [2019-11-18 05:40:25]
  Epoch: [048][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.4017 (0.3894)   Prec@1 87.500 (86.645)   Prec@5 99.219 (99.394)   [2019-11-18 05:40:29]
  Epoch: [048][300/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.4503 (0.3881)   Prec@1 85.938 (86.742)   Prec@5 98.438 (99.408)   [2019-11-18 05:40:34]
  **Train** Prec@1 86.704 Prec@5 99.364 Error@1 13.296
  **Test** Prec@1 78.220 Prec@5 97.620 Error@1 21.780

==>>[2019-11-18 05:40:40] [Epoch=049/200] [Need: 00:48:40] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [049][000/391]   Time 0.285 (0.285)   Data 0.228 (0.228)   Loss 0.4282 (0.4282)   Prec@1 89.062 (89.062)   Prec@5 98.438 (98.438)   [2019-11-18 05:40:40]
  Epoch: [049][100/391]   Time 0.036 (0.046)   Data 0.000 (0.002)   Loss 0.2967 (0.3874)   Prec@1 92.188 (86.750)   Prec@5 100.000 (99.459)   [2019-11-18 05:40:44]
  Epoch: [049][200/391]   Time 0.043 (0.044)   Data 0.000 (0.001)   Loss 0.5378 (0.3889)   Prec@1 85.156 (86.524)   Prec@5 99.219 (99.440)   [2019-11-18 05:40:49]
  Epoch: [049][300/391]   Time 0.045 (0.043)   Data 0.000 (0.001)   Loss 0.3314 (0.3895)   Prec@1 90.625 (86.620)   Prec@5 100.000 (99.439)   [2019-11-18 05:40:53]
  **Train** Prec@1 86.560 Prec@5 99.430 Error@1 13.440
  **Test** Prec@1 79.560 Prec@5 98.520 Error@1 20.440

==>>[2019-11-18 05:40:59] [Epoch=050/200] [Need: 00:48:20] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [050][000/391]   Time 0.279 (0.279)   Data 0.229 (0.229)   Loss 0.2613 (0.2613)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 05:40:59]
  Epoch: [050][100/391]   Time 0.039 (0.046)   Data 0.000 (0.002)   Loss 0.2567 (0.3741)   Prec@1 91.406 (87.152)   Prec@5 100.000 (99.544)   [2019-11-18 05:41:03]
  Epoch: [050][200/391]   Time 0.047 (0.047)   Data 0.000 (0.001)   Loss 0.3294 (0.3849)   Prec@1 89.844 (86.964)   Prec@5 99.219 (99.456)   [2019-11-18 05:41:08]
  Epoch: [050][300/391]   Time 0.033 (0.046)   Data 0.000 (0.001)   Loss 0.5139 (0.3815)   Prec@1 84.375 (87.035)   Prec@5 98.438 (99.452)   [2019-11-18 05:41:13]
  **Train** Prec@1 86.988 Prec@5 99.460 Error@1 13.012
  **Test** Prec@1 82.670 Prec@5 99.200 Error@1 17.330

==>>[2019-11-18 05:41:18] [Epoch=051/200] [Need: 00:48:01] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [051][000/391]   Time 0.293 (0.293)   Data 0.242 (0.242)   Loss 0.3497 (0.3497)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:41:19]
  Epoch: [051][100/391]   Time 0.037 (0.046)   Data 0.000 (0.003)   Loss 0.3766 (0.3716)   Prec@1 89.062 (87.129)   Prec@5 100.000 (99.567)   [2019-11-18 05:41:23]
  Epoch: [051][200/391]   Time 0.067 (0.045)   Data 0.000 (0.001)   Loss 0.2653 (0.3758)   Prec@1 89.062 (87.135)   Prec@5 100.000 (99.502)   [2019-11-18 05:41:27]
  Epoch: [051][300/391]   Time 0.052 (0.045)   Data 0.000 (0.001)   Loss 0.3613 (0.3803)   Prec@1 87.500 (86.955)   Prec@5 100.000 (99.509)   [2019-11-18 05:41:32]
  **Train** Prec@1 86.760 Prec@5 99.462 Error@1 13.240
  **Test** Prec@1 77.200 Prec@5 98.430 Error@1 22.800

==>>[2019-11-18 05:41:37] [Epoch=052/200] [Need: 00:47:41] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [052][000/391]   Time 0.277 (0.277)   Data 0.230 (0.230)   Loss 0.3929 (0.3929)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:41:38]
  Epoch: [052][100/391]   Time 0.046 (0.048)   Data 0.000 (0.002)   Loss 0.3903 (0.3762)   Prec@1 83.594 (87.160)   Prec@5 98.438 (99.474)   [2019-11-18 05:41:42]
  Epoch: [052][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.5370 (0.3917)   Prec@1 82.812 (86.618)   Prec@5 99.219 (99.440)   [2019-11-18 05:41:47]
  Epoch: [052][300/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.3234 (0.3901)   Prec@1 89.062 (86.711)   Prec@5 100.000 (99.447)   [2019-11-18 05:41:51]
  **Train** Prec@1 86.598 Prec@5 99.442 Error@1 13.402
  **Test** Prec@1 80.240 Prec@5 99.000 Error@1 19.760

==>>[2019-11-18 05:41:57] [Epoch=053/200] [Need: 00:47:22] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [053][000/391]   Time 0.284 (0.284)   Data 0.232 (0.232)   Loss 0.3871 (0.3871)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:41:57]
  Epoch: [053][100/391]   Time 0.054 (0.048)   Data 0.000 (0.002)   Loss 0.2712 (0.3720)   Prec@1 92.188 (87.361)   Prec@5 100.000 (99.520)   [2019-11-18 05:42:02]
  Epoch: [053][200/391]   Time 0.058 (0.047)   Data 0.000 (0.001)   Loss 0.2661 (0.3744)   Prec@1 90.625 (87.220)   Prec@5 99.219 (99.514)   [2019-11-18 05:42:06]
  Epoch: [053][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.3583 (0.3777)   Prec@1 88.281 (87.163)   Prec@5 100.000 (99.512)   [2019-11-18 05:42:11]
  **Train** Prec@1 87.010 Prec@5 99.470 Error@1 12.990
  **Test** Prec@1 83.110 Prec@5 98.610 Error@1 16.890

==>>[2019-11-18 05:42:17] [Epoch=054/200] [Need: 00:47:04] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [054][000/391]   Time 0.286 (0.286)   Data 0.229 (0.229)   Loss 0.2659 (0.2659)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-18 05:42:17]
  Epoch: [054][100/391]   Time 0.039 (0.048)   Data 0.000 (0.002)   Loss 0.3349 (0.3661)   Prec@1 89.844 (87.376)   Prec@5 100.000 (99.497)   [2019-11-18 05:42:21]
  Epoch: [054][200/391]   Time 0.036 (0.046)   Data 0.000 (0.001)   Loss 0.3875 (0.3715)   Prec@1 86.719 (87.162)   Prec@5 100.000 (99.495)   [2019-11-18 05:42:26]
  Epoch: [054][300/391]   Time 0.036 (0.046)   Data 0.000 (0.001)   Loss 0.4060 (0.3802)   Prec@1 85.156 (86.874)   Prec@5 99.219 (99.460)   [2019-11-18 05:42:30]
  **Train** Prec@1 86.842 Prec@5 99.454 Error@1 13.158
  **Test** Prec@1 82.980 Prec@5 99.000 Error@1 17.020

==>>[2019-11-18 05:42:36] [Epoch=055/200] [Need: 00:46:45] [LR=0.0100][M=0.90] [Best : Accuracy=83.88, Error=16.12]
  Epoch: [055][000/391]   Time 0.280 (0.280)   Data 0.224 (0.224)   Loss 0.3376 (0.3376)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-18 05:42:36]
  Epoch: [055][100/391]   Time 0.035 (0.043)   Data 0.000 (0.002)   Loss 0.4509 (0.3706)   Prec@1 84.375 (87.136)   Prec@5 100.000 (99.544)   [2019-11-18 05:42:40]
  Epoch: [055][200/391]   Time 0.043 (0.043)   Data 0.000 (0.001)   Loss 0.3037 (0.3688)   Prec@1 89.844 (87.310)   Prec@5 100.000 (99.534)   [2019-11-18 05:42:45]
  Epoch: [055][300/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.3493 (0.3800)   Prec@1 87.500 (86.989)   Prec@5 100.000 (99.481)   [2019-11-18 05:42:49]
  **Train** Prec@1 86.932 Prec@5 99.498 Error@1 13.068
  **Test** Prec@1 84.540 Prec@5 99.330 Error@1 15.460
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:42:55] [Epoch=056/200] [Need: 00:46:25] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [056][000/391]   Time 0.271 (0.271)   Data 0.210 (0.210)   Loss 0.4205 (0.4205)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-18 05:42:55]
  Epoch: [056][100/391]   Time 0.056 (0.048)   Data 0.000 (0.002)   Loss 0.2921 (0.3747)   Prec@1 90.625 (87.338)   Prec@5 100.000 (99.489)   [2019-11-18 05:43:00]
  Epoch: [056][200/391]   Time 0.066 (0.046)   Data 0.000 (0.001)   Loss 0.3461 (0.3812)   Prec@1 85.156 (87.104)   Prec@5 100.000 (99.464)   [2019-11-18 05:43:04]
  Epoch: [056][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.4362 (0.3878)   Prec@1 83.594 (86.856)   Prec@5 98.438 (99.445)   [2019-11-18 05:43:09]
  **Train** Prec@1 86.966 Prec@5 99.448 Error@1 13.034
  **Test** Prec@1 83.320 Prec@5 99.060 Error@1 16.680

==>>[2019-11-18 05:43:15] [Epoch=057/200] [Need: 00:46:06] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [057][000/391]   Time 0.278 (0.278)   Data 0.224 (0.224)   Loss 0.3737 (0.3737)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-18 05:43:15]
  Epoch: [057][100/391]   Time 0.039 (0.044)   Data 0.000 (0.002)   Loss 0.4399 (0.3773)   Prec@1 83.594 (86.835)   Prec@5 99.219 (99.559)   [2019-11-18 05:43:19]
  Epoch: [057][200/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.3091 (0.3787)   Prec@1 89.844 (86.944)   Prec@5 98.438 (99.526)   [2019-11-18 05:43:23]
  Epoch: [057][300/391]   Time 0.038 (0.042)   Data 0.000 (0.001)   Loss 0.4319 (0.3814)   Prec@1 83.594 (86.911)   Prec@5 100.000 (99.528)   [2019-11-18 05:43:27]
  **Train** Prec@1 86.914 Prec@5 99.516 Error@1 13.086
  **Test** Prec@1 78.440 Prec@5 99.160 Error@1 21.560

==>>[2019-11-18 05:43:33] [Epoch=058/200] [Need: 00:45:44] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [058][000/391]   Time 0.279 (0.279)   Data 0.220 (0.220)   Loss 0.3841 (0.3841)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-18 05:43:33]
  Epoch: [058][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.3396 (0.3482)   Prec@1 89.062 (88.204)   Prec@5 98.438 (99.582)   [2019-11-18 05:43:38]
  Epoch: [058][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.3491 (0.3588)   Prec@1 89.062 (87.694)   Prec@5 99.219 (99.537)   [2019-11-18 05:43:42]
  Epoch: [058][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.2312 (0.3657)   Prec@1 92.969 (87.503)   Prec@5 99.219 (99.515)   [2019-11-18 05:43:46]
  **Train** Prec@1 87.374 Prec@5 99.510 Error@1 12.626
  **Test** Prec@1 81.360 Prec@5 99.080 Error@1 18.640

==>>[2019-11-18 05:43:52] [Epoch=059/200] [Need: 00:45:24] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [059][000/391]   Time 0.279 (0.279)   Data 0.229 (0.229)   Loss 0.4486 (0.4486)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2019-11-18 05:43:52]
  Epoch: [059][100/391]   Time 0.037 (0.046)   Data 0.000 (0.002)   Loss 0.3737 (0.3696)   Prec@1 85.938 (87.399)   Prec@5 100.000 (99.505)   [2019-11-18 05:43:57]
  Epoch: [059][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.4040 (0.3583)   Prec@1 85.156 (87.714)   Prec@5 99.219 (99.534)   [2019-11-18 05:44:01]
  Epoch: [059][300/391]   Time 0.040 (0.043)   Data 0.000 (0.001)   Loss 0.3675 (0.3739)   Prec@1 87.500 (87.264)   Prec@5 100.000 (99.486)   [2019-11-18 05:44:05]
  **Train** Prec@1 87.282 Prec@5 99.506 Error@1 12.718
  **Test** Prec@1 83.160 Prec@5 99.170 Error@1 16.840

==>>[2019-11-18 05:44:11] [Epoch=060/200] [Need: 00:45:04] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [060][000/391]   Time 0.278 (0.278)   Data 0.221 (0.221)   Loss 0.3486 (0.3486)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:44:12]
  Epoch: [060][100/391]   Time 0.038 (0.046)   Data 0.000 (0.002)   Loss 0.4390 (0.3631)   Prec@1 85.156 (87.956)   Prec@5 99.219 (99.551)   [2019-11-18 05:44:16]
  Epoch: [060][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.3631 (0.3657)   Prec@1 87.500 (87.760)   Prec@5 99.219 (99.471)   [2019-11-18 05:44:20]
  Epoch: [060][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.4160 (0.3713)   Prec@1 85.938 (87.593)   Prec@5 100.000 (99.473)   [2019-11-18 05:44:25]
  **Train** Prec@1 87.412 Prec@5 99.490 Error@1 12.588
  **Test** Prec@1 83.070 Prec@5 99.190 Error@1 16.930

==>>[2019-11-18 05:44:31] [Epoch=061/200] [Need: 00:44:46] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [061][000/391]   Time 0.289 (0.289)   Data 0.213 (0.213)   Loss 0.3827 (0.3827)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-18 05:44:31]
  Epoch: [061][100/391]   Time 0.036 (0.045)   Data 0.000 (0.002)   Loss 0.3867 (0.3644)   Prec@1 85.938 (87.384)   Prec@5 99.219 (99.489)   [2019-11-18 05:44:35]
  Epoch: [061][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.4361 (0.3677)   Prec@1 84.375 (87.325)   Prec@5 98.438 (99.510)   [2019-11-18 05:44:40]
  Epoch: [061][300/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.3814 (0.3715)   Prec@1 85.938 (87.176)   Prec@5 100.000 (99.483)   [2019-11-18 05:44:44]
  **Train** Prec@1 87.210 Prec@5 99.472 Error@1 12.790
  **Test** Prec@1 83.970 Prec@5 99.240 Error@1 16.030

==>>[2019-11-18 05:44:50] [Epoch=062/200] [Need: 00:44:26] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [062][000/391]   Time 0.278 (0.278)   Data 0.228 (0.228)   Loss 0.3290 (0.3290)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:44:50]
  Epoch: [062][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.4309 (0.3640)   Prec@1 84.375 (87.144)   Prec@5 100.000 (99.567)   [2019-11-18 05:44:55]
  Epoch: [062][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.3590 (0.3706)   Prec@1 89.062 (86.975)   Prec@5 98.438 (99.506)   [2019-11-18 05:44:59]
  Epoch: [062][300/391]   Time 0.045 (0.046)   Data 0.000 (0.001)   Loss 0.3103 (0.3725)   Prec@1 88.281 (87.051)   Prec@5 100.000 (99.481)   [2019-11-18 05:45:04]
  **Train** Prec@1 87.158 Prec@5 99.472 Error@1 12.842
  **Test** Prec@1 82.530 Prec@5 98.980 Error@1 17.470

==>>[2019-11-18 05:45:10] [Epoch=063/200] [Need: 00:44:08] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [063][000/391]   Time 0.268 (0.268)   Data 0.225 (0.225)   Loss 0.3151 (0.3151)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-18 05:45:10]
  Epoch: [063][100/391]   Time 0.044 (0.046)   Data 0.000 (0.002)   Loss 0.3527 (0.3543)   Prec@1 86.719 (87.740)   Prec@5 99.219 (99.513)   [2019-11-18 05:45:14]
  Epoch: [063][200/391]   Time 0.051 (0.044)   Data 0.000 (0.001)   Loss 0.5375 (0.3692)   Prec@1 80.469 (87.321)   Prec@5 99.219 (99.514)   [2019-11-18 05:45:19]
  Epoch: [063][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.3426 (0.3690)   Prec@1 86.719 (87.458)   Prec@5 100.000 (99.522)   [2019-11-18 05:45:23]
  **Train** Prec@1 87.322 Prec@5 99.502 Error@1 12.678
  **Test** Prec@1 79.380 Prec@5 98.860 Error@1 20.620

==>>[2019-11-18 05:45:28] [Epoch=064/200] [Need: 00:43:47] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [064][000/391]   Time 0.292 (0.292)   Data 0.241 (0.241)   Loss 0.3485 (0.3485)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:45:29]
  Epoch: [064][100/391]   Time 0.050 (0.048)   Data 0.000 (0.003)   Loss 0.3509 (0.3520)   Prec@1 86.719 (87.817)   Prec@5 100.000 (99.567)   [2019-11-18 05:45:33]
  Epoch: [064][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.3568 (0.3658)   Prec@1 84.375 (87.290)   Prec@5 98.438 (99.502)   [2019-11-18 05:45:38]
  Epoch: [064][300/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.4990 (0.3711)   Prec@1 82.031 (87.259)   Prec@5 99.219 (99.476)   [2019-11-18 05:45:42]
  **Train** Prec@1 87.208 Prec@5 99.472 Error@1 12.792
  **Test** Prec@1 81.510 Prec@5 99.080 Error@1 18.490

==>>[2019-11-18 05:45:48] [Epoch=065/200] [Need: 00:43:28] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [065][000/391]   Time 0.293 (0.293)   Data 0.213 (0.213)   Loss 0.3810 (0.3810)   Prec@1 89.062 (89.062)   Prec@5 97.656 (97.656)   [2019-11-18 05:45:48]
  Epoch: [065][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.3782 (0.3658)   Prec@1 88.281 (87.848)   Prec@5 100.000 (99.466)   [2019-11-18 05:45:52]
  Epoch: [065][200/391]   Time 0.047 (0.045)   Data 0.000 (0.001)   Loss 0.2869 (0.3688)   Prec@1 90.625 (87.671)   Prec@5 100.000 (99.479)   [2019-11-18 05:45:57]
  Epoch: [065][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.3532 (0.3692)   Prec@1 85.938 (87.609)   Prec@5 100.000 (99.455)   [2019-11-18 05:46:01]
  **Train** Prec@1 87.606 Prec@5 99.478 Error@1 12.394
  **Test** Prec@1 81.320 Prec@5 99.070 Error@1 18.680

==>>[2019-11-18 05:46:07] [Epoch=066/200] [Need: 00:43:09] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [066][000/391]   Time 0.286 (0.286)   Data 0.233 (0.233)   Loss 0.3242 (0.3242)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-18 05:46:08]
  Epoch: [066][100/391]   Time 0.042 (0.045)   Data 0.000 (0.003)   Loss 0.4660 (0.3573)   Prec@1 82.812 (87.794)   Prec@5 100.000 (99.598)   [2019-11-18 05:46:12]
  Epoch: [066][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.3016 (0.3633)   Prec@1 91.406 (87.640)   Prec@5 100.000 (99.561)   [2019-11-18 05:46:16]
  Epoch: [066][300/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.1754 (0.3618)   Prec@1 94.531 (87.669)   Prec@5 100.000 (99.548)   [2019-11-18 05:46:21]
  **Train** Prec@1 87.570 Prec@5 99.532 Error@1 12.430
  **Test** Prec@1 84.240 Prec@5 99.310 Error@1 15.760

==>>[2019-11-18 05:46:26] [Epoch=067/200] [Need: 00:42:49] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [067][000/391]   Time 0.281 (0.281)   Data 0.218 (0.218)   Loss 0.4077 (0.4077)   Prec@1 83.594 (83.594)   Prec@5 97.656 (97.656)   [2019-11-18 05:46:27]
  Epoch: [067][100/391]   Time 0.038 (0.042)   Data 0.000 (0.002)   Loss 0.2851 (0.3561)   Prec@1 92.969 (87.570)   Prec@5 100.000 (99.528)   [2019-11-18 05:46:31]
  Epoch: [067][200/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.3761 (0.3674)   Prec@1 86.719 (87.310)   Prec@5 99.219 (99.545)   [2019-11-18 05:46:35]
  Epoch: [067][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.3757 (0.3658)   Prec@1 85.938 (87.443)   Prec@5 100.000 (99.541)   [2019-11-18 05:46:40]
  **Train** Prec@1 87.436 Prec@5 99.530 Error@1 12.564
  **Test** Prec@1 79.970 Prec@5 98.930 Error@1 20.030

==>>[2019-11-18 05:46:46] [Epoch=068/200] [Need: 00:42:29] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [068][000/391]   Time 0.286 (0.286)   Data 0.223 (0.223)   Loss 0.2877 (0.2877)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-18 05:46:46]
  Epoch: [068][100/391]   Time 0.037 (0.048)   Data 0.000 (0.002)   Loss 0.3036 (0.3564)   Prec@1 88.281 (87.972)   Prec@5 100.000 (99.613)   [2019-11-18 05:46:50]
  Epoch: [068][200/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.5394 (0.3622)   Prec@1 82.031 (87.749)   Prec@5 98.438 (99.537)   [2019-11-18 05:46:55]
  Epoch: [068][300/391]   Time 0.049 (0.045)   Data 0.000 (0.001)   Loss 0.3157 (0.3623)   Prec@1 91.406 (87.705)   Prec@5 99.219 (99.546)   [2019-11-18 05:46:59]
  **Train** Prec@1 87.644 Prec@5 99.542 Error@1 12.356
  **Test** Prec@1 81.820 Prec@5 99.100 Error@1 18.180

==>>[2019-11-18 05:47:05] [Epoch=069/200] [Need: 00:42:10] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [069][000/391]   Time 0.277 (0.277)   Data 0.221 (0.221)   Loss 0.2234 (0.2234)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2019-11-18 05:47:05]
  Epoch: [069][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.3513 (0.3523)   Prec@1 87.500 (87.616)   Prec@5 100.000 (99.621)   [2019-11-18 05:47:09]
  Epoch: [069][200/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.2848 (0.3531)   Prec@1 91.406 (87.539)   Prec@5 100.000 (99.600)   [2019-11-18 05:47:14]
  Epoch: [069][300/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.3810 (0.3576)   Prec@1 89.844 (87.469)   Prec@5 98.438 (99.548)   [2019-11-18 05:47:18]
  **Train** Prec@1 87.472 Prec@5 99.498 Error@1 12.528
  **Test** Prec@1 82.560 Prec@5 99.140 Error@1 17.440

==>>[2019-11-18 05:47:24] [Epoch=070/200] [Need: 00:41:50] [LR=0.0100][M=0.90] [Best : Accuracy=84.54, Error=15.46]
  Epoch: [070][000/391]   Time 0.254 (0.254)   Data 0.198 (0.198)   Loss 0.3488 (0.3488)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-18 05:47:24]
  Epoch: [070][100/391]   Time 0.037 (0.048)   Data 0.000 (0.002)   Loss 0.2935 (0.3453)   Prec@1 88.281 (88.096)   Prec@5 100.000 (99.621)   [2019-11-18 05:47:29]
  Epoch: [070][200/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.3443 (0.3521)   Prec@1 86.719 (87.920)   Prec@5 100.000 (99.584)   [2019-11-18 05:47:33]
  Epoch: [070][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.3353 (0.3574)   Prec@1 88.281 (87.689)   Prec@5 99.219 (99.548)   [2019-11-18 05:47:37]
  **Train** Prec@1 87.600 Prec@5 99.544 Error@1 12.400
  **Test** Prec@1 85.120 Prec@5 99.280 Error@1 14.880
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:47:43] [Epoch=071/200] [Need: 00:41:31] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [071][000/391]   Time 0.281 (0.281)   Data 0.212 (0.212)   Loss 0.1978 (0.1978)   Prec@1 93.750 (93.750)   Prec@5 98.438 (98.438)   [2019-11-18 05:47:43]
  Epoch: [071][100/391]   Time 0.042 (0.047)   Data 0.000 (0.002)   Loss 0.4458 (0.3421)   Prec@1 83.594 (88.258)   Prec@5 98.438 (99.629)   [2019-11-18 05:47:48]
  Epoch: [071][200/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.3002 (0.3505)   Prec@1 89.844 (87.959)   Prec@5 99.219 (99.592)   [2019-11-18 05:47:52]
  Epoch: [071][300/391]   Time 0.042 (0.044)   Data 0.000 (0.001)   Loss 0.2937 (0.3581)   Prec@1 89.062 (87.749)   Prec@5 100.000 (99.538)   [2019-11-18 05:47:56]
  **Train** Prec@1 87.722 Prec@5 99.532 Error@1 12.278
  **Test** Prec@1 83.020 Prec@5 99.090 Error@1 16.980

==>>[2019-11-18 05:48:02] [Epoch=072/200] [Need: 00:41:11] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [072][000/391]   Time 0.290 (0.290)   Data 0.241 (0.241)   Loss 0.3581 (0.3581)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-18 05:48:03]
  Epoch: [072][100/391]   Time 0.052 (0.048)   Data 0.000 (0.003)   Loss 0.4229 (0.3382)   Prec@1 87.500 (88.390)   Prec@5 98.438 (99.667)   [2019-11-18 05:48:07]
  Epoch: [072][200/391]   Time 0.045 (0.045)   Data 0.000 (0.001)   Loss 0.2595 (0.3454)   Prec@1 91.406 (88.141)   Prec@5 99.219 (99.604)   [2019-11-18 05:48:11]
  Epoch: [072][300/391]   Time 0.055 (0.045)   Data 0.000 (0.001)   Loss 0.4614 (0.3548)   Prec@1 83.594 (87.796)   Prec@5 100.000 (99.538)   [2019-11-18 05:48:16]
  **Train** Prec@1 87.554 Prec@5 99.530 Error@1 12.446
  **Test** Prec@1 83.590 Prec@5 98.800 Error@1 16.410

==>>[2019-11-18 05:48:22] [Epoch=073/200] [Need: 00:40:52] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [073][000/391]   Time 0.289 (0.289)   Data 0.219 (0.219)   Loss 0.4313 (0.4313)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-18 05:48:22]
  Epoch: [073][100/391]   Time 0.046 (0.043)   Data 0.000 (0.002)   Loss 0.3663 (0.3541)   Prec@1 85.156 (87.740)   Prec@5 99.219 (99.606)   [2019-11-18 05:48:26]
  Epoch: [073][200/391]   Time 0.067 (0.044)   Data 0.000 (0.001)   Loss 0.2741 (0.3576)   Prec@1 89.062 (87.725)   Prec@5 100.000 (99.530)   [2019-11-18 05:48:31]
  Epoch: [073][300/391]   Time 0.042 (0.044)   Data 0.000 (0.001)   Loss 0.2781 (0.3579)   Prec@1 89.844 (87.754)   Prec@5 100.000 (99.530)   [2019-11-18 05:48:35]
  **Train** Prec@1 87.774 Prec@5 99.530 Error@1 12.226
  **Test** Prec@1 84.700 Prec@5 99.270 Error@1 15.300

==>>[2019-11-18 05:48:40] [Epoch=074/200] [Need: 00:40:31] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [074][000/391]   Time 0.283 (0.283)   Data 0.213 (0.213)   Loss 0.4946 (0.4946)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-18 05:48:41]
  Epoch: [074][100/391]   Time 0.036 (0.044)   Data 0.000 (0.002)   Loss 0.3235 (0.3486)   Prec@1 87.500 (88.049)   Prec@5 99.219 (99.575)   [2019-11-18 05:48:45]
  Epoch: [074][200/391]   Time 0.046 (0.043)   Data 0.000 (0.001)   Loss 0.3598 (0.3567)   Prec@1 87.500 (87.593)   Prec@5 98.438 (99.561)   [2019-11-18 05:48:49]
  Epoch: [074][300/391]   Time 0.033 (0.044)   Data 0.000 (0.001)   Loss 0.3623 (0.3599)   Prec@1 84.375 (87.536)   Prec@5 100.000 (99.559)   [2019-11-18 05:48:54]
  **Train** Prec@1 87.380 Prec@5 99.558 Error@1 12.620
  **Test** Prec@1 82.810 Prec@5 99.190 Error@1 17.190

==>>[2019-11-18 05:49:00] [Epoch=075/200] [Need: 00:40:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [075][000/391]   Time 0.279 (0.279)   Data 0.225 (0.225)   Loss 0.3738 (0.3738)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-18 05:49:00]
  Epoch: [075][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.4292 (0.3477)   Prec@1 85.938 (87.809)   Prec@5 99.219 (99.520)   [2019-11-18 05:49:04]
  Epoch: [075][200/391]   Time 0.042 (0.044)   Data 0.000 (0.001)   Loss 0.3077 (0.3545)   Prec@1 89.062 (87.714)   Prec@5 100.000 (99.522)   [2019-11-18 05:49:09]
  Epoch: [075][300/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.4454 (0.3590)   Prec@1 84.375 (87.731)   Prec@5 99.219 (99.476)   [2019-11-18 05:49:13]
  **Train** Prec@1 87.670 Prec@5 99.492 Error@1 12.330
  **Test** Prec@1 82.730 Prec@5 99.000 Error@1 17.270

==>>[2019-11-18 05:49:19] [Epoch=076/200] [Need: 00:39:53] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [076][000/391]   Time 0.272 (0.272)   Data 0.222 (0.222)   Loss 0.3708 (0.3708)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-18 05:49:20]
  Epoch: [076][100/391]   Time 0.036 (0.041)   Data 0.000 (0.002)   Loss 0.2528 (0.3529)   Prec@1 93.750 (88.103)   Prec@5 98.438 (99.513)   [2019-11-18 05:49:23]
  Epoch: [076][200/391]   Time 0.043 (0.042)   Data 0.000 (0.001)   Loss 0.3214 (0.3624)   Prec@1 90.625 (87.698)   Prec@5 98.438 (99.534)   [2019-11-18 05:49:28]
  Epoch: [076][300/391]   Time 0.048 (0.043)   Data 0.000 (0.001)   Loss 0.2946 (0.3589)   Prec@1 90.625 (87.726)   Prec@5 100.000 (99.551)   [2019-11-18 05:49:32]
  **Train** Prec@1 87.676 Prec@5 99.542 Error@1 12.324
  **Test** Prec@1 83.900 Prec@5 99.420 Error@1 16.100

==>>[2019-11-18 05:49:38] [Epoch=077/200] [Need: 00:39:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [077][000/391]   Time 0.286 (0.286)   Data 0.233 (0.233)   Loss 0.2758 (0.2758)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:49:38]
  Epoch: [077][100/391]   Time 0.063 (0.046)   Data 0.000 (0.002)   Loss 0.4427 (0.3513)   Prec@1 85.156 (87.809)   Prec@5 99.219 (99.551)   [2019-11-18 05:49:43]
  Epoch: [077][200/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.3470 (0.3534)   Prec@1 90.625 (87.768)   Prec@5 99.219 (99.537)   [2019-11-18 05:49:47]
  Epoch: [077][300/391]   Time 0.044 (0.043)   Data 0.000 (0.001)   Loss 0.3060 (0.3526)   Prec@1 89.062 (87.695)   Prec@5 100.000 (99.561)   [2019-11-18 05:49:51]
  **Train** Prec@1 87.654 Prec@5 99.546 Error@1 12.346
  **Test** Prec@1 81.040 Prec@5 98.930 Error@1 18.960

==>>[2019-11-18 05:49:57] [Epoch=078/200] [Need: 00:39:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [078][000/391]   Time 0.281 (0.281)   Data 0.228 (0.228)   Loss 0.2977 (0.2977)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:49:57]
  Epoch: [078][100/391]   Time 0.041 (0.047)   Data 0.000 (0.002)   Loss 0.4209 (0.3355)   Prec@1 82.812 (88.320)   Prec@5 99.219 (99.629)   [2019-11-18 05:50:01]
  Epoch: [078][200/391]   Time 0.069 (0.046)   Data 0.000 (0.001)   Loss 0.2979 (0.3499)   Prec@1 89.062 (87.838)   Prec@5 99.219 (99.518)   [2019-11-18 05:50:06]
  Epoch: [078][300/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.2771 (0.3539)   Prec@1 88.281 (87.770)   Prec@5 99.219 (99.522)   [2019-11-18 05:50:10]
  **Train** Prec@1 87.646 Prec@5 99.552 Error@1 12.354
  **Test** Prec@1 83.710 Prec@5 99.190 Error@1 16.290

==>>[2019-11-18 05:50:16] [Epoch=079/200] [Need: 00:38:54] [LR=0.0100][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [079][000/391]   Time 0.279 (0.279)   Data 0.224 (0.224)   Loss 0.4035 (0.4035)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-18 05:50:16]
  Epoch: [079][100/391]   Time 0.043 (0.045)   Data 0.000 (0.002)   Loss 0.4158 (0.3520)   Prec@1 87.500 (87.956)   Prec@5 98.438 (99.598)   [2019-11-18 05:50:21]
  Epoch: [079][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.4694 (0.3493)   Prec@1 83.594 (88.017)   Prec@5 100.000 (99.600)   [2019-11-18 05:50:25]
  Epoch: [079][300/391]   Time 0.049 (0.045)   Data 0.004 (0.001)   Loss 0.2402 (0.3568)   Prec@1 92.969 (87.754)   Prec@5 100.000 (99.559)   [2019-11-18 05:50:30]
  **Train** Prec@1 87.670 Prec@5 99.552 Error@1 12.330
  **Test** Prec@1 85.050 Prec@5 99.310 Error@1 14.950

==>>[2019-11-18 05:50:36] [Epoch=080/200] [Need: 00:38:35] [LR=0.0010][M=0.90] [Best : Accuracy=85.12, Error=14.88]
  Epoch: [080][000/391]   Time 0.272 (0.272)   Data 0.223 (0.223)   Loss 0.5356 (0.5356)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-18 05:50:36]
  Epoch: [080][100/391]   Time 0.039 (0.046)   Data 0.000 (0.002)   Loss 0.3002 (0.2849)   Prec@1 88.281 (90.447)   Prec@5 100.000 (99.621)   [2019-11-18 05:50:40]
  Epoch: [080][200/391]   Time 0.053 (0.044)   Data 0.000 (0.001)   Loss 0.2878 (0.2724)   Prec@1 89.062 (90.870)   Prec@5 100.000 (99.693)   [2019-11-18 05:50:45]
  Epoch: [080][300/391]   Time 0.063 (0.043)   Data 0.000 (0.001)   Loss 0.2784 (0.2654)   Prec@1 90.625 (91.040)   Prec@5 100.000 (99.720)   [2019-11-18 05:50:49]
  **Train** Prec@1 91.190 Prec@5 99.710 Error@1 8.810
  **Test** Prec@1 88.890 Prec@5 99.560 Error@1 11.110
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:50:54] [Epoch=081/200] [Need: 00:38:15] [LR=0.0010][M=0.90] [Best : Accuracy=88.89, Error=11.11]
  Epoch: [081][000/391]   Time 0.311 (0.311)   Data 0.260 (0.260)   Loss 0.2053 (0.2053)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 05:50:55]
  Epoch: [081][100/391]   Time 0.039 (0.051)   Data 0.000 (0.003)   Loss 0.2700 (0.2326)   Prec@1 91.406 (92.079)   Prec@5 100.000 (99.807)   [2019-11-18 05:51:00]
  Epoch: [081][200/391]   Time 0.048 (0.048)   Data 0.000 (0.002)   Loss 0.2600 (0.2304)   Prec@1 93.750 (92.219)   Prec@5 100.000 (99.825)   [2019-11-18 05:51:04]
  Epoch: [081][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.2397 (0.2269)   Prec@1 91.406 (92.367)   Prec@5 100.000 (99.821)   [2019-11-18 05:51:08]
  **Train** Prec@1 92.264 Prec@5 99.806 Error@1 7.736
  **Test** Prec@1 88.580 Prec@5 99.520 Error@1 11.420

==>>[2019-11-18 05:51:14] [Epoch=082/200] [Need: 00:37:56] [LR=0.0010][M=0.90] [Best : Accuracy=88.89, Error=11.11]
  Epoch: [082][000/391]   Time 0.280 (0.280)   Data 0.231 (0.231)   Loss 0.2016 (0.2016)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:51:15]
  Epoch: [082][100/391]   Time 0.037 (0.049)   Data 0.000 (0.003)   Loss 0.3295 (0.2105)   Prec@1 89.062 (92.574)   Prec@5 100.000 (99.838)   [2019-11-18 05:51:19]
  Epoch: [082][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.1875 (0.2161)   Prec@1 95.312 (92.456)   Prec@5 99.219 (99.825)   [2019-11-18 05:51:24]
  Epoch: [082][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1908 (0.2191)   Prec@1 92.969 (92.393)   Prec@5 100.000 (99.811)   [2019-11-18 05:51:28]
  **Train** Prec@1 92.390 Prec@5 99.820 Error@1 7.610
  **Test** Prec@1 88.700 Prec@5 99.550 Error@1 11.300

==>>[2019-11-18 05:51:34] [Epoch=083/200] [Need: 00:37:37] [LR=0.0010][M=0.90] [Best : Accuracy=88.89, Error=11.11]
  Epoch: [083][000/391]   Time 0.281 (0.281)   Data 0.229 (0.229)   Loss 0.1671 (0.1671)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:51:34]
  Epoch: [083][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.1582 (0.2148)   Prec@1 94.531 (92.597)   Prec@5 100.000 (99.853)   [2019-11-18 05:51:39]
  Epoch: [083][200/391]   Time 0.068 (0.046)   Data 0.000 (0.001)   Loss 0.2312 (0.2132)   Prec@1 92.969 (92.673)   Prec@5 100.000 (99.845)   [2019-11-18 05:51:43]
  Epoch: [083][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.2859 (0.2121)   Prec@1 86.719 (92.696)   Prec@5 99.219 (99.855)   [2019-11-18 05:51:47]
  **Train** Prec@1 92.680 Prec@5 99.836 Error@1 7.320
  **Test** Prec@1 88.860 Prec@5 99.580 Error@1 11.140

==>>[2019-11-18 05:51:53] [Epoch=084/200] [Need: 00:37:18] [LR=0.0010][M=0.90] [Best : Accuracy=88.89, Error=11.11]
  Epoch: [084][000/391]   Time 0.300 (0.300)   Data 0.233 (0.233)   Loss 0.2354 (0.2354)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 05:51:54]
  Epoch: [084][100/391]   Time 0.046 (0.047)   Data 0.000 (0.002)   Loss 0.1695 (0.2060)   Prec@1 93.750 (92.814)   Prec@5 99.219 (99.814)   [2019-11-18 05:51:58]
  Epoch: [084][200/391]   Time 0.032 (0.045)   Data 0.000 (0.001)   Loss 0.1779 (0.2056)   Prec@1 92.188 (92.802)   Prec@5 100.000 (99.833)   [2019-11-18 05:52:02]
  Epoch: [084][300/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.2696 (0.2053)   Prec@1 92.969 (92.844)   Prec@5 99.219 (99.826)   [2019-11-18 05:52:07]
  **Train** Prec@1 92.816 Prec@5 99.832 Error@1 7.184
  **Test** Prec@1 89.020 Prec@5 99.540 Error@1 10.980
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:52:12] [Epoch=085/200] [Need: 00:36:59] [LR=0.0010][M=0.90] [Best : Accuracy=89.02, Error=10.98]
  Epoch: [085][000/391]   Time 0.288 (0.288)   Data 0.239 (0.239)   Loss 0.1622 (0.1622)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-18 05:52:13]
  Epoch: [085][100/391]   Time 0.037 (0.047)   Data 0.000 (0.003)   Loss 0.1614 (0.2121)   Prec@1 93.750 (92.953)   Prec@5 100.000 (99.807)   [2019-11-18 05:52:17]
  Epoch: [085][200/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.1379 (0.2028)   Prec@1 95.312 (93.000)   Prec@5 100.000 (99.837)   [2019-11-18 05:52:22]
  Epoch: [085][300/391]   Time 0.075 (0.046)   Data 0.000 (0.001)   Loss 0.1701 (0.2039)   Prec@1 96.094 (92.958)   Prec@5 100.000 (99.844)   [2019-11-18 05:52:26]
  **Train** Prec@1 92.988 Prec@5 99.840 Error@1 7.012
  **Test** Prec@1 89.260 Prec@5 99.670 Error@1 10.740
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:52:32] [Epoch=086/200] [Need: 00:36:41] [LR=0.0010][M=0.90] [Best : Accuracy=89.26, Error=10.74]
  Epoch: [086][000/391]   Time 0.251 (0.251)   Data 0.202 (0.202)   Loss 0.2106 (0.2106)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:52:33]
  Epoch: [086][100/391]   Time 0.035 (0.046)   Data 0.000 (0.002)   Loss 0.1591 (0.1848)   Prec@1 96.094 (93.626)   Prec@5 100.000 (99.907)   [2019-11-18 05:52:37]
  Epoch: [086][200/391]   Time 0.040 (0.043)   Data 0.000 (0.001)   Loss 0.1568 (0.1917)   Prec@1 95.312 (93.416)   Prec@5 99.219 (99.876)   [2019-11-18 05:52:41]
  Epoch: [086][300/391]   Time 0.032 (0.042)   Data 0.000 (0.001)   Loss 0.2377 (0.1954)   Prec@1 88.281 (93.254)   Prec@5 100.000 (99.862)   [2019-11-18 05:52:45]
  **Train** Prec@1 93.198 Prec@5 99.862 Error@1 6.802
  **Test** Prec@1 88.150 Prec@5 99.560 Error@1 11.850

==>>[2019-11-18 05:52:51] [Epoch=087/200] [Need: 00:36:20] [LR=0.0010][M=0.90] [Best : Accuracy=89.26, Error=10.74]
  Epoch: [087][000/391]   Time 0.292 (0.292)   Data 0.216 (0.216)   Loss 0.1046 (0.1046)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 05:52:51]
  Epoch: [087][100/391]   Time 0.036 (0.047)   Data 0.000 (0.002)   Loss 0.1818 (0.1879)   Prec@1 92.188 (93.286)   Prec@5 100.000 (99.869)   [2019-11-18 05:52:56]
  Epoch: [087][200/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.2456 (0.1917)   Prec@1 92.188 (93.233)   Prec@5 100.000 (99.833)   [2019-11-18 05:53:00]
  Epoch: [087][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1804 (0.1930)   Prec@1 92.969 (93.195)   Prec@5 100.000 (99.852)   [2019-11-18 05:53:04]
  **Train** Prec@1 93.186 Prec@5 99.860 Error@1 6.814
  **Test** Prec@1 89.160 Prec@5 99.560 Error@1 10.840

==>>[2019-11-18 05:53:10] [Epoch=088/200] [Need: 00:36:01] [LR=0.0010][M=0.90] [Best : Accuracy=89.26, Error=10.74]
  Epoch: [088][000/391]   Time 0.280 (0.280)   Data 0.223 (0.223)   Loss 0.1620 (0.1620)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:53:10]
  Epoch: [088][100/391]   Time 0.036 (0.046)   Data 0.000 (0.002)   Loss 0.2043 (0.1955)   Prec@1 90.625 (93.162)   Prec@5 100.000 (99.899)   [2019-11-18 05:53:15]
  Epoch: [088][200/391]   Time 0.046 (0.045)   Data 0.000 (0.001)   Loss 0.1689 (0.1945)   Prec@1 93.750 (93.276)   Prec@5 100.000 (99.899)   [2019-11-18 05:53:19]
  Epoch: [088][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1615 (0.1956)   Prec@1 93.750 (93.213)   Prec@5 100.000 (99.883)   [2019-11-18 05:53:24]
  **Train** Prec@1 93.186 Prec@5 99.866 Error@1 6.814
  **Test** Prec@1 89.040 Prec@5 99.670 Error@1 10.960

==>>[2019-11-18 05:53:30] [Epoch=089/200] [Need: 00:35:42] [LR=0.0010][M=0.90] [Best : Accuracy=89.26, Error=10.74]
  Epoch: [089][000/391]   Time 0.287 (0.287)   Data 0.237 (0.237)   Loss 0.1905 (0.1905)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 05:53:30]
  Epoch: [089][100/391]   Time 0.043 (0.046)   Data 0.000 (0.003)   Loss 0.1661 (0.1909)   Prec@1 93.750 (93.363)   Prec@5 99.219 (99.838)   [2019-11-18 05:53:34]
  Epoch: [089][200/391]   Time 0.046 (0.045)   Data 0.000 (0.001)   Loss 0.1506 (0.1925)   Prec@1 94.531 (93.373)   Prec@5 100.000 (99.864)   [2019-11-18 05:53:39]
  Epoch: [089][300/391]   Time 0.048 (0.045)   Data 0.000 (0.001)   Loss 0.1977 (0.1870)   Prec@1 92.969 (93.610)   Prec@5 100.000 (99.873)   [2019-11-18 05:53:43]
  **Train** Prec@1 93.558 Prec@5 99.870 Error@1 6.442
  **Test** Prec@1 89.360 Prec@5 99.710 Error@1 10.640
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:53:49] [Epoch=090/200] [Need: 00:35:23] [LR=0.0010][M=0.90] [Best : Accuracy=89.36, Error=10.64]
  Epoch: [090][000/391]   Time 0.282 (0.282)   Data 0.219 (0.219)   Loss 0.2111 (0.2111)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 05:53:49]
  Epoch: [090][100/391]   Time 0.047 (0.046)   Data 0.000 (0.002)   Loss 0.0891 (0.1826)   Prec@1 97.656 (93.673)   Prec@5 100.000 (99.930)   [2019-11-18 05:53:54]
  Epoch: [090][200/391]   Time 0.045 (0.046)   Data 0.000 (0.001)   Loss 0.2997 (0.1814)   Prec@1 89.844 (93.754)   Prec@5 99.219 (99.914)   [2019-11-18 05:53:59]
  Epoch: [090][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.2446 (0.1832)   Prec@1 92.969 (93.675)   Prec@5 100.000 (99.888)   [2019-11-18 05:54:03]
  **Train** Prec@1 93.640 Prec@5 99.884 Error@1 6.360
  **Test** Prec@1 89.190 Prec@5 99.670 Error@1 10.810

==>>[2019-11-18 05:54:08] [Epoch=091/200] [Need: 00:35:03] [LR=0.0010][M=0.90] [Best : Accuracy=89.36, Error=10.64]
  Epoch: [091][000/391]   Time 0.288 (0.288)   Data 0.238 (0.238)   Loss 0.2332 (0.2332)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-18 05:54:09]
  Epoch: [091][100/391]   Time 0.039 (0.051)   Data 0.000 (0.003)   Loss 0.1869 (0.1861)   Prec@1 91.406 (93.456)   Prec@5 100.000 (99.884)   [2019-11-18 05:54:14]
  Epoch: [091][200/391]   Time 0.045 (0.047)   Data 0.000 (0.001)   Loss 0.1256 (0.1857)   Prec@1 96.094 (93.501)   Prec@5 100.000 (99.856)   [2019-11-18 05:54:18]
  Epoch: [091][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.2725 (0.1825)   Prec@1 90.625 (93.618)   Prec@5 99.219 (99.870)   [2019-11-18 05:54:22]
  **Train** Prec@1 93.674 Prec@5 99.870 Error@1 6.326
  **Test** Prec@1 89.390 Prec@5 99.670 Error@1 10.610
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:54:28] [Epoch=092/200] [Need: 00:34:44] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [092][000/391]   Time 0.282 (0.282)   Data 0.216 (0.216)   Loss 0.1322 (0.1322)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:54:28]
  Epoch: [092][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.1701 (0.1781)   Prec@1 92.188 (93.835)   Prec@5 100.000 (99.884)   [2019-11-18 05:54:32]
  Epoch: [092][200/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.2146 (0.1795)   Prec@1 92.969 (93.777)   Prec@5 100.000 (99.876)   [2019-11-18 05:54:37]
  Epoch: [092][300/391]   Time 0.049 (0.044)   Data 0.000 (0.001)   Loss 0.1985 (0.1783)   Prec@1 93.750 (93.843)   Prec@5 100.000 (99.873)   [2019-11-18 05:54:41]
  **Train** Prec@1 93.852 Prec@5 99.866 Error@1 6.148
  **Test** Prec@1 89.280 Prec@5 99.630 Error@1 10.720

==>>[2019-11-18 05:54:47] [Epoch=093/200] [Need: 00:34:24] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [093][000/391]   Time 0.300 (0.300)   Data 0.248 (0.248)   Loss 0.1634 (0.1634)   Prec@1 93.750 (93.750)   Prec@5 98.438 (98.438)   [2019-11-18 05:54:47]
  Epoch: [093][100/391]   Time 0.038 (0.049)   Data 0.000 (0.003)   Loss 0.1533 (0.1690)   Prec@1 93.750 (94.152)   Prec@5 100.000 (99.892)   [2019-11-18 05:54:52]
  Epoch: [093][200/391]   Time 0.034 (0.046)   Data 0.000 (0.001)   Loss 0.2432 (0.1755)   Prec@1 89.844 (93.909)   Prec@5 99.219 (99.860)   [2019-11-18 05:54:56]
  Epoch: [093][300/391]   Time 0.043 (0.044)   Data 0.000 (0.001)   Loss 0.1969 (0.1771)   Prec@1 92.188 (93.864)   Prec@5 100.000 (99.878)   [2019-11-18 05:55:00]
  **Train** Prec@1 93.888 Prec@5 99.880 Error@1 6.112
  **Test** Prec@1 89.080 Prec@5 99.720 Error@1 10.920

==>>[2019-11-18 05:55:05] [Epoch=094/200] [Need: 00:34:04] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [094][000/391]   Time 0.273 (0.273)   Data 0.216 (0.216)   Loss 0.2335 (0.2335)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 05:55:06]
  Epoch: [094][100/391]   Time 0.043 (0.046)   Data 0.000 (0.002)   Loss 0.1624 (0.1648)   Prec@1 94.531 (94.121)   Prec@5 100.000 (99.899)   [2019-11-18 05:55:10]
  Epoch: [094][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.1270 (0.1672)   Prec@1 95.312 (94.123)   Prec@5 100.000 (99.899)   [2019-11-18 05:55:14]
  Epoch: [094][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1662 (0.1682)   Prec@1 94.531 (94.041)   Prec@5 100.000 (99.907)   [2019-11-18 05:55:19]
  **Train** Prec@1 93.954 Prec@5 99.902 Error@1 6.046
  **Test** Prec@1 89.040 Prec@5 99.720 Error@1 10.960

==>>[2019-11-18 05:55:25] [Epoch=095/200] [Need: 00:33:45] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [095][000/391]   Time 0.286 (0.286)   Data 0.231 (0.231)   Loss 0.0908 (0.0908)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 05:55:25]
  Epoch: [095][100/391]   Time 0.039 (0.046)   Data 0.000 (0.002)   Loss 0.0836 (0.1610)   Prec@1 96.875 (94.253)   Prec@5 100.000 (99.907)   [2019-11-18 05:55:29]
  Epoch: [095][200/391]   Time 0.046 (0.044)   Data 0.000 (0.001)   Loss 0.1473 (0.1656)   Prec@1 93.750 (94.111)   Prec@5 100.000 (99.903)   [2019-11-18 05:55:33]
  Epoch: [095][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1895 (0.1692)   Prec@1 92.969 (94.051)   Prec@5 100.000 (99.899)   [2019-11-18 05:55:38]
  **Train** Prec@1 94.098 Prec@5 99.894 Error@1 5.902
  **Test** Prec@1 89.010 Prec@5 99.700 Error@1 10.990

==>>[2019-11-18 05:55:44] [Epoch=096/200] [Need: 00:33:26] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [096][000/391]   Time 0.295 (0.295)   Data 0.214 (0.214)   Loss 0.0786 (0.0786)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 05:55:44]
  Epoch: [096][100/391]   Time 0.042 (0.046)   Data 0.000 (0.002)   Loss 0.0418 (0.1670)   Prec@1 98.438 (94.268)   Prec@5 100.000 (99.876)   [2019-11-18 05:55:49]
  Epoch: [096][200/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1369 (0.1666)   Prec@1 93.750 (94.205)   Prec@5 100.000 (99.880)   [2019-11-18 05:55:53]
  Epoch: [096][300/391]   Time 0.033 (0.045)   Data 0.000 (0.001)   Loss 0.2367 (0.1672)   Prec@1 89.844 (94.181)   Prec@5 100.000 (99.886)   [2019-11-18 05:55:57]
  **Train** Prec@1 94.152 Prec@5 99.896 Error@1 5.848
  **Test** Prec@1 89.310 Prec@5 99.660 Error@1 10.690

==>>[2019-11-18 05:56:03] [Epoch=097/200] [Need: 00:33:07] [LR=0.0010][M=0.90] [Best : Accuracy=89.39, Error=10.61]
  Epoch: [097][000/391]   Time 0.276 (0.276)   Data 0.218 (0.218)   Loss 0.1753 (0.1753)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:56:04]
  Epoch: [097][100/391]   Time 0.035 (0.045)   Data 0.000 (0.002)   Loss 0.1942 (0.1694)   Prec@1 92.969 (93.827)   Prec@5 100.000 (99.892)   [2019-11-18 05:56:08]
  Epoch: [097][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.2121 (0.1683)   Prec@1 92.969 (93.972)   Prec@5 99.219 (99.895)   [2019-11-18 05:56:13]
  Epoch: [097][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1194 (0.1695)   Prec@1 96.875 (94.030)   Prec@5 100.000 (99.881)   [2019-11-18 05:56:17]
  **Train** Prec@1 93.954 Prec@5 99.872 Error@1 6.046
  **Test** Prec@1 89.560 Prec@5 99.750 Error@1 10.440
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:56:23] [Epoch=098/200] [Need: 00:32:47] [LR=0.0010][M=0.90] [Best : Accuracy=89.56, Error=10.44]
  Epoch: [098][000/391]   Time 0.287 (0.287)   Data 0.220 (0.220)   Loss 0.1424 (0.1424)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:56:23]
  Epoch: [098][100/391]   Time 0.038 (0.046)   Data 0.000 (0.002)   Loss 0.2243 (0.1633)   Prec@1 91.406 (94.554)   Prec@5 100.000 (99.899)   [2019-11-18 05:56:27]
  Epoch: [098][200/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1756 (0.1645)   Prec@1 95.312 (94.341)   Prec@5 100.000 (99.903)   [2019-11-18 05:56:32]
  Epoch: [098][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1499 (0.1666)   Prec@1 95.312 (94.264)   Prec@5 100.000 (99.901)   [2019-11-18 05:56:36]
  **Train** Prec@1 94.408 Prec@5 99.898 Error@1 5.592
  **Test** Prec@1 89.650 Prec@5 99.650 Error@1 10.350
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:56:42] [Epoch=099/200] [Need: 00:32:28] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [099][000/391]   Time 0.288 (0.288)   Data 0.215 (0.215)   Loss 0.1453 (0.1453)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:56:42]
  Epoch: [099][100/391]   Time 0.035 (0.044)   Data 0.000 (0.002)   Loss 0.1922 (0.1590)   Prec@1 92.969 (94.431)   Prec@5 99.219 (99.869)   [2019-11-18 05:56:46]
  Epoch: [099][200/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.1512 (0.1602)   Prec@1 95.312 (94.419)   Prec@5 100.000 (99.868)   [2019-11-18 05:56:51]
  Epoch: [099][300/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.1565 (0.1640)   Prec@1 94.531 (94.157)   Prec@5 100.000 (99.868)   [2019-11-18 05:56:55]
  **Train** Prec@1 94.112 Prec@5 99.876 Error@1 5.888
  **Test** Prec@1 89.590 Prec@5 99.700 Error@1 10.410

==>>[2019-11-18 05:57:01] [Epoch=100/200] [Need: 00:32:09] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [100][000/391]   Time 0.291 (0.291)   Data 0.242 (0.242)   Loss 0.1476 (0.1476)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 05:57:02]
  Epoch: [100][100/391]   Time 0.036 (0.044)   Data 0.000 (0.003)   Loss 0.2731 (0.1549)   Prec@1 92.188 (94.454)   Prec@5 100.000 (99.899)   [2019-11-18 05:57:06]
  Epoch: [100][200/391]   Time 0.040 (0.043)   Data 0.000 (0.001)   Loss 0.1790 (0.1574)   Prec@1 95.312 (94.512)   Prec@5 100.000 (99.914)   [2019-11-18 05:57:10]
  Epoch: [100][300/391]   Time 0.050 (0.043)   Data 0.000 (0.001)   Loss 0.1085 (0.1592)   Prec@1 96.094 (94.435)   Prec@5 100.000 (99.914)   [2019-11-18 05:57:15]
  **Train** Prec@1 94.440 Prec@5 99.908 Error@1 5.560
  **Test** Prec@1 89.700 Prec@5 99.640 Error@1 10.300
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:57:21] [Epoch=101/200] [Need: 00:31:50] [LR=0.0010][M=0.90] [Best : Accuracy=89.70, Error=10.30]
  Epoch: [101][000/391]   Time 0.272 (0.272)   Data 0.218 (0.218)   Loss 0.1072 (0.1072)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 05:57:21]
  Epoch: [101][100/391]   Time 0.044 (0.049)   Data 0.000 (0.002)   Loss 0.0624 (0.1569)   Prec@1 98.438 (94.531)   Prec@5 100.000 (99.899)   [2019-11-18 05:57:26]
  Epoch: [101][200/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.1916 (0.1609)   Prec@1 91.406 (94.407)   Prec@5 100.000 (99.887)   [2019-11-18 05:57:30]
  Epoch: [101][300/391]   Time 0.043 (0.044)   Data 0.000 (0.001)   Loss 0.2229 (0.1618)   Prec@1 90.625 (94.316)   Prec@5 100.000 (99.901)   [2019-11-18 05:57:34]
  **Train** Prec@1 94.298 Prec@5 99.898 Error@1 5.702
  **Test** Prec@1 89.500 Prec@5 99.660 Error@1 10.500

==>>[2019-11-18 05:57:40] [Epoch=102/200] [Need: 00:31:30] [LR=0.0010][M=0.90] [Best : Accuracy=89.70, Error=10.30]
  Epoch: [102][000/391]   Time 0.275 (0.275)   Data 0.226 (0.226)   Loss 0.1478 (0.1478)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 05:57:40]
  Epoch: [102][100/391]   Time 0.039 (0.042)   Data 0.000 (0.002)   Loss 0.1211 (0.1468)   Prec@1 96.094 (94.895)   Prec@5 100.000 (99.907)   [2019-11-18 05:57:44]
  Epoch: [102][200/391]   Time 0.038 (0.041)   Data 0.000 (0.001)   Loss 0.1857 (0.1547)   Prec@1 92.969 (94.558)   Prec@5 100.000 (99.907)   [2019-11-18 05:57:48]
  Epoch: [102][300/391]   Time 0.038 (0.040)   Data 0.000 (0.001)   Loss 0.1830 (0.1545)   Prec@1 92.969 (94.536)   Prec@5 100.000 (99.904)   [2019-11-18 05:57:52]
  **Train** Prec@1 94.570 Prec@5 99.908 Error@1 5.430
  **Test** Prec@1 89.090 Prec@5 99.580 Error@1 10.910

==>>[2019-11-18 05:57:58] [Epoch=103/200] [Need: 00:31:10] [LR=0.0010][M=0.90] [Best : Accuracy=89.70, Error=10.30]
  Epoch: [103][000/391]   Time 0.285 (0.285)   Data 0.220 (0.220)   Loss 0.1019 (0.1019)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 05:57:59]
  Epoch: [103][100/391]   Time 0.055 (0.049)   Data 0.000 (0.002)   Loss 0.2235 (0.1541)   Prec@1 91.406 (94.779)   Prec@5 100.000 (99.923)   [2019-11-18 05:58:03]
  Epoch: [103][200/391]   Time 0.036 (0.046)   Data 0.000 (0.001)   Loss 0.0960 (0.1527)   Prec@1 96.094 (94.761)   Prec@5 100.000 (99.903)   [2019-11-18 05:58:08]
  Epoch: [103][300/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.0971 (0.1530)   Prec@1 96.875 (94.687)   Prec@5 100.000 (99.891)   [2019-11-18 05:58:12]
  **Train** Prec@1 94.622 Prec@5 99.896 Error@1 5.378
  **Test** Prec@1 89.880 Prec@5 99.700 Error@1 10.120
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:58:18] [Epoch=104/200] [Need: 00:30:51] [LR=0.0010][M=0.90] [Best : Accuracy=89.88, Error=10.12]
  Epoch: [104][000/391]   Time 0.289 (0.289)   Data 0.239 (0.239)   Loss 0.0816 (0.0816)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 05:58:18]
  Epoch: [104][100/391]   Time 0.036 (0.048)   Data 0.000 (0.003)   Loss 0.1563 (0.1519)   Prec@1 95.312 (94.616)   Prec@5 100.000 (99.899)   [2019-11-18 05:58:23]
  Epoch: [104][200/391]   Time 0.066 (0.047)   Data 0.000 (0.001)   Loss 0.0708 (0.1501)   Prec@1 96.875 (94.687)   Prec@5 100.000 (99.911)   [2019-11-18 05:58:27]
  Epoch: [104][300/391]   Time 0.044 (0.046)   Data 0.000 (0.001)   Loss 0.1481 (0.1524)   Prec@1 94.531 (94.578)   Prec@5 100.000 (99.914)   [2019-11-18 05:58:32]
  **Train** Prec@1 94.598 Prec@5 99.910 Error@1 5.402
  **Test** Prec@1 90.230 Prec@5 99.620 Error@1 9.770
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 05:58:38] [Epoch=105/200] [Need: 00:30:32] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [105][000/391]   Time 0.284 (0.284)   Data 0.233 (0.233)   Loss 0.1977 (0.1977)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-18 05:58:38]
  Epoch: [105][100/391]   Time 0.038 (0.045)   Data 0.000 (0.002)   Loss 0.2362 (0.1511)   Prec@1 89.844 (94.794)   Prec@5 100.000 (99.930)   [2019-11-18 05:58:42]
  Epoch: [105][200/391]   Time 0.060 (0.043)   Data 0.000 (0.001)   Loss 0.2169 (0.1526)   Prec@1 94.531 (94.733)   Prec@5 100.000 (99.918)   [2019-11-18 05:58:46]
  Epoch: [105][300/391]   Time 0.049 (0.044)   Data 0.000 (0.001)   Loss 0.2223 (0.1542)   Prec@1 91.406 (94.664)   Prec@5 100.000 (99.904)   [2019-11-18 05:58:51]
  **Train** Prec@1 94.680 Prec@5 99.904 Error@1 5.320
  **Test** Prec@1 89.140 Prec@5 99.650 Error@1 10.860

==>>[2019-11-18 05:58:56] [Epoch=106/200] [Need: 00:30:12] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [106][000/391]   Time 0.282 (0.282)   Data 0.213 (0.213)   Loss 0.0967 (0.0967)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 05:58:57]
  Epoch: [106][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.2058 (0.1462)   Prec@1 93.750 (94.918)   Prec@5 100.000 (99.930)   [2019-11-18 05:59:01]
  Epoch: [106][200/391]   Time 0.053 (0.046)   Data 0.000 (0.001)   Loss 0.0908 (0.1457)   Prec@1 95.312 (94.897)   Prec@5 100.000 (99.918)   [2019-11-18 05:59:06]
  Epoch: [106][300/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.1317 (0.1473)   Prec@1 96.094 (94.845)   Prec@5 100.000 (99.912)   [2019-11-18 05:59:10]
  **Train** Prec@1 94.702 Prec@5 99.908 Error@1 5.298
  **Test** Prec@1 89.170 Prec@5 99.660 Error@1 10.830

==>>[2019-11-18 05:59:16] [Epoch=107/200] [Need: 00:29:53] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [107][000/391]   Time 0.279 (0.279)   Data 0.228 (0.228)   Loss 0.1295 (0.1295)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.219)   [2019-11-18 05:59:16]
  Epoch: [107][100/391]   Time 0.065 (0.044)   Data 0.000 (0.002)   Loss 0.1555 (0.1387)   Prec@1 92.969 (95.111)   Prec@5 100.000 (99.946)   [2019-11-18 05:59:20]
  Epoch: [107][200/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.1509 (0.1469)   Prec@1 94.531 (94.764)   Prec@5 100.000 (99.953)   [2019-11-18 05:59:24]
  Epoch: [107][300/391]   Time 0.073 (0.044)   Data 0.000 (0.001)   Loss 0.1455 (0.1505)   Prec@1 94.531 (94.697)   Prec@5 100.000 (99.945)   [2019-11-18 05:59:29]
  **Train** Prec@1 94.582 Prec@5 99.936 Error@1 5.418
  **Test** Prec@1 89.270 Prec@5 99.680 Error@1 10.730

==>>[2019-11-18 05:59:35] [Epoch=108/200] [Need: 00:29:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [108][000/391]   Time 0.287 (0.287)   Data 0.234 (0.234)   Loss 0.1865 (0.1865)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 05:59:35]
  Epoch: [108][100/391]   Time 0.039 (0.045)   Data 0.000 (0.002)   Loss 0.1519 (0.1410)   Prec@1 93.750 (95.019)   Prec@5 100.000 (99.946)   [2019-11-18 05:59:39]
  Epoch: [108][200/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.1551 (0.1489)   Prec@1 94.531 (94.698)   Prec@5 99.219 (99.895)   [2019-11-18 05:59:44]
  Epoch: [108][300/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.1331 (0.1464)   Prec@1 94.531 (94.786)   Prec@5 100.000 (99.904)   [2019-11-18 05:59:48]
  **Train** Prec@1 94.820 Prec@5 99.912 Error@1 5.180
  **Test** Prec@1 90.040 Prec@5 99.690 Error@1 9.960

==>>[2019-11-18 05:59:53] [Epoch=109/200] [Need: 00:29:14] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [109][000/391]   Time 0.283 (0.283)   Data 0.236 (0.236)   Loss 0.1559 (0.1559)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 05:59:54]
  Epoch: [109][100/391]   Time 0.065 (0.047)   Data 0.000 (0.003)   Loss 0.1565 (0.1389)   Prec@1 94.531 (95.111)   Prec@5 100.000 (99.946)   [2019-11-18 05:59:58]
  Epoch: [109][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.1746 (0.1432)   Prec@1 92.188 (95.002)   Prec@5 100.000 (99.914)   [2019-11-18 06:00:03]
  Epoch: [109][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.1154 (0.1449)   Prec@1 95.312 (94.965)   Prec@5 100.000 (99.907)   [2019-11-18 06:00:07]
  **Train** Prec@1 94.862 Prec@5 99.902 Error@1 5.138
  **Test** Prec@1 89.380 Prec@5 99.680 Error@1 10.620

==>>[2019-11-18 06:00:13] [Epoch=110/200] [Need: 00:28:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [110][000/391]   Time 0.274 (0.274)   Data 0.218 (0.218)   Loss 0.1279 (0.1279)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:00:13]
  Epoch: [110][100/391]   Time 0.038 (0.044)   Data 0.000 (0.002)   Loss 0.1727 (0.1397)   Prec@1 96.875 (95.142)   Prec@5 100.000 (99.923)   [2019-11-18 06:00:17]
  Epoch: [110][200/391]   Time 0.043 (0.043)   Data 0.000 (0.001)   Loss 0.1571 (0.1441)   Prec@1 93.750 (94.943)   Prec@5 100.000 (99.918)   [2019-11-18 06:00:21]
  Epoch: [110][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0846 (0.1431)   Prec@1 96.875 (94.949)   Prec@5 100.000 (99.930)   [2019-11-18 06:00:26]
  **Train** Prec@1 94.906 Prec@5 99.932 Error@1 5.094
  **Test** Prec@1 88.840 Prec@5 99.660 Error@1 11.160

==>>[2019-11-18 06:00:32] [Epoch=111/200] [Need: 00:28:35] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [111][000/391]   Time 0.270 (0.270)   Data 0.204 (0.204)   Loss 0.1558 (0.1558)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:00:32]
  Epoch: [111][100/391]   Time 0.038 (0.045)   Data 0.000 (0.002)   Loss 0.2086 (0.1481)   Prec@1 92.188 (94.879)   Prec@5 100.000 (99.892)   [2019-11-18 06:00:37]
  Epoch: [111][200/391]   Time 0.054 (0.043)   Data 0.000 (0.001)   Loss 0.1600 (0.1429)   Prec@1 96.875 (95.044)   Prec@5 100.000 (99.934)   [2019-11-18 06:00:41]
  Epoch: [111][300/391]   Time 0.056 (0.043)   Data 0.000 (0.001)   Loss 0.1102 (0.1455)   Prec@1 94.531 (94.967)   Prec@5 100.000 (99.935)   [2019-11-18 06:00:45]
  **Train** Prec@1 94.908 Prec@5 99.918 Error@1 5.092
  **Test** Prec@1 89.210 Prec@5 99.650 Error@1 10.790

==>>[2019-11-18 06:00:51] [Epoch=112/200] [Need: 00:28:16] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [112][000/391]   Time 0.277 (0.277)   Data 0.213 (0.213)   Loss 0.0983 (0.0983)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:00:51]
  Epoch: [112][100/391]   Time 0.039 (0.045)   Data 0.000 (0.002)   Loss 0.2622 (0.1382)   Prec@1 89.844 (95.166)   Prec@5 99.219 (99.946)   [2019-11-18 06:00:56]
  Epoch: [112][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.1341 (0.1406)   Prec@1 94.531 (95.021)   Prec@5 100.000 (99.914)   [2019-11-18 06:01:00]
  Epoch: [112][300/391]   Time 0.043 (0.045)   Data 0.000 (0.001)   Loss 0.0943 (0.1429)   Prec@1 95.312 (94.928)   Prec@5 100.000 (99.909)   [2019-11-18 06:01:05]
  **Train** Prec@1 94.870 Prec@5 99.920 Error@1 5.130
  **Test** Prec@1 89.080 Prec@5 99.610 Error@1 10.920

==>>[2019-11-18 06:01:10] [Epoch=113/200] [Need: 00:27:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [113][000/391]   Time 0.304 (0.304)   Data 0.254 (0.254)   Loss 0.1663 (0.1663)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:01:11]
  Epoch: [113][100/391]   Time 0.037 (0.044)   Data 0.000 (0.003)   Loss 0.0677 (0.1378)   Prec@1 97.656 (95.235)   Prec@5 100.000 (99.969)   [2019-11-18 06:01:15]
  Epoch: [113][200/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0754 (0.1411)   Prec@1 97.656 (94.978)   Prec@5 100.000 (99.961)   [2019-11-18 06:01:19]
  Epoch: [113][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1447 (0.1429)   Prec@1 94.531 (94.985)   Prec@5 100.000 (99.948)   [2019-11-18 06:01:24]
  **Train** Prec@1 94.872 Prec@5 99.944 Error@1 5.128
  **Test** Prec@1 88.330 Prec@5 99.550 Error@1 11.670

==>>[2019-11-18 06:01:30] [Epoch=114/200] [Need: 00:27:37] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [114][000/391]   Time 0.279 (0.279)   Data 0.225 (0.225)   Loss 0.1977 (0.1977)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:01:30]
  Epoch: [114][100/391]   Time 0.035 (0.048)   Data 0.000 (0.002)   Loss 0.1747 (0.1407)   Prec@1 92.188 (95.050)   Prec@5 100.000 (99.961)   [2019-11-18 06:01:35]
  Epoch: [114][200/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.1556 (0.1428)   Prec@1 93.750 (95.013)   Prec@5 100.000 (99.949)   [2019-11-18 06:01:38]
  Epoch: [114][300/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.1966 (0.1445)   Prec@1 92.969 (94.908)   Prec@5 99.219 (99.945)   [2019-11-18 06:01:43]
  **Train** Prec@1 94.930 Prec@5 99.950 Error@1 5.070
  **Test** Prec@1 89.730 Prec@5 99.700 Error@1 10.270

==>>[2019-11-18 06:01:49] [Epoch=115/200] [Need: 00:27:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [115][000/391]   Time 0.300 (0.300)   Data 0.250 (0.250)   Loss 0.0709 (0.0709)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:01:49]
  Epoch: [115][100/391]   Time 0.038 (0.048)   Data 0.000 (0.003)   Loss 0.1527 (0.1413)   Prec@1 94.531 (94.848)   Prec@5 100.000 (99.961)   [2019-11-18 06:01:54]
  Epoch: [115][200/391]   Time 0.065 (0.046)   Data 0.000 (0.001)   Loss 0.1467 (0.1469)   Prec@1 94.531 (94.660)   Prec@5 100.000 (99.922)   [2019-11-18 06:01:58]
  Epoch: [115][300/391]   Time 0.033 (0.045)   Data 0.000 (0.001)   Loss 0.1464 (0.1474)   Prec@1 94.531 (94.721)   Prec@5 100.000 (99.933)   [2019-11-18 06:02:03]
  **Train** Prec@1 94.856 Prec@5 99.930 Error@1 5.144
  **Test** Prec@1 89.520 Prec@5 99.660 Error@1 10.480

==>>[2019-11-18 06:02:08] [Epoch=116/200] [Need: 00:26:59] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [116][000/391]   Time 0.286 (0.286)   Data 0.236 (0.236)   Loss 0.2262 (0.2262)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-18 06:02:08]
  Epoch: [116][100/391]   Time 0.039 (0.051)   Data 0.000 (0.003)   Loss 0.1542 (0.1362)   Prec@1 94.531 (94.903)   Prec@5 100.000 (99.938)   [2019-11-18 06:02:13]
  Epoch: [116][200/391]   Time 0.031 (0.047)   Data 0.000 (0.001)   Loss 0.1155 (0.1406)   Prec@1 94.531 (94.834)   Prec@5 100.000 (99.946)   [2019-11-18 06:02:18]
  Epoch: [116][300/391]   Time 0.038 (0.046)   Data 0.000 (0.001)   Loss 0.1805 (0.1400)   Prec@1 91.406 (94.892)   Prec@5 100.000 (99.948)   [2019-11-18 06:02:22]
  **Train** Prec@1 94.876 Prec@5 99.940 Error@1 5.124
  **Test** Prec@1 89.030 Prec@5 99.440 Error@1 10.970

==>>[2019-11-18 06:02:28] [Epoch=117/200] [Need: 00:26:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [117][000/391]   Time 0.303 (0.303)   Data 0.249 (0.249)   Loss 0.1789 (0.1789)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 06:02:28]
  Epoch: [117][100/391]   Time 0.039 (0.048)   Data 0.000 (0.003)   Loss 0.1714 (0.1360)   Prec@1 93.750 (95.196)   Prec@5 100.000 (99.969)   [2019-11-18 06:02:33]
  Epoch: [117][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.1570 (0.1434)   Prec@1 92.188 (94.920)   Prec@5 100.000 (99.961)   [2019-11-18 06:02:37]
  Epoch: [117][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.2268 (0.1490)   Prec@1 91.406 (94.710)   Prec@5 99.219 (99.925)   [2019-11-18 06:02:42]
  **Train** Prec@1 94.738 Prec@5 99.926 Error@1 5.262
  **Test** Prec@1 89.130 Prec@5 99.590 Error@1 10.870

==>>[2019-11-18 06:02:47] [Epoch=118/200] [Need: 00:26:21] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [118][000/391]   Time 0.282 (0.282)   Data 0.223 (0.223)   Loss 0.1943 (0.1943)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-18 06:02:48]
  Epoch: [118][100/391]   Time 0.037 (0.046)   Data 0.000 (0.002)   Loss 0.2191 (0.1401)   Prec@1 92.969 (94.972)   Prec@5 100.000 (99.946)   [2019-11-18 06:02:52]
  Epoch: [118][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1122 (0.1424)   Prec@1 97.656 (95.040)   Prec@5 99.219 (99.911)   [2019-11-18 06:02:56]
  Epoch: [118][300/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.0967 (0.1448)   Prec@1 96.875 (94.970)   Prec@5 100.000 (99.925)   [2019-11-18 06:03:00]
  **Train** Prec@1 94.974 Prec@5 99.924 Error@1 5.026
  **Test** Prec@1 89.230 Prec@5 99.600 Error@1 10.770

==>>[2019-11-18 06:03:06] [Epoch=119/200] [Need: 00:26:01] [LR=0.0010][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [119][000/391]   Time 0.283 (0.283)   Data 0.220 (0.220)   Loss 0.0420 (0.0420)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:03:06]
  Epoch: [119][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.1957 (0.1385)   Prec@1 94.531 (95.104)   Prec@5 99.219 (99.923)   [2019-11-18 06:03:11]
  Epoch: [119][200/391]   Time 0.034 (0.045)   Data 0.000 (0.001)   Loss 0.1348 (0.1440)   Prec@1 94.531 (94.885)   Prec@5 100.000 (99.926)   [2019-11-18 06:03:15]
  Epoch: [119][300/391]   Time 0.055 (0.045)   Data 0.000 (0.001)   Loss 0.1836 (0.1447)   Prec@1 92.969 (94.812)   Prec@5 100.000 (99.933)   [2019-11-18 06:03:19]
  **Train** Prec@1 94.876 Prec@5 99.932 Error@1 5.124
  **Test** Prec@1 89.330 Prec@5 99.510 Error@1 10.670

==>>[2019-11-18 06:03:26] [Epoch=120/200] [Need: 00:25:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [120][000/391]   Time 0.277 (0.277)   Data 0.230 (0.230)   Loss 0.0909 (0.0909)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:03:26]
  Epoch: [120][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.1214 (0.1347)   Prec@1 96.875 (95.351)   Prec@5 100.000 (99.923)   [2019-11-18 06:03:30]
  Epoch: [120][200/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0868 (0.1288)   Prec@1 96.875 (95.546)   Prec@5 100.000 (99.918)   [2019-11-18 06:03:34]
  Epoch: [120][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.0886 (0.1292)   Prec@1 96.094 (95.476)   Prec@5 100.000 (99.909)   [2019-11-18 06:03:39]
  **Train** Prec@1 95.606 Prec@5 99.924 Error@1 4.394
  **Test** Prec@1 89.840 Prec@5 99.710 Error@1 10.160

==>>[2019-11-18 06:03:45] [Epoch=121/200] [Need: 00:25:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.23, Error=9.77]
  Epoch: [121][000/391]   Time 0.291 (0.291)   Data 0.242 (0.242)   Loss 0.1332 (0.1332)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:03:45]
  Epoch: [121][100/391]   Time 0.045 (0.046)   Data 0.000 (0.003)   Loss 0.1358 (0.1233)   Prec@1 95.312 (95.707)   Prec@5 100.000 (99.930)   [2019-11-18 06:03:50]
  Epoch: [121][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.1327 (0.1224)   Prec@1 93.750 (95.763)   Prec@5 100.000 (99.930)   [2019-11-18 06:03:54]
  Epoch: [121][300/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.1878 (0.1196)   Prec@1 93.750 (95.839)   Prec@5 100.000 (99.933)   [2019-11-18 06:03:58]
  **Train** Prec@1 95.808 Prec@5 99.934 Error@1 4.192
  **Test** Prec@1 90.300 Prec@5 99.610 Error@1 9.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:04:04] [Epoch=122/200] [Need: 00:25:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.30, Error=9.70]
  Epoch: [122][000/391]   Time 0.280 (0.280)   Data 0.228 (0.228)   Loss 0.1492 (0.1492)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 06:04:05]
  Epoch: [122][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.1245 (0.1163)   Prec@1 96.875 (96.040)   Prec@5 100.000 (99.954)   [2019-11-18 06:04:09]
  Epoch: [122][200/391]   Time 0.037 (0.047)   Data 0.000 (0.001)   Loss 0.1593 (0.1191)   Prec@1 94.531 (95.896)   Prec@5 100.000 (99.934)   [2019-11-18 06:04:14]
  Epoch: [122][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.0608 (0.1174)   Prec@1 98.438 (95.938)   Prec@5 100.000 (99.940)   [2019-11-18 06:04:18]
  **Train** Prec@1 95.864 Prec@5 99.944 Error@1 4.136
  **Test** Prec@1 90.180 Prec@5 99.620 Error@1 9.820

==>>[2019-11-18 06:04:24] [Epoch=123/200] [Need: 00:24:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.30, Error=9.70]
  Epoch: [123][000/391]   Time 0.294 (0.294)   Data 0.215 (0.215)   Loss 0.1515 (0.1515)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:04:24]
  Epoch: [123][100/391]   Time 0.055 (0.046)   Data 0.000 (0.002)   Loss 0.0626 (0.1133)   Prec@1 97.656 (96.055)   Prec@5 100.000 (99.938)   [2019-11-18 06:04:29]
  Epoch: [123][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.0946 (0.1165)   Prec@1 96.094 (95.903)   Prec@5 100.000 (99.946)   [2019-11-18 06:04:33]
  Epoch: [123][300/391]   Time 0.066 (0.044)   Data 0.000 (0.001)   Loss 0.0915 (0.1156)   Prec@1 96.875 (96.000)   Prec@5 100.000 (99.938)   [2019-11-18 06:04:37]
  **Train** Prec@1 95.970 Prec@5 99.938 Error@1 4.030
  **Test** Prec@1 90.150 Prec@5 99.600 Error@1 9.850

==>>[2019-11-18 06:04:43] [Epoch=124/200] [Need: 00:24:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.30, Error=9.70]
  Epoch: [124][000/391]   Time 0.283 (0.283)   Data 0.228 (0.228)   Loss 0.1227 (0.1227)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 06:04:44]
  Epoch: [124][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.0843 (0.1116)   Prec@1 98.438 (96.171)   Prec@5 100.000 (99.954)   [2019-11-18 06:04:48]
  Epoch: [124][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0665 (0.1139)   Prec@1 97.656 (95.989)   Prec@5 100.000 (99.946)   [2019-11-18 06:04:53]
  Epoch: [124][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.0970 (0.1166)   Prec@1 94.531 (95.948)   Prec@5 100.000 (99.935)   [2019-11-18 06:04:57]
  **Train** Prec@1 95.902 Prec@5 99.942 Error@1 4.098
  **Test** Prec@1 90.350 Prec@5 99.590 Error@1 9.650
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:05:03] [Epoch=125/200] [Need: 00:24:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [125][000/391]   Time 0.279 (0.279)   Data 0.230 (0.230)   Loss 0.0706 (0.0706)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:05:04]
  Epoch: [125][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.0826 (0.1067)   Prec@1 97.656 (96.334)   Prec@5 100.000 (99.977)   [2019-11-18 06:05:08]
  Epoch: [125][200/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.0762 (0.1082)   Prec@1 96.094 (96.261)   Prec@5 100.000 (99.977)   [2019-11-18 06:05:12]
  Epoch: [125][300/391]   Time 0.046 (0.045)   Data 0.000 (0.001)   Loss 0.0919 (0.1109)   Prec@1 97.656 (96.151)   Prec@5 100.000 (99.982)   [2019-11-18 06:05:17]
  **Train** Prec@1 96.154 Prec@5 99.972 Error@1 3.846
  **Test** Prec@1 90.020 Prec@5 99.680 Error@1 9.980

==>>[2019-11-18 06:05:23] [Epoch=126/200] [Need: 00:23:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [126][000/391]   Time 0.284 (0.284)   Data 0.228 (0.228)   Loss 0.1091 (0.1091)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:05:23]
  Epoch: [126][100/391]   Time 0.034 (0.046)   Data 0.000 (0.002)   Loss 0.1052 (0.1124)   Prec@1 96.875 (96.086)   Prec@5 100.000 (99.977)   [2019-11-18 06:05:27]
  Epoch: [126][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.0680 (0.1115)   Prec@1 97.656 (96.051)   Prec@5 100.000 (99.973)   [2019-11-18 06:05:32]
  Epoch: [126][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.0732 (0.1129)   Prec@1 98.438 (96.047)   Prec@5 100.000 (99.964)   [2019-11-18 06:05:36]
  **Train** Prec@1 96.022 Prec@5 99.962 Error@1 3.978
  **Test** Prec@1 90.220 Prec@5 99.670 Error@1 9.780

==>>[2019-11-18 06:05:42] [Epoch=127/200] [Need: 00:23:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [127][000/391]   Time 0.284 (0.284)   Data 0.231 (0.231)   Loss 0.2307 (0.2307)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-18 06:05:42]
  Epoch: [127][100/391]   Time 0.075 (0.047)   Data 0.000 (0.002)   Loss 0.0650 (0.1100)   Prec@1 98.438 (96.071)   Prec@5 100.000 (99.930)   [2019-11-18 06:05:46]
  Epoch: [127][200/391]   Time 0.047 (0.045)   Data 0.000 (0.001)   Loss 0.0975 (0.1144)   Prec@1 97.656 (95.962)   Prec@5 100.000 (99.934)   [2019-11-18 06:05:51]
  Epoch: [127][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.1413 (0.1142)   Prec@1 97.656 (95.972)   Prec@5 100.000 (99.943)   [2019-11-18 06:05:55]
  **Train** Prec@1 95.968 Prec@5 99.946 Error@1 4.032
  **Test** Prec@1 90.140 Prec@5 99.630 Error@1 9.860

==>>[2019-11-18 06:06:01] [Epoch=128/200] [Need: 00:23:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [128][000/391]   Time 0.302 (0.302)   Data 0.236 (0.236)   Loss 0.1372 (0.1372)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.219)   [2019-11-18 06:06:01]
  Epoch: [128][100/391]   Time 0.046 (0.046)   Data 0.000 (0.003)   Loss 0.1056 (0.1134)   Prec@1 96.094 (95.939)   Prec@5 100.000 (99.938)   [2019-11-18 06:06:05]
  Epoch: [128][200/391]   Time 0.060 (0.044)   Data 0.000 (0.001)   Loss 0.1658 (0.1128)   Prec@1 92.969 (95.954)   Prec@5 100.000 (99.965)   [2019-11-18 06:06:09]
  Epoch: [128][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0615 (0.1125)   Prec@1 97.656 (96.011)   Prec@5 100.000 (99.964)   [2019-11-18 06:06:14]
  **Train** Prec@1 96.058 Prec@5 99.962 Error@1 3.942
  **Test** Prec@1 90.380 Prec@5 99.590 Error@1 9.620
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:06:20] [Epoch=129/200] [Need: 00:22:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [129][000/391]   Time 0.292 (0.292)   Data 0.243 (0.243)   Loss 0.0909 (0.0909)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:06:21]
  Epoch: [129][100/391]   Time 0.041 (0.045)   Data 0.000 (0.003)   Loss 0.0759 (0.1115)   Prec@1 96.875 (96.218)   Prec@5 100.000 (99.961)   [2019-11-18 06:06:25]
  Epoch: [129][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0393 (0.1093)   Prec@1 99.219 (96.218)   Prec@5 100.000 (99.965)   [2019-11-18 06:06:29]
  Epoch: [129][300/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.0600 (0.1122)   Prec@1 98.438 (96.107)   Prec@5 100.000 (99.969)   [2019-11-18 06:06:34]
  **Train** Prec@1 96.052 Prec@5 99.956 Error@1 3.948
  **Test** Prec@1 90.380 Prec@5 99.680 Error@1 9.620
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:06:39] [Epoch=130/200] [Need: 00:22:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [130][000/391]   Time 0.295 (0.295)   Data 0.227 (0.227)   Loss 0.1218 (0.1218)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:06:40]
  Epoch: [130][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.1274 (0.1111)   Prec@1 95.312 (96.101)   Prec@5 100.000 (99.969)   [2019-11-18 06:06:44]
  Epoch: [130][200/391]   Time 0.034 (0.043)   Data 0.000 (0.001)   Loss 0.0816 (0.1111)   Prec@1 96.875 (96.129)   Prec@5 100.000 (99.969)   [2019-11-18 06:06:48]
  Epoch: [130][300/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.0463 (0.1133)   Prec@1 100.000 (96.039)   Prec@5 100.000 (99.961)   [2019-11-18 06:06:52]
  **Train** Prec@1 96.048 Prec@5 99.968 Error@1 3.952
  **Test** Prec@1 89.730 Prec@5 99.630 Error@1 10.270

==>>[2019-11-18 06:06:58] [Epoch=131/200] [Need: 00:22:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [131][000/391]   Time 0.290 (0.290)   Data 0.229 (0.229)   Loss 0.1473 (0.1473)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:06:59]
  Epoch: [131][100/391]   Time 0.035 (0.045)   Data 0.000 (0.002)   Loss 0.1175 (0.1123)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.915)   [2019-11-18 06:07:03]
  Epoch: [131][200/391]   Time 0.073 (0.044)   Data 0.000 (0.001)   Loss 0.1241 (0.1103)   Prec@1 93.750 (96.140)   Prec@5 100.000 (99.938)   [2019-11-18 06:07:07]
  Epoch: [131][300/391]   Time 0.069 (0.044)   Data 0.000 (0.001)   Loss 0.1141 (0.1088)   Prec@1 96.094 (96.185)   Prec@5 100.000 (99.938)   [2019-11-18 06:07:11]
  **Train** Prec@1 96.156 Prec@5 99.946 Error@1 3.844
  **Test** Prec@1 90.040 Prec@5 99.720 Error@1 9.960

==>>[2019-11-18 06:07:18] [Epoch=132/200] [Need: 00:21:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [132][000/391]   Time 0.276 (0.276)   Data 0.225 (0.225)   Loss 0.1016 (0.1016)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:07:18]
  Epoch: [132][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.0864 (0.1107)   Prec@1 97.656 (96.171)   Prec@5 100.000 (99.930)   [2019-11-18 06:07:22]
  Epoch: [132][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.2207 (0.1127)   Prec@1 91.406 (96.043)   Prec@5 100.000 (99.934)   [2019-11-18 06:07:27]
  Epoch: [132][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.1041 (0.1100)   Prec@1 95.312 (96.112)   Prec@5 100.000 (99.943)   [2019-11-18 06:07:31]
  **Train** Prec@1 96.130 Prec@5 99.948 Error@1 3.870
  **Test** Prec@1 89.620 Prec@5 99.680 Error@1 10.380

==>>[2019-11-18 06:07:37] [Epoch=133/200] [Need: 00:21:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [133][000/391]   Time 0.284 (0.284)   Data 0.235 (0.235)   Loss 0.1022 (0.1022)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:07:37]
  Epoch: [133][100/391]   Time 0.038 (0.047)   Data 0.000 (0.003)   Loss 0.0958 (0.1027)   Prec@1 98.438 (96.519)   Prec@5 99.219 (99.946)   [2019-11-18 06:07:42]
  Epoch: [133][200/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 0.0437 (0.1072)   Prec@1 99.219 (96.377)   Prec@5 100.000 (99.953)   [2019-11-18 06:07:46]
  Epoch: [133][300/391]   Time 0.066 (0.044)   Data 0.000 (0.001)   Loss 0.0944 (0.1080)   Prec@1 97.656 (96.335)   Prec@5 100.000 (99.951)   [2019-11-18 06:07:50]
  **Train** Prec@1 96.286 Prec@5 99.946 Error@1 3.714
  **Test** Prec@1 89.900 Prec@5 99.600 Error@1 10.100

==>>[2019-11-18 06:07:56] [Epoch=134/200] [Need: 00:21:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [134][000/391]   Time 0.289 (0.289)   Data 0.219 (0.219)   Loss 0.0654 (0.0654)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:07:57]
  Epoch: [134][100/391]   Time 0.035 (0.048)   Data 0.000 (0.002)   Loss 0.0826 (0.1144)   Prec@1 97.656 (96.117)   Prec@5 100.000 (99.892)   [2019-11-18 06:08:01]
  Epoch: [134][200/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.1274 (0.1115)   Prec@1 94.531 (96.129)   Prec@5 100.000 (99.938)   [2019-11-18 06:08:05]
  Epoch: [134][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1469 (0.1103)   Prec@1 94.531 (96.096)   Prec@5 100.000 (99.953)   [2019-11-18 06:08:10]
  **Train** Prec@1 96.098 Prec@5 99.950 Error@1 3.902
  **Test** Prec@1 90.130 Prec@5 99.650 Error@1 9.870

==>>[2019-11-18 06:08:16] [Epoch=135/200] [Need: 00:20:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [135][000/391]   Time 0.289 (0.289)   Data 0.236 (0.236)   Loss 0.1378 (0.1378)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:08:16]
  Epoch: [135][100/391]   Time 0.046 (0.048)   Data 0.000 (0.003)   Loss 0.0688 (0.1056)   Prec@1 97.656 (96.287)   Prec@5 100.000 (99.954)   [2019-11-18 06:08:21]
  Epoch: [135][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.0951 (0.1044)   Prec@1 96.875 (96.346)   Prec@5 100.000 (99.949)   [2019-11-18 06:08:25]
  Epoch: [135][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1366 (0.1066)   Prec@1 96.094 (96.270)   Prec@5 100.000 (99.951)   [2019-11-18 06:08:30]
  **Train** Prec@1 96.166 Prec@5 99.954 Error@1 3.834
  **Test** Prec@1 89.930 Prec@5 99.600 Error@1 10.070

==>>[2019-11-18 06:08:35] [Epoch=136/200] [Need: 00:20:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [136][000/391]   Time 0.284 (0.284)   Data 0.229 (0.229)   Loss 0.1239 (0.1239)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:08:36]
  Epoch: [136][100/391]   Time 0.044 (0.048)   Data 0.000 (0.002)   Loss 0.1145 (0.1032)   Prec@1 96.094 (96.465)   Prec@5 100.000 (99.946)   [2019-11-18 06:08:40]
  Epoch: [136][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0617 (0.1076)   Prec@1 97.656 (96.308)   Prec@5 100.000 (99.946)   [2019-11-18 06:08:44]
  Epoch: [136][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0540 (0.1068)   Prec@1 97.656 (96.301)   Prec@5 100.000 (99.945)   [2019-11-18 06:08:49]
  **Train** Prec@1 96.290 Prec@5 99.954 Error@1 3.710
  **Test** Prec@1 90.330 Prec@5 99.630 Error@1 9.670

==>>[2019-11-18 06:08:55] [Epoch=137/200] [Need: 00:20:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [137][000/391]   Time 0.289 (0.289)   Data 0.236 (0.236)   Loss 0.1092 (0.1092)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 06:08:55]
  Epoch: [137][100/391]   Time 0.045 (0.045)   Data 0.000 (0.003)   Loss 0.1174 (0.1114)   Prec@1 96.094 (96.009)   Prec@5 100.000 (99.923)   [2019-11-18 06:08:59]
  Epoch: [137][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.1062 (0.1115)   Prec@1 96.875 (96.121)   Prec@5 100.000 (99.949)   [2019-11-18 06:09:04]
  Epoch: [137][300/391]   Time 0.048 (0.044)   Data 0.000 (0.001)   Loss 0.1018 (0.1114)   Prec@1 98.438 (96.120)   Prec@5 100.000 (99.938)   [2019-11-18 06:09:08]
  **Train** Prec@1 96.194 Prec@5 99.944 Error@1 3.806
  **Test** Prec@1 90.090 Prec@5 99.620 Error@1 9.910

==>>[2019-11-18 06:09:14] [Epoch=138/200] [Need: 00:19:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [138][000/391]   Time 0.296 (0.296)   Data 0.220 (0.220)   Loss 0.1028 (0.1028)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:09:14]
  Epoch: [138][100/391]   Time 0.037 (0.047)   Data 0.000 (0.002)   Loss 0.1339 (0.1147)   Prec@1 96.094 (95.885)   Prec@5 100.000 (99.961)   [2019-11-18 06:09:19]
  Epoch: [138][200/391]   Time 0.044 (0.046)   Data 0.000 (0.001)   Loss 0.1132 (0.1106)   Prec@1 96.094 (96.039)   Prec@5 100.000 (99.961)   [2019-11-18 06:09:23]
  Epoch: [138][300/391]   Time 0.034 (0.044)   Data 0.000 (0.001)   Loss 0.1394 (0.1093)   Prec@1 94.531 (96.159)   Prec@5 100.000 (99.966)   [2019-11-18 06:09:27]
  **Train** Prec@1 96.132 Prec@5 99.966 Error@1 3.868
  **Test** Prec@1 89.710 Prec@5 99.710 Error@1 10.290

==>>[2019-11-18 06:09:34] [Epoch=139/200] [Need: 00:19:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [139][000/391]   Time 0.282 (0.282)   Data 0.215 (0.215)   Loss 0.0966 (0.0966)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:09:34]
  Epoch: [139][100/391]   Time 0.057 (0.048)   Data 0.000 (0.002)   Loss 0.1063 (0.1016)   Prec@1 96.875 (96.535)   Prec@5 100.000 (99.961)   [2019-11-18 06:09:39]
  Epoch: [139][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.1336 (0.1068)   Prec@1 96.875 (96.315)   Prec@5 100.000 (99.957)   [2019-11-18 06:09:43]
  Epoch: [139][300/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.0958 (0.1059)   Prec@1 96.094 (96.307)   Prec@5 100.000 (99.961)   [2019-11-18 06:09:47]
  **Train** Prec@1 96.320 Prec@5 99.962 Error@1 3.680
  **Test** Prec@1 90.080 Prec@5 99.700 Error@1 9.920

==>>[2019-11-18 06:09:53] [Epoch=140/200] [Need: 00:19:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [140][000/391]   Time 0.276 (0.276)   Data 0.225 (0.225)   Loss 0.0904 (0.0904)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:09:53]
  Epoch: [140][100/391]   Time 0.037 (0.047)   Data 0.000 (0.002)   Loss 0.1036 (0.1108)   Prec@1 96.094 (95.962)   Prec@5 100.000 (99.969)   [2019-11-18 06:09:58]
  Epoch: [140][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.0982 (0.1089)   Prec@1 97.656 (96.160)   Prec@5 100.000 (99.961)   [2019-11-18 06:10:02]
  Epoch: [140][300/391]   Time 0.050 (0.046)   Data 0.000 (0.001)   Loss 0.0618 (0.1090)   Prec@1 97.656 (96.151)   Prec@5 100.000 (99.966)   [2019-11-18 06:10:07]
  **Train** Prec@1 96.156 Prec@5 99.962 Error@1 3.844
  **Test** Prec@1 90.300 Prec@5 99.600 Error@1 9.700

==>>[2019-11-18 06:10:13] [Epoch=141/200] [Need: 00:18:58] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [141][000/391]   Time 0.279 (0.279)   Data 0.221 (0.221)   Loss 0.1190 (0.1190)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:10:13]
  Epoch: [141][100/391]   Time 0.065 (0.047)   Data 0.000 (0.002)   Loss 0.1560 (0.1088)   Prec@1 94.531 (96.403)   Prec@5 100.000 (99.977)   [2019-11-18 06:10:18]
  Epoch: [141][200/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.1200 (0.1090)   Prec@1 95.312 (96.276)   Prec@5 100.000 (99.957)   [2019-11-18 06:10:22]
  Epoch: [141][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0512 (0.1096)   Prec@1 97.656 (96.224)   Prec@5 100.000 (99.951)   [2019-11-18 06:10:26]
  **Train** Prec@1 96.186 Prec@5 99.958 Error@1 3.814
  **Test** Prec@1 90.110 Prec@5 99.670 Error@1 9.890

==>>[2019-11-18 06:10:32] [Epoch=142/200] [Need: 00:18:39] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [142][000/391]   Time 0.288 (0.288)   Data 0.227 (0.227)   Loss 0.1542 (0.1542)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:10:32]
  Epoch: [142][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.2126 (0.1082)   Prec@1 92.188 (96.279)   Prec@5 100.000 (99.915)   [2019-11-18 06:10:37]
  Epoch: [142][200/391]   Time 0.037 (0.048)   Data 0.000 (0.001)   Loss 0.1484 (0.1033)   Prec@1 96.875 (96.420)   Prec@5 100.000 (99.946)   [2019-11-18 06:10:42]
  Epoch: [142][300/391]   Time 0.061 (0.047)   Data 0.000 (0.001)   Loss 0.0918 (0.1043)   Prec@1 96.094 (96.369)   Prec@5 100.000 (99.958)   [2019-11-18 06:10:46]
  **Train** Prec@1 96.314 Prec@5 99.958 Error@1 3.686
  **Test** Prec@1 90.270 Prec@5 99.620 Error@1 9.730

==>>[2019-11-18 06:10:52] [Epoch=143/200] [Need: 00:18:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [143][000/391]   Time 0.287 (0.287)   Data 0.237 (0.237)   Loss 0.0718 (0.0718)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:10:53]
  Epoch: [143][100/391]   Time 0.034 (0.044)   Data 0.000 (0.003)   Loss 0.1244 (0.1075)   Prec@1 94.531 (96.364)   Prec@5 100.000 (99.923)   [2019-11-18 06:10:57]
  Epoch: [143][200/391]   Time 0.041 (0.044)   Data 0.000 (0.001)   Loss 0.1163 (0.1079)   Prec@1 95.312 (96.175)   Prec@5 100.000 (99.946)   [2019-11-18 06:11:01]
  Epoch: [143][300/391]   Time 0.046 (0.045)   Data 0.000 (0.001)   Loss 0.1298 (0.1067)   Prec@1 97.656 (96.257)   Prec@5 100.000 (99.948)   [2019-11-18 06:11:06]
  **Train** Prec@1 96.266 Prec@5 99.948 Error@1 3.734
  **Test** Prec@1 89.830 Prec@5 99.600 Error@1 10.170

==>>[2019-11-18 06:11:11] [Epoch=144/200] [Need: 00:18:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [144][000/391]   Time 0.292 (0.292)   Data 0.241 (0.241)   Loss 0.0904 (0.0904)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:11:12]
  Epoch: [144][100/391]   Time 0.042 (0.047)   Data 0.000 (0.003)   Loss 0.0900 (0.1053)   Prec@1 97.656 (96.481)   Prec@5 100.000 (99.954)   [2019-11-18 06:11:16]
  Epoch: [144][200/391]   Time 0.052 (0.045)   Data 0.000 (0.001)   Loss 0.1547 (0.1040)   Prec@1 94.531 (96.436)   Prec@5 100.000 (99.965)   [2019-11-18 06:11:21]
  Epoch: [144][300/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.0683 (0.1076)   Prec@1 98.438 (96.281)   Prec@5 100.000 (99.969)   [2019-11-18 06:11:25]
  **Train** Prec@1 96.256 Prec@5 99.972 Error@1 3.744
  **Test** Prec@1 90.030 Prec@5 99.660 Error@1 9.970

==>>[2019-11-18 06:11:30] [Epoch=145/200] [Need: 00:17:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [145][000/391]   Time 0.287 (0.287)   Data 0.238 (0.238)   Loss 0.1025 (0.1025)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:11:30]
  Epoch: [145][100/391]   Time 0.076 (0.046)   Data 0.000 (0.003)   Loss 0.0729 (0.1135)   Prec@1 98.438 (95.877)   Prec@5 100.000 (99.961)   [2019-11-18 06:11:35]
  Epoch: [145][200/391]   Time 0.045 (0.044)   Data 0.000 (0.001)   Loss 0.1039 (0.1088)   Prec@1 96.094 (96.105)   Prec@5 100.000 (99.961)   [2019-11-18 06:11:39]
  Epoch: [145][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.0594 (0.1080)   Prec@1 98.438 (96.164)   Prec@5 100.000 (99.953)   [2019-11-18 06:11:43]
  **Train** Prec@1 96.154 Prec@5 99.958 Error@1 3.846
  **Test** Prec@1 90.140 Prec@5 99.690 Error@1 9.860

==>>[2019-11-18 06:11:50] [Epoch=146/200] [Need: 00:17:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [146][000/391]   Time 0.273 (0.273)   Data 0.212 (0.212)   Loss 0.0564 (0.0564)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:11:50]
  Epoch: [146][100/391]   Time 0.035 (0.045)   Data 0.000 (0.002)   Loss 0.0647 (0.1025)   Prec@1 96.875 (96.372)   Prec@5 100.000 (99.977)   [2019-11-18 06:11:54]
  Epoch: [146][200/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.1422 (0.1031)   Prec@1 96.094 (96.381)   Prec@5 100.000 (99.977)   [2019-11-18 06:11:59]
  Epoch: [146][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1027 (0.1070)   Prec@1 96.094 (96.203)   Prec@5 100.000 (99.969)   [2019-11-18 06:12:03]
  **Train** Prec@1 96.192 Prec@5 99.964 Error@1 3.808
  **Test** Prec@1 89.890 Prec@5 99.670 Error@1 10.110

==>>[2019-11-18 06:12:09] [Epoch=147/200] [Need: 00:17:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [147][000/391]   Time 0.277 (0.277)   Data 0.226 (0.226)   Loss 0.0684 (0.0684)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:12:10]
  Epoch: [147][100/391]   Time 0.036 (0.045)   Data 0.000 (0.002)   Loss 0.1978 (0.1112)   Prec@1 94.531 (96.047)   Prec@5 100.000 (99.961)   [2019-11-18 06:12:14]
  Epoch: [147][200/391]   Time 0.062 (0.044)   Data 0.000 (0.001)   Loss 0.1055 (0.1090)   Prec@1 94.531 (96.171)   Prec@5 100.000 (99.953)   [2019-11-18 06:12:18]
  Epoch: [147][300/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.0910 (0.1074)   Prec@1 96.875 (96.249)   Prec@5 100.000 (99.951)   [2019-11-18 06:12:22]
  **Train** Prec@1 96.246 Prec@5 99.950 Error@1 3.754
  **Test** Prec@1 90.220 Prec@5 99.610 Error@1 9.780

==>>[2019-11-18 06:12:28] [Epoch=148/200] [Need: 00:16:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [148][000/391]   Time 0.290 (0.290)   Data 0.238 (0.238)   Loss 0.0697 (0.0697)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:12:29]
  Epoch: [148][100/391]   Time 0.061 (0.043)   Data 0.000 (0.003)   Loss 0.1024 (0.1034)   Prec@1 96.875 (96.349)   Prec@5 100.000 (99.954)   [2019-11-18 06:12:33]
  Epoch: [148][200/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.0270 (0.1066)   Prec@1 100.000 (96.276)   Prec@5 100.000 (99.965)   [2019-11-18 06:12:37]
  Epoch: [148][300/391]   Time 0.061 (0.044)   Data 0.000 (0.001)   Loss 0.1359 (0.1060)   Prec@1 96.094 (96.288)   Prec@5 100.000 (99.964)   [2019-11-18 06:12:42]
  **Train** Prec@1 96.334 Prec@5 99.962 Error@1 3.666
  **Test** Prec@1 89.870 Prec@5 99.640 Error@1 10.130

==>>[2019-11-18 06:12:48] [Epoch=149/200] [Need: 00:16:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.38, Error=9.62]
  Epoch: [149][000/391]   Time 0.279 (0.279)   Data 0.218 (0.218)   Loss 0.1475 (0.1475)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 06:12:48]
  Epoch: [149][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.1143 (0.1027)   Prec@1 96.875 (96.310)   Prec@5 100.000 (99.992)   [2019-11-18 06:12:53]
  Epoch: [149][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.1120 (0.1050)   Prec@1 97.656 (96.265)   Prec@5 100.000 (99.973)   [2019-11-18 06:12:57]
  Epoch: [149][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.1206 (0.1050)   Prec@1 96.094 (96.330)   Prec@5 100.000 (99.961)   [2019-11-18 06:13:01]
  **Train** Prec@1 96.334 Prec@5 99.966 Error@1 3.666
  **Test** Prec@1 90.390 Prec@5 99.650 Error@1 9.610
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:13:07] [Epoch=150/200] [Need: 00:16:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [150][000/391]   Time 0.279 (0.279)   Data 0.232 (0.232)   Loss 0.0754 (0.0754)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:13:08]
  Epoch: [150][100/391]   Time 0.075 (0.050)   Data 0.000 (0.002)   Loss 0.1371 (0.1041)   Prec@1 94.531 (96.364)   Prec@5 100.000 (99.961)   [2019-11-18 06:13:12]
  Epoch: [150][200/391]   Time 0.039 (0.048)   Data 0.000 (0.001)   Loss 0.1431 (0.1040)   Prec@1 96.094 (96.377)   Prec@5 99.219 (99.949)   [2019-11-18 06:13:17]
  Epoch: [150][300/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.1484 (0.1062)   Prec@1 96.094 (96.260)   Prec@5 100.000 (99.961)   [2019-11-18 06:13:21]
  **Train** Prec@1 96.280 Prec@5 99.956 Error@1 3.720
  **Test** Prec@1 89.880 Prec@5 99.700 Error@1 10.120

==>>[2019-11-18 06:13:27] [Epoch=151/200] [Need: 00:15:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [151][000/391]   Time 0.263 (0.263)   Data 0.210 (0.210)   Loss 0.1166 (0.1166)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:13:27]
  Epoch: [151][100/391]   Time 0.035 (0.048)   Data 0.000 (0.002)   Loss 0.0482 (0.1040)   Prec@1 99.219 (96.411)   Prec@5 100.000 (99.946)   [2019-11-18 06:13:32]
  Epoch: [151][200/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 0.0931 (0.1032)   Prec@1 97.656 (96.412)   Prec@5 100.000 (99.957)   [2019-11-18 06:13:36]
  Epoch: [151][300/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0749 (0.1033)   Prec@1 96.875 (96.366)   Prec@5 100.000 (99.966)   [2019-11-18 06:13:41]
  **Train** Prec@1 96.372 Prec@5 99.968 Error@1 3.628
  **Test** Prec@1 89.470 Prec@5 99.660 Error@1 10.530

==>>[2019-11-18 06:13:47] [Epoch=152/200] [Need: 00:15:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [152][000/391]   Time 0.289 (0.289)   Data 0.222 (0.222)   Loss 0.1636 (0.1636)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-18 06:13:47]
  Epoch: [152][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.0737 (0.1098)   Prec@1 96.875 (96.132)   Prec@5 100.000 (99.938)   [2019-11-18 06:13:52]
  Epoch: [152][200/391]   Time 0.068 (0.046)   Data 0.000 (0.001)   Loss 0.0626 (0.1070)   Prec@1 96.875 (96.234)   Prec@5 100.000 (99.969)   [2019-11-18 06:13:56]
  Epoch: [152][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.1091 (0.1073)   Prec@1 96.875 (96.205)   Prec@5 100.000 (99.969)   [2019-11-18 06:14:00]
  **Train** Prec@1 96.162 Prec@5 99.968 Error@1 3.838
  **Test** Prec@1 90.170 Prec@5 99.720 Error@1 9.830

==>>[2019-11-18 06:14:06] [Epoch=153/200] [Need: 00:15:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [153][000/391]   Time 0.293 (0.293)   Data 0.246 (0.246)   Loss 0.0654 (0.0654)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:14:07]
  Epoch: [153][100/391]   Time 0.068 (0.046)   Data 0.000 (0.003)   Loss 0.0862 (0.1053)   Prec@1 98.438 (96.125)   Prec@5 100.000 (99.985)   [2019-11-18 06:14:11]
  Epoch: [153][200/391]   Time 0.046 (0.044)   Data 0.000 (0.001)   Loss 0.1048 (0.1018)   Prec@1 96.094 (96.428)   Prec@5 100.000 (99.965)   [2019-11-18 06:14:15]
  Epoch: [153][300/391]   Time 0.074 (0.044)   Data 0.000 (0.001)   Loss 0.1187 (0.1046)   Prec@1 95.312 (96.320)   Prec@5 100.000 (99.964)   [2019-11-18 06:14:20]
  **Train** Prec@1 96.344 Prec@5 99.964 Error@1 3.656
  **Test** Prec@1 90.050 Prec@5 99.710 Error@1 9.950

==>>[2019-11-18 06:14:26] [Epoch=154/200] [Need: 00:14:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [154][000/391]   Time 0.291 (0.291)   Data 0.215 (0.215)   Loss 0.0582 (0.0582)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:14:26]
  Epoch: [154][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.1328 (0.1040)   Prec@1 96.875 (96.411)   Prec@5 100.000 (99.961)   [2019-11-18 06:14:31]
  Epoch: [154][200/391]   Time 0.074 (0.046)   Data 0.000 (0.001)   Loss 0.1103 (0.1060)   Prec@1 96.875 (96.311)   Prec@5 99.219 (99.953)   [2019-11-18 06:14:35]
  Epoch: [154][300/391]   Time 0.063 (0.046)   Data 0.000 (0.001)   Loss 0.0871 (0.1053)   Prec@1 97.656 (96.312)   Prec@5 100.000 (99.956)   [2019-11-18 06:14:40]
  **Train** Prec@1 96.310 Prec@5 99.960 Error@1 3.690
  **Test** Prec@1 89.770 Prec@5 99.640 Error@1 10.230

==>>[2019-11-18 06:14:46] [Epoch=155/200] [Need: 00:14:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [155][000/391]   Time 0.274 (0.274)   Data 0.223 (0.223)   Loss 0.0798 (0.0798)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-18 06:14:46]
  Epoch: [155][100/391]   Time 0.037 (0.049)   Data 0.000 (0.002)   Loss 0.1091 (0.0991)   Prec@1 97.656 (96.535)   Prec@5 99.219 (99.954)   [2019-11-18 06:14:51]
  Epoch: [155][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0956 (0.1007)   Prec@1 96.875 (96.510)   Prec@5 99.219 (99.953)   [2019-11-18 06:14:55]
  Epoch: [155][300/391]   Time 0.047 (0.046)   Data 0.000 (0.001)   Loss 0.1459 (0.1036)   Prec@1 93.750 (96.348)   Prec@5 100.000 (99.953)   [2019-11-18 06:15:00]
  **Train** Prec@1 96.370 Prec@5 99.954 Error@1 3.630
  **Test** Prec@1 89.740 Prec@5 99.580 Error@1 10.260

==>>[2019-11-18 06:15:05] [Epoch=156/200] [Need: 00:14:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [156][000/391]   Time 0.272 (0.272)   Data 0.214 (0.214)   Loss 0.0845 (0.0845)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:15:05]
  Epoch: [156][100/391]   Time 0.036 (0.044)   Data 0.000 (0.002)   Loss 0.1528 (0.1029)   Prec@1 95.312 (96.357)   Prec@5 100.000 (99.961)   [2019-11-18 06:15:10]
  Epoch: [156][200/391]   Time 0.035 (0.044)   Data 0.000 (0.001)   Loss 0.1317 (0.1053)   Prec@1 94.531 (96.269)   Prec@5 100.000 (99.961)   [2019-11-18 06:15:14]
  Epoch: [156][300/391]   Time 0.033 (0.043)   Data 0.000 (0.001)   Loss 0.0891 (0.1013)   Prec@1 95.312 (96.410)   Prec@5 100.000 (99.964)   [2019-11-18 06:15:18]
  **Train** Prec@1 96.334 Prec@5 99.964 Error@1 3.666
  **Test** Prec@1 89.740 Prec@5 99.690 Error@1 10.260

==>>[2019-11-18 06:15:24] [Epoch=157/200] [Need: 00:13:50] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [157][000/391]   Time 0.279 (0.279)   Data 0.227 (0.227)   Loss 0.0890 (0.0890)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:15:24]
  Epoch: [157][100/391]   Time 0.045 (0.048)   Data 0.000 (0.002)   Loss 0.0374 (0.1077)   Prec@1 99.219 (96.194)   Prec@5 100.000 (99.915)   [2019-11-18 06:15:29]
  Epoch: [157][200/391]   Time 0.032 (0.047)   Data 0.000 (0.001)   Loss 0.0849 (0.1094)   Prec@1 97.656 (96.164)   Prec@5 100.000 (99.922)   [2019-11-18 06:15:33]
  Epoch: [157][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.0780 (0.1067)   Prec@1 97.656 (96.205)   Prec@5 100.000 (99.935)   [2019-11-18 06:15:37]
  **Train** Prec@1 96.230 Prec@5 99.946 Error@1 3.770
  **Test** Prec@1 90.000 Prec@5 99.560 Error@1 10.000

==>>[2019-11-18 06:15:43] [Epoch=158/200] [Need: 00:13:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.39, Error=9.61]
  Epoch: [158][000/391]   Time 0.301 (0.301)   Data 0.242 (0.242)   Loss 0.1282 (0.1282)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:15:43]
  Epoch: [158][100/391]   Time 0.037 (0.047)   Data 0.000 (0.003)   Loss 0.0692 (0.1040)   Prec@1 98.438 (96.357)   Prec@5 100.000 (99.969)   [2019-11-18 06:15:48]
  Epoch: [158][200/391]   Time 0.038 (0.045)   Data 0.000 (0.001)   Loss 0.1018 (0.1031)   Prec@1 93.750 (96.381)   Prec@5 100.000 (99.973)   [2019-11-18 06:15:52]
  Epoch: [158][300/391]   Time 0.038 (0.046)   Data 0.000 (0.001)   Loss 0.1536 (0.1030)   Prec@1 96.094 (96.405)   Prec@5 100.000 (99.953)   [2019-11-18 06:15:57]
  **Train** Prec@1 96.366 Prec@5 99.956 Error@1 3.634
  **Test** Prec@1 90.460 Prec@5 99.640 Error@1 9.540
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:16:03] [Epoch=159/200] [Need: 00:13:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [159][000/391]   Time 0.294 (0.294)   Data 0.235 (0.235)   Loss 0.1153 (0.1153)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:16:03]
  Epoch: [159][100/391]   Time 0.040 (0.049)   Data 0.000 (0.003)   Loss 0.1296 (0.1027)   Prec@1 95.312 (96.295)   Prec@5 100.000 (99.969)   [2019-11-18 06:16:08]
  Epoch: [159][200/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1676 (0.1038)   Prec@1 95.312 (96.319)   Prec@5 100.000 (99.961)   [2019-11-18 06:16:12]
  Epoch: [159][300/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.0354 (0.1041)   Prec@1 100.000 (96.291)   Prec@5 100.000 (99.961)   [2019-11-18 06:16:16]
  **Train** Prec@1 96.328 Prec@5 99.956 Error@1 3.672
  **Test** Prec@1 89.590 Prec@5 99.540 Error@1 10.410

==>>[2019-11-18 06:16:22] [Epoch=160/200] [Need: 00:12:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [160][000/391]   Time 0.275 (0.275)   Data 0.227 (0.227)   Loss 0.1644 (0.1644)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 06:16:22]
  Epoch: [160][100/391]   Time 0.039 (0.047)   Data 0.000 (0.002)   Loss 0.0827 (0.1019)   Prec@1 96.875 (96.419)   Prec@5 100.000 (99.969)   [2019-11-18 06:16:27]
  Epoch: [160][200/391]   Time 0.050 (0.044)   Data 0.000 (0.001)   Loss 0.1475 (0.1000)   Prec@1 93.750 (96.521)   Prec@5 100.000 (99.973)   [2019-11-18 06:16:31]
  Epoch: [160][300/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.0665 (0.0987)   Prec@1 98.438 (96.589)   Prec@5 100.000 (99.971)   [2019-11-18 06:16:35]
  **Train** Prec@1 96.474 Prec@5 99.964 Error@1 3.526
  **Test** Prec@1 90.020 Prec@5 99.670 Error@1 9.980

==>>[2019-11-18 06:16:41] [Epoch=161/200] [Need: 00:12:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [161][000/391]   Time 0.279 (0.279)   Data 0.218 (0.218)   Loss 0.0746 (0.0746)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:16:41]
  Epoch: [161][100/391]   Time 0.039 (0.045)   Data 0.000 (0.002)   Loss 0.0959 (0.1035)   Prec@1 96.875 (96.357)   Prec@5 100.000 (99.961)   [2019-11-18 06:16:46]
  Epoch: [161][200/391]   Time 0.063 (0.044)   Data 0.000 (0.001)   Loss 0.1176 (0.1008)   Prec@1 94.531 (96.459)   Prec@5 100.000 (99.957)   [2019-11-18 06:16:50]
  Epoch: [161][300/391]   Time 0.035 (0.044)   Data 0.000 (0.001)   Loss 0.1624 (0.0984)   Prec@1 95.312 (96.504)   Prec@5 99.219 (99.951)   [2019-11-18 06:16:54]
  **Train** Prec@1 96.408 Prec@5 99.952 Error@1 3.592
  **Test** Prec@1 89.870 Prec@5 99.630 Error@1 10.130

==>>[2019-11-18 06:17:00] [Epoch=162/200] [Need: 00:12:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [162][000/391]   Time 0.272 (0.272)   Data 0.227 (0.227)   Loss 0.0688 (0.0688)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:17:00]
  Epoch: [162][100/391]   Time 0.037 (0.049)   Data 0.000 (0.002)   Loss 0.1310 (0.0975)   Prec@1 93.750 (96.519)   Prec@5 100.000 (99.977)   [2019-11-18 06:17:05]
  Epoch: [162][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1220 (0.0988)   Prec@1 96.875 (96.482)   Prec@5 99.219 (99.977)   [2019-11-18 06:17:09]
  Epoch: [162][300/391]   Time 0.054 (0.045)   Data 0.000 (0.001)   Loss 0.0938 (0.0989)   Prec@1 96.094 (96.527)   Prec@5 100.000 (99.966)   [2019-11-18 06:17:13]
  **Train** Prec@1 96.528 Prec@5 99.970 Error@1 3.472
  **Test** Prec@1 90.200 Prec@5 99.680 Error@1 9.800

==>>[2019-11-18 06:17:20] [Epoch=163/200] [Need: 00:11:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [163][000/391]   Time 0.292 (0.292)   Data 0.231 (0.231)   Loss 0.1178 (0.1178)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:17:20]
  Epoch: [163][100/391]   Time 0.039 (0.043)   Data 0.000 (0.003)   Loss 0.0717 (0.1019)   Prec@1 97.656 (96.457)   Prec@5 100.000 (99.977)   [2019-11-18 06:17:24]
  Epoch: [163][200/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.1098 (0.1030)   Prec@1 96.094 (96.362)   Prec@5 100.000 (99.981)   [2019-11-18 06:17:28]
  Epoch: [163][300/391]   Time 0.040 (0.043)   Data 0.000 (0.001)   Loss 0.0933 (0.1010)   Prec@1 97.656 (96.473)   Prec@5 100.000 (99.977)   [2019-11-18 06:17:33]
  **Train** Prec@1 96.440 Prec@5 99.974 Error@1 3.560
  **Test** Prec@1 90.400 Prec@5 99.660 Error@1 9.600

==>>[2019-11-18 06:17:38] [Epoch=164/200] [Need: 00:11:35] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [164][000/391]   Time 0.279 (0.279)   Data 0.236 (0.236)   Loss 0.0769 (0.0769)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:17:39]
  Epoch: [164][100/391]   Time 0.055 (0.044)   Data 0.000 (0.002)   Loss 0.0752 (0.1033)   Prec@1 96.875 (96.241)   Prec@5 100.000 (99.969)   [2019-11-18 06:17:43]
  Epoch: [164][200/391]   Time 0.046 (0.044)   Data 0.000 (0.001)   Loss 0.0691 (0.0997)   Prec@1 98.438 (96.490)   Prec@5 100.000 (99.977)   [2019-11-18 06:17:47]
  Epoch: [164][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.1692 (0.0990)   Prec@1 96.094 (96.488)   Prec@5 100.000 (99.969)   [2019-11-18 06:17:52]
  **Train** Prec@1 96.480 Prec@5 99.970 Error@1 3.520
  **Test** Prec@1 90.290 Prec@5 99.640 Error@1 9.710

==>>[2019-11-18 06:17:58] [Epoch=165/200] [Need: 00:11:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [165][000/391]   Time 0.279 (0.279)   Data 0.220 (0.220)   Loss 0.0880 (0.0880)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:17:58]
  Epoch: [165][100/391]   Time 0.054 (0.047)   Data 0.000 (0.002)   Loss 0.1361 (0.1045)   Prec@1 96.094 (96.334)   Prec@5 100.000 (99.954)   [2019-11-18 06:18:02]
  Epoch: [165][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.1140 (0.1019)   Prec@1 95.312 (96.385)   Prec@5 100.000 (99.965)   [2019-11-18 06:18:07]
  Epoch: [165][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1102 (0.0990)   Prec@1 96.875 (96.449)   Prec@5 100.000 (99.974)   [2019-11-18 06:18:11]
  **Train** Prec@1 96.468 Prec@5 99.976 Error@1 3.532
  **Test** Prec@1 90.380 Prec@5 99.640 Error@1 9.620

==>>[2019-11-18 06:18:17] [Epoch=166/200] [Need: 00:10:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [166][000/391]   Time 0.279 (0.279)   Data 0.216 (0.216)   Loss 0.0430 (0.0430)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:18:17]
  Epoch: [166][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.0831 (0.1018)   Prec@1 97.656 (96.403)   Prec@5 100.000 (99.961)   [2019-11-18 06:18:22]
  Epoch: [166][200/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.0439 (0.1002)   Prec@1 98.438 (96.482)   Prec@5 100.000 (99.953)   [2019-11-18 06:18:26]
  Epoch: [166][300/391]   Time 0.073 (0.045)   Data 0.000 (0.001)   Loss 0.1064 (0.1028)   Prec@1 96.094 (96.423)   Prec@5 100.000 (99.953)   [2019-11-18 06:18:31]
  **Train** Prec@1 96.378 Prec@5 99.958 Error@1 3.622
  **Test** Prec@1 89.950 Prec@5 99.660 Error@1 10.050

==>>[2019-11-18 06:18:36] [Epoch=167/200] [Need: 00:10:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [167][000/391]   Time 0.278 (0.278)   Data 0.213 (0.213)   Loss 0.0939 (0.0939)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:18:37]
  Epoch: [167][100/391]   Time 0.044 (0.047)   Data 0.000 (0.002)   Loss 0.1550 (0.1105)   Prec@1 95.312 (96.140)   Prec@5 100.000 (99.961)   [2019-11-18 06:18:41]
  Epoch: [167][200/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.1103 (0.1040)   Prec@1 96.875 (96.420)   Prec@5 100.000 (99.969)   [2019-11-18 06:18:46]
  Epoch: [167][300/391]   Time 0.043 (0.045)   Data 0.000 (0.001)   Loss 0.0600 (0.1040)   Prec@1 98.438 (96.426)   Prec@5 100.000 (99.969)   [2019-11-18 06:18:50]
  **Train** Prec@1 96.346 Prec@5 99.964 Error@1 3.654
  **Test** Prec@1 90.120 Prec@5 99.690 Error@1 9.880

==>>[2019-11-18 06:18:56] [Epoch=168/200] [Need: 00:10:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [168][000/391]   Time 0.284 (0.284)   Data 0.229 (0.229)   Loss 0.0799 (0.0799)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:18:56]
  Epoch: [168][100/391]   Time 0.037 (0.041)   Data 0.000 (0.002)   Loss 0.1330 (0.0967)   Prec@1 96.094 (96.496)   Prec@5 100.000 (99.969)   [2019-11-18 06:19:00]
  Epoch: [168][200/391]   Time 0.036 (0.041)   Data 0.000 (0.001)   Loss 0.0785 (0.0981)   Prec@1 96.094 (96.486)   Prec@5 100.000 (99.973)   [2019-11-18 06:19:04]
  Epoch: [168][300/391]   Time 0.063 (0.041)   Data 0.000 (0.001)   Loss 0.1314 (0.0978)   Prec@1 95.312 (96.514)   Prec@5 100.000 (99.974)   [2019-11-18 06:19:08]
  **Train** Prec@1 96.482 Prec@5 99.968 Error@1 3.518
  **Test** Prec@1 90.040 Prec@5 99.620 Error@1 9.960

==>>[2019-11-18 06:19:14] [Epoch=169/200] [Need: 00:09:58] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [169][000/391]   Time 0.277 (0.277)   Data 0.225 (0.225)   Loss 0.1425 (0.1425)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-18 06:19:14]
  Epoch: [169][100/391]   Time 0.046 (0.047)   Data 0.000 (0.002)   Loss 0.0800 (0.0988)   Prec@1 97.656 (96.434)   Prec@5 100.000 (99.946)   [2019-11-18 06:19:19]
  Epoch: [169][200/391]   Time 0.055 (0.045)   Data 0.000 (0.001)   Loss 0.1418 (0.0981)   Prec@1 93.750 (96.377)   Prec@5 100.000 (99.961)   [2019-11-18 06:19:23]
  Epoch: [169][300/391]   Time 0.044 (0.044)   Data 0.000 (0.001)   Loss 0.0567 (0.1004)   Prec@1 97.656 (96.403)   Prec@5 100.000 (99.958)   [2019-11-18 06:19:27]
  **Train** Prec@1 96.470 Prec@5 99.956 Error@1 3.530
  **Test** Prec@1 89.730 Prec@5 99.620 Error@1 10.270

==>>[2019-11-18 06:19:33] [Epoch=170/200] [Need: 00:09:39] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [170][000/391]   Time 0.275 (0.275)   Data 0.226 (0.226)   Loss 0.0917 (0.0917)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:19:34]
  Epoch: [170][100/391]   Time 0.045 (0.045)   Data 0.000 (0.002)   Loss 0.0516 (0.0984)   Prec@1 99.219 (96.426)   Prec@5 100.000 (99.969)   [2019-11-18 06:19:38]
  Epoch: [170][200/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.0695 (0.1000)   Prec@1 99.219 (96.358)   Prec@5 100.000 (99.961)   [2019-11-18 06:19:42]
  Epoch: [170][300/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0518 (0.1011)   Prec@1 98.438 (96.408)   Prec@5 100.000 (99.951)   [2019-11-18 06:19:47]
  **Train** Prec@1 96.350 Prec@5 99.950 Error@1 3.650
  **Test** Prec@1 89.920 Prec@5 99.620 Error@1 10.080

==>>[2019-11-18 06:19:53] [Epoch=171/200] [Need: 00:09:19] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [171][000/391]   Time 0.282 (0.282)   Data 0.215 (0.215)   Loss 0.0794 (0.0794)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:19:53]
  Epoch: [171][100/391]   Time 0.044 (0.046)   Data 0.000 (0.002)   Loss 0.1822 (0.0993)   Prec@1 92.969 (96.527)   Prec@5 100.000 (99.977)   [2019-11-18 06:19:58]
  Epoch: [171][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.1610 (0.1007)   Prec@1 92.969 (96.405)   Prec@5 100.000 (99.969)   [2019-11-18 06:20:02]
  Epoch: [171][300/391]   Time 0.047 (0.045)   Data 0.000 (0.001)   Loss 0.0796 (0.1007)   Prec@1 96.875 (96.423)   Prec@5 100.000 (99.966)   [2019-11-18 06:20:06]
  **Train** Prec@1 96.418 Prec@5 99.966 Error@1 3.582
  **Test** Prec@1 90.060 Prec@5 99.590 Error@1 9.940

==>>[2019-11-18 06:20:12] [Epoch=172/200] [Need: 00:09:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.46, Error=9.54]
  Epoch: [172][000/391]   Time 0.292 (0.292)   Data 0.231 (0.231)   Loss 0.0650 (0.0650)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:20:12]
  Epoch: [172][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.1336 (0.0955)   Prec@1 94.531 (96.558)   Prec@5 100.000 (99.985)   [2019-11-18 06:20:17]
  Epoch: [172][200/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.1416 (0.0977)   Prec@1 93.750 (96.545)   Prec@5 100.000 (99.973)   [2019-11-18 06:20:21]
  Epoch: [172][300/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.1050 (0.0990)   Prec@1 96.094 (96.460)   Prec@5 99.219 (99.966)   [2019-11-18 06:20:26]
  **Train** Prec@1 96.422 Prec@5 99.970 Error@1 3.578
  **Test** Prec@1 90.520 Prec@5 99.650 Error@1 9.480
=> Obtain best accuracy, and update the best model

==>>[2019-11-18 06:20:31] [Epoch=173/200] [Need: 00:08:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [173][000/391]   Time 0.278 (0.278)   Data 0.217 (0.217)   Loss 0.0964 (0.0964)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:20:32]
  Epoch: [173][100/391]   Time 0.045 (0.049)   Data 0.000 (0.002)   Loss 0.0861 (0.0943)   Prec@1 98.438 (96.573)   Prec@5 100.000 (99.977)   [2019-11-18 06:20:36]
  Epoch: [173][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.0988 (0.0976)   Prec@1 96.875 (96.514)   Prec@5 100.000 (99.973)   [2019-11-18 06:20:41]
  Epoch: [173][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.1040 (0.1006)   Prec@1 97.656 (96.353)   Prec@5 100.000 (99.974)   [2019-11-18 06:20:45]
  **Train** Prec@1 96.342 Prec@5 99.976 Error@1 3.658
  **Test** Prec@1 89.350 Prec@5 99.520 Error@1 10.650

==>>[2019-11-18 06:20:50] [Epoch=174/200] [Need: 00:08:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [174][000/391]   Time 0.283 (0.283)   Data 0.226 (0.226)   Loss 0.2185 (0.2185)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-18 06:20:51]
  Epoch: [174][100/391]   Time 0.048 (0.049)   Data 0.000 (0.002)   Loss 0.1055 (0.1041)   Prec@1 96.875 (96.303)   Prec@5 100.000 (99.969)   [2019-11-18 06:20:55]
  Epoch: [174][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.1408 (0.1029)   Prec@1 94.531 (96.381)   Prec@5 100.000 (99.953)   [2019-11-18 06:21:00]
  Epoch: [174][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.0597 (0.1024)   Prec@1 98.438 (96.384)   Prec@5 100.000 (99.953)   [2019-11-18 06:21:04]
  **Train** Prec@1 96.298 Prec@5 99.960 Error@1 3.702
  **Test** Prec@1 89.840 Prec@5 99.620 Error@1 10.160

==>>[2019-11-18 06:21:10] [Epoch=175/200] [Need: 00:08:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [175][000/391]   Time 0.288 (0.288)   Data 0.239 (0.239)   Loss 0.0967 (0.0967)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:21:10]
  Epoch: [175][100/391]   Time 0.039 (0.047)   Data 0.000 (0.003)   Loss 0.0803 (0.0992)   Prec@1 95.312 (96.419)   Prec@5 100.000 (99.923)   [2019-11-18 06:21:14]
  Epoch: [175][200/391]   Time 0.038 (0.044)   Data 0.000 (0.001)   Loss 0.0905 (0.1016)   Prec@1 96.094 (96.343)   Prec@5 100.000 (99.949)   [2019-11-18 06:21:19]
  Epoch: [175][300/391]   Time 0.036 (0.043)   Data 0.000 (0.001)   Loss 0.1725 (0.1007)   Prec@1 96.094 (96.405)   Prec@5 100.000 (99.951)   [2019-11-18 06:21:23]
  **Train** Prec@1 96.410 Prec@5 99.958 Error@1 3.590
  **Test** Prec@1 89.760 Prec@5 99.610 Error@1 10.240

==>>[2019-11-18 06:21:29] [Epoch=176/200] [Need: 00:07:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [176][000/391]   Time 0.297 (0.297)   Data 0.245 (0.245)   Loss 0.1431 (0.1431)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-18 06:21:29]
  Epoch: [176][100/391]   Time 0.036 (0.047)   Data 0.000 (0.003)   Loss 0.1091 (0.1015)   Prec@1 93.750 (96.388)   Prec@5 100.000 (99.954)   [2019-11-18 06:21:33]
  Epoch: [176][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.0852 (0.0984)   Prec@1 96.094 (96.521)   Prec@5 100.000 (99.946)   [2019-11-18 06:21:38]
  Epoch: [176][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.0960 (0.0995)   Prec@1 96.094 (96.470)   Prec@5 100.000 (99.956)   [2019-11-18 06:21:42]
  **Train** Prec@1 96.504 Prec@5 99.960 Error@1 3.496
  **Test** Prec@1 89.910 Prec@5 99.620 Error@1 10.090

==>>[2019-11-18 06:21:48] [Epoch=177/200] [Need: 00:07:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [177][000/391]   Time 0.288 (0.288)   Data 0.225 (0.225)   Loss 0.0513 (0.0513)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:21:48]
  Epoch: [177][100/391]   Time 0.045 (0.048)   Data 0.000 (0.002)   Loss 0.1054 (0.1001)   Prec@1 97.656 (96.488)   Prec@5 100.000 (99.961)   [2019-11-18 06:21:53]
  Epoch: [177][200/391]   Time 0.053 (0.045)   Data 0.000 (0.001)   Loss 0.1918 (0.1009)   Prec@1 92.188 (96.412)   Prec@5 100.000 (99.965)   [2019-11-18 06:21:57]
  Epoch: [177][300/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 0.0741 (0.0971)   Prec@1 97.656 (96.577)   Prec@5 100.000 (99.971)   [2019-11-18 06:22:02]
  **Train** Prec@1 96.468 Prec@5 99.968 Error@1 3.532
  **Test** Prec@1 89.860 Prec@5 99.700 Error@1 10.140

==>>[2019-11-18 06:22:07] [Epoch=178/200] [Need: 00:07:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [178][000/391]   Time 0.286 (0.286)   Data 0.230 (0.230)   Loss 0.0948 (0.0948)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:22:08]
  Epoch: [178][100/391]   Time 0.037 (0.044)   Data 0.000 (0.002)   Loss 0.0829 (0.0983)   Prec@1 97.656 (96.481)   Prec@5 100.000 (99.992)   [2019-11-18 06:22:12]
  Epoch: [178][200/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.0530 (0.0948)   Prec@1 97.656 (96.583)   Prec@5 100.000 (99.984)   [2019-11-18 06:22:16]
  Epoch: [178][300/391]   Time 0.045 (0.042)   Data 0.000 (0.001)   Loss 0.0944 (0.0968)   Prec@1 96.875 (96.527)   Prec@5 99.219 (99.979)   [2019-11-18 06:22:20]
  **Train** Prec@1 96.456 Prec@5 99.970 Error@1 3.544
  **Test** Prec@1 89.940 Prec@5 99.620 Error@1 10.060

==>>[2019-11-18 06:22:26] [Epoch=179/200] [Need: 00:06:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [179][000/391]   Time 0.285 (0.285)   Data 0.234 (0.234)   Loss 0.0567 (0.0567)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:22:26]
  Epoch: [179][100/391]   Time 0.046 (0.048)   Data 0.000 (0.002)   Loss 0.0619 (0.0974)   Prec@1 96.875 (96.519)   Prec@5 100.000 (99.969)   [2019-11-18 06:22:31]
  Epoch: [179][200/391]   Time 0.035 (0.046)   Data 0.000 (0.001)   Loss 0.0722 (0.0974)   Prec@1 98.438 (96.580)   Prec@5 100.000 (99.973)   [2019-11-18 06:22:35]
  Epoch: [179][300/391]   Time 0.036 (0.045)   Data 0.000 (0.001)   Loss 0.1048 (0.0989)   Prec@1 97.656 (96.558)   Prec@5 99.219 (99.969)   [2019-11-18 06:22:39]
  **Train** Prec@1 96.532 Prec@5 99.972 Error@1 3.468
  **Test** Prec@1 90.390 Prec@5 99.710 Error@1 9.610

==>>[2019-11-18 06:22:46] [Epoch=180/200] [Need: 00:06:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [180][000/391]   Time 0.280 (0.280)   Data 0.226 (0.226)   Loss 0.0365 (0.0365)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:22:46]
  Epoch: [180][100/391]   Time 0.068 (0.048)   Data 0.000 (0.002)   Loss 0.0868 (0.0928)   Prec@1 96.094 (96.751)   Prec@5 100.000 (99.977)   [2019-11-18 06:22:51]
  Epoch: [180][200/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.0979 (0.0971)   Prec@1 96.875 (96.521)   Prec@5 100.000 (99.969)   [2019-11-18 06:22:55]
  Epoch: [180][300/391]   Time 0.045 (0.046)   Data 0.000 (0.001)   Loss 0.0613 (0.1007)   Prec@1 96.875 (96.400)   Prec@5 100.000 (99.969)   [2019-11-18 06:23:00]
  **Train** Prec@1 96.454 Prec@5 99.970 Error@1 3.546
  **Test** Prec@1 90.270 Prec@5 99.590 Error@1 9.730

==>>[2019-11-18 06:23:06] [Epoch=181/200] [Need: 00:06:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [181][000/391]   Time 0.287 (0.287)   Data 0.217 (0.217)   Loss 0.0894 (0.0894)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:23:06]
  Epoch: [181][100/391]   Time 0.038 (0.042)   Data 0.000 (0.002)   Loss 0.0436 (0.0937)   Prec@1 98.438 (96.759)   Prec@5 100.000 (99.961)   [2019-11-18 06:23:10]
  Epoch: [181][200/391]   Time 0.036 (0.041)   Data 0.000 (0.001)   Loss 0.0931 (0.0953)   Prec@1 97.656 (96.657)   Prec@5 100.000 (99.957)   [2019-11-18 06:23:14]
  Epoch: [181][300/391]   Time 0.041 (0.042)   Data 0.000 (0.001)   Loss 0.0618 (0.0962)   Prec@1 98.438 (96.621)   Prec@5 100.000 (99.966)   [2019-11-18 06:23:18]
  **Train** Prec@1 96.604 Prec@5 99.970 Error@1 3.396
  **Test** Prec@1 89.850 Prec@5 99.590 Error@1 10.150

==>>[2019-11-18 06:23:25] [Epoch=182/200] [Need: 00:05:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [182][000/391]   Time 0.287 (0.287)   Data 0.211 (0.211)   Loss 0.1826 (0.1826)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2019-11-18 06:23:25]
  Epoch: [182][100/391]   Time 0.044 (0.049)   Data 0.000 (0.002)   Loss 0.0813 (0.0983)   Prec@1 98.438 (96.550)   Prec@5 100.000 (99.969)   [2019-11-18 06:23:30]
  Epoch: [182][200/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.0685 (0.1020)   Prec@1 98.438 (96.370)   Prec@5 100.000 (99.969)   [2019-11-18 06:23:34]
  Epoch: [182][300/391]   Time 0.057 (0.044)   Data 0.000 (0.001)   Loss 0.0605 (0.1003)   Prec@1 96.875 (96.426)   Prec@5 100.000 (99.969)   [2019-11-18 06:23:38]
  **Train** Prec@1 96.434 Prec@5 99.962 Error@1 3.566
  **Test** Prec@1 90.050 Prec@5 99.660 Error@1 9.950

==>>[2019-11-18 06:23:44] [Epoch=183/200] [Need: 00:05:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [183][000/391]   Time 0.289 (0.289)   Data 0.227 (0.227)   Loss 0.0614 (0.0614)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:23:44]
  Epoch: [183][100/391]   Time 0.046 (0.045)   Data 0.000 (0.002)   Loss 0.1244 (0.0994)   Prec@1 96.094 (96.527)   Prec@5 100.000 (99.961)   [2019-11-18 06:23:48]
  Epoch: [183][200/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.0415 (0.1009)   Prec@1 99.219 (96.409)   Prec@5 100.000 (99.961)   [2019-11-18 06:23:52]
  Epoch: [183][300/391]   Time 0.036 (0.044)   Data 0.000 (0.001)   Loss 0.1016 (0.0991)   Prec@1 97.656 (96.491)   Prec@5 100.000 (99.969)   [2019-11-18 06:23:57]
  **Train** Prec@1 96.486 Prec@5 99.964 Error@1 3.514
  **Test** Prec@1 90.120 Prec@5 99.660 Error@1 9.880

==>>[2019-11-18 06:24:02] [Epoch=184/200] [Need: 00:05:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [184][000/391]   Time 0.283 (0.283)   Data 0.234 (0.234)   Loss 0.0551 (0.0551)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-18 06:24:03]
  Epoch: [184][100/391]   Time 0.042 (0.043)   Data 0.000 (0.002)   Loss 0.1566 (0.1021)   Prec@1 95.312 (96.442)   Prec@5 100.000 (99.985)   [2019-11-18 06:24:07]
  Epoch: [184][200/391]   Time 0.054 (0.044)   Data 0.000 (0.001)   Loss 0.1217 (0.1012)   Prec@1 96.094 (96.498)   Prec@5 100.000 (99.969)   [2019-11-18 06:24:11]
  Epoch: [184][300/391]   Time 0.041 (0.044)   Data 0.000 (0.001)   Loss 0.1155 (0.1001)   Prec@1 96.875 (96.538)   Prec@5 100.000 (99.964)   [2019-11-18 06:24:15]
  **Train** Prec@1 96.432 Prec@5 99.964 Error@1 3.568
  **Test** Prec@1 89.750 Prec@5 99.640 Error@1 10.250

==>>[2019-11-18 06:24:21] [Epoch=185/200] [Need: 00:04:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [185][000/391]   Time 0.282 (0.282)   Data 0.230 (0.230)   Loss 0.0964 (0.0964)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:24:21]
  Epoch: [185][100/391]   Time 0.038 (0.046)   Data 0.000 (0.003)   Loss 0.0816 (0.1023)   Prec@1 96.875 (96.256)   Prec@5 100.000 (99.954)   [2019-11-18 06:24:26]
  Epoch: [185][200/391]   Time 0.032 (0.044)   Data 0.000 (0.001)   Loss 0.0865 (0.1050)   Prec@1 96.094 (96.261)   Prec@5 100.000 (99.949)   [2019-11-18 06:24:30]
  Epoch: [185][300/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.1019 (0.1031)   Prec@1 96.094 (96.322)   Prec@5 100.000 (99.958)   [2019-11-18 06:24:34]
  **Train** Prec@1 96.324 Prec@5 99.960 Error@1 3.676
  **Test** Prec@1 90.210 Prec@5 99.700 Error@1 9.790

==>>[2019-11-18 06:24:40] [Epoch=186/200] [Need: 00:04:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [186][000/391]   Time 0.289 (0.289)   Data 0.235 (0.235)   Loss 0.1007 (0.1007)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:24:41]
  Epoch: [186][100/391]   Time 0.047 (0.046)   Data 0.000 (0.002)   Loss 0.0571 (0.0982)   Prec@1 97.656 (96.287)   Prec@5 100.000 (99.961)   [2019-11-18 06:24:45]
  Epoch: [186][200/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.1138 (0.1015)   Prec@1 97.656 (96.273)   Prec@5 100.000 (99.949)   [2019-11-18 06:24:49]
  Epoch: [186][300/391]   Time 0.045 (0.045)   Data 0.000 (0.001)   Loss 0.0938 (0.0976)   Prec@1 96.875 (96.442)   Prec@5 100.000 (99.961)   [2019-11-18 06:24:54]
  **Train** Prec@1 96.466 Prec@5 99.962 Error@1 3.534
  **Test** Prec@1 89.840 Prec@5 99.590 Error@1 10.160

==>>[2019-11-18 06:25:00] [Epoch=187/200] [Need: 00:04:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [187][000/391]   Time 0.293 (0.293)   Data 0.221 (0.221)   Loss 0.1215 (0.1215)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:25:00]
  Epoch: [187][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.1205 (0.0959)   Prec@1 94.531 (96.573)   Prec@5 100.000 (99.969)   [2019-11-18 06:25:05]
  Epoch: [187][200/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.1018 (0.0984)   Prec@1 95.312 (96.490)   Prec@5 100.000 (99.973)   [2019-11-18 06:25:09]
  Epoch: [187][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.0854 (0.0975)   Prec@1 96.875 (96.522)   Prec@5 100.000 (99.969)   [2019-11-18 06:25:13]
  **Train** Prec@1 96.546 Prec@5 99.964 Error@1 3.454
  **Test** Prec@1 89.500 Prec@5 99.640 Error@1 10.500

==>>[2019-11-18 06:25:19] [Epoch=188/200] [Need: 00:03:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [188][000/391]   Time 0.291 (0.291)   Data 0.241 (0.241)   Loss 0.0536 (0.0536)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:25:20]
  Epoch: [188][100/391]   Time 0.046 (0.045)   Data 0.000 (0.003)   Loss 0.0818 (0.1002)   Prec@1 96.094 (96.504)   Prec@5 100.000 (99.946)   [2019-11-18 06:25:24]
  Epoch: [188][200/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.0577 (0.1015)   Prec@1 98.438 (96.401)   Prec@5 100.000 (99.949)   [2019-11-18 06:25:28]
  Epoch: [188][300/391]   Time 0.038 (0.043)   Data 0.000 (0.001)   Loss 0.0249 (0.1013)   Prec@1 100.000 (96.434)   Prec@5 100.000 (99.956)   [2019-11-18 06:25:32]
  **Train** Prec@1 96.412 Prec@5 99.960 Error@1 3.588
  **Test** Prec@1 89.850 Prec@5 99.630 Error@1 10.150

==>>[2019-11-18 06:25:38] [Epoch=189/200] [Need: 00:03:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [189][000/391]   Time 0.293 (0.293)   Data 0.242 (0.242)   Loss 0.0609 (0.0609)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-18 06:25:39]
  Epoch: [189][100/391]   Time 0.036 (0.048)   Data 0.000 (0.003)   Loss 0.1452 (0.0959)   Prec@1 93.750 (96.689)   Prec@5 100.000 (99.977)   [2019-11-18 06:25:43]
  Epoch: [189][200/391]   Time 0.038 (0.046)   Data 0.000 (0.001)   Loss 0.1202 (0.1023)   Prec@1 95.312 (96.440)   Prec@5 100.000 (99.961)   [2019-11-18 06:25:48]
  Epoch: [189][300/391]   Time 0.037 (0.046)   Data 0.000 (0.001)   Loss 0.0822 (0.1016)   Prec@1 97.656 (96.483)   Prec@5 100.000 (99.961)   [2019-11-18 06:25:52]
  **Train** Prec@1 96.426 Prec@5 99.952 Error@1 3.574
  **Test** Prec@1 90.130 Prec@5 99.660 Error@1 9.870

==>>[2019-11-18 06:25:58] [Epoch=190/200] [Need: 00:03:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [190][000/391]   Time 0.271 (0.271)   Data 0.213 (0.213)   Loss 0.0875 (0.0875)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:25:58]
  Epoch: [190][100/391]   Time 0.032 (0.044)   Data 0.000 (0.002)   Loss 0.1268 (0.1066)   Prec@1 97.656 (96.264)   Prec@5 100.000 (99.961)   [2019-11-18 06:26:02]
  Epoch: [190][200/391]   Time 0.036 (0.042)   Data 0.000 (0.001)   Loss 0.1109 (0.1038)   Prec@1 96.094 (96.412)   Prec@5 100.000 (99.961)   [2019-11-18 06:26:07]
  Epoch: [190][300/391]   Time 0.067 (0.042)   Data 0.000 (0.001)   Loss 0.1421 (0.1020)   Prec@1 96.094 (96.413)   Prec@5 100.000 (99.966)   [2019-11-18 06:26:11]
  **Train** Prec@1 96.388 Prec@5 99.966 Error@1 3.612
  **Test** Prec@1 89.900 Prec@5 99.620 Error@1 10.100

==>>[2019-11-18 06:26:16] [Epoch=191/200] [Need: 00:02:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [191][000/391]   Time 0.309 (0.309)   Data 0.258 (0.258)   Loss 0.1010 (0.1010)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:26:16]
  Epoch: [191][100/391]   Time 0.037 (0.047)   Data 0.000 (0.003)   Loss 0.0969 (0.0924)   Prec@1 96.094 (96.697)   Prec@5 100.000 (99.954)   [2019-11-18 06:26:21]
  Epoch: [191][200/391]   Time 0.037 (0.045)   Data 0.000 (0.002)   Loss 0.1104 (0.0969)   Prec@1 96.094 (96.572)   Prec@5 100.000 (99.957)   [2019-11-18 06:26:25]
  Epoch: [191][300/391]   Time 0.043 (0.044)   Data 0.000 (0.001)   Loss 0.0490 (0.0975)   Prec@1 99.219 (96.621)   Prec@5 100.000 (99.966)   [2019-11-18 06:26:29]
  **Train** Prec@1 96.596 Prec@5 99.970 Error@1 3.404
  **Test** Prec@1 90.070 Prec@5 99.630 Error@1 9.930

==>>[2019-11-18 06:26:35] [Epoch=192/200] [Need: 00:02:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [192][000/391]   Time 0.294 (0.294)   Data 0.240 (0.240)   Loss 0.0966 (0.0966)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:26:36]
  Epoch: [192][100/391]   Time 0.066 (0.045)   Data 0.000 (0.003)   Loss 0.0587 (0.0945)   Prec@1 97.656 (96.759)   Prec@5 100.000 (99.985)   [2019-11-18 06:26:40]
  Epoch: [192][200/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.0698 (0.0974)   Prec@1 98.438 (96.685)   Prec@5 100.000 (99.981)   [2019-11-18 06:26:44]
  Epoch: [192][300/391]   Time 0.037 (0.044)   Data 0.000 (0.001)   Loss 0.1123 (0.1010)   Prec@1 96.094 (96.535)   Prec@5 100.000 (99.979)   [2019-11-18 06:26:48]
  **Train** Prec@1 96.586 Prec@5 99.976 Error@1 3.414
  **Test** Prec@1 90.160 Prec@5 99.710 Error@1 9.840

==>>[2019-11-18 06:26:54] [Epoch=193/200] [Need: 00:02:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [193][000/391]   Time 0.286 (0.286)   Data 0.225 (0.225)   Loss 0.1316 (0.1316)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-18 06:26:55]
  Epoch: [193][100/391]   Time 0.040 (0.049)   Data 0.004 (0.002)   Loss 0.1567 (0.0915)   Prec@1 96.094 (96.805)   Prec@5 100.000 (99.954)   [2019-11-18 06:26:59]
  Epoch: [193][200/391]   Time 0.036 (0.047)   Data 0.000 (0.001)   Loss 0.1333 (0.0943)   Prec@1 96.094 (96.661)   Prec@5 100.000 (99.961)   [2019-11-18 06:27:04]
  Epoch: [193][300/391]   Time 0.062 (0.047)   Data 0.000 (0.001)   Loss 0.1164 (0.0976)   Prec@1 95.312 (96.579)   Prec@5 100.000 (99.961)   [2019-11-18 06:27:08]
  **Train** Prec@1 96.504 Prec@5 99.962 Error@1 3.496
  **Test** Prec@1 90.000 Prec@5 99.660 Error@1 10.000

==>>[2019-11-18 06:27:14] [Epoch=194/200] [Need: 00:01:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [194][000/391]   Time 0.277 (0.277)   Data 0.225 (0.225)   Loss 0.1077 (0.1077)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-18 06:27:15]
  Epoch: [194][100/391]   Time 0.040 (0.044)   Data 0.000 (0.002)   Loss 0.0849 (0.0936)   Prec@1 97.656 (96.697)   Prec@5 100.000 (99.969)   [2019-11-18 06:27:19]
  Epoch: [194][200/391]   Time 0.037 (0.043)   Data 0.000 (0.001)   Loss 0.0901 (0.0954)   Prec@1 96.094 (96.630)   Prec@5 100.000 (99.961)   [2019-11-18 06:27:23]
  Epoch: [194][300/391]   Time 0.039 (0.043)   Data 0.000 (0.001)   Loss 0.0648 (0.0962)   Prec@1 98.438 (96.605)   Prec@5 100.000 (99.964)   [2019-11-18 06:27:27]
  **Train** Prec@1 96.546 Prec@5 99.966 Error@1 3.454
  **Test** Prec@1 89.680 Prec@5 99.680 Error@1 10.320

==>>[2019-11-18 06:27:33] [Epoch=195/200] [Need: 00:01:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [195][000/391]   Time 0.288 (0.288)   Data 0.237 (0.237)   Loss 0.1635 (0.1635)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 06:27:34]
  Epoch: [195][100/391]   Time 0.038 (0.049)   Data 0.000 (0.003)   Loss 0.2547 (0.0956)   Prec@1 93.750 (96.620)   Prec@5 100.000 (99.961)   [2019-11-18 06:27:38]
  Epoch: [195][200/391]   Time 0.046 (0.047)   Data 0.000 (0.001)   Loss 0.1410 (0.0977)   Prec@1 96.875 (96.486)   Prec@5 100.000 (99.969)   [2019-11-18 06:27:43]
  Epoch: [195][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.1321 (0.0985)   Prec@1 92.969 (96.462)   Prec@5 100.000 (99.979)   [2019-11-18 06:27:47]
  **Train** Prec@1 96.482 Prec@5 99.982 Error@1 3.518
  **Test** Prec@1 90.230 Prec@5 99.650 Error@1 9.770

==>>[2019-11-18 06:27:53] [Epoch=196/200] [Need: 00:01:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [196][000/391]   Time 0.283 (0.283)   Data 0.233 (0.233)   Loss 0.1914 (0.1914)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-18 06:27:53]
  Epoch: [196][100/391]   Time 0.040 (0.044)   Data 0.000 (0.002)   Loss 0.1721 (0.0989)   Prec@1 94.531 (96.442)   Prec@5 100.000 (99.992)   [2019-11-18 06:27:58]
  Epoch: [196][200/391]   Time 0.063 (0.045)   Data 0.000 (0.001)   Loss 0.1171 (0.0969)   Prec@1 93.750 (96.541)   Prec@5 100.000 (99.969)   [2019-11-18 06:28:02]
  Epoch: [196][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.1364 (0.0972)   Prec@1 94.531 (96.579)   Prec@5 100.000 (99.971)   [2019-11-18 06:28:07]
  **Train** Prec@1 96.520 Prec@5 99.972 Error@1 3.480
  **Test** Prec@1 90.000 Prec@5 99.630 Error@1 10.000

==>>[2019-11-18 06:28:13] [Epoch=197/200] [Need: 00:00:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [197][000/391]   Time 0.276 (0.276)   Data 0.219 (0.219)   Loss 0.0755 (0.0755)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-18 06:28:13]
  Epoch: [197][100/391]   Time 0.049 (0.046)   Data 0.000 (0.002)   Loss 0.0776 (0.0982)   Prec@1 97.656 (96.589)   Prec@5 100.000 (99.961)   [2019-11-18 06:28:17]
  Epoch: [197][200/391]   Time 0.036 (0.046)   Data 0.000 (0.001)   Loss 0.1046 (0.0970)   Prec@1 96.875 (96.630)   Prec@5 100.000 (99.961)   [2019-11-18 06:28:22]
  Epoch: [197][300/391]   Time 0.062 (0.045)   Data 0.000 (0.001)   Loss 0.0644 (0.0972)   Prec@1 97.656 (96.623)   Prec@5 100.000 (99.961)   [2019-11-18 06:28:26]
  **Train** Prec@1 96.514 Prec@5 99.956 Error@1 3.486
  **Test** Prec@1 89.750 Prec@5 99.640 Error@1 10.250

==>>[2019-11-18 06:28:32] [Epoch=198/200] [Need: 00:00:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [198][000/391]   Time 0.279 (0.279)   Data 0.226 (0.226)   Loss 0.1299 (0.1299)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-18 06:28:33]
  Epoch: [198][100/391]   Time 0.043 (0.046)   Data 0.000 (0.002)   Loss 0.1309 (0.0906)   Prec@1 93.750 (96.798)   Prec@5 100.000 (99.977)   [2019-11-18 06:28:37]
  Epoch: [198][200/391]   Time 0.035 (0.045)   Data 0.000 (0.001)   Loss 0.1166 (0.0949)   Prec@1 96.094 (96.634)   Prec@5 99.219 (99.953)   [2019-11-18 06:28:41]
  Epoch: [198][300/391]   Time 0.046 (0.044)   Data 0.000 (0.001)   Loss 0.1042 (0.0954)   Prec@1 95.312 (96.621)   Prec@5 100.000 (99.964)   [2019-11-18 06:28:46]
  **Train** Prec@1 96.628 Prec@5 99.964 Error@1 3.372
  **Test** Prec@1 90.100 Prec@5 99.600 Error@1 9.900

==>>[2019-11-18 06:28:51] [Epoch=199/200] [Need: 00:00:19] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [199][000/391]   Time 0.276 (0.276)   Data 0.221 (0.221)   Loss 0.0742 (0.0742)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-18 06:28:51]
  Epoch: [199][100/391]   Time 0.038 (0.046)   Data 0.000 (0.002)   Loss 0.0325 (0.0935)   Prec@1 99.219 (96.713)   Prec@5 100.000 (99.992)   [2019-11-18 06:28:56]
  Epoch: [199][200/391]   Time 0.043 (0.045)   Data 0.000 (0.001)   Loss 0.0818 (0.0960)   Prec@1 96.875 (96.650)   Prec@5 100.000 (99.969)   [2019-11-18 06:29:00]
  Epoch: [199][300/391]   Time 0.055 (0.044)   Data 0.000 (0.001)   Loss 0.0978 (0.0984)   Prec@1 95.312 (96.501)   Prec@5 100.000 (99.964)   [2019-11-18 06:29:05]
  **Train** Prec@1 96.506 Prec@5 99.966 Error@1 3.494
  **Test** Prec@1 89.960 Prec@5 99.620 Error@1 10.040
