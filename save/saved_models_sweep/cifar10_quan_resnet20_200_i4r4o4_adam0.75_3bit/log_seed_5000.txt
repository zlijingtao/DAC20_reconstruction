save path : ./save/2019-11-22/cifar10_quan_resnet20_200_i4r4o4_adam0.75_3bit
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.75, 'input_grain_size': [1, 4], 'input_num_bits': 3, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.75, 'output_grain_size': [1, 4], 'output_num_bits': 3, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.75, 'res_grain_size': [1, 4], 'res_num_bits': 3, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-22/cifar10_quan_resnet20_200_i4r4o4_adam0.75_3bit', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-23 04:47:56] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.601 (1.601)   Data 0.162 (0.162)   Loss 3.8409 (3.8409)   Prec@1 9.375 (9.375)   Prec@5 50.000 (50.000)   [2019-11-23 04:47:58]
  Epoch: [000][100/391]   Time 0.078 (0.062)   Data 0.000 (0.002)   Loss 1.7892 (1.9418)   Prec@1 39.844 (28.759)   Prec@5 86.719 (81.931)   [2019-11-23 04:48:02]
  Epoch: [000][200/391]   Time 0.042 (0.055)   Data 0.000 (0.001)   Loss 1.5125 (1.7602)   Prec@1 46.875 (34.729)   Prec@5 90.625 (86.307)   [2019-11-23 04:48:07]
  Epoch: [000][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 1.2774 (1.6295)   Prec@1 55.469 (39.750)   Prec@5 96.094 (88.593)   [2019-11-23 04:48:12]
  **Train** Prec@1 43.442 Prec@5 89.994 Error@1 56.558
  **Test** Prec@1 55.670 Prec@5 94.050 Error@1 44.330
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:48:18] [Epoch=001/200] [Need: 01:12:34] [LR=0.0100][M=0.90] [Best : Accuracy=55.67, Error=44.33]
  Epoch: [001][000/391]   Time 0.236 (0.236)   Data 0.160 (0.160)   Loss 1.1509 (1.1509)   Prec@1 60.938 (60.938)   Prec@5 96.875 (96.875)   [2019-11-23 04:48:19]
  Epoch: [001][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 1.1591 (1.1316)   Prec@1 61.719 (59.244)   Prec@5 94.531 (95.715)   [2019-11-23 04:48:24]
  Epoch: [001][200/391]   Time 0.079 (0.050)   Data 0.000 (0.001)   Loss 1.0051 (1.0860)   Prec@1 63.281 (60.798)   Prec@5 96.875 (96.039)   [2019-11-23 04:48:28]
  Epoch: [001][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.9776 (1.0651)   Prec@1 66.406 (61.794)   Prec@5 96.094 (96.208)   [2019-11-23 04:48:33]
  **Train** Prec@1 62.920 Prec@5 96.380 Error@1 37.080
  **Test** Prec@1 64.340 Prec@5 96.820 Error@1 35.660
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:48:39] [Epoch=002/200] [Need: 01:10:44] [LR=0.0100][M=0.90] [Best : Accuracy=64.34, Error=35.66]
  Epoch: [002][000/391]   Time 0.252 (0.252)   Data 0.196 (0.196)   Loss 0.9362 (0.9362)   Prec@1 70.312 (70.312)   Prec@5 95.312 (95.312)   [2019-11-23 04:48:40]
  Epoch: [002][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.9908 (0.9049)   Prec@1 64.844 (68.332)   Prec@5 97.656 (97.324)   [2019-11-23 04:48:45]
  Epoch: [002][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.9264 (0.8712)   Prec@1 65.625 (69.240)   Prec@5 98.438 (97.722)   [2019-11-23 04:48:50]
  Epoch: [002][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.8540 (0.8547)   Prec@1 71.875 (70.066)   Prec@5 96.094 (97.768)   [2019-11-23 04:48:54]
  **Train** Prec@1 70.486 Prec@5 97.838 Error@1 29.514
  **Test** Prec@1 70.150 Prec@5 97.750 Error@1 29.850
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:49:01] [Epoch=003/200] [Need: 01:10:02] [LR=0.0100][M=0.90] [Best : Accuracy=70.15, Error=29.85]
  Epoch: [003][000/391]   Time 0.260 (0.260)   Data 0.200 (0.200)   Loss 0.9474 (0.9474)   Prec@1 65.625 (65.625)   Prec@5 95.312 (95.312)   [2019-11-23 04:49:01]
  Epoch: [003][100/391]   Time 0.068 (0.052)   Data 0.000 (0.002)   Loss 0.7820 (0.7634)   Prec@1 71.875 (73.584)   Prec@5 99.219 (98.097)   [2019-11-23 04:49:06]
  Epoch: [003][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.7709 (0.7619)   Prec@1 69.531 (73.589)   Prec@5 99.219 (98.119)   [2019-11-23 04:49:11]
  Epoch: [003][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5938 (0.7580)   Prec@1 82.812 (73.780)   Prec@5 97.656 (98.103)   [2019-11-23 04:49:16]
  **Train** Prec@1 74.076 Prec@5 98.162 Error@1 25.924
  **Test** Prec@1 68.910 Prec@5 96.980 Error@1 31.090

==>>[2019-11-23 04:49:22] [Epoch=004/200] [Need: 01:09:51] [LR=0.0100][M=0.90] [Best : Accuracy=70.15, Error=29.85]
  Epoch: [004][000/391]   Time 0.243 (0.243)   Data 0.171 (0.171)   Loss 0.7287 (0.7287)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-23 04:49:22]
  Epoch: [004][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.6834 (0.6980)   Prec@1 77.344 (75.851)   Prec@5 97.656 (98.407)   [2019-11-23 04:49:27]
  Epoch: [004][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.5610 (0.6935)   Prec@1 78.906 (75.976)   Prec@5 99.219 (98.406)   [2019-11-23 04:49:32]
  Epoch: [004][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.6341 (0.6869)   Prec@1 75.000 (76.202)   Prec@5 98.438 (98.518)   [2019-11-23 04:49:37]
  **Train** Prec@1 76.500 Prec@5 98.570 Error@1 23.500
  **Test** Prec@1 73.220 Prec@5 97.930 Error@1 26.780
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:49:43] [Epoch=005/200] [Need: 01:09:22] [LR=0.0100][M=0.90] [Best : Accuracy=73.22, Error=26.78]
  Epoch: [005][000/391]   Time 0.241 (0.241)   Data 0.168 (0.168)   Loss 0.6182 (0.6182)   Prec@1 78.125 (78.125)   Prec@5 98.438 (98.438)   [2019-11-23 04:49:44]
  Epoch: [005][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.5273 (0.6343)   Prec@1 85.156 (77.947)   Prec@5 98.438 (98.832)   [2019-11-23 04:49:49]
  Epoch: [005][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.6308 (0.6436)   Prec@1 80.469 (77.713)   Prec@5 97.656 (98.756)   [2019-11-23 04:49:54]
  Epoch: [005][300/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.6547 (0.6378)   Prec@1 79.688 (77.925)   Prec@5 98.438 (98.715)   [2019-11-23 04:49:59]
  **Train** Prec@1 78.310 Prec@5 98.734 Error@1 21.690
  **Test** Prec@1 76.830 Prec@5 98.720 Error@1 23.170
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:50:06] [Epoch=006/200] [Need: 01:09:46] [LR=0.0100][M=0.90] [Best : Accuracy=76.83, Error=23.17]
  Epoch: [006][000/391]   Time 0.238 (0.238)   Data 0.174 (0.174)   Loss 0.5600 (0.5600)   Prec@1 78.906 (78.906)   Prec@5 99.219 (99.219)   [2019-11-23 04:50:06]
  Epoch: [006][100/391]   Time 0.075 (0.054)   Data 0.000 (0.002)   Loss 0.6292 (0.6140)   Prec@1 77.344 (78.628)   Prec@5 99.219 (98.762)   [2019-11-23 04:50:11]
  Epoch: [006][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.6908 (0.6079)   Prec@1 73.438 (78.895)   Prec@5 100.000 (98.822)   [2019-11-23 04:50:16]
  Epoch: [006][300/391]   Time 0.066 (0.051)   Data 0.000 (0.001)   Loss 0.6070 (0.6081)   Prec@1 78.125 (78.969)   Prec@5 97.656 (98.832)   [2019-11-23 04:50:21]
  **Train** Prec@1 79.022 Prec@5 98.842 Error@1 20.978
  **Test** Prec@1 75.500 Prec@5 98.430 Error@1 24.500

==>>[2019-11-23 04:50:27] [Epoch=007/200] [Need: 01:09:20] [LR=0.0100][M=0.90] [Best : Accuracy=76.83, Error=23.17]
  Epoch: [007][000/391]   Time 0.255 (0.255)   Data 0.198 (0.198)   Loss 0.6637 (0.6637)   Prec@1 77.344 (77.344)   Prec@5 96.875 (96.875)   [2019-11-23 04:50:28]
  Epoch: [007][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.7346 (0.5760)   Prec@1 76.562 (80.260)   Prec@5 97.656 (98.894)   [2019-11-23 04:50:33]
  Epoch: [007][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.6477 (0.5736)   Prec@1 75.781 (80.263)   Prec@5 99.219 (98.919)   [2019-11-23 04:50:38]
  Epoch: [007][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.6608 (0.5750)   Prec@1 75.000 (80.111)   Prec@5 98.438 (98.902)   [2019-11-23 04:50:43]
  **Train** Prec@1 80.112 Prec@5 98.916 Error@1 19.888
  **Test** Prec@1 75.790 Prec@5 98.130 Error@1 24.210

==>>[2019-11-23 04:50:50] [Epoch=008/200] [Need: 01:09:14] [LR=0.0100][M=0.90] [Best : Accuracy=76.83, Error=23.17]
  Epoch: [008][000/391]   Time 0.258 (0.258)   Data 0.171 (0.171)   Loss 0.5566 (0.5566)   Prec@1 79.688 (79.688)   Prec@5 99.219 (99.219)   [2019-11-23 04:50:50]
  Epoch: [008][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.4802 (0.5685)   Prec@1 84.375 (80.654)   Prec@5 98.438 (98.793)   [2019-11-23 04:50:55]
  Epoch: [008][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.5885 (0.5588)   Prec@1 82.812 (80.939)   Prec@5 98.438 (98.869)   [2019-11-23 04:51:00]
  Epoch: [008][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.7023 (0.5577)   Prec@1 71.094 (80.861)   Prec@5 100.000 (98.941)   [2019-11-23 04:51:05]
  **Train** Prec@1 80.862 Prec@5 98.974 Error@1 19.138
  **Test** Prec@1 78.920 Prec@5 98.820 Error@1 21.080
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:51:11] [Epoch=009/200] [Need: 01:08:46] [LR=0.0100][M=0.90] [Best : Accuracy=78.92, Error=21.08]
  Epoch: [009][000/391]   Time 0.246 (0.246)   Data 0.161 (0.161)   Loss 0.7275 (0.7275)   Prec@1 73.438 (73.438)   Prec@5 97.656 (97.656)   [2019-11-23 04:51:11]
  Epoch: [009][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.4986 (0.5295)   Prec@1 84.375 (81.590)   Prec@5 99.219 (99.110)   [2019-11-23 04:51:16]
  Epoch: [009][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.5403 (0.5273)   Prec@1 86.719 (81.658)   Prec@5 98.438 (99.153)   [2019-11-23 04:51:22]
  Epoch: [009][300/391]   Time 0.069 (0.051)   Data 0.000 (0.001)   Loss 0.6220 (0.5257)   Prec@1 78.125 (81.844)   Prec@5 97.656 (99.118)   [2019-11-23 04:51:26]
  **Train** Prec@1 81.678 Prec@5 99.092 Error@1 18.322
  **Test** Prec@1 77.530 Prec@5 98.250 Error@1 22.470

==>>[2019-11-23 04:51:33] [Epoch=010/200] [Need: 01:08:24] [LR=0.0100][M=0.90] [Best : Accuracy=78.92, Error=21.08]
  Epoch: [010][000/391]   Time 0.248 (0.248)   Data 0.187 (0.187)   Loss 0.4915 (0.4915)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2019-11-23 04:51:33]
  Epoch: [010][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.4289 (0.5114)   Prec@1 79.688 (82.256)   Prec@5 99.219 (99.149)   [2019-11-23 04:51:38]
  Epoch: [010][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4132 (0.5207)   Prec@1 84.375 (82.121)   Prec@5 100.000 (99.040)   [2019-11-23 04:51:43]
  Epoch: [010][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.3091 (0.5203)   Prec@1 90.625 (82.161)   Prec@5 99.219 (99.110)   [2019-11-23 04:51:48]
  **Train** Prec@1 82.224 Prec@5 99.114 Error@1 17.776
  **Test** Prec@1 79.790 Prec@5 98.880 Error@1 20.210
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:51:54] [Epoch=011/200] [Need: 01:08:05] [LR=0.0100][M=0.90] [Best : Accuracy=79.79, Error=20.21]
  Epoch: [011][000/391]   Time 0.259 (0.259)   Data 0.203 (0.203)   Loss 0.3956 (0.3956)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 04:51:55]
  Epoch: [011][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.5235 (0.4987)   Prec@1 76.562 (82.959)   Prec@5 99.219 (99.141)   [2019-11-23 04:52:00]
  Epoch: [011][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.5828 (0.5010)   Prec@1 77.344 (82.844)   Prec@5 100.000 (99.199)   [2019-11-23 04:52:05]
  Epoch: [011][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.4230 (0.5053)   Prec@1 86.719 (82.680)   Prec@5 96.875 (99.172)   [2019-11-23 04:52:10]
  **Train** Prec@1 82.678 Prec@5 99.138 Error@1 17.322
  **Test** Prec@1 80.030 Prec@5 98.610 Error@1 19.970
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:52:16] [Epoch=012/200] [Need: 01:07:50] [LR=0.0100][M=0.90] [Best : Accuracy=80.03, Error=19.97]
  Epoch: [012][000/391]   Time 0.254 (0.254)   Data 0.175 (0.175)   Loss 0.4070 (0.4070)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-23 04:52:17]
  Epoch: [012][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.4762 (0.4777)   Prec@1 83.594 (83.362)   Prec@5 100.000 (99.250)   [2019-11-23 04:52:21]
  Epoch: [012][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.6229 (0.4857)   Prec@1 81.250 (83.252)   Prec@5 98.438 (99.145)   [2019-11-23 04:52:26]
  Epoch: [012][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3824 (0.4892)   Prec@1 87.500 (83.140)   Prec@5 99.219 (99.180)   [2019-11-23 04:52:31]
  **Train** Prec@1 83.194 Prec@5 99.180 Error@1 16.806
  **Test** Prec@1 78.070 Prec@5 98.620 Error@1 21.930

==>>[2019-11-23 04:52:38] [Epoch=013/200] [Need: 01:07:25] [LR=0.0100][M=0.90] [Best : Accuracy=80.03, Error=19.97]
  Epoch: [013][000/391]   Time 0.276 (0.276)   Data 0.213 (0.213)   Loss 0.5146 (0.5146)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2019-11-23 04:52:38]
  Epoch: [013][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.4217 (0.4698)   Prec@1 82.812 (83.849)   Prec@5 100.000 (99.265)   [2019-11-23 04:52:43]
  Epoch: [013][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.4687 (0.4663)   Prec@1 85.156 (83.928)   Prec@5 99.219 (99.328)   [2019-11-23 04:52:48]
  Epoch: [013][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.5165 (0.4742)   Prec@1 81.250 (83.747)   Prec@5 99.219 (99.242)   [2019-11-23 04:52:53]
  **Train** Prec@1 83.698 Prec@5 99.214 Error@1 16.302
  **Test** Prec@1 78.760 Prec@5 98.880 Error@1 21.240

==>>[2019-11-23 04:53:00] [Epoch=014/200] [Need: 01:07:08] [LR=0.0100][M=0.90] [Best : Accuracy=80.03, Error=19.97]
  Epoch: [014][000/391]   Time 0.256 (0.256)   Data 0.187 (0.187)   Loss 0.5542 (0.5542)   Prec@1 82.031 (82.031)   Prec@5 100.000 (100.000)   [2019-11-23 04:53:00]
  Epoch: [014][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.4600 (0.4521)   Prec@1 82.031 (84.244)   Prec@5 99.219 (99.257)   [2019-11-23 04:53:05]
  Epoch: [014][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5259 (0.4674)   Prec@1 81.250 (83.815)   Prec@5 98.438 (99.250)   [2019-11-23 04:53:10]
  Epoch: [014][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.5465 (0.4669)   Prec@1 80.469 (83.851)   Prec@5 99.219 (99.255)   [2019-11-23 04:53:15]
  **Train** Prec@1 83.836 Prec@5 99.258 Error@1 16.164
  **Test** Prec@1 80.990 Prec@5 99.000 Error@1 19.010
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:53:22] [Epoch=015/200] [Need: 01:06:58] [LR=0.0100][M=0.90] [Best : Accuracy=80.99, Error=19.01]
  Epoch: [015][000/391]   Time 0.248 (0.248)   Data 0.188 (0.188)   Loss 0.6567 (0.6567)   Prec@1 75.781 (75.781)   Prec@5 99.219 (99.219)   [2019-11-23 04:53:23]
  Epoch: [015][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.3648 (0.4413)   Prec@1 87.500 (84.963)   Prec@5 98.438 (99.319)   [2019-11-23 04:53:28]
  Epoch: [015][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.5675 (0.4530)   Prec@1 82.031 (84.453)   Prec@5 100.000 (99.339)   [2019-11-23 04:53:33]
  Epoch: [015][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.4543 (0.4513)   Prec@1 84.375 (84.463)   Prec@5 99.219 (99.372)   [2019-11-23 04:53:38]
  **Train** Prec@1 84.392 Prec@5 99.340 Error@1 15.608
  **Test** Prec@1 79.990 Prec@5 98.920 Error@1 20.010

==>>[2019-11-23 04:53:44] [Epoch=016/200] [Need: 01:06:41] [LR=0.0100][M=0.90] [Best : Accuracy=80.99, Error=19.01]
  Epoch: [016][000/391]   Time 0.264 (0.264)   Data 0.200 (0.200)   Loss 0.4698 (0.4698)   Prec@1 82.031 (82.031)   Prec@5 100.000 (100.000)   [2019-11-23 04:53:45]
  Epoch: [016][100/391]   Time 0.081 (0.056)   Data 0.000 (0.002)   Loss 0.3379 (0.4298)   Prec@1 89.844 (85.249)   Prec@5 100.000 (99.497)   [2019-11-23 04:53:50]
  Epoch: [016][200/391]   Time 0.076 (0.054)   Data 0.000 (0.001)   Loss 0.5817 (0.4383)   Prec@1 76.562 (84.966)   Prec@5 99.219 (99.436)   [2019-11-23 04:53:55]
  Epoch: [016][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3823 (0.4460)   Prec@1 85.938 (84.671)   Prec@5 100.000 (99.349)   [2019-11-23 04:54:00]
  **Train** Prec@1 84.718 Prec@5 99.322 Error@1 15.282
  **Test** Prec@1 81.390 Prec@5 99.020 Error@1 18.610
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:54:07] [Epoch=017/200] [Need: 01:06:22] [LR=0.0100][M=0.90] [Best : Accuracy=81.39, Error=18.61]
  Epoch: [017][000/391]   Time 0.238 (0.238)   Data 0.174 (0.174)   Loss 0.2905 (0.2905)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 04:54:07]
  Epoch: [017][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5263 (0.4273)   Prec@1 81.250 (85.334)   Prec@5 100.000 (99.459)   [2019-11-23 04:54:12]
  Epoch: [017][200/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.5499 (0.4318)   Prec@1 78.906 (85.141)   Prec@5 99.219 (99.390)   [2019-11-23 04:54:17]
  Epoch: [017][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.5123 (0.4393)   Prec@1 83.594 (84.941)   Prec@5 98.438 (99.367)   [2019-11-23 04:54:22]
  **Train** Prec@1 84.898 Prec@5 99.370 Error@1 15.102
  **Test** Prec@1 81.640 Prec@5 99.140 Error@1 18.360
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:54:28] [Epoch=018/200] [Need: 01:06:00] [LR=0.0100][M=0.90] [Best : Accuracy=81.64, Error=18.36]
  Epoch: [018][000/391]   Time 0.257 (0.257)   Data 0.168 (0.168)   Loss 0.3453 (0.3453)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 04:54:29]
  Epoch: [018][100/391]   Time 0.078 (0.055)   Data 0.000 (0.002)   Loss 0.4718 (0.4241)   Prec@1 85.938 (85.504)   Prec@5 97.656 (99.273)   [2019-11-23 04:54:34]
  Epoch: [018][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.4442 (0.4253)   Prec@1 83.594 (85.506)   Prec@5 100.000 (99.296)   [2019-11-23 04:54:39]
  Epoch: [018][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.4326 (0.4295)   Prec@1 85.156 (85.263)   Prec@5 100.000 (99.333)   [2019-11-23 04:54:43]
  **Train** Prec@1 85.268 Prec@5 99.344 Error@1 14.732
  **Test** Prec@1 82.600 Prec@5 98.990 Error@1 17.400
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:54:50] [Epoch=019/200] [Need: 01:05:35] [LR=0.0100][M=0.90] [Best : Accuracy=82.60, Error=17.40]
  Epoch: [019][000/391]   Time 0.252 (0.252)   Data 0.191 (0.191)   Loss 0.5336 (0.5336)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2019-11-23 04:54:50]
  Epoch: [019][100/391]   Time 0.062 (0.054)   Data 0.000 (0.002)   Loss 0.4378 (0.4284)   Prec@1 83.594 (85.342)   Prec@5 98.438 (99.335)   [2019-11-23 04:54:55]
  Epoch: [019][200/391]   Time 0.070 (0.053)   Data 0.000 (0.001)   Loss 0.4877 (0.4233)   Prec@1 82.812 (85.506)   Prec@5 100.000 (99.378)   [2019-11-23 04:55:00]
  Epoch: [019][300/391]   Time 0.082 (0.052)   Data 0.000 (0.001)   Loss 0.4696 (0.4236)   Prec@1 85.156 (85.551)   Prec@5 100.000 (99.387)   [2019-11-23 04:55:05]
  **Train** Prec@1 85.292 Prec@5 99.378 Error@1 14.708
  **Test** Prec@1 82.130 Prec@5 98.970 Error@1 17.870

==>>[2019-11-23 04:55:12] [Epoch=020/200] [Need: 01:05:16] [LR=0.0100][M=0.90] [Best : Accuracy=82.60, Error=17.40]
  Epoch: [020][000/391]   Time 0.244 (0.244)   Data 0.181 (0.181)   Loss 0.4668 (0.4668)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-23 04:55:12]
  Epoch: [020][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.4208 (0.4207)   Prec@1 86.719 (85.644)   Prec@5 99.219 (99.366)   [2019-11-23 04:55:17]
  Epoch: [020][200/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.4164 (0.4195)   Prec@1 85.938 (85.685)   Prec@5 98.438 (99.401)   [2019-11-23 04:55:22]
  Epoch: [020][300/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.5082 (0.4208)   Prec@1 85.156 (85.732)   Prec@5 98.438 (99.349)   [2019-11-23 04:55:28]
  **Train** Prec@1 85.584 Prec@5 99.368 Error@1 14.416
  **Test** Prec@1 81.510 Prec@5 98.960 Error@1 18.490

==>>[2019-11-23 04:55:34] [Epoch=021/200] [Need: 01:05:02] [LR=0.0100][M=0.90] [Best : Accuracy=82.60, Error=17.40]
  Epoch: [021][000/391]   Time 0.247 (0.247)   Data 0.179 (0.179)   Loss 0.4797 (0.4797)   Prec@1 80.469 (80.469)   Prec@5 100.000 (100.000)   [2019-11-23 04:55:35]
  Epoch: [021][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.5956 (0.4002)   Prec@1 78.906 (86.131)   Prec@5 99.219 (99.505)   [2019-11-23 04:55:39]
  Epoch: [021][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.4508 (0.4090)   Prec@1 82.812 (85.813)   Prec@5 100.000 (99.440)   [2019-11-23 04:55:45]
  Epoch: [021][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.6390 (0.4157)   Prec@1 81.250 (85.681)   Prec@5 100.000 (99.382)   [2019-11-23 04:55:50]
  **Train** Prec@1 85.504 Prec@5 99.390 Error@1 14.496
  **Test** Prec@1 83.090 Prec@5 99.280 Error@1 16.910
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:55:56] [Epoch=022/200] [Need: 01:04:41] [LR=0.0100][M=0.90] [Best : Accuracy=83.09, Error=16.91]
  Epoch: [022][000/391]   Time 0.246 (0.246)   Data 0.181 (0.181)   Loss 0.3459 (0.3459)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 04:55:57]
  Epoch: [022][100/391]   Time 0.063 (0.055)   Data 0.000 (0.002)   Loss 0.4860 (0.4139)   Prec@1 82.812 (85.667)   Prec@5 99.219 (99.381)   [2019-11-23 04:56:02]
  Epoch: [022][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.6234 (0.4159)   Prec@1 77.344 (85.731)   Prec@5 98.438 (99.378)   [2019-11-23 04:56:07]
  Epoch: [022][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.4047 (0.4171)   Prec@1 85.938 (85.740)   Prec@5 100.000 (99.385)   [2019-11-23 04:56:13]
  **Train** Prec@1 85.706 Prec@5 99.378 Error@1 14.294
  **Test** Prec@1 82.680 Prec@5 99.060 Error@1 17.320

==>>[2019-11-23 04:56:19] [Epoch=023/200] [Need: 01:04:28] [LR=0.0100][M=0.90] [Best : Accuracy=83.09, Error=16.91]
  Epoch: [023][000/391]   Time 0.244 (0.244)   Data 0.172 (0.172)   Loss 0.3207 (0.3207)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 04:56:19]
  Epoch: [023][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.4773 (0.3862)   Prec@1 85.938 (86.572)   Prec@5 100.000 (99.551)   [2019-11-23 04:56:24]
  Epoch: [023][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3826 (0.3987)   Prec@1 87.500 (86.054)   Prec@5 100.000 (99.510)   [2019-11-23 04:56:30]
  Epoch: [023][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4444 (0.4054)   Prec@1 87.500 (85.839)   Prec@5 98.438 (99.434)   [2019-11-23 04:56:35]
  **Train** Prec@1 85.534 Prec@5 99.438 Error@1 14.466
  **Test** Prec@1 81.020 Prec@5 98.780 Error@1 18.980

==>>[2019-11-23 04:56:42] [Epoch=024/200] [Need: 01:04:10] [LR=0.0100][M=0.90] [Best : Accuracy=83.09, Error=16.91]
  Epoch: [024][000/391]   Time 0.244 (0.244)   Data 0.173 (0.173)   Loss 0.4642 (0.4642)   Prec@1 83.594 (83.594)   Prec@5 97.656 (97.656)   [2019-11-23 04:56:42]
  Epoch: [024][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.3629 (0.4065)   Prec@1 89.062 (86.479)   Prec@5 100.000 (99.420)   [2019-11-23 04:56:47]
  Epoch: [024][200/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.4942 (0.4052)   Prec@1 84.375 (86.528)   Prec@5 99.219 (99.452)   [2019-11-23 04:56:52]
  Epoch: [024][300/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.4246 (0.4049)   Prec@1 82.812 (86.290)   Prec@5 100.000 (99.468)   [2019-11-23 04:56:57]
  **Train** Prec@1 86.164 Prec@5 99.476 Error@1 13.836
  **Test** Prec@1 83.930 Prec@5 99.200 Error@1 16.070
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:57:04] [Epoch=025/200] [Need: 01:03:50] [LR=0.0100][M=0.90] [Best : Accuracy=83.93, Error=16.07]
  Epoch: [025][000/391]   Time 0.245 (0.245)   Data 0.195 (0.195)   Loss 0.2640 (0.2640)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 04:57:04]
  Epoch: [025][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.4142 (0.3912)   Prec@1 86.719 (86.317)   Prec@5 99.219 (99.551)   [2019-11-23 04:57:09]
  Epoch: [025][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.4496 (0.3951)   Prec@1 83.594 (86.311)   Prec@5 99.219 (99.518)   [2019-11-23 04:57:14]
  Epoch: [025][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3776 (0.4024)   Prec@1 85.938 (86.067)   Prec@5 100.000 (99.499)   [2019-11-23 04:57:19]
  **Train** Prec@1 86.058 Prec@5 99.476 Error@1 13.942
  **Test** Prec@1 83.540 Prec@5 99.250 Error@1 16.460

==>>[2019-11-23 04:57:25] [Epoch=026/200] [Need: 01:03:27] [LR=0.0100][M=0.90] [Best : Accuracy=83.93, Error=16.07]
  Epoch: [026][000/391]   Time 0.250 (0.250)   Data 0.189 (0.189)   Loss 0.2530 (0.2530)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 04:57:26]
  Epoch: [026][100/391]   Time 0.047 (0.051)   Data 0.000 (0.002)   Loss 0.3276 (0.3852)   Prec@1 90.625 (86.866)   Prec@5 98.438 (99.435)   [2019-11-23 04:57:31]
  Epoch: [026][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.4194 (0.3993)   Prec@1 84.375 (86.307)   Prec@5 100.000 (99.409)   [2019-11-23 04:57:36]
  Epoch: [026][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.2918 (0.4016)   Prec@1 91.406 (86.156)   Prec@5 100.000 (99.429)   [2019-11-23 04:57:41]
  **Train** Prec@1 86.072 Prec@5 99.444 Error@1 13.928
  **Test** Prec@1 82.260 Prec@5 98.900 Error@1 17.740

==>>[2019-11-23 04:57:47] [Epoch=027/200] [Need: 01:03:04] [LR=0.0100][M=0.90] [Best : Accuracy=83.93, Error=16.07]
  Epoch: [027][000/391]   Time 0.244 (0.244)   Data 0.173 (0.173)   Loss 0.4676 (0.4676)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 04:57:47]
  Epoch: [027][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3213 (0.3803)   Prec@1 89.844 (87.028)   Prec@5 99.219 (99.621)   [2019-11-23 04:57:52]
  Epoch: [027][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.5377 (0.3886)   Prec@1 85.156 (86.552)   Prec@5 98.438 (99.580)   [2019-11-23 04:57:57]
  Epoch: [027][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.2880 (0.3902)   Prec@1 91.406 (86.547)   Prec@5 100.000 (99.517)   [2019-11-23 04:58:02]
  **Train** Prec@1 86.562 Prec@5 99.510 Error@1 13.438
  **Test** Prec@1 84.210 Prec@5 99.260 Error@1 15.790
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:58:08] [Epoch=028/200] [Need: 01:02:37] [LR=0.0100][M=0.90] [Best : Accuracy=84.21, Error=15.79]
  Epoch: [028][000/391]   Time 0.253 (0.253)   Data 0.190 (0.190)   Loss 0.4126 (0.4126)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 04:58:08]
  Epoch: [028][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.3984 (0.3814)   Prec@1 85.156 (86.951)   Prec@5 100.000 (99.575)   [2019-11-23 04:58:13]
  Epoch: [028][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.5743 (0.3842)   Prec@1 78.125 (86.598)   Prec@5 100.000 (99.557)   [2019-11-23 04:58:19]
  Epoch: [028][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.3772 (0.3876)   Prec@1 84.375 (86.589)   Prec@5 100.000 (99.499)   [2019-11-23 04:58:24]
  **Train** Prec@1 86.602 Prec@5 99.506 Error@1 13.398
  **Test** Prec@1 80.970 Prec@5 98.950 Error@1 19.030

==>>[2019-11-23 04:58:30] [Epoch=029/200] [Need: 01:02:16] [LR=0.0100][M=0.90] [Best : Accuracy=84.21, Error=15.79]
  Epoch: [029][000/391]   Time 0.243 (0.243)   Data 0.184 (0.184)   Loss 0.3804 (0.3804)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 04:58:30]
  Epoch: [029][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3458 (0.3776)   Prec@1 89.062 (87.237)   Prec@5 100.000 (99.567)   [2019-11-23 04:58:36]
  Epoch: [029][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.5131 (0.3825)   Prec@1 78.906 (86.898)   Prec@5 100.000 (99.553)   [2019-11-23 04:58:40]
  Epoch: [029][300/391]   Time 0.053 (0.049)   Data 0.000 (0.001)   Loss 0.4501 (0.3885)   Prec@1 83.594 (86.667)   Prec@5 99.219 (99.561)   [2019-11-23 04:58:45]
  **Train** Prec@1 86.736 Prec@5 99.514 Error@1 13.264
  **Test** Prec@1 84.920 Prec@5 99.240 Error@1 15.080
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 04:58:51] [Epoch=030/200] [Need: 01:01:50] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [030][000/391]   Time 0.252 (0.252)   Data 0.192 (0.192)   Loss 0.3255 (0.3255)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 04:58:52]
  Epoch: [030][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.4683 (0.3663)   Prec@1 82.812 (87.407)   Prec@5 99.219 (99.482)   [2019-11-23 04:58:57]
  Epoch: [030][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3458 (0.3789)   Prec@1 85.938 (86.983)   Prec@5 100.000 (99.483)   [2019-11-23 04:59:02]
  Epoch: [030][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3743 (0.3768)   Prec@1 84.375 (87.033)   Prec@5 100.000 (99.509)   [2019-11-23 04:59:07]
  **Train** Prec@1 87.030 Prec@5 99.512 Error@1 12.970
  **Test** Prec@1 82.250 Prec@5 99.090 Error@1 17.750

==>>[2019-11-23 04:59:13] [Epoch=031/200] [Need: 01:01:29] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [031][000/391]   Time 0.250 (0.250)   Data 0.179 (0.179)   Loss 0.4627 (0.4627)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 04:59:14]
  Epoch: [031][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.2788 (0.3692)   Prec@1 92.969 (87.407)   Prec@5 99.219 (99.575)   [2019-11-23 04:59:19]
  Epoch: [031][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.3684 (0.3776)   Prec@1 84.375 (87.088)   Prec@5 99.219 (99.576)   [2019-11-23 04:59:23]
  Epoch: [031][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.4152 (0.3783)   Prec@1 83.594 (86.882)   Prec@5 100.000 (99.556)   [2019-11-23 04:59:29]
  **Train** Prec@1 86.836 Prec@5 99.520 Error@1 13.164
  **Test** Prec@1 83.750 Prec@5 99.210 Error@1 16.250

==>>[2019-11-23 04:59:35] [Epoch=032/200] [Need: 01:01:07] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [032][000/391]   Time 0.271 (0.271)   Data 0.211 (0.211)   Loss 0.4525 (0.4525)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-23 04:59:35]
  Epoch: [032][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.4677 (0.3718)   Prec@1 85.938 (87.113)   Prec@5 100.000 (99.474)   [2019-11-23 04:59:41]
  Epoch: [032][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.3775 (0.3684)   Prec@1 86.719 (87.216)   Prec@5 99.219 (99.522)   [2019-11-23 04:59:45]
  Epoch: [032][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.3733 (0.3752)   Prec@1 86.719 (87.035)   Prec@5 100.000 (99.478)   [2019-11-23 04:59:50]
  **Train** Prec@1 86.886 Prec@5 99.496 Error@1 13.114
  **Test** Prec@1 80.400 Prec@5 99.060 Error@1 19.600

==>>[2019-11-23 04:59:57] [Epoch=033/200] [Need: 01:00:45] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [033][000/391]   Time 0.258 (0.258)   Data 0.195 (0.195)   Loss 0.3268 (0.3268)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 04:59:57]
  Epoch: [033][100/391]   Time 0.047 (0.059)   Data 0.000 (0.002)   Loss 0.4290 (0.3578)   Prec@1 83.594 (87.245)   Prec@5 100.000 (99.621)   [2019-11-23 05:00:03]
  Epoch: [033][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4605 (0.3694)   Prec@1 85.156 (87.135)   Prec@5 99.219 (99.631)   [2019-11-23 05:00:08]
  Epoch: [033][300/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.2818 (0.3681)   Prec@1 89.062 (87.194)   Prec@5 100.000 (99.603)   [2019-11-23 05:00:12]
  **Train** Prec@1 86.952 Prec@5 99.574 Error@1 13.048
  **Test** Prec@1 84.560 Prec@5 99.280 Error@1 15.440

==>>[2019-11-23 05:00:19] [Epoch=034/200] [Need: 01:00:24] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [034][000/391]   Time 0.258 (0.258)   Data 0.199 (0.199)   Loss 0.2875 (0.2875)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 05:00:19]
  Epoch: [034][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.4540 (0.3634)   Prec@1 86.719 (87.407)   Prec@5 100.000 (99.652)   [2019-11-23 05:00:24]
  Epoch: [034][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4122 (0.3668)   Prec@1 85.938 (87.352)   Prec@5 99.219 (99.623)   [2019-11-23 05:00:29]
  Epoch: [034][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.3328 (0.3690)   Prec@1 86.719 (87.248)   Prec@5 100.000 (99.613)   [2019-11-23 05:00:34]
  **Train** Prec@1 87.196 Prec@5 99.606 Error@1 12.804
  **Test** Prec@1 82.430 Prec@5 99.060 Error@1 17.570

==>>[2019-11-23 05:00:40] [Epoch=035/200] [Need: 01:00:01] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [035][000/391]   Time 0.259 (0.259)   Data 0.185 (0.185)   Loss 0.2552 (0.2552)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 05:00:41]
  Epoch: [035][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.2785 (0.3615)   Prec@1 91.406 (87.075)   Prec@5 100.000 (99.606)   [2019-11-23 05:00:46]
  Epoch: [035][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3480 (0.3664)   Prec@1 85.156 (87.142)   Prec@5 99.219 (99.584)   [2019-11-23 05:00:51]
  Epoch: [035][300/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.4044 (0.3654)   Prec@1 83.594 (87.279)   Prec@5 99.219 (99.546)   [2019-11-23 05:00:56]
  **Train** Prec@1 87.132 Prec@5 99.512 Error@1 12.868
  **Test** Prec@1 83.560 Prec@5 99.080 Error@1 16.440

==>>[2019-11-23 05:01:02] [Epoch=036/200] [Need: 00:59:38] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [036][000/391]   Time 0.252 (0.252)   Data 0.178 (0.178)   Loss 0.3913 (0.3913)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 05:01:02]
  Epoch: [036][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.4539 (0.3605)   Prec@1 82.812 (87.515)   Prec@5 100.000 (99.621)   [2019-11-23 05:01:07]
  Epoch: [036][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.2970 (0.3530)   Prec@1 90.625 (87.842)   Prec@5 100.000 (99.631)   [2019-11-23 05:01:13]
  Epoch: [036][300/391]   Time 0.040 (0.052)   Data 0.000 (0.001)   Loss 0.3316 (0.3623)   Prec@1 88.281 (87.500)   Prec@5 100.000 (99.603)   [2019-11-23 05:01:18]
  **Train** Prec@1 87.342 Prec@5 99.564 Error@1 12.658
  **Test** Prec@1 81.450 Prec@5 98.600 Error@1 18.550

==>>[2019-11-23 05:01:23] [Epoch=037/200] [Need: 00:59:14] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [037][000/391]   Time 0.264 (0.264)   Data 0.199 (0.199)   Loss 0.3549 (0.3549)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-23 05:01:24]
  Epoch: [037][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.2861 (0.3610)   Prec@1 91.406 (87.531)   Prec@5 98.438 (99.474)   [2019-11-23 05:01:29]
  Epoch: [037][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.4009 (0.3628)   Prec@1 83.594 (87.500)   Prec@5 100.000 (99.518)   [2019-11-23 05:01:34]
  Epoch: [037][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3624 (0.3679)   Prec@1 88.281 (87.233)   Prec@5 100.000 (99.504)   [2019-11-23 05:01:39]
  **Train** Prec@1 87.186 Prec@5 99.506 Error@1 12.814
  **Test** Prec@1 84.200 Prec@5 99.180 Error@1 15.800

==>>[2019-11-23 05:01:46] [Epoch=038/200] [Need: 00:58:55] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [038][000/391]   Time 0.246 (0.246)   Data 0.177 (0.177)   Loss 0.2278 (0.2278)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 05:01:46]
  Epoch: [038][100/391]   Time 0.059 (0.051)   Data 0.000 (0.002)   Loss 0.3622 (0.3439)   Prec@1 89.844 (88.157)   Prec@5 100.000 (99.544)   [2019-11-23 05:01:51]
  Epoch: [038][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3404 (0.3551)   Prec@1 88.281 (87.687)   Prec@5 99.219 (99.561)   [2019-11-23 05:01:56]
  Epoch: [038][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4900 (0.3612)   Prec@1 82.812 (87.497)   Prec@5 99.219 (99.530)   [2019-11-23 05:02:01]
  **Train** Prec@1 87.336 Prec@5 99.528 Error@1 12.664
  **Test** Prec@1 84.480 Prec@5 99.210 Error@1 15.520

==>>[2019-11-23 05:02:07] [Epoch=039/200] [Need: 00:58:31] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [039][000/391]   Time 0.248 (0.248)   Data 0.190 (0.190)   Loss 0.3619 (0.3619)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-23 05:02:07]
  Epoch: [039][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.3312 (0.3525)   Prec@1 85.938 (87.840)   Prec@5 100.000 (99.520)   [2019-11-23 05:02:13]
  Epoch: [039][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.3192 (0.3545)   Prec@1 89.844 (87.799)   Prec@5 99.219 (99.572)   [2019-11-23 05:02:18]
  Epoch: [039][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3702 (0.3558)   Prec@1 86.719 (87.752)   Prec@5 100.000 (99.577)   [2019-11-23 05:02:23]
  **Train** Prec@1 87.716 Prec@5 99.588 Error@1 12.284
  **Test** Prec@1 84.860 Prec@5 99.280 Error@1 15.140

==>>[2019-11-23 05:02:30] [Epoch=040/200] [Need: 00:58:11] [LR=0.0100][M=0.90] [Best : Accuracy=84.92, Error=15.08]
  Epoch: [040][000/391]   Time 0.253 (0.253)   Data 0.178 (0.178)   Loss 0.2970 (0.2970)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-23 05:02:30]
  Epoch: [040][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.2379 (0.3403)   Prec@1 92.188 (88.018)   Prec@5 100.000 (99.575)   [2019-11-23 05:02:35]
  Epoch: [040][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4873 (0.3532)   Prec@1 82.812 (87.652)   Prec@5 99.219 (99.584)   [2019-11-23 05:02:40]
  Epoch: [040][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3669 (0.3553)   Prec@1 88.281 (87.612)   Prec@5 99.219 (99.585)   [2019-11-23 05:02:45]
  **Train** Prec@1 87.694 Prec@5 99.572 Error@1 12.306
  **Test** Prec@1 84.960 Prec@5 99.260 Error@1 15.040
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:02:51] [Epoch=041/200] [Need: 00:57:49] [LR=0.0100][M=0.90] [Best : Accuracy=84.96, Error=15.04]
  Epoch: [041][000/391]   Time 0.240 (0.240)   Data 0.171 (0.171)   Loss 0.4154 (0.4154)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 05:02:51]
  Epoch: [041][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.3361 (0.3656)   Prec@1 89.062 (87.369)   Prec@5 99.219 (99.660)   [2019-11-23 05:02:56]
  Epoch: [041][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.3249 (0.3588)   Prec@1 89.844 (87.566)   Prec@5 99.219 (99.607)   [2019-11-23 05:03:01]
  Epoch: [041][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.3037 (0.3559)   Prec@1 90.625 (87.741)   Prec@5 100.000 (99.608)   [2019-11-23 05:03:06]
  **Train** Prec@1 87.666 Prec@5 99.588 Error@1 12.334
  **Test** Prec@1 79.410 Prec@5 98.730 Error@1 20.590

==>>[2019-11-23 05:03:13] [Epoch=042/200] [Need: 00:57:25] [LR=0.0100][M=0.90] [Best : Accuracy=84.96, Error=15.04]
  Epoch: [042][000/391]   Time 0.247 (0.247)   Data 0.175 (0.175)   Loss 0.4100 (0.4100)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-23 05:03:13]
  Epoch: [042][100/391]   Time 0.041 (0.054)   Data 0.000 (0.002)   Loss 0.3873 (0.3483)   Prec@1 89.844 (88.304)   Prec@5 99.219 (99.489)   [2019-11-23 05:03:18]
  Epoch: [042][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.3764 (0.3435)   Prec@1 85.938 (88.328)   Prec@5 100.000 (99.576)   [2019-11-23 05:03:23]
  Epoch: [042][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3708 (0.3478)   Prec@1 84.375 (88.131)   Prec@5 100.000 (99.613)   [2019-11-23 05:03:28]
  **Train** Prec@1 88.038 Prec@5 99.616 Error@1 11.962
  **Test** Prec@1 81.560 Prec@5 99.260 Error@1 18.440

==>>[2019-11-23 05:03:34] [Epoch=043/200] [Need: 00:57:03] [LR=0.0100][M=0.90] [Best : Accuracy=84.96, Error=15.04]
  Epoch: [043][000/391]   Time 0.246 (0.246)   Data 0.183 (0.183)   Loss 0.3858 (0.3858)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 05:03:34]
  Epoch: [043][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.2931 (0.3466)   Prec@1 89.844 (87.724)   Prec@5 99.219 (99.575)   [2019-11-23 05:03:40]
  Epoch: [043][200/391]   Time 0.040 (0.053)   Data 0.000 (0.001)   Loss 0.3341 (0.3396)   Prec@1 88.281 (87.947)   Prec@5 99.219 (99.584)   [2019-11-23 05:03:45]
  Epoch: [043][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3541 (0.3454)   Prec@1 85.938 (87.866)   Prec@5 100.000 (99.595)   [2019-11-23 05:03:50]
  **Train** Prec@1 87.714 Prec@5 99.582 Error@1 12.286
  **Test** Prec@1 79.780 Prec@5 98.680 Error@1 20.220

==>>[2019-11-23 05:03:56] [Epoch=044/200] [Need: 00:56:41] [LR=0.0100][M=0.90] [Best : Accuracy=84.96, Error=15.04]
  Epoch: [044][000/391]   Time 0.260 (0.260)   Data 0.193 (0.193)   Loss 0.3173 (0.3173)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 05:03:56]
  Epoch: [044][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.4360 (0.3486)   Prec@1 85.938 (87.972)   Prec@5 99.219 (99.505)   [2019-11-23 05:04:01]
  Epoch: [044][200/391]   Time 0.061 (0.050)   Data 0.000 (0.001)   Loss 0.2926 (0.3502)   Prec@1 89.844 (87.823)   Prec@5 99.219 (99.541)   [2019-11-23 05:04:06]
  Epoch: [044][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.5082 (0.3520)   Prec@1 82.031 (87.726)   Prec@5 99.219 (99.554)   [2019-11-23 05:04:11]
  **Train** Prec@1 87.708 Prec@5 99.548 Error@1 12.292
  **Test** Prec@1 81.430 Prec@5 98.900 Error@1 18.570

==>>[2019-11-23 05:04:17] [Epoch=045/200] [Need: 00:56:18] [LR=0.0100][M=0.90] [Best : Accuracy=84.96, Error=15.04]
  Epoch: [045][000/391]   Time 0.245 (0.245)   Data 0.174 (0.174)   Loss 0.3171 (0.3171)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 05:04:18]
  Epoch: [045][100/391]   Time 0.055 (0.056)   Data 0.000 (0.002)   Loss 0.5355 (0.3459)   Prec@1 78.125 (87.925)   Prec@5 98.438 (99.613)   [2019-11-23 05:04:23]
  Epoch: [045][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3176 (0.3488)   Prec@1 88.281 (87.912)   Prec@5 99.219 (99.607)   [2019-11-23 05:04:28]
  Epoch: [045][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4109 (0.3491)   Prec@1 87.500 (87.856)   Prec@5 99.219 (99.600)   [2019-11-23 05:04:33]
  **Train** Prec@1 87.904 Prec@5 99.594 Error@1 12.096
  **Test** Prec@1 85.190 Prec@5 99.440 Error@1 14.810
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:04:39] [Epoch=046/200] [Need: 00:55:55] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [046][000/391]   Time 0.250 (0.250)   Data 0.180 (0.180)   Loss 0.3384 (0.3384)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 05:04:39]
  Epoch: [046][100/391]   Time 0.068 (0.053)   Data 0.000 (0.002)   Loss 0.2439 (0.3474)   Prec@1 92.969 (88.235)   Prec@5 100.000 (99.567)   [2019-11-23 05:04:44]
  Epoch: [046][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.4459 (0.3560)   Prec@1 85.938 (87.951)   Prec@5 98.438 (99.576)   [2019-11-23 05:04:49]
  Epoch: [046][300/391]   Time 0.070 (0.051)   Data 0.000 (0.001)   Loss 0.3228 (0.3497)   Prec@1 86.719 (88.042)   Prec@5 99.219 (99.580)   [2019-11-23 05:04:54]
  **Train** Prec@1 88.138 Prec@5 99.572 Error@1 11.862
  **Test** Prec@1 83.840 Prec@5 98.830 Error@1 16.160

==>>[2019-11-23 05:05:01] [Epoch=047/200] [Need: 00:55:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [047][000/391]   Time 0.250 (0.250)   Data 0.190 (0.190)   Loss 0.1911 (0.1911)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 05:05:01]
  Epoch: [047][100/391]   Time 0.060 (0.050)   Data 0.000 (0.002)   Loss 0.2193 (0.3308)   Prec@1 91.406 (88.537)   Prec@5 99.219 (99.621)   [2019-11-23 05:05:06]
  Epoch: [047][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.2570 (0.3436)   Prec@1 92.969 (88.227)   Prec@5 100.000 (99.604)   [2019-11-23 05:05:11]
  Epoch: [047][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.3601 (0.3498)   Prec@1 85.938 (87.959)   Prec@5 100.000 (99.595)   [2019-11-23 05:05:16]
  **Train** Prec@1 87.782 Prec@5 99.590 Error@1 12.218
  **Test** Prec@1 83.570 Prec@5 99.300 Error@1 16.430

==>>[2019-11-23 05:05:23] [Epoch=048/200] [Need: 00:55:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [048][000/391]   Time 0.264 (0.264)   Data 0.205 (0.205)   Loss 0.2857 (0.2857)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-23 05:05:23]
  Epoch: [048][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.3650 (0.3292)   Prec@1 82.812 (88.645)   Prec@5 100.000 (99.559)   [2019-11-23 05:05:28]
  Epoch: [048][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.3440 (0.3376)   Prec@1 85.156 (88.266)   Prec@5 100.000 (99.557)   [2019-11-23 05:05:33]
  Epoch: [048][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3625 (0.3433)   Prec@1 85.938 (88.123)   Prec@5 100.000 (99.538)   [2019-11-23 05:05:38]
  **Train** Prec@1 88.092 Prec@5 99.532 Error@1 11.908
  **Test** Prec@1 84.270 Prec@5 99.250 Error@1 15.730

==>>[2019-11-23 05:05:45] [Epoch=049/200] [Need: 00:54:51] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [049][000/391]   Time 0.248 (0.248)   Data 0.190 (0.190)   Loss 0.3315 (0.3315)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 05:05:45]
  Epoch: [049][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.3922 (0.3413)   Prec@1 87.500 (88.127)   Prec@5 100.000 (99.644)   [2019-11-23 05:05:50]
  Epoch: [049][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5050 (0.3437)   Prec@1 81.250 (88.029)   Prec@5 100.000 (99.619)   [2019-11-23 05:05:55]
  Epoch: [049][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.2901 (0.3459)   Prec@1 89.062 (87.980)   Prec@5 100.000 (99.624)   [2019-11-23 05:06:00]
  **Train** Prec@1 87.954 Prec@5 99.612 Error@1 12.046
  **Test** Prec@1 84.510 Prec@5 99.410 Error@1 15.490

==>>[2019-11-23 05:06:06] [Epoch=050/200] [Need: 00:54:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [050][000/391]   Time 0.252 (0.252)   Data 0.180 (0.180)   Loss 0.2528 (0.2528)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 05:06:07]
  Epoch: [050][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.2336 (0.3237)   Prec@1 92.969 (88.908)   Prec@5 99.219 (99.660)   [2019-11-23 05:06:12]
  Epoch: [050][200/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.2873 (0.3309)   Prec@1 90.625 (88.763)   Prec@5 99.219 (99.572)   [2019-11-23 05:06:16]
  Epoch: [050][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.4017 (0.3360)   Prec@1 82.812 (88.489)   Prec@5 100.000 (99.528)   [2019-11-23 05:06:21]
  **Train** Prec@1 88.222 Prec@5 99.538 Error@1 11.778
  **Test** Prec@1 83.520 Prec@5 99.000 Error@1 16.480

==>>[2019-11-23 05:06:28] [Epoch=051/200] [Need: 00:54:06] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [051][000/391]   Time 0.267 (0.267)   Data 0.200 (0.200)   Loss 0.2824 (0.2824)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 05:06:28]
  Epoch: [051][100/391]   Time 0.056 (0.055)   Data 0.000 (0.002)   Loss 0.3374 (0.3338)   Prec@1 86.719 (88.103)   Prec@5 100.000 (99.636)   [2019-11-23 05:06:34]
  Epoch: [051][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.3112 (0.3399)   Prec@1 86.719 (87.951)   Prec@5 100.000 (99.615)   [2019-11-23 05:06:39]
  Epoch: [051][300/391]   Time 0.084 (0.053)   Data 0.000 (0.001)   Loss 0.2930 (0.3403)   Prec@1 88.281 (88.063)   Prec@5 99.219 (99.605)   [2019-11-23 05:06:44]
  **Train** Prec@1 88.058 Prec@5 99.592 Error@1 11.942
  **Test** Prec@1 81.940 Prec@5 98.750 Error@1 18.060

==>>[2019-11-23 05:06:51] [Epoch=052/200] [Need: 00:53:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [052][000/391]   Time 0.249 (0.249)   Data 0.186 (0.186)   Loss 0.3037 (0.3037)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 05:06:51]
  Epoch: [052][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.2997 (0.3216)   Prec@1 92.188 (89.016)   Prec@5 99.219 (99.667)   [2019-11-23 05:06:56]
  Epoch: [052][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.4434 (0.3431)   Prec@1 80.469 (88.052)   Prec@5 99.219 (99.580)   [2019-11-23 05:07:01]
  Epoch: [052][300/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.3330 (0.3437)   Prec@1 86.719 (88.042)   Prec@5 99.219 (99.585)   [2019-11-23 05:07:06]
  **Train** Prec@1 87.994 Prec@5 99.580 Error@1 12.006
  **Test** Prec@1 83.580 Prec@5 99.150 Error@1 16.420

==>>[2019-11-23 05:07:12] [Epoch=053/200] [Need: 00:53:25] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [053][000/391]   Time 0.232 (0.232)   Data 0.168 (0.168)   Loss 0.2733 (0.2733)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:07:12]
  Epoch: [053][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.2835 (0.3219)   Prec@1 92.188 (88.614)   Prec@5 100.000 (99.606)   [2019-11-23 05:07:18]
  Epoch: [053][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2649 (0.3285)   Prec@1 89.844 (88.468)   Prec@5 100.000 (99.607)   [2019-11-23 05:07:22]
  Epoch: [053][300/391]   Time 0.066 (0.051)   Data 0.000 (0.001)   Loss 0.4633 (0.3356)   Prec@1 85.156 (88.250)   Prec@5 99.219 (99.600)   [2019-11-23 05:07:27]
  **Train** Prec@1 88.098 Prec@5 99.614 Error@1 11.902
  **Test** Prec@1 81.530 Prec@5 98.540 Error@1 18.470

==>>[2019-11-23 05:07:34] [Epoch=054/200] [Need: 00:53:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [054][000/391]   Time 0.264 (0.264)   Data 0.185 (0.185)   Loss 0.2740 (0.2740)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:07:34]
  Epoch: [054][100/391]   Time 0.048 (0.051)   Data 0.000 (0.002)   Loss 0.3098 (0.3253)   Prec@1 88.281 (88.761)   Prec@5 100.000 (99.691)   [2019-11-23 05:07:39]
  Epoch: [054][200/391]   Time 0.063 (0.050)   Data 0.000 (0.001)   Loss 0.3497 (0.3265)   Prec@1 86.719 (88.752)   Prec@5 100.000 (99.662)   [2019-11-23 05:07:44]
  Epoch: [054][300/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.4776 (0.3379)   Prec@1 82.031 (88.323)   Prec@5 100.000 (99.631)   [2019-11-23 05:07:49]
  **Train** Prec@1 88.264 Prec@5 99.606 Error@1 11.736
  **Test** Prec@1 83.700 Prec@5 98.600 Error@1 16.300

==>>[2019-11-23 05:07:55] [Epoch=055/200] [Need: 00:52:40] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [055][000/391]   Time 0.261 (0.261)   Data 0.205 (0.205)   Loss 0.3522 (0.3522)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 05:07:56]
  Epoch: [055][100/391]   Time 0.051 (0.048)   Data 0.000 (0.002)   Loss 0.3682 (0.3245)   Prec@1 88.281 (88.745)   Prec@5 99.219 (99.660)   [2019-11-23 05:08:00]
  Epoch: [055][200/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.3183 (0.3262)   Prec@1 89.062 (88.763)   Prec@5 99.219 (99.611)   [2019-11-23 05:08:05]
  Epoch: [055][300/391]   Time 0.058 (0.049)   Data 0.000 (0.001)   Loss 0.4528 (0.3302)   Prec@1 85.938 (88.595)   Prec@5 99.219 (99.603)   [2019-11-23 05:08:10]
  **Train** Prec@1 88.580 Prec@5 99.616 Error@1 11.420
  **Test** Prec@1 84.430 Prec@5 99.360 Error@1 15.570

==>>[2019-11-23 05:08:17] [Epoch=056/200] [Need: 00:52:17] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [056][000/391]   Time 0.255 (0.255)   Data 0.192 (0.192)   Loss 0.3597 (0.3597)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-23 05:08:17]
  Epoch: [056][100/391]   Time 0.048 (0.049)   Data 0.000 (0.002)   Loss 0.2970 (0.3107)   Prec@1 88.281 (89.171)   Prec@5 100.000 (99.636)   [2019-11-23 05:08:22]
  Epoch: [056][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2976 (0.3298)   Prec@1 89.844 (88.592)   Prec@5 100.000 (99.580)   [2019-11-23 05:08:27]
  Epoch: [056][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.3572 (0.3382)   Prec@1 89.844 (88.325)   Prec@5 100.000 (99.590)   [2019-11-23 05:08:32]
  **Train** Prec@1 88.390 Prec@5 99.586 Error@1 11.610
  **Test** Prec@1 84.850 Prec@5 99.140 Error@1 15.150

==>>[2019-11-23 05:08:39] [Epoch=057/200] [Need: 00:51:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [057][000/391]   Time 0.254 (0.254)   Data 0.194 (0.194)   Loss 0.3057 (0.3057)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 05:08:39]
  Epoch: [057][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3689 (0.3287)   Prec@1 88.281 (88.405)   Prec@5 99.219 (99.675)   [2019-11-23 05:08:44]
  Epoch: [057][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2909 (0.3310)   Prec@1 90.625 (88.487)   Prec@5 98.438 (99.619)   [2019-11-23 05:08:49]
  Epoch: [057][300/391]   Time 0.072 (0.052)   Data 0.000 (0.001)   Loss 0.3323 (0.3361)   Prec@1 86.719 (88.331)   Prec@5 100.000 (99.598)   [2019-11-23 05:08:54]
  **Train** Prec@1 88.264 Prec@5 99.580 Error@1 11.736
  **Test** Prec@1 83.840 Prec@5 99.140 Error@1 16.160

==>>[2019-11-23 05:09:00] [Epoch=058/200] [Need: 00:51:34] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [058][000/391]   Time 0.246 (0.246)   Data 0.194 (0.194)   Loss 0.3605 (0.3605)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2019-11-23 05:09:01]
  Epoch: [058][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.2821 (0.3080)   Prec@1 90.625 (89.333)   Prec@5 99.219 (99.667)   [2019-11-23 05:09:06]
  Epoch: [058][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.3563 (0.3163)   Prec@1 88.281 (89.109)   Prec@5 99.219 (99.604)   [2019-11-23 05:09:11]
  Epoch: [058][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.2285 (0.3250)   Prec@1 95.312 (88.847)   Prec@5 98.438 (99.605)   [2019-11-23 05:09:16]
  **Train** Prec@1 88.708 Prec@5 99.592 Error@1 11.292
  **Test** Prec@1 80.250 Prec@5 99.140 Error@1 19.750

==>>[2019-11-23 05:09:22] [Epoch=059/200] [Need: 00:51:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [059][000/391]   Time 0.252 (0.252)   Data 0.189 (0.189)   Loss 0.2898 (0.2898)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 05:09:22]
  Epoch: [059][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.2764 (0.3268)   Prec@1 89.844 (88.598)   Prec@5 100.000 (99.737)   [2019-11-23 05:09:28]
  Epoch: [059][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.3682 (0.3248)   Prec@1 85.156 (88.674)   Prec@5 100.000 (99.708)   [2019-11-23 05:09:33]
  Epoch: [059][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3104 (0.3381)   Prec@1 89.844 (88.382)   Prec@5 100.000 (99.603)   [2019-11-23 05:09:37]
  **Train** Prec@1 88.316 Prec@5 99.628 Error@1 11.684
  **Test** Prec@1 80.740 Prec@5 99.060 Error@1 19.260

==>>[2019-11-23 05:09:44] [Epoch=060/200] [Need: 00:50:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [060][000/391]   Time 0.241 (0.241)   Data 0.185 (0.185)   Loss 0.2601 (0.2601)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:09:44]
  Epoch: [060][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.4082 (0.3274)   Prec@1 85.938 (89.078)   Prec@5 100.000 (99.559)   [2019-11-23 05:09:49]
  Epoch: [060][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.3561 (0.3291)   Prec@1 85.938 (88.822)   Prec@5 99.219 (99.600)   [2019-11-23 05:09:54]
  Epoch: [060][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3544 (0.3309)   Prec@1 87.500 (88.655)   Prec@5 100.000 (99.587)   [2019-11-23 05:09:59]
  **Train** Prec@1 88.568 Prec@5 99.616 Error@1 11.432
  **Test** Prec@1 85.000 Prec@5 99.220 Error@1 15.000

==>>[2019-11-23 05:10:06] [Epoch=061/200] [Need: 00:50:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.19, Error=14.81]
  Epoch: [061][000/391]   Time 0.250 (0.250)   Data 0.196 (0.196)   Loss 0.2678 (0.2678)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-23 05:10:06]
  Epoch: [061][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.2456 (0.3326)   Prec@1 92.188 (88.444)   Prec@5 100.000 (99.551)   [2019-11-23 05:10:11]
  Epoch: [061][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.3418 (0.3289)   Prec@1 89.062 (88.689)   Prec@5 98.438 (99.615)   [2019-11-23 05:10:16]
  Epoch: [061][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.3602 (0.3317)   Prec@1 86.719 (88.603)   Prec@5 100.000 (99.572)   [2019-11-23 05:10:21]
  **Train** Prec@1 88.568 Prec@5 99.586 Error@1 11.432
  **Test** Prec@1 85.840 Prec@5 99.360 Error@1 14.160
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:10:27] [Epoch=062/200] [Need: 00:50:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.84, Error=14.16]
  Epoch: [062][000/391]   Time 0.243 (0.243)   Data 0.173 (0.173)   Loss 0.3443 (0.3443)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:10:27]
  Epoch: [062][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.4005 (0.3181)   Prec@1 85.938 (89.024)   Prec@5 100.000 (99.629)   [2019-11-23 05:10:32]
  Epoch: [062][200/391]   Time 0.072 (0.051)   Data 0.000 (0.001)   Loss 0.2341 (0.3279)   Prec@1 93.750 (88.592)   Prec@5 99.219 (99.588)   [2019-11-23 05:10:37]
  Epoch: [062][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.2836 (0.3304)   Prec@1 88.281 (88.538)   Prec@5 100.000 (99.618)   [2019-11-23 05:10:42]
  **Train** Prec@1 88.562 Prec@5 99.646 Error@1 11.438
  **Test** Prec@1 85.000 Prec@5 99.280 Error@1 15.000

==>>[2019-11-23 05:10:48] [Epoch=063/200] [Need: 00:49:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.84, Error=14.16]
  Epoch: [063][000/391]   Time 0.252 (0.252)   Data 0.173 (0.173)   Loss 0.2837 (0.2837)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 05:10:48]
  Epoch: [063][100/391]   Time 0.054 (0.050)   Data 0.000 (0.002)   Loss 0.3238 (0.3094)   Prec@1 90.625 (89.256)   Prec@5 99.219 (99.621)   [2019-11-23 05:10:53]
  Epoch: [063][200/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.3520 (0.3234)   Prec@1 87.500 (88.720)   Prec@5 100.000 (99.635)   [2019-11-23 05:10:58]
  Epoch: [063][300/391]   Time 0.057 (0.049)   Data 0.000 (0.001)   Loss 0.3953 (0.3277)   Prec@1 88.281 (88.717)   Prec@5 100.000 (99.650)   [2019-11-23 05:11:03]
  **Train** Prec@1 88.590 Prec@5 99.644 Error@1 11.410
  **Test** Prec@1 86.220 Prec@5 99.310 Error@1 13.780
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:11:09] [Epoch=064/200] [Need: 00:49:19] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [064][000/391]   Time 0.247 (0.247)   Data 0.173 (0.173)   Loss 0.4232 (0.4232)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 05:11:10]
  Epoch: [064][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.3448 (0.3250)   Prec@1 88.281 (88.761)   Prec@5 99.219 (99.706)   [2019-11-23 05:11:14]
  Epoch: [064][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3367 (0.3266)   Prec@1 86.719 (88.635)   Prec@5 99.219 (99.646)   [2019-11-23 05:11:20]
  Epoch: [064][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.4392 (0.3287)   Prec@1 84.375 (88.658)   Prec@5 99.219 (99.657)   [2019-11-23 05:11:24]
  **Train** Prec@1 88.614 Prec@5 99.642 Error@1 11.386
  **Test** Prec@1 85.290 Prec@5 99.230 Error@1 14.710

==>>[2019-11-23 05:11:31] [Epoch=065/200] [Need: 00:48:57] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [065][000/391]   Time 0.262 (0.262)   Data 0.205 (0.205)   Loss 0.3068 (0.3068)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-23 05:11:31]
  Epoch: [065][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.3015 (0.3118)   Prec@1 89.062 (89.480)   Prec@5 99.219 (99.644)   [2019-11-23 05:11:36]
  Epoch: [065][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.2569 (0.3133)   Prec@1 89.062 (89.187)   Prec@5 100.000 (99.670)   [2019-11-23 05:11:41]
  Epoch: [065][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3193 (0.3227)   Prec@1 88.281 (88.933)   Prec@5 100.000 (99.613)   [2019-11-23 05:11:46]
  **Train** Prec@1 88.874 Prec@5 99.614 Error@1 11.126
  **Test** Prec@1 83.890 Prec@5 99.360 Error@1 16.110

==>>[2019-11-23 05:11:53] [Epoch=066/200] [Need: 00:48:35] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [066][000/391]   Time 0.253 (0.253)   Data 0.165 (0.165)   Loss 0.2948 (0.2948)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:11:53]
  Epoch: [066][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.4908 (0.3205)   Prec@1 82.812 (88.869)   Prec@5 100.000 (99.691)   [2019-11-23 05:11:58]
  Epoch: [066][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.3185 (0.3215)   Prec@1 88.281 (88.701)   Prec@5 100.000 (99.615)   [2019-11-23 05:12:03]
  Epoch: [066][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.1807 (0.3242)   Prec@1 93.750 (88.689)   Prec@5 100.000 (99.611)   [2019-11-23 05:12:08]
  **Train** Prec@1 88.704 Prec@5 99.608 Error@1 11.296
  **Test** Prec@1 85.210 Prec@5 99.290 Error@1 14.790

==>>[2019-11-23 05:12:14] [Epoch=067/200] [Need: 00:48:14] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [067][000/391]   Time 0.250 (0.250)   Data 0.188 (0.188)   Loss 0.3695 (0.3695)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-23 05:12:15]
  Epoch: [067][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.2874 (0.3188)   Prec@1 89.844 (88.807)   Prec@5 100.000 (99.698)   [2019-11-23 05:12:20]
  Epoch: [067][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3703 (0.3228)   Prec@1 87.500 (88.685)   Prec@5 100.000 (99.658)   [2019-11-23 05:12:25]
  Epoch: [067][300/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.2833 (0.3216)   Prec@1 91.406 (88.681)   Prec@5 100.000 (99.673)   [2019-11-23 05:12:30]
  **Train** Prec@1 88.600 Prec@5 99.680 Error@1 11.400
  **Test** Prec@1 85.280 Prec@5 99.390 Error@1 14.720

==>>[2019-11-23 05:12:37] [Epoch=068/200] [Need: 00:47:53] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [068][000/391]   Time 0.246 (0.246)   Data 0.188 (0.188)   Loss 0.2316 (0.2316)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 05:12:37]
  Epoch: [068][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3278 (0.3127)   Prec@1 89.844 (89.062)   Prec@5 100.000 (99.660)   [2019-11-23 05:12:42]
  Epoch: [068][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4343 (0.3253)   Prec@1 86.719 (88.701)   Prec@5 100.000 (99.607)   [2019-11-23 05:12:47]
  Epoch: [068][300/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.1730 (0.3251)   Prec@1 95.312 (88.712)   Prec@5 100.000 (99.624)   [2019-11-23 05:12:52]
  **Train** Prec@1 88.654 Prec@5 99.646 Error@1 11.346
  **Test** Prec@1 81.010 Prec@5 99.200 Error@1 18.990

==>>[2019-11-23 05:12:59] [Epoch=069/200] [Need: 00:47:31] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [069][000/391]   Time 0.256 (0.256)   Data 0.200 (0.200)   Loss 0.2367 (0.2367)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:12:59]
  Epoch: [069][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.3135 (0.3190)   Prec@1 88.281 (88.792)   Prec@5 100.000 (99.683)   [2019-11-23 05:13:04]
  Epoch: [069][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3074 (0.3241)   Prec@1 89.062 (88.647)   Prec@5 100.000 (99.685)   [2019-11-23 05:13:09]
  Epoch: [069][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.2727 (0.3229)   Prec@1 89.844 (88.777)   Prec@5 99.219 (99.652)   [2019-11-23 05:13:14]
  **Train** Prec@1 88.664 Prec@5 99.628 Error@1 11.336
  **Test** Prec@1 85.710 Prec@5 99.280 Error@1 14.290

==>>[2019-11-23 05:13:20] [Epoch=070/200] [Need: 00:47:09] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [070][000/391]   Time 0.246 (0.246)   Data 0.185 (0.185)   Loss 0.2869 (0.2869)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 05:13:20]
  Epoch: [070][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1692 (0.2968)   Prec@1 95.312 (89.619)   Prec@5 100.000 (99.737)   [2019-11-23 05:13:25]
  Epoch: [070][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3168 (0.3157)   Prec@1 90.625 (89.043)   Prec@5 100.000 (99.674)   [2019-11-23 05:13:31]
  Epoch: [070][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3488 (0.3171)   Prec@1 89.062 (89.062)   Prec@5 100.000 (99.663)   [2019-11-23 05:13:36]
  **Train** Prec@1 88.980 Prec@5 99.664 Error@1 11.020
  **Test** Prec@1 82.810 Prec@5 98.340 Error@1 17.190

==>>[2019-11-23 05:13:42] [Epoch=071/200] [Need: 00:46:48] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [071][000/391]   Time 0.260 (0.260)   Data 0.182 (0.182)   Loss 0.2115 (0.2115)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 05:13:42]
  Epoch: [071][100/391]   Time 0.060 (0.055)   Data 0.000 (0.002)   Loss 0.4317 (0.3255)   Prec@1 85.156 (88.714)   Prec@5 98.438 (99.698)   [2019-11-23 05:13:48]
  Epoch: [071][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.2834 (0.3181)   Prec@1 89.062 (88.856)   Prec@5 100.000 (99.728)   [2019-11-23 05:13:53]
  Epoch: [071][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2588 (0.3253)   Prec@1 92.188 (88.697)   Prec@5 100.000 (99.673)   [2019-11-23 05:13:58]
  **Train** Prec@1 88.754 Prec@5 99.670 Error@1 11.246
  **Test** Prec@1 84.720 Prec@5 99.230 Error@1 15.280

==>>[2019-11-23 05:14:04] [Epoch=072/200] [Need: 00:46:27] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [072][000/391]   Time 0.255 (0.255)   Data 0.181 (0.181)   Loss 0.2582 (0.2582)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:14:05]
  Epoch: [072][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3031 (0.2917)   Prec@1 89.062 (90.153)   Prec@5 98.438 (99.660)   [2019-11-23 05:14:10]
  Epoch: [072][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.2249 (0.3049)   Prec@1 91.406 (89.552)   Prec@5 100.000 (99.666)   [2019-11-23 05:14:14]
  Epoch: [072][300/391]   Time 0.073 (0.048)   Data 0.000 (0.001)   Loss 0.2946 (0.3172)   Prec@1 88.281 (89.101)   Prec@5 100.000 (99.642)   [2019-11-23 05:14:19]
  **Train** Prec@1 89.018 Prec@5 99.650 Error@1 10.982
  **Test** Prec@1 85.100 Prec@5 99.150 Error@1 14.900

==>>[2019-11-23 05:14:25] [Epoch=073/200] [Need: 00:46:04] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [073][000/391]   Time 0.245 (0.245)   Data 0.182 (0.182)   Loss 0.2988 (0.2988)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 05:14:26]
  Epoch: [073][100/391]   Time 0.074 (0.054)   Data 0.000 (0.002)   Loss 0.4111 (0.3179)   Prec@1 86.719 (89.008)   Prec@5 100.000 (99.691)   [2019-11-23 05:14:31]
  Epoch: [073][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2323 (0.3203)   Prec@1 90.625 (88.923)   Prec@5 100.000 (99.662)   [2019-11-23 05:14:36]
  Epoch: [073][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2673 (0.3168)   Prec@1 91.406 (89.075)   Prec@5 100.000 (99.681)   [2019-11-23 05:14:41]
  **Train** Prec@1 89.066 Prec@5 99.668 Error@1 10.934
  **Test** Prec@1 84.280 Prec@5 99.230 Error@1 15.720

==>>[2019-11-23 05:14:48] [Epoch=074/200] [Need: 00:45:43] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [074][000/391]   Time 0.247 (0.247)   Data 0.174 (0.174)   Loss 0.3439 (0.3439)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 05:14:48]
  Epoch: [074][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3064 (0.3025)   Prec@1 88.281 (89.542)   Prec@5 100.000 (99.722)   [2019-11-23 05:14:53]
  Epoch: [074][200/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.3950 (0.3067)   Prec@1 87.500 (89.397)   Prec@5 100.000 (99.708)   [2019-11-23 05:14:58]
  Epoch: [074][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3768 (0.3212)   Prec@1 85.938 (88.969)   Prec@5 100.000 (99.660)   [2019-11-23 05:15:03]
  **Train** Prec@1 88.896 Prec@5 99.646 Error@1 11.104
  **Test** Prec@1 82.890 Prec@5 98.860 Error@1 17.110

==>>[2019-11-23 05:15:10] [Epoch=075/200] [Need: 00:45:21] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [075][000/391]   Time 0.256 (0.256)   Data 0.176 (0.176)   Loss 0.3049 (0.3049)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 05:15:10]
  Epoch: [075][100/391]   Time 0.074 (0.055)   Data 0.000 (0.002)   Loss 0.3876 (0.3067)   Prec@1 87.500 (89.503)   Prec@5 99.219 (99.698)   [2019-11-23 05:15:15]
  Epoch: [075][200/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 0.3148 (0.3143)   Prec@1 88.281 (89.055)   Prec@5 99.219 (99.662)   [2019-11-23 05:15:21]
  Epoch: [075][300/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.3247 (0.3204)   Prec@1 89.062 (88.842)   Prec@5 99.219 (99.629)   [2019-11-23 05:15:26]
  **Train** Prec@1 88.832 Prec@5 99.616 Error@1 11.168
  **Test** Prec@1 82.160 Prec@5 99.050 Error@1 17.840

==>>[2019-11-23 05:15:32] [Epoch=076/200] [Need: 00:45:00] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [076][000/391]   Time 0.257 (0.257)   Data 0.180 (0.180)   Loss 0.4232 (0.4232)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 05:15:32]
  Epoch: [076][100/391]   Time 0.045 (0.058)   Data 0.000 (0.002)   Loss 0.2601 (0.3184)   Prec@1 93.750 (88.939)   Prec@5 99.219 (99.683)   [2019-11-23 05:15:38]
  Epoch: [076][200/391]   Time 0.063 (0.055)   Data 0.000 (0.001)   Loss 0.2935 (0.3214)   Prec@1 89.062 (88.845)   Prec@5 100.000 (99.677)   [2019-11-23 05:15:43]
  Epoch: [076][300/391]   Time 0.075 (0.055)   Data 0.000 (0.001)   Loss 0.3337 (0.3201)   Prec@1 89.062 (88.951)   Prec@5 100.000 (99.657)   [2019-11-23 05:15:48]
  **Train** Prec@1 88.804 Prec@5 99.654 Error@1 11.196
  **Test** Prec@1 85.070 Prec@5 99.360 Error@1 14.930

==>>[2019-11-23 05:15:55] [Epoch=077/200] [Need: 00:44:41] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [077][000/391]   Time 0.264 (0.264)   Data 0.174 (0.174)   Loss 0.2364 (0.2364)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 05:15:55]
  Epoch: [077][100/391]   Time 0.047 (0.052)   Data 0.000 (0.002)   Loss 0.3960 (0.3291)   Prec@1 87.500 (88.699)   Prec@5 99.219 (99.683)   [2019-11-23 05:16:00]
  Epoch: [077][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3542 (0.3216)   Prec@1 85.938 (88.942)   Prec@5 99.219 (99.685)   [2019-11-23 05:16:05]
  Epoch: [077][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3560 (0.3216)   Prec@1 85.156 (88.873)   Prec@5 100.000 (99.702)   [2019-11-23 05:16:10]
  **Train** Prec@1 88.796 Prec@5 99.672 Error@1 11.204
  **Test** Prec@1 86.110 Prec@5 99.330 Error@1 13.890

==>>[2019-11-23 05:16:16] [Epoch=078/200] [Need: 00:44:18] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [078][000/391]   Time 0.251 (0.251)   Data 0.176 (0.176)   Loss 0.2185 (0.2185)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 05:16:17]
  Epoch: [078][100/391]   Time 0.040 (0.056)   Data 0.000 (0.002)   Loss 0.4507 (0.3038)   Prec@1 82.812 (89.527)   Prec@5 98.438 (99.667)   [2019-11-23 05:16:22]
  Epoch: [078][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3050 (0.3104)   Prec@1 88.281 (89.202)   Prec@5 100.000 (99.650)   [2019-11-23 05:16:27]
  Epoch: [078][300/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.3263 (0.3118)   Prec@1 87.500 (89.203)   Prec@5 99.219 (99.655)   [2019-11-23 05:16:32]
  **Train** Prec@1 88.968 Prec@5 99.642 Error@1 11.032
  **Test** Prec@1 85.640 Prec@5 99.230 Error@1 14.360

==>>[2019-11-23 05:16:39] [Epoch=079/200] [Need: 00:43:58] [LR=0.0100][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [079][000/391]   Time 0.261 (0.261)   Data 0.204 (0.204)   Loss 0.2724 (0.2724)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 05:16:39]
  Epoch: [079][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.3743 (0.3128)   Prec@1 83.594 (89.279)   Prec@5 96.875 (99.621)   [2019-11-23 05:16:44]
  Epoch: [079][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.3176 (0.3084)   Prec@1 88.281 (89.412)   Prec@5 100.000 (99.693)   [2019-11-23 05:16:50]
  Epoch: [079][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.3063 (0.3167)   Prec@1 87.500 (89.026)   Prec@5 100.000 (99.676)   [2019-11-23 05:16:54]
  **Train** Prec@1 88.928 Prec@5 99.642 Error@1 11.072
  **Test** Prec@1 83.390 Prec@5 99.340 Error@1 16.610

==>>[2019-11-23 05:17:01] [Epoch=080/200] [Need: 00:43:36] [LR=0.0010][M=0.90] [Best : Accuracy=86.22, Error=13.78]
  Epoch: [080][000/391]   Time 0.246 (0.246)   Data 0.175 (0.175)   Loss 0.3973 (0.3973)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 05:17:01]
  Epoch: [080][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.2956 (0.2666)   Prec@1 87.500 (90.942)   Prec@5 100.000 (99.737)   [2019-11-23 05:17:06]
  Epoch: [080][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1762 (0.2469)   Prec@1 95.312 (91.554)   Prec@5 100.000 (99.782)   [2019-11-23 05:17:12]
  Epoch: [080][300/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.1842 (0.2376)   Prec@1 92.969 (91.858)   Prec@5 100.000 (99.818)   [2019-11-23 05:17:17]
  **Train** Prec@1 92.068 Prec@5 99.832 Error@1 7.932
  **Test** Prec@1 89.850 Prec@5 99.620 Error@1 10.150
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:17:23] [Epoch=081/200] [Need: 00:43:15] [LR=0.0010][M=0.90] [Best : Accuracy=89.85, Error=10.15]
  Epoch: [081][000/391]   Time 0.256 (0.256)   Data 0.185 (0.185)   Loss 0.2289 (0.2289)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 05:17:23]
  Epoch: [081][100/391]   Time 0.054 (0.053)   Data 0.000 (0.002)   Loss 0.2217 (0.1990)   Prec@1 89.844 (93.069)   Prec@5 100.000 (99.830)   [2019-11-23 05:17:29]
  Epoch: [081][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.2381 (0.2001)   Prec@1 93.750 (93.113)   Prec@5 100.000 (99.845)   [2019-11-23 05:17:34]
  Epoch: [081][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2061 (0.1979)   Prec@1 93.750 (93.200)   Prec@5 100.000 (99.847)   [2019-11-23 05:17:39]
  **Train** Prec@1 93.184 Prec@5 99.842 Error@1 6.816
  **Test** Prec@1 89.950 Prec@5 99.650 Error@1 10.050
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:17:45] [Epoch=082/200] [Need: 00:42:53] [LR=0.0010][M=0.90] [Best : Accuracy=89.95, Error=10.05]
  Epoch: [082][000/391]   Time 0.242 (0.242)   Data 0.183 (0.183)   Loss 0.1358 (0.1358)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:17:45]
  Epoch: [082][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.3064 (0.1787)   Prec@1 88.281 (93.680)   Prec@5 99.219 (99.876)   [2019-11-23 05:17:50]
  Epoch: [082][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1971 (0.1861)   Prec@1 93.750 (93.560)   Prec@5 99.219 (99.872)   [2019-11-23 05:17:56]
  Epoch: [082][300/391]   Time 0.077 (0.052)   Data 0.000 (0.001)   Loss 0.1446 (0.1882)   Prec@1 96.094 (93.415)   Prec@5 100.000 (99.870)   [2019-11-23 05:18:01]
  **Train** Prec@1 93.460 Prec@5 99.876 Error@1 6.540
  **Test** Prec@1 89.930 Prec@5 99.700 Error@1 10.070

==>>[2019-11-23 05:18:07] [Epoch=083/200] [Need: 00:42:32] [LR=0.0010][M=0.90] [Best : Accuracy=89.95, Error=10.05]
  Epoch: [083][000/391]   Time 0.241 (0.241)   Data 0.182 (0.182)   Loss 0.1395 (0.1395)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 05:18:07]
  Epoch: [083][100/391]   Time 0.073 (0.049)   Data 0.000 (0.002)   Loss 0.1605 (0.1780)   Prec@1 93.750 (93.974)   Prec@5 100.000 (99.869)   [2019-11-23 05:18:12]
  Epoch: [083][200/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.2949 (0.1778)   Prec@1 90.625 (93.956)   Prec@5 99.219 (99.848)   [2019-11-23 05:18:17]
  Epoch: [083][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.2363 (0.1764)   Prec@1 90.625 (93.997)   Prec@5 100.000 (99.865)   [2019-11-23 05:18:22]
  **Train** Prec@1 93.956 Prec@5 99.862 Error@1 6.044
  **Test** Prec@1 89.880 Prec@5 99.640 Error@1 10.120

==>>[2019-11-23 05:18:28] [Epoch=084/200] [Need: 00:42:09] [LR=0.0010][M=0.90] [Best : Accuracy=89.95, Error=10.05]
  Epoch: [084][000/391]   Time 0.248 (0.248)   Data 0.177 (0.177)   Loss 0.1306 (0.1306)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:18:29]
  Epoch: [084][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1389 (0.1738)   Prec@1 95.312 (93.936)   Prec@5 100.000 (99.930)   [2019-11-23 05:18:34]
  Epoch: [084][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.1329 (0.1706)   Prec@1 97.656 (94.127)   Prec@5 100.000 (99.876)   [2019-11-23 05:18:38]
  Epoch: [084][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.2022 (0.1712)   Prec@1 96.094 (94.163)   Prec@5 100.000 (99.875)   [2019-11-23 05:18:43]
  **Train** Prec@1 94.128 Prec@5 99.872 Error@1 5.872
  **Test** Prec@1 89.940 Prec@5 99.670 Error@1 10.060

==>>[2019-11-23 05:18:50] [Epoch=085/200] [Need: 00:41:46] [LR=0.0010][M=0.90] [Best : Accuracy=89.95, Error=10.05]
  Epoch: [085][000/391]   Time 0.234 (0.234)   Data 0.177 (0.177)   Loss 0.1219 (0.1219)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:18:50]
  Epoch: [085][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.1105 (0.1602)   Prec@1 96.094 (94.307)   Prec@5 100.000 (99.869)   [2019-11-23 05:18:55]
  Epoch: [085][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1051 (0.1615)   Prec@1 96.094 (94.240)   Prec@5 100.000 (99.903)   [2019-11-23 05:19:00]
  Epoch: [085][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.1344 (0.1635)   Prec@1 94.531 (94.228)   Prec@5 100.000 (99.886)   [2019-11-23 05:19:05]
  **Train** Prec@1 94.160 Prec@5 99.896 Error@1 5.840
  **Test** Prec@1 90.260 Prec@5 99.650 Error@1 9.740
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:19:11] [Epoch=086/200] [Need: 00:41:24] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [086][000/391]   Time 0.239 (0.239)   Data 0.185 (0.185)   Loss 0.1494 (0.1494)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:19:11]
  Epoch: [086][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.1614 (0.1528)   Prec@1 94.531 (94.663)   Prec@5 100.000 (99.915)   [2019-11-23 05:19:16]
  Epoch: [086][200/391]   Time 0.067 (0.051)   Data 0.000 (0.001)   Loss 0.1478 (0.1558)   Prec@1 94.531 (94.609)   Prec@5 100.000 (99.887)   [2019-11-23 05:19:21]
  Epoch: [086][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1506 (0.1564)   Prec@1 95.312 (94.596)   Prec@5 100.000 (99.894)   [2019-11-23 05:19:26]
  **Train** Prec@1 94.504 Prec@5 99.896 Error@1 5.496
  **Test** Prec@1 90.220 Prec@5 99.700 Error@1 9.780

==>>[2019-11-23 05:19:32] [Epoch=087/200] [Need: 00:41:02] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [087][000/391]   Time 0.262 (0.262)   Data 0.175 (0.175)   Loss 0.1350 (0.1350)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 05:19:33]
  Epoch: [087][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.1738 (0.1557)   Prec@1 96.094 (94.601)   Prec@5 100.000 (99.915)   [2019-11-23 05:19:38]
  Epoch: [087][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.1596 (0.1561)   Prec@1 95.312 (94.551)   Prec@5 100.000 (99.918)   [2019-11-23 05:19:43]
  Epoch: [087][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0987 (0.1563)   Prec@1 98.438 (94.521)   Prec@5 100.000 (99.933)   [2019-11-23 05:19:48]
  **Train** Prec@1 94.542 Prec@5 99.926 Error@1 5.458
  **Test** Prec@1 90.050 Prec@5 99.670 Error@1 9.950

==>>[2019-11-23 05:19:54] [Epoch=088/200] [Need: 00:40:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [088][000/391]   Time 0.245 (0.245)   Data 0.175 (0.175)   Loss 0.1538 (0.1538)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:19:54]
  Epoch: [088][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.1923 (0.1501)   Prec@1 92.188 (94.632)   Prec@5 99.219 (99.946)   [2019-11-23 05:19:59]
  Epoch: [088][200/391]   Time 0.061 (0.051)   Data 0.000 (0.001)   Loss 0.1236 (0.1464)   Prec@1 95.312 (94.718)   Prec@5 100.000 (99.942)   [2019-11-23 05:20:04]
  Epoch: [088][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.1606 (0.1473)   Prec@1 94.531 (94.793)   Prec@5 100.000 (99.927)   [2019-11-23 05:20:09]
  **Train** Prec@1 94.810 Prec@5 99.924 Error@1 5.190
  **Test** Prec@1 90.110 Prec@5 99.670 Error@1 9.890

==>>[2019-11-23 05:20:16] [Epoch=089/200] [Need: 00:40:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [089][000/391]   Time 0.263 (0.263)   Data 0.174 (0.174)   Loss 0.1321 (0.1321)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.219)   [2019-11-23 05:20:16]
  Epoch: [089][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.1271 (0.1483)   Prec@1 96.875 (94.926)   Prec@5 100.000 (99.884)   [2019-11-23 05:20:21]
  Epoch: [089][200/391]   Time 0.040 (0.052)   Data 0.000 (0.001)   Loss 0.1838 (0.1508)   Prec@1 92.188 (94.854)   Prec@5 100.000 (99.895)   [2019-11-23 05:20:26]
  Epoch: [089][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.1441 (0.1467)   Prec@1 96.875 (94.941)   Prec@5 100.000 (99.894)   [2019-11-23 05:20:31]
  **Train** Prec@1 94.892 Prec@5 99.908 Error@1 5.108
  **Test** Prec@1 90.190 Prec@5 99.640 Error@1 9.810

==>>[2019-11-23 05:20:38] [Epoch=090/200] [Need: 00:39:56] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [090][000/391]   Time 0.248 (0.248)   Data 0.190 (0.190)   Loss 0.1732 (0.1732)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:20:38]
  Epoch: [090][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.1207 (0.1351)   Prec@1 95.312 (95.374)   Prec@5 100.000 (99.923)   [2019-11-23 05:20:43]
  Epoch: [090][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2365 (0.1361)   Prec@1 89.844 (95.227)   Prec@5 100.000 (99.934)   [2019-11-23 05:20:48]
  Epoch: [090][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2020 (0.1386)   Prec@1 93.750 (95.165)   Prec@5 100.000 (99.927)   [2019-11-23 05:20:53]
  **Train** Prec@1 95.118 Prec@5 99.920 Error@1 4.882
  **Test** Prec@1 89.900 Prec@5 99.600 Error@1 10.100

==>>[2019-11-23 05:20:59] [Epoch=091/200] [Need: 00:39:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [091][000/391]   Time 0.246 (0.246)   Data 0.173 (0.173)   Loss 0.1257 (0.1257)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:20:59]
  Epoch: [091][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0884 (0.1372)   Prec@1 96.094 (94.972)   Prec@5 100.000 (99.930)   [2019-11-23 05:21:04]
  Epoch: [091][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1288 (0.1379)   Prec@1 96.094 (95.040)   Prec@5 100.000 (99.938)   [2019-11-23 05:21:09]
  Epoch: [091][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1549 (0.1398)   Prec@1 94.531 (94.993)   Prec@5 100.000 (99.935)   [2019-11-23 05:21:14]
  **Train** Prec@1 95.050 Prec@5 99.926 Error@1 4.950
  **Test** Prec@1 90.030 Prec@5 99.620 Error@1 9.970

==>>[2019-11-23 05:21:21] [Epoch=092/200] [Need: 00:39:12] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [092][000/391]   Time 0.250 (0.250)   Data 0.175 (0.175)   Loss 0.0869 (0.0869)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:21:21]
  Epoch: [092][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.1381 (0.1347)   Prec@1 96.875 (95.405)   Prec@5 100.000 (99.946)   [2019-11-23 05:21:26]
  Epoch: [092][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.1020 (0.1400)   Prec@1 96.875 (95.149)   Prec@5 100.000 (99.949)   [2019-11-23 05:21:31]
  Epoch: [092][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1659 (0.1395)   Prec@1 92.969 (95.170)   Prec@5 99.219 (99.945)   [2019-11-23 05:21:36]
  **Train** Prec@1 95.096 Prec@5 99.948 Error@1 4.904
  **Test** Prec@1 90.230 Prec@5 99.660 Error@1 9.770

==>>[2019-11-23 05:21:43] [Epoch=093/200] [Need: 00:38:51] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [093][000/391]   Time 0.239 (0.239)   Data 0.177 (0.177)   Loss 0.0731 (0.0731)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:21:43]
  Epoch: [093][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1549 (0.1336)   Prec@1 92.188 (95.088)   Prec@5 100.000 (99.961)   [2019-11-23 05:21:48]
  Epoch: [093][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.2341 (0.1354)   Prec@1 91.406 (95.017)   Prec@5 99.219 (99.938)   [2019-11-23 05:21:53]
  Epoch: [093][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.2252 (0.1362)   Prec@1 93.750 (95.074)   Prec@5 100.000 (99.940)   [2019-11-23 05:21:59]
  **Train** Prec@1 95.092 Prec@5 99.944 Error@1 4.908
  **Test** Prec@1 89.730 Prec@5 99.630 Error@1 10.270

==>>[2019-11-23 05:22:05] [Epoch=094/200] [Need: 00:38:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.26, Error=9.74]
  Epoch: [094][000/391]   Time 0.251 (0.251)   Data 0.187 (0.187)   Loss 0.1219 (0.1219)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:22:05]
  Epoch: [094][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0860 (0.1283)   Prec@1 97.656 (95.537)   Prec@5 100.000 (99.938)   [2019-11-23 05:22:10]
  Epoch: [094][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0808 (0.1301)   Prec@1 96.875 (95.472)   Prec@5 100.000 (99.953)   [2019-11-23 05:22:15]
  Epoch: [094][300/391]   Time 0.072 (0.052)   Data 0.000 (0.001)   Loss 0.1152 (0.1310)   Prec@1 96.094 (95.383)   Prec@5 100.000 (99.951)   [2019-11-23 05:22:21]
  **Train** Prec@1 95.322 Prec@5 99.944 Error@1 4.678
  **Test** Prec@1 90.540 Prec@5 99.650 Error@1 9.460
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:22:27] [Epoch=095/200] [Need: 00:38:08] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [095][000/391]   Time 0.258 (0.258)   Data 0.187 (0.187)   Loss 0.0873 (0.0873)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:22:27]
  Epoch: [095][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.0701 (0.1181)   Prec@1 98.438 (95.854)   Prec@5 100.000 (99.946)   [2019-11-23 05:22:32]
  Epoch: [095][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0621 (0.1251)   Prec@1 97.656 (95.608)   Prec@5 100.000 (99.934)   [2019-11-23 05:22:37]
  Epoch: [095][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1307 (0.1269)   Prec@1 94.531 (95.551)   Prec@5 100.000 (99.940)   [2019-11-23 05:22:42]
  **Train** Prec@1 95.438 Prec@5 99.934 Error@1 4.562
  **Test** Prec@1 90.300 Prec@5 99.650 Error@1 9.700

==>>[2019-11-23 05:22:49] [Epoch=096/200] [Need: 00:37:46] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [096][000/391]   Time 0.256 (0.256)   Data 0.198 (0.198)   Loss 0.1029 (0.1029)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:22:49]
  Epoch: [096][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0693 (0.1258)   Prec@1 97.656 (95.367)   Prec@5 100.000 (99.907)   [2019-11-23 05:22:54]
  Epoch: [096][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.0772 (0.1274)   Prec@1 97.656 (95.363)   Prec@5 100.000 (99.918)   [2019-11-23 05:22:59]
  Epoch: [096][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0885 (0.1274)   Prec@1 97.656 (95.346)   Prec@5 100.000 (99.927)   [2019-11-23 05:23:04]
  **Train** Prec@1 95.396 Prec@5 99.930 Error@1 4.604
  **Test** Prec@1 90.330 Prec@5 99.640 Error@1 9.670

==>>[2019-11-23 05:23:11] [Epoch=097/200] [Need: 00:37:24] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [097][000/391]   Time 0.245 (0.245)   Data 0.173 (0.173)   Loss 0.1487 (0.1487)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:23:11]
  Epoch: [097][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.1431 (0.1219)   Prec@1 95.312 (95.715)   Prec@5 100.000 (99.907)   [2019-11-23 05:23:16]
  Epoch: [097][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.1045 (0.1240)   Prec@1 95.312 (95.631)   Prec@5 100.000 (99.934)   [2019-11-23 05:23:21]
  Epoch: [097][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1226 (0.1256)   Prec@1 97.656 (95.614)   Prec@5 100.000 (99.943)   [2019-11-23 05:23:26]
  **Train** Prec@1 95.586 Prec@5 99.946 Error@1 4.414
  **Test** Prec@1 89.670 Prec@5 99.510 Error@1 10.330

==>>[2019-11-23 05:23:33] [Epoch=098/200] [Need: 00:37:03] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [098][000/391]   Time 0.244 (0.244)   Data 0.188 (0.188)   Loss 0.1034 (0.1034)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:23:33]
  Epoch: [098][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.1373 (0.1224)   Prec@1 96.094 (95.769)   Prec@5 100.000 (99.930)   [2019-11-23 05:23:38]
  Epoch: [098][200/391]   Time 0.063 (0.052)   Data 0.000 (0.001)   Loss 0.1299 (0.1230)   Prec@1 96.094 (95.678)   Prec@5 100.000 (99.946)   [2019-11-23 05:23:43]
  Epoch: [098][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1120 (0.1255)   Prec@1 96.875 (95.559)   Prec@5 100.000 (99.945)   [2019-11-23 05:23:48]
  **Train** Prec@1 95.556 Prec@5 99.944 Error@1 4.444
  **Test** Prec@1 89.980 Prec@5 99.670 Error@1 10.020

==>>[2019-11-23 05:23:54] [Epoch=099/200] [Need: 00:36:41] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [099][000/391]   Time 0.237 (0.237)   Data 0.173 (0.173)   Loss 0.1170 (0.1170)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:23:55]
  Epoch: [099][100/391]   Time 0.048 (0.054)   Data 0.000 (0.002)   Loss 0.1382 (0.1212)   Prec@1 94.531 (95.939)   Prec@5 100.000 (99.915)   [2019-11-23 05:24:00]
  Epoch: [099][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0872 (0.1207)   Prec@1 95.312 (95.853)   Prec@5 100.000 (99.930)   [2019-11-23 05:24:05]
  Epoch: [099][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0966 (0.1203)   Prec@1 96.094 (95.785)   Prec@5 100.000 (99.948)   [2019-11-23 05:24:10]
  **Train** Prec@1 95.810 Prec@5 99.950 Error@1 4.190
  **Test** Prec@1 90.500 Prec@5 99.640 Error@1 9.500

==>>[2019-11-23 05:24:16] [Epoch=100/200] [Need: 00:36:19] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [100][000/391]   Time 0.255 (0.255)   Data 0.182 (0.182)   Loss 0.1175 (0.1175)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 05:24:16]
  Epoch: [100][100/391]   Time 0.048 (0.054)   Data 0.000 (0.002)   Loss 0.1101 (0.1141)   Prec@1 96.094 (96.156)   Prec@5 100.000 (99.961)   [2019-11-23 05:24:21]
  Epoch: [100][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.1235 (0.1181)   Prec@1 94.531 (95.927)   Prec@5 100.000 (99.949)   [2019-11-23 05:24:27]
  Epoch: [100][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1509 (0.1169)   Prec@1 92.188 (95.925)   Prec@5 100.000 (99.945)   [2019-11-23 05:24:32]
  **Train** Prec@1 95.922 Prec@5 99.942 Error@1 4.078
  **Test** Prec@1 90.480 Prec@5 99.590 Error@1 9.520

==>>[2019-11-23 05:24:38] [Epoch=101/200] [Need: 00:35:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [101][000/391]   Time 0.246 (0.246)   Data 0.174 (0.174)   Loss 0.1077 (0.1077)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:24:38]
  Epoch: [101][100/391]   Time 0.073 (0.055)   Data 0.000 (0.002)   Loss 0.0343 (0.1114)   Prec@1 99.219 (95.962)   Prec@5 100.000 (99.954)   [2019-11-23 05:24:43]
  Epoch: [101][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.1290 (0.1145)   Prec@1 93.750 (95.934)   Prec@5 100.000 (99.953)   [2019-11-23 05:24:48]
  Epoch: [101][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.1233 (0.1163)   Prec@1 95.312 (95.847)   Prec@5 100.000 (99.958)   [2019-11-23 05:24:53]
  **Train** Prec@1 95.796 Prec@5 99.962 Error@1 4.204
  **Test** Prec@1 90.400 Prec@5 99.690 Error@1 9.600

==>>[2019-11-23 05:25:00] [Epoch=102/200] [Need: 00:35:36] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [102][000/391]   Time 0.256 (0.256)   Data 0.175 (0.175)   Loss 0.1925 (0.1925)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 05:25:00]
  Epoch: [102][100/391]   Time 0.060 (0.053)   Data 0.000 (0.002)   Loss 0.0844 (0.1105)   Prec@1 97.656 (96.063)   Prec@5 100.000 (99.946)   [2019-11-23 05:25:05]
  Epoch: [102][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1097 (0.1120)   Prec@1 96.094 (96.032)   Prec@5 100.000 (99.965)   [2019-11-23 05:25:10]
  Epoch: [102][300/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.0915 (0.1128)   Prec@1 95.312 (96.050)   Prec@5 100.000 (99.964)   [2019-11-23 05:25:15]
  **Train** Prec@1 96.038 Prec@5 99.960 Error@1 3.962
  **Test** Prec@1 89.880 Prec@5 99.640 Error@1 10.120

==>>[2019-11-23 05:25:22] [Epoch=103/200] [Need: 00:35:14] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [103][000/391]   Time 0.247 (0.247)   Data 0.178 (0.178)   Loss 0.0809 (0.0809)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:25:22]
  Epoch: [103][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1165 (0.1136)   Prec@1 95.312 (95.924)   Prec@5 100.000 (99.938)   [2019-11-23 05:25:27]
  Epoch: [103][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1234 (0.1131)   Prec@1 96.094 (96.012)   Prec@5 100.000 (99.946)   [2019-11-23 05:25:32]
  Epoch: [103][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0914 (0.1148)   Prec@1 96.094 (95.951)   Prec@5 100.000 (99.935)   [2019-11-23 05:25:37]
  **Train** Prec@1 95.948 Prec@5 99.942 Error@1 4.052
  **Test** Prec@1 90.230 Prec@5 99.660 Error@1 9.770

==>>[2019-11-23 05:25:44] [Epoch=104/200] [Need: 00:34:52] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [104][000/391]   Time 0.248 (0.248)   Data 0.192 (0.192)   Loss 0.0265 (0.0265)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:25:44]
  Epoch: [104][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.1000 (0.1066)   Prec@1 96.094 (96.225)   Prec@5 100.000 (99.938)   [2019-11-23 05:25:49]
  Epoch: [104][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.1171 (0.1067)   Prec@1 97.656 (96.206)   Prec@5 100.000 (99.969)   [2019-11-23 05:25:54]
  Epoch: [104][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.1258 (0.1097)   Prec@1 96.094 (96.039)   Prec@5 100.000 (99.964)   [2019-11-23 05:25:59]
  **Train** Prec@1 96.032 Prec@5 99.964 Error@1 3.968
  **Test** Prec@1 90.050 Prec@5 99.630 Error@1 9.950

==>>[2019-11-23 05:26:05] [Epoch=105/200] [Need: 00:34:30] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [105][000/391]   Time 0.264 (0.264)   Data 0.171 (0.171)   Loss 0.1035 (0.1035)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:26:05]
  Epoch: [105][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1119 (0.1064)   Prec@1 94.531 (96.202)   Prec@5 100.000 (99.969)   [2019-11-23 05:26:11]
  Epoch: [105][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1744 (0.1119)   Prec@1 92.188 (95.938)   Prec@5 100.000 (99.961)   [2019-11-23 05:26:16]
  Epoch: [105][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1012 (0.1113)   Prec@1 96.094 (95.987)   Prec@5 100.000 (99.956)   [2019-11-23 05:26:21]
  **Train** Prec@1 95.998 Prec@5 99.958 Error@1 4.002
  **Test** Prec@1 89.940 Prec@5 99.610 Error@1 10.060

==>>[2019-11-23 05:26:28] [Epoch=106/200] [Need: 00:34:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [106][000/391]   Time 0.249 (0.249)   Data 0.182 (0.182)   Loss 0.1245 (0.1245)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:26:28]
  Epoch: [106][100/391]   Time 0.044 (0.049)   Data 0.000 (0.002)   Loss 0.1182 (0.1048)   Prec@1 94.531 (96.372)   Prec@5 100.000 (99.961)   [2019-11-23 05:26:33]
  Epoch: [106][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0818 (0.1065)   Prec@1 96.875 (96.343)   Prec@5 100.000 (99.938)   [2019-11-23 05:26:38]
  Epoch: [106][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0699 (0.1079)   Prec@1 97.656 (96.166)   Prec@5 100.000 (99.948)   [2019-11-23 05:26:42]
  **Train** Prec@1 96.118 Prec@5 99.952 Error@1 3.882
  **Test** Prec@1 90.140 Prec@5 99.690 Error@1 9.860

==>>[2019-11-23 05:26:48] [Epoch=107/200] [Need: 00:33:46] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [107][000/391]   Time 0.255 (0.255)   Data 0.190 (0.190)   Loss 0.0815 (0.0815)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:26:49]
  Epoch: [107][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1693 (0.1001)   Prec@1 95.312 (96.426)   Prec@5 100.000 (99.961)   [2019-11-23 05:26:54]
  Epoch: [107][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.1528 (0.1030)   Prec@1 93.750 (96.280)   Prec@5 100.000 (99.973)   [2019-11-23 05:26:59]
  Epoch: [107][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1232 (0.1054)   Prec@1 94.531 (96.211)   Prec@5 100.000 (99.971)   [2019-11-23 05:27:04]
  **Train** Prec@1 96.194 Prec@5 99.970 Error@1 3.806
  **Test** Prec@1 89.890 Prec@5 99.610 Error@1 10.110

==>>[2019-11-23 05:27:10] [Epoch=108/200] [Need: 00:33:25] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [108][000/391]   Time 0.254 (0.254)   Data 0.173 (0.173)   Loss 0.0834 (0.0834)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:27:11]
  Epoch: [108][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.0958 (0.1013)   Prec@1 95.312 (96.426)   Prec@5 100.000 (99.992)   [2019-11-23 05:27:16]
  Epoch: [108][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0683 (0.1037)   Prec@1 96.875 (96.304)   Prec@5 100.000 (99.988)   [2019-11-23 05:27:20]
  Epoch: [108][300/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.1226 (0.1029)   Prec@1 92.969 (96.299)   Prec@5 100.000 (99.977)   [2019-11-23 05:27:25]
  **Train** Prec@1 96.246 Prec@5 99.978 Error@1 3.754
  **Test** Prec@1 89.970 Prec@5 99.670 Error@1 10.030

==>>[2019-11-23 05:27:32] [Epoch=109/200] [Need: 00:33:03] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [109][000/391]   Time 0.249 (0.249)   Data 0.191 (0.191)   Loss 0.0870 (0.0870)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:27:32]
  Epoch: [109][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.1275 (0.0956)   Prec@1 94.531 (96.550)   Prec@5 100.000 (99.992)   [2019-11-23 05:27:37]
  Epoch: [109][200/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.1019 (0.1038)   Prec@1 96.875 (96.331)   Prec@5 100.000 (99.988)   [2019-11-23 05:27:42]
  Epoch: [109][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0994 (0.1019)   Prec@1 96.875 (96.364)   Prec@5 100.000 (99.987)   [2019-11-23 05:27:47]
  **Train** Prec@1 96.332 Prec@5 99.978 Error@1 3.668
  **Test** Prec@1 89.920 Prec@5 99.610 Error@1 10.080

==>>[2019-11-23 05:27:53] [Epoch=110/200] [Need: 00:32:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [110][000/391]   Time 0.247 (0.247)   Data 0.185 (0.185)   Loss 0.0713 (0.0713)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:27:53]
  Epoch: [110][100/391]   Time 0.040 (0.052)   Data 0.000 (0.002)   Loss 0.0799 (0.1008)   Prec@1 98.438 (96.395)   Prec@5 100.000 (99.946)   [2019-11-23 05:27:58]
  Epoch: [110][200/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0642 (0.0990)   Prec@1 97.656 (96.541)   Prec@5 100.000 (99.969)   [2019-11-23 05:28:03]
  Epoch: [110][300/391]   Time 0.049 (0.049)   Data 0.000 (0.001)   Loss 0.0795 (0.1007)   Prec@1 97.656 (96.470)   Prec@5 100.000 (99.971)   [2019-11-23 05:28:08]
  **Train** Prec@1 96.400 Prec@5 99.968 Error@1 3.600
  **Test** Prec@1 89.760 Prec@5 99.710 Error@1 10.240

==>>[2019-11-23 05:28:14] [Epoch=111/200] [Need: 00:32:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [111][000/391]   Time 0.249 (0.249)   Data 0.190 (0.190)   Loss 0.1097 (0.1097)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:28:14]
  Epoch: [111][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.1481 (0.1033)   Prec@1 96.094 (96.264)   Prec@5 100.000 (99.961)   [2019-11-23 05:28:19]
  Epoch: [111][200/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.1524 (0.1044)   Prec@1 93.750 (96.109)   Prec@5 100.000 (99.965)   [2019-11-23 05:28:24]
  Epoch: [111][300/391]   Time 0.064 (0.050)   Data 0.000 (0.001)   Loss 0.0764 (0.1039)   Prec@1 97.656 (96.153)   Prec@5 100.000 (99.966)   [2019-11-23 05:28:29]
  **Train** Prec@1 96.112 Prec@5 99.966 Error@1 3.888
  **Test** Prec@1 90.340 Prec@5 99.700 Error@1 9.660

==>>[2019-11-23 05:28:36] [Epoch=112/200] [Need: 00:31:56] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [112][000/391]   Time 0.252 (0.252)   Data 0.184 (0.184)   Loss 0.0943 (0.0943)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:28:36]
  Epoch: [112][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.1015 (0.0962)   Prec@1 96.094 (96.535)   Prec@5 100.000 (99.969)   [2019-11-23 05:28:41]
  Epoch: [112][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0750 (0.1013)   Prec@1 97.656 (96.296)   Prec@5 100.000 (99.969)   [2019-11-23 05:28:46]
  Epoch: [112][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0923 (0.1024)   Prec@1 95.312 (96.257)   Prec@5 100.000 (99.966)   [2019-11-23 05:28:51]
  **Train** Prec@1 96.248 Prec@5 99.960 Error@1 3.752
  **Test** Prec@1 89.990 Prec@5 99.610 Error@1 10.010

==>>[2019-11-23 05:28:57] [Epoch=113/200] [Need: 00:31:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [113][000/391]   Time 0.251 (0.251)   Data 0.177 (0.177)   Loss 0.0984 (0.0984)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:28:58]
  Epoch: [113][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.0569 (0.0950)   Prec@1 98.438 (96.705)   Prec@5 100.000 (99.969)   [2019-11-23 05:29:03]
  Epoch: [113][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0675 (0.0951)   Prec@1 98.438 (96.615)   Prec@5 100.000 (99.973)   [2019-11-23 05:29:08]
  Epoch: [113][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0929 (0.0956)   Prec@1 96.875 (96.600)   Prec@5 100.000 (99.977)   [2019-11-23 05:29:13]
  **Train** Prec@1 96.468 Prec@5 99.974 Error@1 3.532
  **Test** Prec@1 90.030 Prec@5 99.640 Error@1 9.970

==>>[2019-11-23 05:29:19] [Epoch=114/200] [Need: 00:31:13] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [114][000/391]   Time 0.265 (0.265)   Data 0.175 (0.175)   Loss 0.1171 (0.1171)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:29:20]
  Epoch: [114][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.1520 (0.0943)   Prec@1 94.531 (96.651)   Prec@5 100.000 (99.961)   [2019-11-23 05:29:25]
  Epoch: [114][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.1084 (0.0974)   Prec@1 96.875 (96.626)   Prec@5 100.000 (99.965)   [2019-11-23 05:29:30]
  Epoch: [114][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0848 (0.0980)   Prec@1 95.312 (96.556)   Prec@5 100.000 (99.964)   [2019-11-23 05:29:35]
  **Train** Prec@1 96.550 Prec@5 99.968 Error@1 3.450
  **Test** Prec@1 90.310 Prec@5 99.630 Error@1 9.690

==>>[2019-11-23 05:29:41] [Epoch=115/200] [Need: 00:30:51] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [115][000/391]   Time 0.248 (0.248)   Data 0.175 (0.175)   Loss 0.0945 (0.0945)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:29:42]
  Epoch: [115][100/391]   Time 0.066 (0.056)   Data 0.000 (0.002)   Loss 0.0577 (0.0974)   Prec@1 97.656 (96.589)   Prec@5 100.000 (99.977)   [2019-11-23 05:29:47]
  Epoch: [115][200/391]   Time 0.044 (0.055)   Data 0.000 (0.001)   Loss 0.0611 (0.0992)   Prec@1 97.656 (96.482)   Prec@5 100.000 (99.981)   [2019-11-23 05:29:52]
  Epoch: [115][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1298 (0.0978)   Prec@1 96.094 (96.504)   Prec@5 100.000 (99.979)   [2019-11-23 05:29:57]
  **Train** Prec@1 96.566 Prec@5 99.978 Error@1 3.434
  **Test** Prec@1 90.450 Prec@5 99.630 Error@1 9.550

==>>[2019-11-23 05:30:04] [Epoch=116/200] [Need: 00:30:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [116][000/391]   Time 0.243 (0.243)   Data 0.188 (0.188)   Loss 0.1448 (0.1448)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-23 05:30:04]
  Epoch: [116][100/391]   Time 0.052 (0.049)   Data 0.000 (0.002)   Loss 0.1098 (0.0952)   Prec@1 94.531 (96.519)   Prec@5 100.000 (99.961)   [2019-11-23 05:30:09]
  Epoch: [116][200/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.1311 (0.0953)   Prec@1 94.531 (96.541)   Prec@5 99.219 (99.977)   [2019-11-23 05:30:13]
  Epoch: [116][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.1601 (0.0947)   Prec@1 92.969 (96.574)   Prec@5 100.000 (99.984)   [2019-11-23 05:30:18]
  **Train** Prec@1 96.546 Prec@5 99.986 Error@1 3.454
  **Test** Prec@1 90.190 Prec@5 99.580 Error@1 9.810

==>>[2019-11-23 05:30:25] [Epoch=117/200] [Need: 00:30:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [117][000/391]   Time 0.256 (0.256)   Data 0.189 (0.189)   Loss 0.0746 (0.0746)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:30:25]
  Epoch: [117][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.1129 (0.0962)   Prec@1 97.656 (96.550)   Prec@5 100.000 (99.985)   [2019-11-23 05:30:30]
  Epoch: [117][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.1011 (0.0988)   Prec@1 96.875 (96.506)   Prec@5 100.000 (99.973)   [2019-11-23 05:30:35]
  Epoch: [117][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1330 (0.1002)   Prec@1 97.656 (96.480)   Prec@5 100.000 (99.964)   [2019-11-23 05:30:40]
  **Train** Prec@1 96.494 Prec@5 99.968 Error@1 3.506
  **Test** Prec@1 90.500 Prec@5 99.640 Error@1 9.500

==>>[2019-11-23 05:30:46] [Epoch=118/200] [Need: 00:29:45] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [118][000/391]   Time 0.250 (0.250)   Data 0.196 (0.196)   Loss 0.0861 (0.0861)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:30:46]
  Epoch: [118][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.1030 (0.0895)   Prec@1 96.094 (96.720)   Prec@5 100.000 (99.977)   [2019-11-23 05:30:52]
  Epoch: [118][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0384 (0.0943)   Prec@1 98.438 (96.650)   Prec@5 100.000 (99.965)   [2019-11-23 05:30:57]
  Epoch: [118][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0291 (0.0937)   Prec@1 99.219 (96.704)   Prec@5 100.000 (99.971)   [2019-11-23 05:31:02]
  **Train** Prec@1 96.746 Prec@5 99.972 Error@1 3.254
  **Test** Prec@1 90.290 Prec@5 99.620 Error@1 9.710

==>>[2019-11-23 05:31:08] [Epoch=119/200] [Need: 00:29:23] [LR=0.0010][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [119][000/391]   Time 0.251 (0.251)   Data 0.175 (0.175)   Loss 0.0686 (0.0686)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:31:08]
  Epoch: [119][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.1322 (0.0891)   Prec@1 95.312 (96.945)   Prec@5 100.000 (99.985)   [2019-11-23 05:31:13]
  Epoch: [119][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.1548 (0.0908)   Prec@1 92.969 (96.770)   Prec@5 100.000 (99.981)   [2019-11-23 05:31:18]
  Epoch: [119][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0835 (0.0925)   Prec@1 96.094 (96.693)   Prec@5 100.000 (99.982)   [2019-11-23 05:31:23]
  **Train** Prec@1 96.670 Prec@5 99.984 Error@1 3.330
  **Test** Prec@1 90.290 Prec@5 99.670 Error@1 9.710

==>>[2019-11-23 05:31:30] [Epoch=120/200] [Need: 00:29:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.54, Error=9.46]
  Epoch: [120][000/391]   Time 0.282 (0.282)   Data 0.222 (0.222)   Loss 0.0400 (0.0400)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:31:30]
  Epoch: [120][100/391]   Time 0.076 (0.053)   Data 0.000 (0.002)   Loss 0.1007 (0.0843)   Prec@1 96.094 (96.821)   Prec@5 100.000 (99.985)   [2019-11-23 05:31:35]
  Epoch: [120][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0720 (0.0803)   Prec@1 97.656 (97.081)   Prec@5 100.000 (99.977)   [2019-11-23 05:31:40]
  Epoch: [120][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0604 (0.0807)   Prec@1 96.875 (97.135)   Prec@5 100.000 (99.977)   [2019-11-23 05:31:45]
  **Train** Prec@1 97.240 Prec@5 99.980 Error@1 2.760
  **Test** Prec@1 90.700 Prec@5 99.650 Error@1 9.300
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:31:51] [Epoch=121/200] [Need: 00:28:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.70, Error=9.30]
  Epoch: [121][000/391]   Time 0.245 (0.245)   Data 0.179 (0.179)   Loss 0.0692 (0.0692)   Prec@1 99.219 (99.219)   Prec@5 99.219 (99.219)   [2019-11-23 05:31:51]
  Epoch: [121][100/391]   Time 0.057 (0.051)   Data 0.000 (0.002)   Loss 0.0633 (0.0730)   Prec@1 97.656 (97.587)   Prec@5 100.000 (99.954)   [2019-11-23 05:31:56]
  Epoch: [121][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1135 (0.0773)   Prec@1 95.312 (97.361)   Prec@5 100.000 (99.953)   [2019-11-23 05:32:01]
  Epoch: [121][300/391]   Time 0.063 (0.049)   Data 0.000 (0.001)   Loss 0.0728 (0.0760)   Prec@1 96.094 (97.345)   Prec@5 100.000 (99.964)   [2019-11-23 05:32:06]
  **Train** Prec@1 97.370 Prec@5 99.966 Error@1 2.630
  **Test** Prec@1 90.770 Prec@5 99.630 Error@1 9.230
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:32:12] [Epoch=122/200] [Need: 00:28:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [122][000/391]   Time 0.262 (0.262)   Data 0.183 (0.183)   Loss 0.0975 (0.0975)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:32:13]
  Epoch: [122][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.0982 (0.0753)   Prec@1 96.094 (97.308)   Prec@5 100.000 (99.985)   [2019-11-23 05:32:18]
  Epoch: [122][200/391]   Time 0.057 (0.053)   Data 0.000 (0.001)   Loss 0.0425 (0.0755)   Prec@1 98.438 (97.318)   Prec@5 100.000 (99.984)   [2019-11-23 05:32:23]
  Epoch: [122][300/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.0332 (0.0716)   Prec@1 99.219 (97.508)   Prec@5 100.000 (99.990)   [2019-11-23 05:32:28]
  **Train** Prec@1 97.558 Prec@5 99.988 Error@1 2.442
  **Test** Prec@1 90.900 Prec@5 99.680 Error@1 9.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:32:35] [Epoch=123/200] [Need: 00:27:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [123][000/391]   Time 0.259 (0.259)   Data 0.175 (0.175)   Loss 0.0802 (0.0802)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:32:35]
  Epoch: [123][100/391]   Time 0.048 (0.050)   Data 0.000 (0.002)   Loss 0.0357 (0.0705)   Prec@1 100.000 (97.594)   Prec@5 100.000 (99.992)   [2019-11-23 05:32:40]
  Epoch: [123][200/391]   Time 0.047 (0.049)   Data 0.000 (0.001)   Loss 0.0592 (0.0698)   Prec@1 98.438 (97.567)   Prec@5 100.000 (99.992)   [2019-11-23 05:32:45]
  Epoch: [123][300/391]   Time 0.063 (0.049)   Data 0.000 (0.001)   Loss 0.0689 (0.0695)   Prec@1 97.656 (97.623)   Prec@5 100.000 (99.984)   [2019-11-23 05:32:50]
  **Train** Prec@1 97.584 Prec@5 99.984 Error@1 2.416
  **Test** Prec@1 90.740 Prec@5 99.690 Error@1 9.260

==>>[2019-11-23 05:32:57] [Epoch=124/200] [Need: 00:27:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [124][000/391]   Time 0.244 (0.244)   Data 0.182 (0.182)   Loss 0.0800 (0.0800)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:32:57]
  Epoch: [124][100/391]   Time 0.081 (0.051)   Data 0.000 (0.002)   Loss 0.0580 (0.0677)   Prec@1 96.875 (97.710)   Prec@5 100.000 (99.961)   [2019-11-23 05:33:02]
  Epoch: [124][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0835 (0.0673)   Prec@1 96.875 (97.695)   Prec@5 100.000 (99.961)   [2019-11-23 05:33:07]
  Epoch: [124][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0611 (0.0678)   Prec@1 99.219 (97.604)   Prec@5 100.000 (99.971)   [2019-11-23 05:33:12]
  **Train** Prec@1 97.560 Prec@5 99.974 Error@1 2.440
  **Test** Prec@1 90.780 Prec@5 99.620 Error@1 9.220

==>>[2019-11-23 05:33:18] [Epoch=125/200] [Need: 00:27:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [125][000/391]   Time 0.245 (0.245)   Data 0.190 (0.190)   Loss 0.0375 (0.0375)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:33:18]
  Epoch: [125][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0405 (0.0659)   Prec@1 98.438 (97.618)   Prec@5 100.000 (99.985)   [2019-11-23 05:33:23]
  Epoch: [125][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0375 (0.0655)   Prec@1 99.219 (97.726)   Prec@5 100.000 (99.992)   [2019-11-23 05:33:28]
  Epoch: [125][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1434 (0.0679)   Prec@1 96.094 (97.654)   Prec@5 100.000 (99.987)   [2019-11-23 05:33:34]
  **Train** Prec@1 97.642 Prec@5 99.988 Error@1 2.358
  **Test** Prec@1 90.870 Prec@5 99.670 Error@1 9.130

==>>[2019-11-23 05:33:40] [Epoch=126/200] [Need: 00:26:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [126][000/391]   Time 0.262 (0.262)   Data 0.201 (0.201)   Loss 0.0848 (0.0848)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:33:40]
  Epoch: [126][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0717 (0.0661)   Prec@1 96.875 (97.842)   Prec@5 100.000 (99.992)   [2019-11-23 05:33:45]
  Epoch: [126][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1124 (0.0651)   Prec@1 94.531 (97.882)   Prec@5 100.000 (99.996)   [2019-11-23 05:33:50]
  Epoch: [126][300/391]   Time 0.076 (0.052)   Data 0.000 (0.001)   Loss 0.0604 (0.0654)   Prec@1 97.656 (97.846)   Prec@5 100.000 (99.990)   [2019-11-23 05:33:56]
  **Train** Prec@1 97.840 Prec@5 99.990 Error@1 2.160
  **Test** Prec@1 90.730 Prec@5 99.680 Error@1 9.270

==>>[2019-11-23 05:34:03] [Epoch=127/200] [Need: 00:26:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [127][000/391]   Time 0.244 (0.244)   Data 0.178 (0.178)   Loss 0.0940 (0.0940)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:03]
  Epoch: [127][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0426 (0.0683)   Prec@1 100.000 (97.664)   Prec@5 100.000 (99.977)   [2019-11-23 05:34:08]
  Epoch: [127][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0340 (0.0683)   Prec@1 100.000 (97.699)   Prec@5 100.000 (99.977)   [2019-11-23 05:34:13]
  Epoch: [127][300/391]   Time 0.079 (0.052)   Data 0.000 (0.001)   Loss 0.0855 (0.0672)   Prec@1 95.312 (97.685)   Prec@5 100.000 (99.982)   [2019-11-23 05:34:18]
  **Train** Prec@1 97.680 Prec@5 99.980 Error@1 2.320
  **Test** Prec@1 90.990 Prec@5 99.650 Error@1 9.010
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 05:34:25] [Epoch=128/200] [Need: 00:26:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [128][000/391]   Time 0.248 (0.248)   Data 0.177 (0.177)   Loss 0.0858 (0.0858)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:25]
  Epoch: [128][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.0846 (0.0674)   Prec@1 98.438 (97.664)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:30]
  Epoch: [128][200/391]   Time 0.040 (0.052)   Data 0.000 (0.001)   Loss 0.0817 (0.0666)   Prec@1 97.656 (97.652)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:35]
  Epoch: [128][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0388 (0.0668)   Prec@1 99.219 (97.674)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:40]
  **Train** Prec@1 97.638 Prec@5 99.994 Error@1 2.362
  **Test** Prec@1 90.710 Prec@5 99.690 Error@1 9.290

==>>[2019-11-23 05:34:47] [Epoch=129/200] [Need: 00:25:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [129][000/391]   Time 0.238 (0.238)   Data 0.187 (0.187)   Loss 0.0321 (0.0321)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:34:47]
  Epoch: [129][100/391]   Time 0.081 (0.056)   Data 0.000 (0.002)   Loss 0.0440 (0.0636)   Prec@1 97.656 (97.850)   Prec@5 100.000 (99.985)   [2019-11-23 05:34:52]
  Epoch: [129][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0178 (0.0642)   Prec@1 100.000 (97.843)   Prec@5 100.000 (99.984)   [2019-11-23 05:34:57]
  Epoch: [129][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0304 (0.0654)   Prec@1 98.438 (97.802)   Prec@5 100.000 (99.987)   [2019-11-23 05:35:02]
  **Train** Prec@1 97.810 Prec@5 99.988 Error@1 2.190
  **Test** Prec@1 90.710 Prec@5 99.720 Error@1 9.290

==>>[2019-11-23 05:35:09] [Epoch=130/200] [Need: 00:25:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [130][000/391]   Time 0.254 (0.254)   Data 0.184 (0.184)   Loss 0.0873 (0.0873)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:35:09]
  Epoch: [130][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.0721 (0.0627)   Prec@1 96.875 (97.757)   Prec@5 100.000 (99.977)   [2019-11-23 05:35:14]
  Epoch: [130][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0469 (0.0625)   Prec@1 97.656 (97.761)   Prec@5 100.000 (99.973)   [2019-11-23 05:35:19]
  Epoch: [130][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0331 (0.0644)   Prec@1 99.219 (97.672)   Prec@5 100.000 (99.979)   [2019-11-23 05:35:25]
  **Train** Prec@1 97.678 Prec@5 99.984 Error@1 2.322
  **Test** Prec@1 90.810 Prec@5 99.690 Error@1 9.190

==>>[2019-11-23 05:35:31] [Epoch=131/200] [Need: 00:25:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [131][000/391]   Time 0.246 (0.246)   Data 0.179 (0.179)   Loss 0.0549 (0.0549)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:35:31]
  Epoch: [131][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0787 (0.0613)   Prec@1 97.656 (97.912)   Prec@5 100.000 (99.985)   [2019-11-23 05:35:36]
  Epoch: [131][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.0653 (0.0637)   Prec@1 96.094 (97.765)   Prec@5 100.000 (99.984)   [2019-11-23 05:35:41]
  Epoch: [131][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0587 (0.0637)   Prec@1 97.656 (97.776)   Prec@5 100.000 (99.982)   [2019-11-23 05:35:46]
  **Train** Prec@1 97.740 Prec@5 99.982 Error@1 2.260
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-23 05:35:53] [Epoch=132/200] [Need: 00:24:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [132][000/391]   Time 0.250 (0.250)   Data 0.194 (0.194)   Loss 0.0607 (0.0607)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:35:53]
  Epoch: [132][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0810 (0.0650)   Prec@1 96.094 (97.734)   Prec@5 100.000 (99.969)   [2019-11-23 05:35:59]
  Epoch: [132][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.1879 (0.0656)   Prec@1 94.531 (97.668)   Prec@5 100.000 (99.977)   [2019-11-23 05:36:04]
  Epoch: [132][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0372 (0.0638)   Prec@1 98.438 (97.757)   Prec@5 100.000 (99.984)   [2019-11-23 05:36:09]
  **Train** Prec@1 97.720 Prec@5 99.982 Error@1 2.280
  **Test** Prec@1 90.820 Prec@5 99.690 Error@1 9.180

==>>[2019-11-23 05:36:15] [Epoch=133/200] [Need: 00:24:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [133][000/391]   Time 0.258 (0.258)   Data 0.185 (0.185)   Loss 0.0407 (0.0407)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:36:15]
  Epoch: [133][100/391]   Time 0.077 (0.053)   Data 0.000 (0.002)   Loss 0.0410 (0.0581)   Prec@1 98.438 (98.066)   Prec@5 100.000 (100.000)   [2019-11-23 05:36:20]
  Epoch: [133][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0599 (0.0615)   Prec@1 97.656 (97.928)   Prec@5 100.000 (99.996)   [2019-11-23 05:36:25]
  Epoch: [133][300/391]   Time 0.067 (0.050)   Data 0.000 (0.001)   Loss 0.0384 (0.0604)   Prec@1 98.438 (97.975)   Prec@5 100.000 (99.992)   [2019-11-23 05:36:30]
  **Train** Prec@1 97.914 Prec@5 99.986 Error@1 2.086
  **Test** Prec@1 90.590 Prec@5 99.660 Error@1 9.410

==>>[2019-11-23 05:36:36] [Epoch=134/200] [Need: 00:23:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [134][000/391]   Time 0.246 (0.246)   Data 0.172 (0.172)   Loss 0.0189 (0.0189)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:36:36]
  Epoch: [134][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0644 (0.0593)   Prec@1 97.656 (97.927)   Prec@5 100.000 (99.985)   [2019-11-23 05:36:41]
  Epoch: [134][200/391]   Time 0.075 (0.053)   Data 0.000 (0.001)   Loss 0.0496 (0.0613)   Prec@1 98.438 (97.909)   Prec@5 100.000 (99.992)   [2019-11-23 05:36:47]
  Epoch: [134][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0397 (0.0618)   Prec@1 97.656 (97.848)   Prec@5 100.000 (99.990)   [2019-11-23 05:36:52]
  **Train** Prec@1 97.840 Prec@5 99.988 Error@1 2.160
  **Test** Prec@1 90.850 Prec@5 99.700 Error@1 9.150

==>>[2019-11-23 05:36:59] [Epoch=135/200] [Need: 00:23:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [135][000/391]   Time 0.254 (0.254)   Data 0.192 (0.192)   Loss 0.0485 (0.0485)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:36:59]
  Epoch: [135][100/391]   Time 0.056 (0.054)   Data 0.000 (0.002)   Loss 0.0467 (0.0625)   Prec@1 98.438 (97.834)   Prec@5 100.000 (99.985)   [2019-11-23 05:37:04]
  Epoch: [135][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0399 (0.0618)   Prec@1 99.219 (97.831)   Prec@5 100.000 (99.981)   [2019-11-23 05:37:09]
  Epoch: [135][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0393 (0.0617)   Prec@1 98.438 (97.846)   Prec@5 100.000 (99.987)   [2019-11-23 05:37:14]
  **Train** Prec@1 97.816 Prec@5 99.988 Error@1 2.184
  **Test** Prec@1 90.600 Prec@5 99.610 Error@1 9.400

==>>[2019-11-23 05:37:20] [Epoch=136/200] [Need: 00:23:14] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [136][000/391]   Time 0.250 (0.250)   Data 0.187 (0.187)   Loss 0.1034 (0.1034)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:37:21]
  Epoch: [136][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.1142 (0.0608)   Prec@1 94.531 (97.927)   Prec@5 100.000 (99.977)   [2019-11-23 05:37:25]
  Epoch: [136][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0241 (0.0616)   Prec@1 100.000 (97.897)   Prec@5 100.000 (99.981)   [2019-11-23 05:37:30]
  Epoch: [136][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.0261 (0.0622)   Prec@1 99.219 (97.892)   Prec@5 100.000 (99.987)   [2019-11-23 05:37:36]
  **Train** Prec@1 97.880 Prec@5 99.986 Error@1 2.120
  **Test** Prec@1 90.770 Prec@5 99.690 Error@1 9.230

==>>[2019-11-23 05:37:42] [Epoch=137/200] [Need: 00:22:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [137][000/391]   Time 0.259 (0.259)   Data 0.179 (0.179)   Loss 0.0864 (0.0864)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:37:42]
  Epoch: [137][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0811 (0.0649)   Prec@1 98.438 (97.896)   Prec@5 100.000 (99.992)   [2019-11-23 05:37:48]
  Epoch: [137][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.0920 (0.0627)   Prec@1 96.094 (97.913)   Prec@5 100.000 (99.996)   [2019-11-23 05:37:53]
  Epoch: [137][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0372 (0.0647)   Prec@1 99.219 (97.791)   Prec@5 100.000 (99.995)   [2019-11-23 05:37:58]
  **Train** Prec@1 97.774 Prec@5 99.994 Error@1 2.226
  **Test** Prec@1 90.600 Prec@5 99.670 Error@1 9.400

==>>[2019-11-23 05:38:04] [Epoch=138/200] [Need: 00:22:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [138][000/391]   Time 0.243 (0.243)   Data 0.193 (0.193)   Loss 0.0757 (0.0757)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:38:05]
  Epoch: [138][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0683 (0.0603)   Prec@1 99.219 (98.066)   Prec@5 100.000 (99.992)   [2019-11-23 05:38:10]
  Epoch: [138][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.0310 (0.0621)   Prec@1 99.219 (97.889)   Prec@5 100.000 (99.996)   [2019-11-23 05:38:15]
  Epoch: [138][300/391]   Time 0.076 (0.052)   Data 0.000 (0.001)   Loss 0.0865 (0.0603)   Prec@1 96.094 (97.926)   Prec@5 100.000 (99.997)   [2019-11-23 05:38:20]
  **Train** Prec@1 97.932 Prec@5 99.998 Error@1 2.068
  **Test** Prec@1 90.500 Prec@5 99.610 Error@1 9.500

==>>[2019-11-23 05:38:27] [Epoch=139/200] [Need: 00:22:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [139][000/391]   Time 0.246 (0.246)   Data 0.174 (0.174)   Loss 0.0594 (0.0594)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:38:27]
  Epoch: [139][100/391]   Time 0.049 (0.054)   Data 0.000 (0.002)   Loss 0.0366 (0.0605)   Prec@1 98.438 (97.834)   Prec@5 100.000 (99.977)   [2019-11-23 05:38:32]
  Epoch: [139][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0486 (0.0614)   Prec@1 96.875 (97.827)   Prec@5 100.000 (99.981)   [2019-11-23 05:38:37]
  Epoch: [139][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.0747 (0.0606)   Prec@1 97.656 (97.859)   Prec@5 100.000 (99.977)   [2019-11-23 05:38:42]
  **Train** Prec@1 97.848 Prec@5 99.976 Error@1 2.152
  **Test** Prec@1 90.640 Prec@5 99.700 Error@1 9.360

==>>[2019-11-23 05:38:49] [Epoch=140/200] [Need: 00:21:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [140][000/391]   Time 0.255 (0.255)   Data 0.197 (0.197)   Loss 0.0614 (0.0614)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:38:49]
  Epoch: [140][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.0344 (0.0597)   Prec@1 99.219 (97.950)   Prec@5 100.000 (100.000)   [2019-11-23 05:38:54]
  Epoch: [140][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0482 (0.0609)   Prec@1 99.219 (97.901)   Prec@5 100.000 (99.988)   [2019-11-23 05:38:59]
  Epoch: [140][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0509 (0.0606)   Prec@1 98.438 (97.898)   Prec@5 100.000 (99.990)   [2019-11-23 05:39:04]
  **Train** Prec@1 97.868 Prec@5 99.988 Error@1 2.132
  **Test** Prec@1 90.640 Prec@5 99.640 Error@1 9.360

==>>[2019-11-23 05:39:10] [Epoch=141/200] [Need: 00:21:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [141][000/391]   Time 0.240 (0.240)   Data 0.187 (0.187)   Loss 0.0834 (0.0834)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:39:11]
  Epoch: [141][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.0777 (0.0626)   Prec@1 96.875 (97.958)   Prec@5 100.000 (100.000)   [2019-11-23 05:39:16]
  Epoch: [141][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.1143 (0.0624)   Prec@1 95.312 (97.901)   Prec@5 100.000 (99.988)   [2019-11-23 05:39:21]
  Epoch: [141][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0382 (0.0624)   Prec@1 98.438 (97.879)   Prec@5 100.000 (99.982)   [2019-11-23 05:39:26]
  **Train** Prec@1 97.870 Prec@5 99.980 Error@1 2.130
  **Test** Prec@1 90.710 Prec@5 99.640 Error@1 9.290

==>>[2019-11-23 05:39:32] [Epoch=142/200] [Need: 00:21:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [142][000/391]   Time 0.273 (0.273)   Data 0.217 (0.217)   Loss 0.0982 (0.0982)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:39:32]
  Epoch: [142][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1097 (0.0663)   Prec@1 96.094 (97.672)   Prec@5 100.000 (99.969)   [2019-11-23 05:39:37]
  Epoch: [142][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0625 (0.0609)   Prec@1 97.656 (97.932)   Prec@5 100.000 (99.981)   [2019-11-23 05:39:42]
  Epoch: [142][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1064 (0.0605)   Prec@1 95.312 (97.950)   Prec@5 100.000 (99.982)   [2019-11-23 05:39:48]
  **Train** Prec@1 97.912 Prec@5 99.984 Error@1 2.088
  **Test** Prec@1 90.370 Prec@5 99.660 Error@1 9.630

==>>[2019-11-23 05:39:54] [Epoch=143/200] [Need: 00:20:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [143][000/391]   Time 0.262 (0.262)   Data 0.204 (0.204)   Loss 0.0468 (0.0468)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:39:54]
  Epoch: [143][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0550 (0.0601)   Prec@1 98.438 (97.881)   Prec@5 100.000 (100.000)   [2019-11-23 05:39:59]
  Epoch: [143][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1121 (0.0596)   Prec@1 95.312 (97.909)   Prec@5 100.000 (99.996)   [2019-11-23 05:40:04]
  Epoch: [143][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0551 (0.0586)   Prec@1 99.219 (98.001)   Prec@5 100.000 (99.992)   [2019-11-23 05:40:10]
  **Train** Prec@1 97.972 Prec@5 99.994 Error@1 2.028
  **Test** Prec@1 90.790 Prec@5 99.670 Error@1 9.210

==>>[2019-11-23 05:40:16] [Epoch=144/200] [Need: 00:20:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [144][000/391]   Time 0.266 (0.266)   Data 0.184 (0.184)   Loss 0.0812 (0.0812)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:40:17]
  Epoch: [144][100/391]   Time 0.051 (0.054)   Data 0.000 (0.002)   Loss 0.0364 (0.0606)   Prec@1 99.219 (97.912)   Prec@5 100.000 (100.000)   [2019-11-23 05:40:22]
  Epoch: [144][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.0696 (0.0608)   Prec@1 96.875 (97.901)   Prec@5 100.000 (99.992)   [2019-11-23 05:40:27]
  Epoch: [144][300/391]   Time 0.038 (0.053)   Data 0.000 (0.001)   Loss 0.0610 (0.0621)   Prec@1 98.438 (97.854)   Prec@5 100.000 (99.995)   [2019-11-23 05:40:32]
  **Train** Prec@1 97.900 Prec@5 99.996 Error@1 2.100
  **Test** Prec@1 90.690 Prec@5 99.600 Error@1 9.310

==>>[2019-11-23 05:40:39] [Epoch=145/200] [Need: 00:19:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [145][000/391]   Time 0.258 (0.258)   Data 0.184 (0.184)   Loss 0.0362 (0.0362)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:40:39]
  Epoch: [145][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.1379 (0.0583)   Prec@1 95.312 (97.942)   Prec@5 99.219 (99.992)   [2019-11-23 05:40:44]
  Epoch: [145][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0224 (0.0599)   Prec@1 100.000 (97.893)   Prec@5 100.000 (99.984)   [2019-11-23 05:40:49]
  Epoch: [145][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0558 (0.0605)   Prec@1 97.656 (97.892)   Prec@5 100.000 (99.982)   [2019-11-23 05:40:54]
  **Train** Prec@1 97.886 Prec@5 99.986 Error@1 2.114
  **Test** Prec@1 90.640 Prec@5 99.680 Error@1 9.360

==>>[2019-11-23 05:41:01] [Epoch=146/200] [Need: 00:19:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [146][000/391]   Time 0.262 (0.262)   Data 0.182 (0.182)   Loss 0.0180 (0.0180)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:01]
  Epoch: [146][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.0363 (0.0583)   Prec@1 99.219 (98.105)   Prec@5 100.000 (99.992)   [2019-11-23 05:41:06]
  Epoch: [146][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0797 (0.0588)   Prec@1 96.875 (98.064)   Prec@5 100.000 (99.996)   [2019-11-23 05:41:11]
  Epoch: [146][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0626 (0.0602)   Prec@1 98.438 (97.988)   Prec@5 100.000 (99.990)   [2019-11-23 05:41:16]
  **Train** Prec@1 97.962 Prec@5 99.992 Error@1 2.038
  **Test** Prec@1 90.790 Prec@5 99.650 Error@1 9.210

==>>[2019-11-23 05:41:23] [Epoch=147/200] [Need: 00:19:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [147][000/391]   Time 0.258 (0.258)   Data 0.176 (0.176)   Loss 0.0821 (0.0821)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:23]
  Epoch: [147][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.0662 (0.0561)   Prec@1 96.875 (98.020)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:28]
  Epoch: [147][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0606 (0.0576)   Prec@1 97.656 (97.991)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:33]
  Epoch: [147][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1190 (0.0588)   Prec@1 96.094 (97.931)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:38]
  **Train** Prec@1 97.884 Prec@5 100.000 Error@1 2.116
  **Test** Prec@1 90.790 Prec@5 99.650 Error@1 9.210

==>>[2019-11-23 05:41:45] [Epoch=148/200] [Need: 00:18:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [148][000/391]   Time 0.234 (0.234)   Data 0.176 (0.176)   Loss 0.0189 (0.0189)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:45]
  Epoch: [148][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0406 (0.0558)   Prec@1 98.438 (98.198)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:50]
  Epoch: [148][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0388 (0.0583)   Prec@1 98.438 (98.014)   Prec@5 100.000 (100.000)   [2019-11-23 05:41:55]
  Epoch: [148][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0505 (0.0600)   Prec@1 98.438 (97.924)   Prec@5 100.000 (100.000)   [2019-11-23 05:42:00]
  **Train** Prec@1 97.884 Prec@5 99.998 Error@1 2.116
  **Test** Prec@1 90.690 Prec@5 99.700 Error@1 9.310

==>>[2019-11-23 05:42:07] [Epoch=149/200] [Need: 00:18:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [149][000/391]   Time 0.245 (0.245)   Data 0.172 (0.172)   Loss 0.1252 (0.1252)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 05:42:07]
  Epoch: [149][100/391]   Time 0.054 (0.052)   Data 0.000 (0.002)   Loss 0.0388 (0.0606)   Prec@1 100.000 (97.888)   Prec@5 100.000 (100.000)   [2019-11-23 05:42:12]
  Epoch: [149][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0731 (0.0599)   Prec@1 96.094 (97.874)   Prec@5 100.000 (99.996)   [2019-11-23 05:42:17]
  Epoch: [149][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0935 (0.0601)   Prec@1 95.312 (97.846)   Prec@5 100.000 (99.995)   [2019-11-23 05:42:22]
  **Train** Prec@1 97.852 Prec@5 99.994 Error@1 2.148
  **Test** Prec@1 90.690 Prec@5 99.650 Error@1 9.310

==>>[2019-11-23 05:42:29] [Epoch=150/200] [Need: 00:18:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [150][000/391]   Time 0.243 (0.243)   Data 0.176 (0.176)   Loss 0.0327 (0.0327)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:42:29]
  Epoch: [150][100/391]   Time 0.049 (0.052)   Data 0.000 (0.002)   Loss 0.0265 (0.0542)   Prec@1 100.000 (98.182)   Prec@5 100.000 (99.992)   [2019-11-23 05:42:34]
  Epoch: [150][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0743 (0.0589)   Prec@1 97.656 (97.971)   Prec@5 100.000 (99.992)   [2019-11-23 05:42:39]
  Epoch: [150][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0762 (0.0597)   Prec@1 98.438 (97.978)   Prec@5 100.000 (99.992)   [2019-11-23 05:42:44]
  **Train** Prec@1 97.946 Prec@5 99.994 Error@1 2.054
  **Test** Prec@1 90.630 Prec@5 99.700 Error@1 9.370

==>>[2019-11-23 05:42:50] [Epoch=151/200] [Need: 00:17:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [151][000/391]   Time 0.253 (0.253)   Data 0.195 (0.195)   Loss 0.0688 (0.0688)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:42:51]
  Epoch: [151][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0243 (0.0594)   Prec@1 99.219 (97.997)   Prec@5 100.000 (99.977)   [2019-11-23 05:42:56]
  Epoch: [151][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0601 (0.0579)   Prec@1 98.438 (97.991)   Prec@5 100.000 (99.988)   [2019-11-23 05:43:01]
  Epoch: [151][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0149 (0.0596)   Prec@1 100.000 (97.963)   Prec@5 100.000 (99.990)   [2019-11-23 05:43:06]
  **Train** Prec@1 97.928 Prec@5 99.990 Error@1 2.072
  **Test** Prec@1 90.710 Prec@5 99.590 Error@1 9.290

==>>[2019-11-23 05:43:13] [Epoch=152/200] [Need: 00:17:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [152][000/391]   Time 0.242 (0.242)   Data 0.175 (0.175)   Loss 0.0881 (0.0881)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 05:43:13]
  Epoch: [152][100/391]   Time 0.075 (0.053)   Data 0.000 (0.002)   Loss 0.1244 (0.0636)   Prec@1 93.750 (97.803)   Prec@5 100.000 (99.985)   [2019-11-23 05:43:18]
  Epoch: [152][200/391]   Time 0.058 (0.050)   Data 0.000 (0.001)   Loss 0.0680 (0.0623)   Prec@1 96.094 (97.839)   Prec@5 100.000 (99.988)   [2019-11-23 05:43:23]
  Epoch: [152][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0991 (0.0614)   Prec@1 97.656 (97.877)   Prec@5 99.219 (99.990)   [2019-11-23 05:43:28]
  **Train** Prec@1 97.890 Prec@5 99.990 Error@1 2.110
  **Test** Prec@1 90.730 Prec@5 99.670 Error@1 9.270

==>>[2019-11-23 05:43:34] [Epoch=153/200] [Need: 00:17:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [153][000/391]   Time 0.235 (0.235)   Data 0.175 (0.175)   Loss 0.0534 (0.0534)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:43:35]
  Epoch: [153][100/391]   Time 0.074 (0.054)   Data 0.000 (0.002)   Loss 0.0229 (0.0551)   Prec@1 100.000 (98.097)   Prec@5 100.000 (99.985)   [2019-11-23 05:43:40]
  Epoch: [153][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0883 (0.0561)   Prec@1 96.875 (98.146)   Prec@5 100.000 (99.992)   [2019-11-23 05:43:45]
  Epoch: [153][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0320 (0.0578)   Prec@1 100.000 (98.056)   Prec@5 100.000 (99.992)   [2019-11-23 05:43:50]
  **Train** Prec@1 98.082 Prec@5 99.994 Error@1 1.918
  **Test** Prec@1 90.740 Prec@5 99.600 Error@1 9.260

==>>[2019-11-23 05:43:56] [Epoch=154/200] [Need: 00:16:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [154][000/391]   Time 0.251 (0.251)   Data 0.172 (0.172)   Loss 0.0240 (0.0240)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:43:57]
  Epoch: [154][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0799 (0.0550)   Prec@1 96.875 (98.136)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:02]
  Epoch: [154][200/391]   Time 0.057 (0.053)   Data 0.000 (0.001)   Loss 0.0368 (0.0562)   Prec@1 99.219 (98.165)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:07]
  Epoch: [154][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0722 (0.0572)   Prec@1 96.875 (98.048)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:12]
  **Train** Prec@1 98.052 Prec@5 99.996 Error@1 1.948
  **Test** Prec@1 90.890 Prec@5 99.630 Error@1 9.110

==>>[2019-11-23 05:44:18] [Epoch=155/200] [Need: 00:16:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [155][000/391]   Time 0.259 (0.259)   Data 0.194 (0.194)   Loss 0.0381 (0.0381)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:19]
  Epoch: [155][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0762 (0.0566)   Prec@1 96.875 (98.089)   Prec@5 100.000 (99.992)   [2019-11-23 05:44:24]
  Epoch: [155][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.0596 (0.0589)   Prec@1 97.656 (98.029)   Prec@5 100.000 (99.996)   [2019-11-23 05:44:29]
  Epoch: [155][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0378 (0.0594)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.992)   [2019-11-23 05:44:34]
  **Train** Prec@1 97.972 Prec@5 99.992 Error@1 2.028
  **Test** Prec@1 90.520 Prec@5 99.680 Error@1 9.480

==>>[2019-11-23 05:44:40] [Epoch=156/200] [Need: 00:16:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [156][000/391]   Time 0.234 (0.234)   Data 0.166 (0.166)   Loss 0.0265 (0.0265)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:41]
  Epoch: [156][100/391]   Time 0.051 (0.048)   Data 0.000 (0.002)   Loss 0.0754 (0.0544)   Prec@1 98.438 (98.198)   Prec@5 100.000 (100.000)   [2019-11-23 05:44:45]
  Epoch: [156][200/391]   Time 0.057 (0.050)   Data 0.000 (0.001)   Loss 0.0122 (0.0561)   Prec@1 100.000 (98.162)   Prec@5 100.000 (99.992)   [2019-11-23 05:44:50]
  Epoch: [156][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0462 (0.0568)   Prec@1 96.875 (98.121)   Prec@5 100.000 (99.992)   [2019-11-23 05:44:55]
  **Train** Prec@1 98.058 Prec@5 99.990 Error@1 1.942
  **Test** Prec@1 90.660 Prec@5 99.640 Error@1 9.340

==>>[2019-11-23 05:45:02] [Epoch=157/200] [Need: 00:15:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [157][000/391]   Time 0.260 (0.260)   Data 0.202 (0.202)   Loss 0.0540 (0.0540)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:45:02]
  Epoch: [157][100/391]   Time 0.047 (0.057)   Data 0.000 (0.002)   Loss 0.0278 (0.0557)   Prec@1 99.219 (98.004)   Prec@5 100.000 (100.000)   [2019-11-23 05:45:08]
  Epoch: [157][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0639 (0.0588)   Prec@1 96.875 (97.831)   Prec@5 100.000 (99.992)   [2019-11-23 05:45:13]
  Epoch: [157][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0521 (0.0583)   Prec@1 98.438 (97.885)   Prec@5 100.000 (99.995)   [2019-11-23 05:45:18]
  **Train** Prec@1 97.848 Prec@5 99.992 Error@1 2.152
  **Test** Prec@1 90.900 Prec@5 99.610 Error@1 9.100

==>>[2019-11-23 05:45:24] [Epoch=158/200] [Need: 00:15:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [158][000/391]   Time 0.245 (0.245)   Data 0.189 (0.189)   Loss 0.0882 (0.0882)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2019-11-23 05:45:25]
  Epoch: [158][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0938 (0.0594)   Prec@1 96.875 (97.966)   Prec@5 100.000 (99.969)   [2019-11-23 05:45:30]
  Epoch: [158][200/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0428 (0.0575)   Prec@1 99.219 (98.041)   Prec@5 100.000 (99.981)   [2019-11-23 05:45:35]
  Epoch: [158][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0880 (0.0582)   Prec@1 96.094 (97.988)   Prec@5 100.000 (99.984)   [2019-11-23 05:45:39]
  **Train** Prec@1 97.932 Prec@5 99.988 Error@1 2.068
  **Test** Prec@1 90.650 Prec@5 99.610 Error@1 9.350

==>>[2019-11-23 05:45:46] [Epoch=159/200] [Need: 00:14:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [159][000/391]   Time 0.247 (0.247)   Data 0.179 (0.179)   Loss 0.0734 (0.0734)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:45:46]
  Epoch: [159][100/391]   Time 0.066 (0.052)   Data 0.000 (0.002)   Loss 0.1193 (0.0573)   Prec@1 97.656 (98.012)   Prec@5 100.000 (100.000)   [2019-11-23 05:45:51]
  Epoch: [159][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0641 (0.0583)   Prec@1 97.656 (97.975)   Prec@5 100.000 (99.996)   [2019-11-23 05:45:56]
  Epoch: [159][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0203 (0.0582)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.995)   [2019-11-23 05:46:01]
  **Train** Prec@1 97.964 Prec@5 99.992 Error@1 2.036
  **Test** Prec@1 90.700 Prec@5 99.710 Error@1 9.300

==>>[2019-11-23 05:46:08] [Epoch=160/200] [Need: 00:14:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [160][000/391]   Time 0.261 (0.261)   Data 0.190 (0.190)   Loss 0.0486 (0.0486)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:46:08]
  Epoch: [160][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.0234 (0.0564)   Prec@1 99.219 (98.020)   Prec@5 100.000 (100.000)   [2019-11-23 05:46:13]
  Epoch: [160][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0660 (0.0554)   Prec@1 96.094 (98.072)   Prec@5 100.000 (99.992)   [2019-11-23 05:46:18]
  Epoch: [160][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0610 (0.0544)   Prec@1 98.438 (98.116)   Prec@5 100.000 (99.995)   [2019-11-23 05:46:24]
  **Train** Prec@1 98.056 Prec@5 99.992 Error@1 1.944
  **Test** Prec@1 90.690 Prec@5 99.720 Error@1 9.310

==>>[2019-11-23 05:46:30] [Epoch=161/200] [Need: 00:14:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [161][000/391]   Time 0.247 (0.247)   Data 0.189 (0.189)   Loss 0.0660 (0.0660)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:46:30]
  Epoch: [161][100/391]   Time 0.043 (0.058)   Data 0.000 (0.002)   Loss 0.0121 (0.0573)   Prec@1 100.000 (98.066)   Prec@5 100.000 (99.977)   [2019-11-23 05:46:36]
  Epoch: [161][200/391]   Time 0.040 (0.055)   Data 0.000 (0.001)   Loss 0.0210 (0.0555)   Prec@1 100.000 (98.138)   Prec@5 100.000 (99.988)   [2019-11-23 05:46:41]
  Epoch: [161][300/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.0577 (0.0559)   Prec@1 98.438 (98.105)   Prec@5 99.219 (99.990)   [2019-11-23 05:46:46]
  **Train** Prec@1 98.090 Prec@5 99.988 Error@1 1.910
  **Test** Prec@1 90.770 Prec@5 99.600 Error@1 9.230

==>>[2019-11-23 05:46:52] [Epoch=162/200] [Need: 00:13:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [162][000/391]   Time 0.248 (0.248)   Data 0.186 (0.186)   Loss 0.0411 (0.0411)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:46:52]
  Epoch: [162][100/391]   Time 0.058 (0.048)   Data 0.000 (0.002)   Loss 0.0514 (0.0605)   Prec@1 99.219 (97.958)   Prec@5 100.000 (100.000)   [2019-11-23 05:46:57]
  Epoch: [162][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0463 (0.0583)   Prec@1 98.438 (97.952)   Prec@5 100.000 (99.996)   [2019-11-23 05:47:02]
  Epoch: [162][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0339 (0.0560)   Prec@1 99.219 (98.048)   Prec@5 100.000 (99.995)   [2019-11-23 05:47:07]
  **Train** Prec@1 98.060 Prec@5 99.996 Error@1 1.940
  **Test** Prec@1 90.580 Prec@5 99.680 Error@1 9.420

==>>[2019-11-23 05:47:13] [Epoch=163/200] [Need: 00:13:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [163][000/391]   Time 0.255 (0.255)   Data 0.184 (0.184)   Loss 0.0909 (0.0909)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:47:14]
  Epoch: [163][100/391]   Time 0.082 (0.052)   Data 0.000 (0.002)   Loss 0.0793 (0.0551)   Prec@1 98.438 (98.120)   Prec@5 100.000 (99.992)   [2019-11-23 05:47:19]
  Epoch: [163][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0986 (0.0547)   Prec@1 96.875 (98.150)   Prec@5 100.000 (99.996)   [2019-11-23 05:47:24]
  Epoch: [163][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0591 (0.0544)   Prec@1 96.875 (98.178)   Prec@5 100.000 (99.997)   [2019-11-23 05:47:29]
  **Train** Prec@1 98.098 Prec@5 99.998 Error@1 1.902
  **Test** Prec@1 90.640 Prec@5 99.700 Error@1 9.360

==>>[2019-11-23 05:47:35] [Epoch=164/200] [Need: 00:13:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [164][000/391]   Time 0.255 (0.255)   Data 0.191 (0.191)   Loss 0.0683 (0.0683)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:47:35]
  Epoch: [164][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0603 (0.0594)   Prec@1 97.656 (97.857)   Prec@5 100.000 (99.992)   [2019-11-23 05:47:40]
  Epoch: [164][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0422 (0.0583)   Prec@1 97.656 (97.994)   Prec@5 100.000 (99.996)   [2019-11-23 05:47:45]
  Epoch: [164][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0413 (0.0562)   Prec@1 99.219 (98.105)   Prec@5 100.000 (99.995)   [2019-11-23 05:47:50]
  **Train** Prec@1 98.140 Prec@5 99.996 Error@1 1.860
  **Test** Prec@1 90.660 Prec@5 99.660 Error@1 9.340

==>>[2019-11-23 05:47:57] [Epoch=165/200] [Need: 00:12:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [165][000/391]   Time 0.252 (0.252)   Data 0.166 (0.166)   Loss 0.0426 (0.0426)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:47:57]
  Epoch: [165][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0623 (0.0550)   Prec@1 99.219 (98.151)   Prec@5 100.000 (99.992)   [2019-11-23 05:48:02]
  Epoch: [165][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0648 (0.0534)   Prec@1 98.438 (98.282)   Prec@5 100.000 (99.992)   [2019-11-23 05:48:07]
  Epoch: [165][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0787 (0.0535)   Prec@1 98.438 (98.258)   Prec@5 100.000 (99.992)   [2019-11-23 05:48:12]
  **Train** Prec@1 98.178 Prec@5 99.994 Error@1 1.822
  **Test** Prec@1 90.830 Prec@5 99.680 Error@1 9.170

==>>[2019-11-23 05:48:18] [Epoch=166/200] [Need: 00:12:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [166][000/391]   Time 0.269 (0.269)   Data 0.191 (0.191)   Loss 0.0186 (0.0186)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:48:18]
  Epoch: [166][100/391]   Time 0.068 (0.054)   Data 0.000 (0.002)   Loss 0.0259 (0.0522)   Prec@1 99.219 (98.136)   Prec@5 100.000 (100.000)   [2019-11-23 05:48:23]
  Epoch: [166][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0371 (0.0536)   Prec@1 98.438 (98.146)   Prec@5 100.000 (99.996)   [2019-11-23 05:48:28]
  Epoch: [166][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0183 (0.0538)   Prec@1 100.000 (98.152)   Prec@5 100.000 (99.995)   [2019-11-23 05:48:33]
  **Train** Prec@1 98.092 Prec@5 99.996 Error@1 1.908
  **Test** Prec@1 90.630 Prec@5 99.690 Error@1 9.370

==>>[2019-11-23 05:48:39] [Epoch=167/200] [Need: 00:11:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [167][000/391]   Time 0.256 (0.256)   Data 0.200 (0.200)   Loss 0.0493 (0.0493)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:48:40]
  Epoch: [167][100/391]   Time 0.051 (0.054)   Data 0.000 (0.002)   Loss 0.0543 (0.0513)   Prec@1 99.219 (98.383)   Prec@5 100.000 (100.000)   [2019-11-23 05:48:45]
  Epoch: [167][200/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.0638 (0.0525)   Prec@1 97.656 (98.274)   Prec@5 100.000 (99.996)   [2019-11-23 05:48:50]
  Epoch: [167][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0838 (0.0526)   Prec@1 98.438 (98.264)   Prec@5 100.000 (99.995)   [2019-11-23 05:48:55]
  **Train** Prec@1 98.244 Prec@5 99.996 Error@1 1.756
  **Test** Prec@1 90.690 Prec@5 99.650 Error@1 9.310

==>>[2019-11-23 05:49:01] [Epoch=168/200] [Need: 00:11:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [168][000/391]   Time 0.244 (0.244)   Data 0.191 (0.191)   Loss 0.0475 (0.0475)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:49:02]
  Epoch: [168][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.0707 (0.0504)   Prec@1 97.656 (98.298)   Prec@5 100.000 (100.000)   [2019-11-23 05:49:07]
  Epoch: [168][200/391]   Time 0.067 (0.052)   Data 0.000 (0.001)   Loss 0.0288 (0.0542)   Prec@1 99.219 (98.103)   Prec@5 100.000 (99.992)   [2019-11-23 05:49:12]
  Epoch: [168][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0414 (0.0539)   Prec@1 99.219 (98.147)   Prec@5 100.000 (99.995)   [2019-11-23 05:49:17]
  **Train** Prec@1 98.146 Prec@5 99.994 Error@1 1.854
  **Test** Prec@1 90.790 Prec@5 99.660 Error@1 9.210

==>>[2019-11-23 05:49:24] [Epoch=169/200] [Need: 00:11:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [169][000/391]   Time 0.252 (0.252)   Data 0.195 (0.195)   Loss 0.0622 (0.0622)   Prec@1 98.438 (98.438)   Prec@5 99.219 (99.219)   [2019-11-23 05:49:24]
  Epoch: [169][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0350 (0.0525)   Prec@1 97.656 (98.182)   Prec@5 100.000 (99.977)   [2019-11-23 05:49:29]
  Epoch: [169][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0815 (0.0527)   Prec@1 96.875 (98.138)   Prec@5 100.000 (99.984)   [2019-11-23 05:49:34]
  Epoch: [169][300/391]   Time 0.049 (0.049)   Data 0.000 (0.001)   Loss 0.0386 (0.0553)   Prec@1 97.656 (98.046)   Prec@5 100.000 (99.990)   [2019-11-23 05:49:39]
  **Train** Prec@1 98.040 Prec@5 99.992 Error@1 1.960
  **Test** Prec@1 90.680 Prec@5 99.680 Error@1 9.320

==>>[2019-11-23 05:49:45] [Epoch=170/200] [Need: 00:10:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [170][000/391]   Time 0.249 (0.249)   Data 0.178 (0.178)   Loss 0.0706 (0.0706)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:49:45]
  Epoch: [170][100/391]   Time 0.073 (0.055)   Data 0.000 (0.002)   Loss 0.0267 (0.0509)   Prec@1 99.219 (98.252)   Prec@5 100.000 (99.985)   [2019-11-23 05:49:51]
  Epoch: [170][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0523 (0.0526)   Prec@1 98.438 (98.162)   Prec@5 100.000 (99.992)   [2019-11-23 05:49:55]
  Epoch: [170][300/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.0519 (0.0531)   Prec@1 99.219 (98.165)   Prec@5 100.000 (99.992)   [2019-11-23 05:50:00]
  **Train** Prec@1 98.164 Prec@5 99.994 Error@1 1.836
  **Test** Prec@1 90.400 Prec@5 99.680 Error@1 9.600

==>>[2019-11-23 05:50:06] [Epoch=171/200] [Need: 00:10:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [171][000/391]   Time 0.261 (0.261)   Data 0.192 (0.192)   Loss 0.0134 (0.0134)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:07]
  Epoch: [171][100/391]   Time 0.056 (0.051)   Data 0.000 (0.002)   Loss 0.0703 (0.0525)   Prec@1 96.875 (98.213)   Prec@5 100.000 (99.992)   [2019-11-23 05:50:11]
  Epoch: [171][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0976 (0.0530)   Prec@1 96.875 (98.127)   Prec@5 100.000 (99.992)   [2019-11-23 05:50:16]
  Epoch: [171][300/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0378 (0.0531)   Prec@1 99.219 (98.131)   Prec@5 100.000 (99.995)   [2019-11-23 05:50:21]
  **Train** Prec@1 98.132 Prec@5 99.994 Error@1 1.868
  **Test** Prec@1 90.690 Prec@5 99.670 Error@1 9.310

==>>[2019-11-23 05:50:28] [Epoch=172/200] [Need: 00:10:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [172][000/391]   Time 0.242 (0.242)   Data 0.188 (0.188)   Loss 0.0619 (0.0619)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:28]
  Epoch: [172][100/391]   Time 0.043 (0.058)   Data 0.000 (0.002)   Loss 0.0376 (0.0564)   Prec@1 99.219 (98.020)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:34]
  Epoch: [172][200/391]   Time 0.047 (0.055)   Data 0.000 (0.001)   Loss 0.0706 (0.0545)   Prec@1 95.312 (98.127)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:39]
  Epoch: [172][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0646 (0.0545)   Prec@1 97.656 (98.173)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:44]
  **Train** Prec@1 98.192 Prec@5 100.000 Error@1 1.808
  **Test** Prec@1 90.850 Prec@5 99.640 Error@1 9.150

==>>[2019-11-23 05:50:51] [Epoch=173/200] [Need: 00:09:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [173][000/391]   Time 0.247 (0.247)   Data 0.175 (0.175)   Loss 0.0867 (0.0867)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:50:51]
  Epoch: [173][100/391]   Time 0.047 (0.052)   Data 0.000 (0.002)   Loss 0.0923 (0.0550)   Prec@1 95.312 (98.167)   Prec@5 100.000 (99.992)   [2019-11-23 05:50:56]
  Epoch: [173][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0206 (0.0542)   Prec@1 99.219 (98.173)   Prec@5 100.000 (99.988)   [2019-11-23 05:51:01]
  Epoch: [173][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0373 (0.0536)   Prec@1 98.438 (98.194)   Prec@5 100.000 (99.990)   [2019-11-23 05:51:06]
  **Train** Prec@1 98.186 Prec@5 99.992 Error@1 1.814
  **Test** Prec@1 90.690 Prec@5 99.710 Error@1 9.310

==>>[2019-11-23 05:51:13] [Epoch=174/200] [Need: 00:09:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [174][000/391]   Time 0.248 (0.248)   Data 0.184 (0.184)   Loss 0.0611 (0.0611)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:51:13]
  Epoch: [174][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0373 (0.0503)   Prec@1 99.219 (98.352)   Prec@5 100.000 (99.992)   [2019-11-23 05:51:18]
  Epoch: [174][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0610 (0.0515)   Prec@1 98.438 (98.313)   Prec@5 100.000 (99.984)   [2019-11-23 05:51:23]
  Epoch: [174][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0196 (0.0517)   Prec@1 100.000 (98.282)   Prec@5 100.000 (99.984)   [2019-11-23 05:51:28]
  **Train** Prec@1 98.296 Prec@5 99.984 Error@1 1.704
  **Test** Prec@1 90.670 Prec@5 99.620 Error@1 9.330

==>>[2019-11-23 05:51:35] [Epoch=175/200] [Need: 00:09:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [175][000/391]   Time 0.242 (0.242)   Data 0.173 (0.173)   Loss 0.0517 (0.0517)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:51:35]
  Epoch: [175][100/391]   Time 0.080 (0.053)   Data 0.000 (0.002)   Loss 0.0539 (0.0522)   Prec@1 97.656 (98.267)   Prec@5 100.000 (99.977)   [2019-11-23 05:51:40]
  Epoch: [175][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0464 (0.0542)   Prec@1 96.875 (98.123)   Prec@5 100.000 (99.981)   [2019-11-23 05:51:45]
  Epoch: [175][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.1026 (0.0544)   Prec@1 96.094 (98.118)   Prec@5 100.000 (99.984)   [2019-11-23 05:51:50]
  **Train** Prec@1 98.136 Prec@5 99.988 Error@1 1.864
  **Test** Prec@1 90.710 Prec@5 99.710 Error@1 9.290

==>>[2019-11-23 05:51:56] [Epoch=176/200] [Need: 00:08:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [176][000/391]   Time 0.242 (0.242)   Data 0.176 (0.176)   Loss 0.0625 (0.0625)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:51:57]
  Epoch: [176][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.0404 (0.0511)   Prec@1 100.000 (98.105)   Prec@5 100.000 (100.000)   [2019-11-23 05:52:02]
  Epoch: [176][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0538 (0.0534)   Prec@1 99.219 (98.084)   Prec@5 100.000 (100.000)   [2019-11-23 05:52:07]
  Epoch: [176][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0504 (0.0542)   Prec@1 98.438 (98.082)   Prec@5 100.000 (99.995)   [2019-11-23 05:52:12]
  **Train** Prec@1 98.086 Prec@5 99.996 Error@1 1.914
  **Test** Prec@1 90.640 Prec@5 99.710 Error@1 9.360

==>>[2019-11-23 05:52:18] [Epoch=177/200] [Need: 00:08:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [177][000/391]   Time 0.251 (0.251)   Data 0.184 (0.184)   Loss 0.0450 (0.0450)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:52:18]
  Epoch: [177][100/391]   Time 0.067 (0.055)   Data 0.000 (0.002)   Loss 0.0358 (0.0508)   Prec@1 99.219 (98.167)   Prec@5 100.000 (99.992)   [2019-11-23 05:52:24]
  Epoch: [177][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0452 (0.0510)   Prec@1 98.438 (98.162)   Prec@5 100.000 (99.992)   [2019-11-23 05:52:29]
  Epoch: [177][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0706 (0.0515)   Prec@1 96.094 (98.087)   Prec@5 100.000 (99.992)   [2019-11-23 05:52:34]
  **Train** Prec@1 98.042 Prec@5 99.992 Error@1 1.958
  **Test** Prec@1 90.420 Prec@5 99.530 Error@1 9.580

==>>[2019-11-23 05:52:40] [Epoch=178/200] [Need: 00:08:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [178][000/391]   Time 0.285 (0.285)   Data 0.207 (0.207)   Loss 0.0476 (0.0476)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:52:41]
  Epoch: [178][100/391]   Time 0.075 (0.053)   Data 0.000 (0.002)   Loss 0.0463 (0.0547)   Prec@1 98.438 (98.113)   Prec@5 100.000 (99.992)   [2019-11-23 05:52:46]
  Epoch: [178][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0270 (0.0539)   Prec@1 99.219 (98.154)   Prec@5 100.000 (99.996)   [2019-11-23 05:52:51]
  Epoch: [178][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0281 (0.0537)   Prec@1 99.219 (98.121)   Prec@5 100.000 (99.997)   [2019-11-23 05:52:56]
  **Train** Prec@1 98.102 Prec@5 99.998 Error@1 1.898
  **Test** Prec@1 90.750 Prec@5 99.610 Error@1 9.250

==>>[2019-11-23 05:53:03] [Epoch=179/200] [Need: 00:07:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [179][000/391]   Time 0.241 (0.241)   Data 0.175 (0.175)   Loss 0.0361 (0.0361)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:53:03]
  Epoch: [179][100/391]   Time 0.070 (0.051)   Data 0.000 (0.002)   Loss 0.0324 (0.0564)   Prec@1 99.219 (98.058)   Prec@5 100.000 (99.992)   [2019-11-23 05:53:08]
  Epoch: [179][200/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.0426 (0.0532)   Prec@1 98.438 (98.212)   Prec@5 100.000 (99.992)   [2019-11-23 05:53:12]
  Epoch: [179][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.0818 (0.0539)   Prec@1 97.656 (98.196)   Prec@5 100.000 (99.992)   [2019-11-23 05:53:18]
  **Train** Prec@1 98.170 Prec@5 99.990 Error@1 1.830
  **Test** Prec@1 90.700 Prec@5 99.660 Error@1 9.300

==>>[2019-11-23 05:53:24] [Epoch=180/200] [Need: 00:07:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [180][000/391]   Time 0.256 (0.256)   Data 0.201 (0.201)   Loss 0.0234 (0.0234)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:53:24]
  Epoch: [180][100/391]   Time 0.077 (0.055)   Data 0.000 (0.002)   Loss 0.0268 (0.0534)   Prec@1 99.219 (98.144)   Prec@5 100.000 (99.985)   [2019-11-23 05:53:29]
  Epoch: [180][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0208 (0.0553)   Prec@1 99.219 (98.080)   Prec@5 100.000 (99.973)   [2019-11-23 05:53:34]
  Epoch: [180][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0284 (0.0562)   Prec@1 99.219 (98.046)   Prec@5 100.000 (99.979)   [2019-11-23 05:53:39]
  **Train** Prec@1 98.016 Prec@5 99.984 Error@1 1.984
  **Test** Prec@1 90.780 Prec@5 99.660 Error@1 9.220

==>>[2019-11-23 05:53:46] [Epoch=181/200] [Need: 00:06:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [181][000/391]   Time 0.244 (0.244)   Data 0.181 (0.181)   Loss 0.0409 (0.0409)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:53:46]
  Epoch: [181][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.0256 (0.0533)   Prec@1 99.219 (98.151)   Prec@5 100.000 (99.992)   [2019-11-23 05:53:51]
  Epoch: [181][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0244 (0.0542)   Prec@1 99.219 (98.165)   Prec@5 100.000 (99.996)   [2019-11-23 05:53:56]
  Epoch: [181][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0266 (0.0537)   Prec@1 100.000 (98.186)   Prec@5 100.000 (99.997)   [2019-11-23 05:54:01]
  **Train** Prec@1 98.144 Prec@5 99.994 Error@1 1.856
  **Test** Prec@1 90.630 Prec@5 99.690 Error@1 9.370

==>>[2019-11-23 05:54:08] [Epoch=182/200] [Need: 00:06:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [182][000/391]   Time 0.248 (0.248)   Data 0.185 (0.185)   Loss 0.0774 (0.0774)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:54:08]
  Epoch: [182][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.0647 (0.0522)   Prec@1 98.438 (98.182)   Prec@5 100.000 (99.985)   [2019-11-23 05:54:13]
  Epoch: [182][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0127 (0.0525)   Prec@1 100.000 (98.204)   Prec@5 100.000 (99.984)   [2019-11-23 05:54:18]
  Epoch: [182][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0621 (0.0529)   Prec@1 97.656 (98.199)   Prec@5 100.000 (99.990)   [2019-11-23 05:54:23]
  **Train** Prec@1 98.184 Prec@5 99.988 Error@1 1.816
  **Test** Prec@1 90.630 Prec@5 99.630 Error@1 9.370

==>>[2019-11-23 05:54:29] [Epoch=183/200] [Need: 00:06:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [183][000/391]   Time 0.256 (0.256)   Data 0.195 (0.195)   Loss 0.0281 (0.0281)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:54:29]
  Epoch: [183][100/391]   Time 0.072 (0.056)   Data 0.000 (0.002)   Loss 0.0470 (0.0508)   Prec@1 98.438 (98.376)   Prec@5 100.000 (100.000)   [2019-11-23 05:54:35]
  Epoch: [183][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0216 (0.0531)   Prec@1 99.219 (98.286)   Prec@5 100.000 (99.996)   [2019-11-23 05:54:40]
  Epoch: [183][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0277 (0.0526)   Prec@1 100.000 (98.313)   Prec@5 100.000 (99.992)   [2019-11-23 05:54:45]
  **Train** Prec@1 98.314 Prec@5 99.994 Error@1 1.686
  **Test** Prec@1 90.520 Prec@5 99.730 Error@1 9.480

==>>[2019-11-23 05:54:51] [Epoch=184/200] [Need: 00:05:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [184][000/391]   Time 0.266 (0.266)   Data 0.204 (0.204)   Loss 0.0454 (0.0454)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:54:51]
  Epoch: [184][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.0769 (0.0526)   Prec@1 96.875 (98.213)   Prec@5 100.000 (99.977)   [2019-11-23 05:54:56]
  Epoch: [184][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0538 (0.0520)   Prec@1 97.656 (98.231)   Prec@5 100.000 (99.984)   [2019-11-23 05:55:01]
  Epoch: [184][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0231 (0.0516)   Prec@1 100.000 (98.258)   Prec@5 100.000 (99.987)   [2019-11-23 05:55:06]
  **Train** Prec@1 98.242 Prec@5 99.986 Error@1 1.758
  **Test** Prec@1 90.640 Prec@5 99.660 Error@1 9.360

==>>[2019-11-23 05:55:13] [Epoch=185/200] [Need: 00:05:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [185][000/391]   Time 0.252 (0.252)   Data 0.188 (0.188)   Loss 0.0526 (0.0526)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:55:13]
  Epoch: [185][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0490 (0.0553)   Prec@1 97.656 (98.097)   Prec@5 100.000 (100.000)   [2019-11-23 05:55:18]
  Epoch: [185][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0680 (0.0568)   Prec@1 97.656 (98.002)   Prec@5 100.000 (99.996)   [2019-11-23 05:55:23]
  Epoch: [185][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0431 (0.0546)   Prec@1 99.219 (98.097)   Prec@5 100.000 (99.997)   [2019-11-23 05:55:28]
  **Train** Prec@1 98.114 Prec@5 99.996 Error@1 1.886
  **Test** Prec@1 90.590 Prec@5 99.640 Error@1 9.410

==>>[2019-11-23 05:55:34] [Epoch=186/200] [Need: 00:05:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [186][000/391]   Time 0.253 (0.253)   Data 0.187 (0.187)   Loss 0.0352 (0.0352)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:55:35]
  Epoch: [186][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0468 (0.0482)   Prec@1 98.438 (98.244)   Prec@5 100.000 (99.992)   [2019-11-23 05:55:40]
  Epoch: [186][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0260 (0.0527)   Prec@1 99.219 (98.181)   Prec@5 100.000 (99.992)   [2019-11-23 05:55:45]
  Epoch: [186][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0710 (0.0514)   Prec@1 96.875 (98.238)   Prec@5 100.000 (99.995)   [2019-11-23 05:55:50]
  **Train** Prec@1 98.246 Prec@5 99.996 Error@1 1.754
  **Test** Prec@1 90.540 Prec@5 99.650 Error@1 9.460

==>>[2019-11-23 05:55:56] [Epoch=187/200] [Need: 00:04:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [187][000/391]   Time 0.255 (0.255)   Data 0.179 (0.179)   Loss 0.0414 (0.0414)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:55:56]
  Epoch: [187][100/391]   Time 0.052 (0.050)   Data 0.000 (0.002)   Loss 0.0711 (0.0477)   Prec@1 96.875 (98.430)   Prec@5 100.000 (100.000)   [2019-11-23 05:56:01]
  Epoch: [187][200/391]   Time 0.059 (0.050)   Data 0.000 (0.001)   Loss 0.0130 (0.0503)   Prec@1 100.000 (98.325)   Prec@5 100.000 (100.000)   [2019-11-23 05:56:06]
  Epoch: [187][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0455 (0.0511)   Prec@1 99.219 (98.261)   Prec@5 100.000 (100.000)   [2019-11-23 05:56:11]
  **Train** Prec@1 98.284 Prec@5 100.000 Error@1 1.716
  **Test** Prec@1 90.530 Prec@5 99.680 Error@1 9.470

==>>[2019-11-23 05:56:17] [Epoch=188/200] [Need: 00:04:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [188][000/391]   Time 0.275 (0.275)   Data 0.210 (0.210)   Loss 0.0800 (0.0800)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:56:18]
  Epoch: [188][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0370 (0.0538)   Prec@1 99.219 (98.167)   Prec@5 100.000 (99.977)   [2019-11-23 05:56:23]
  Epoch: [188][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0165 (0.0523)   Prec@1 100.000 (98.208)   Prec@5 100.000 (99.984)   [2019-11-23 05:56:28]
  Epoch: [188][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0456 (0.0517)   Prec@1 98.438 (98.271)   Prec@5 100.000 (99.990)   [2019-11-23 05:56:32]
  **Train** Prec@1 98.190 Prec@5 99.992 Error@1 1.810
  **Test** Prec@1 90.540 Prec@5 99.660 Error@1 9.460

==>>[2019-11-23 05:56:39] [Epoch=189/200] [Need: 00:03:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [189][000/391]   Time 0.255 (0.255)   Data 0.190 (0.190)   Loss 0.0634 (0.0634)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:56:39]
  Epoch: [189][100/391]   Time 0.043 (0.058)   Data 0.000 (0.002)   Loss 0.0537 (0.0499)   Prec@1 99.219 (98.213)   Prec@5 100.000 (99.992)   [2019-11-23 05:56:44]
  Epoch: [189][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0343 (0.0520)   Prec@1 99.219 (98.130)   Prec@5 100.000 (99.996)   [2019-11-23 05:56:49]
  Epoch: [189][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0548 (0.0523)   Prec@1 98.438 (98.134)   Prec@5 100.000 (99.997)   [2019-11-23 05:56:54]
  **Train** Prec@1 98.180 Prec@5 99.996 Error@1 1.820
  **Test** Prec@1 90.680 Prec@5 99.640 Error@1 9.320

==>>[2019-11-23 05:57:01] [Epoch=190/200] [Need: 00:03:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [190][000/391]   Time 0.250 (0.250)   Data 0.171 (0.171)   Loss 0.0374 (0.0374)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:57:01]
  Epoch: [190][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0216 (0.0535)   Prec@1 100.000 (98.035)   Prec@5 100.000 (99.992)   [2019-11-23 05:57:06]
  Epoch: [190][200/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0874 (0.0538)   Prec@1 96.094 (98.099)   Prec@5 100.000 (99.988)   [2019-11-23 05:57:11]
  Epoch: [190][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0540 (0.0541)   Prec@1 98.438 (98.072)   Prec@5 100.000 (99.990)   [2019-11-23 05:57:16]
  **Train** Prec@1 98.068 Prec@5 99.990 Error@1 1.932
  **Test** Prec@1 90.470 Prec@5 99.670 Error@1 9.530

==>>[2019-11-23 05:57:22] [Epoch=191/200] [Need: 00:03:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [191][000/391]   Time 0.242 (0.242)   Data 0.183 (0.183)   Loss 0.0731 (0.0731)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 05:57:22]
  Epoch: [191][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.0516 (0.0505)   Prec@1 97.656 (98.283)   Prec@5 100.000 (100.000)   [2019-11-23 05:57:27]
  Epoch: [191][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0309 (0.0509)   Prec@1 98.438 (98.228)   Prec@5 100.000 (99.996)   [2019-11-23 05:57:32]
  Epoch: [191][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0243 (0.0507)   Prec@1 100.000 (98.261)   Prec@5 100.000 (99.997)   [2019-11-23 05:57:37]
  **Train** Prec@1 98.206 Prec@5 99.990 Error@1 1.794
  **Test** Prec@1 90.660 Prec@5 99.630 Error@1 9.340

==>>[2019-11-23 05:57:43] [Epoch=192/200] [Need: 00:02:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [192][000/391]   Time 0.243 (0.243)   Data 0.183 (0.183)   Loss 0.0162 (0.0162)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 05:57:44]
  Epoch: [192][100/391]   Time 0.056 (0.054)   Data 0.000 (0.002)   Loss 0.0252 (0.0527)   Prec@1 99.219 (98.306)   Prec@5 100.000 (99.985)   [2019-11-23 05:57:49]
  Epoch: [192][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0577 (0.0527)   Prec@1 96.875 (98.239)   Prec@5 100.000 (99.988)   [2019-11-23 05:57:54]
  Epoch: [192][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0952 (0.0526)   Prec@1 96.094 (98.199)   Prec@5 100.000 (99.992)   [2019-11-23 05:57:59]
  **Train** Prec@1 98.198 Prec@5 99.990 Error@1 1.802
  **Test** Prec@1 90.480 Prec@5 99.650 Error@1 9.520

==>>[2019-11-23 05:58:05] [Epoch=193/200] [Need: 00:02:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [193][000/391]   Time 0.259 (0.259)   Data 0.174 (0.174)   Loss 0.0369 (0.0369)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:05]
  Epoch: [193][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.1062 (0.0525)   Prec@1 96.094 (98.066)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:11]
  Epoch: [193][200/391]   Time 0.064 (0.053)   Data 0.000 (0.001)   Loss 0.0317 (0.0516)   Prec@1 98.438 (98.088)   Prec@5 100.000 (99.996)   [2019-11-23 05:58:16]
  Epoch: [193][300/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.0870 (0.0517)   Prec@1 97.656 (98.129)   Prec@5 100.000 (99.995)   [2019-11-23 05:58:21]
  **Train** Prec@1 98.132 Prec@5 99.994 Error@1 1.868
  **Test** Prec@1 90.580 Prec@5 99.660 Error@1 9.420

==>>[2019-11-23 05:58:28] [Epoch=194/200] [Need: 00:02:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [194][000/391]   Time 0.250 (0.250)   Data 0.192 (0.192)   Loss 0.0475 (0.0475)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:28]
  Epoch: [194][100/391]   Time 0.076 (0.052)   Data 0.002 (0.002)   Loss 0.0412 (0.0491)   Prec@1 99.219 (98.252)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:33]
  Epoch: [194][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0227 (0.0498)   Prec@1 100.000 (98.298)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:38]
  Epoch: [194][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0633 (0.0494)   Prec@1 97.656 (98.370)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:43]
  **Train** Prec@1 98.308 Prec@5 99.998 Error@1 1.692
  **Test** Prec@1 90.680 Prec@5 99.650 Error@1 9.320

==>>[2019-11-23 05:58:49] [Epoch=195/200] [Need: 00:01:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [195][000/391]   Time 0.277 (0.277)   Data 0.212 (0.212)   Loss 0.0689 (0.0689)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:49]
  Epoch: [195][100/391]   Time 0.060 (0.056)   Data 0.000 (0.002)   Loss 0.0891 (0.0516)   Prec@1 96.094 (98.205)   Prec@5 100.000 (100.000)   [2019-11-23 05:58:55]
  Epoch: [195][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0266 (0.0518)   Prec@1 99.219 (98.197)   Prec@5 100.000 (100.000)   [2019-11-23 05:59:00]
  Epoch: [195][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0442 (0.0511)   Prec@1 99.219 (98.266)   Prec@5 100.000 (100.000)   [2019-11-23 05:59:05]
  **Train** Prec@1 98.280 Prec@5 100.000 Error@1 1.720
  **Test** Prec@1 90.480 Prec@5 99.670 Error@1 9.520

==>>[2019-11-23 05:59:12] [Epoch=196/200] [Need: 00:01:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [196][000/391]   Time 0.248 (0.248)   Data 0.174 (0.174)   Loss 0.0471 (0.0471)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 05:59:12]
  Epoch: [196][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.0355 (0.0514)   Prec@1 98.438 (98.182)   Prec@5 100.000 (99.992)   [2019-11-23 05:59:17]
  Epoch: [196][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0571 (0.0505)   Prec@1 98.438 (98.220)   Prec@5 100.000 (99.996)   [2019-11-23 05:59:22]
  Epoch: [196][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0580 (0.0508)   Prec@1 97.656 (98.232)   Prec@5 100.000 (99.995)   [2019-11-23 05:59:27]
  **Train** Prec@1 98.232 Prec@5 99.994 Error@1 1.768
  **Test** Prec@1 90.590 Prec@5 99.720 Error@1 9.410

==>>[2019-11-23 05:59:33] [Epoch=197/200] [Need: 00:01:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [197][000/391]   Time 0.253 (0.253)   Data 0.203 (0.203)   Loss 0.0366 (0.0366)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 05:59:34]
  Epoch: [197][100/391]   Time 0.056 (0.055)   Data 0.000 (0.002)   Loss 0.0135 (0.0520)   Prec@1 100.000 (98.120)   Prec@5 100.000 (99.992)   [2019-11-23 05:59:39]
  Epoch: [197][200/391]   Time 0.073 (0.054)   Data 0.000 (0.001)   Loss 0.0732 (0.0505)   Prec@1 96.094 (98.259)   Prec@5 100.000 (99.992)   [2019-11-23 05:59:44]
  Epoch: [197][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0378 (0.0510)   Prec@1 98.438 (98.264)   Prec@5 100.000 (99.992)   [2019-11-23 05:59:49]
  **Train** Prec@1 98.194 Prec@5 99.994 Error@1 1.806
  **Test** Prec@1 90.640 Prec@5 99.620 Error@1 9.360

==>>[2019-11-23 05:59:55] [Epoch=198/200] [Need: 00:00:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [198][000/391]   Time 0.260 (0.260)   Data 0.176 (0.176)   Loss 0.0788 (0.0788)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 05:59:55]
  Epoch: [198][100/391]   Time 0.043 (0.057)   Data 0.000 (0.002)   Loss 0.0839 (0.0495)   Prec@1 96.875 (98.329)   Prec@5 100.000 (100.000)   [2019-11-23 06:00:01]
  Epoch: [198][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.0731 (0.0506)   Prec@1 97.656 (98.247)   Prec@5 100.000 (100.000)   [2019-11-23 06:00:06]
  Epoch: [198][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0759 (0.0502)   Prec@1 98.438 (98.271)   Prec@5 100.000 (100.000)   [2019-11-23 06:00:11]
  **Train** Prec@1 98.272 Prec@5 99.998 Error@1 1.728
  **Test** Prec@1 90.470 Prec@5 99.670 Error@1 9.530

==>>[2019-11-23 06:00:17] [Epoch=199/200] [Need: 00:00:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.99, Error=9.01]
  Epoch: [199][000/391]   Time 0.250 (0.250)   Data 0.180 (0.180)   Loss 0.0267 (0.0267)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 06:00:18]
  Epoch: [199][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0366 (0.0528)   Prec@1 99.219 (98.105)   Prec@5 100.000 (99.992)   [2019-11-23 06:00:23]
  Epoch: [199][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0221 (0.0521)   Prec@1 100.000 (98.208)   Prec@5 100.000 (99.992)   [2019-11-23 06:00:28]
  Epoch: [199][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0835 (0.0522)   Prec@1 96.875 (98.183)   Prec@5 100.000 (99.995)   [2019-11-23 06:00:32]
  **Train** Prec@1 98.252 Prec@5 99.996 Error@1 1.748
  **Test** Prec@1 90.590 Prec@5 99.670 Error@1 9.410
