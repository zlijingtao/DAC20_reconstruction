save path : ./save/2019-11-22/cifar10_quan_resnet20_200_i2r2o2_adam0.85_3bit
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.85, 'input_grain_size': [1, 2], 'input_num_bits': 3, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.85, 'output_grain_size': [1, 2], 'output_num_bits': 3, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.85, 'res_grain_size': [1, 2], 'res_num_bits': 3, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-22/cifar10_quan_resnet20_200_i2r2o2_adam0.85_3bit', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-23 10:55:53] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.633 (1.633)   Data 0.149 (0.149)   Loss 4.1073 (4.1073)   Prec@1 10.156 (10.156)   Prec@5 47.656 (47.656)   [2019-11-23 10:55:54]
  Epoch: [000][100/391]   Time 0.052 (0.067)   Data 0.000 (0.002)   Loss 1.7630 (2.0527)   Prec@1 33.594 (25.371)   Prec@5 85.156 (78.434)   [2019-11-23 10:55:59]
  Epoch: [000][200/391]   Time 0.051 (0.058)   Data 0.000 (0.001)   Loss 1.6332 (1.8823)   Prec@1 41.406 (30.636)   Prec@5 89.844 (83.205)   [2019-11-23 10:56:04]
  Epoch: [000][300/391]   Time 0.055 (0.056)   Data 0.000 (0.001)   Loss 1.4482 (1.7611)   Prec@1 43.750 (35.037)   Prec@5 92.188 (85.901)   [2019-11-23 10:56:09]
  **Train** Prec@1 38.336 Prec@5 87.620 Error@1 61.664
  **Test** Prec@1 51.730 Prec@5 94.360 Error@1 48.270
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:56:16] [Epoch=001/200] [Need: 01:17:22] [LR=0.0100][M=0.90] [Best : Accuracy=51.73, Error=48.27]
  Epoch: [001][000/391]   Time 0.255 (0.255)   Data 0.180 (0.180)   Loss 1.3142 (1.3142)   Prec@1 48.438 (48.438)   Prec@5 95.312 (95.312)   [2019-11-23 10:56:16]
  Epoch: [001][100/391]   Time 0.057 (0.049)   Data 0.000 (0.002)   Loss 1.2739 (1.2513)   Prec@1 57.031 (54.440)   Prec@5 96.094 (94.910)   [2019-11-23 10:56:21]
  Epoch: [001][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 1.1677 (1.1921)   Prec@1 53.906 (56.911)   Prec@5 95.312 (95.421)   [2019-11-23 10:56:26]
  Epoch: [001][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.9947 (1.1550)   Prec@1 66.406 (58.511)   Prec@5 96.094 (95.655)   [2019-11-23 10:56:31]
  **Train** Prec@1 59.848 Prec@5 95.878 Error@1 40.152
  **Test** Prec@1 56.480 Prec@5 95.480 Error@1 43.520
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:56:37] [Epoch=002/200] [Need: 01:13:36] [LR=0.0100][M=0.90] [Best : Accuracy=56.48, Error=43.52]
  Epoch: [002][000/391]   Time 0.252 (0.252)   Data 0.190 (0.190)   Loss 0.9809 (0.9809)   Prec@1 67.969 (67.969)   Prec@5 95.312 (95.312)   [2019-11-23 10:56:38]
  Epoch: [002][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 1.0196 (0.9548)   Prec@1 61.719 (66.097)   Prec@5 96.094 (97.107)   [2019-11-23 10:56:43]
  Epoch: [002][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 1.1086 (0.9207)   Prec@1 57.812 (67.378)   Prec@5 96.875 (97.446)   [2019-11-23 10:56:48]
  Epoch: [002][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.8449 (0.9028)   Prec@1 71.875 (68.034)   Prec@5 96.094 (97.537)   [2019-11-23 10:56:53]
  **Train** Prec@1 68.472 Prec@5 97.602 Error@1 31.528
  **Test** Prec@1 67.070 Prec@5 97.180 Error@1 32.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:57:00] [Epoch=003/200] [Need: 01:13:33] [LR=0.0100][M=0.90] [Best : Accuracy=67.07, Error=32.93]
  Epoch: [003][000/391]   Time 0.245 (0.245)   Data 0.185 (0.185)   Loss 1.0364 (1.0364)   Prec@1 64.844 (64.844)   Prec@5 94.531 (94.531)   [2019-11-23 10:57:00]
  Epoch: [003][100/391]   Time 0.036 (0.053)   Data 0.000 (0.002)   Loss 0.7268 (0.8047)   Prec@1 77.344 (71.945)   Prec@5 98.438 (97.950)   [2019-11-23 10:57:05]
  Epoch: [003][200/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.7838 (0.7935)   Prec@1 71.875 (72.427)   Prec@5 98.438 (98.029)   [2019-11-23 10:57:10]
  Epoch: [003][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.6421 (0.7908)   Prec@1 78.125 (72.532)   Prec@5 98.438 (98.014)   [2019-11-23 10:57:15]
  **Train** Prec@1 72.888 Prec@5 98.090 Error@1 27.112
  **Test** Prec@1 67.930 Prec@5 96.850 Error@1 32.070
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:57:22] [Epoch=004/200] [Need: 01:12:37] [LR=0.0100][M=0.90] [Best : Accuracy=67.93, Error=32.07]
  Epoch: [004][000/391]   Time 0.266 (0.266)   Data 0.202 (0.202)   Loss 0.6921 (0.6921)   Prec@1 78.125 (78.125)   Prec@5 99.219 (99.219)   [2019-11-23 10:57:22]
  Epoch: [004][100/391]   Time 0.058 (0.054)   Data 0.000 (0.002)   Loss 0.6077 (0.7382)   Prec@1 79.688 (74.366)   Prec@5 98.438 (98.144)   [2019-11-23 10:57:27]
  Epoch: [004][200/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.5744 (0.7266)   Prec@1 79.688 (75.023)   Prec@5 99.219 (98.259)   [2019-11-23 10:57:32]
  Epoch: [004][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.6412 (0.7171)   Prec@1 75.781 (75.335)   Prec@5 100.000 (98.417)   [2019-11-23 10:57:37]
  **Train** Prec@1 75.718 Prec@5 98.490 Error@1 24.282
  **Test** Prec@1 68.050 Prec@5 96.330 Error@1 31.950
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:57:44] [Epoch=005/200] [Need: 01:12:11] [LR=0.0100][M=0.90] [Best : Accuracy=68.05, Error=31.95]
  Epoch: [005][000/391]   Time 0.267 (0.267)   Data 0.206 (0.206)   Loss 0.5961 (0.5961)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-23 10:57:44]
  Epoch: [005][100/391]   Time 0.048 (0.055)   Data 0.000 (0.002)   Loss 0.5451 (0.6784)   Prec@1 82.031 (76.423)   Prec@5 98.438 (98.608)   [2019-11-23 10:57:50]
  Epoch: [005][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.7284 (0.6773)   Prec@1 77.344 (76.458)   Prec@5 97.656 (98.539)   [2019-11-23 10:57:55]
  Epoch: [005][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.6597 (0.6673)   Prec@1 82.031 (76.960)   Prec@5 96.875 (98.528)   [2019-11-23 10:58:00]
  **Train** Prec@1 77.376 Prec@5 98.554 Error@1 22.624
  **Test** Prec@1 71.270 Prec@5 97.010 Error@1 28.730
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:58:06] [Epoch=006/200] [Need: 01:11:57] [LR=0.0100][M=0.90] [Best : Accuracy=71.27, Error=28.73]
  Epoch: [006][000/391]   Time 0.256 (0.256)   Data 0.186 (0.186)   Loss 0.6363 (0.6363)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-23 10:58:07]
  Epoch: [006][100/391]   Time 0.071 (0.054)   Data 0.000 (0.002)   Loss 0.6567 (0.6328)   Prec@1 78.125 (78.481)   Prec@5 98.438 (98.639)   [2019-11-23 10:58:12]
  Epoch: [006][200/391]   Time 0.080 (0.054)   Data 0.000 (0.001)   Loss 0.7665 (0.6264)   Prec@1 70.312 (78.428)   Prec@5 99.219 (98.713)   [2019-11-23 10:58:17]
  Epoch: [006][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.5781 (0.6253)   Prec@1 78.125 (78.325)   Prec@5 98.438 (98.754)   [2019-11-23 10:58:22]
  **Train** Prec@1 78.410 Prec@5 98.768 Error@1 21.590
  **Test** Prec@1 75.520 Prec@5 98.490 Error@1 24.480
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:58:29] [Epoch=007/200] [Need: 01:11:35] [LR=0.0100][M=0.90] [Best : Accuracy=75.52, Error=24.48]
  Epoch: [007][000/391]   Time 0.268 (0.268)   Data 0.186 (0.186)   Loss 0.7302 (0.7302)   Prec@1 75.781 (75.781)   Prec@5 95.312 (95.312)   [2019-11-23 10:58:29]
  Epoch: [007][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.7333 (0.5948)   Prec@1 76.562 (79.657)   Prec@5 98.438 (98.855)   [2019-11-23 10:58:34]
  Epoch: [007][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.7145 (0.5873)   Prec@1 75.000 (79.792)   Prec@5 98.438 (98.884)   [2019-11-23 10:58:39]
  Epoch: [007][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.6040 (0.5890)   Prec@1 78.125 (79.812)   Prec@5 98.438 (98.842)   [2019-11-23 10:58:44]
  **Train** Prec@1 79.716 Prec@5 98.840 Error@1 20.284
  **Test** Prec@1 73.210 Prec@5 98.530 Error@1 26.790

==>>[2019-11-23 10:58:51] [Epoch=008/200] [Need: 01:11:17] [LR=0.0100][M=0.90] [Best : Accuracy=75.52, Error=24.48]
  Epoch: [008][000/391]   Time 0.271 (0.271)   Data 0.189 (0.189)   Loss 0.6384 (0.6384)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-23 10:58:51]
  Epoch: [008][100/391]   Time 0.040 (0.051)   Data 0.000 (0.002)   Loss 0.5384 (0.5826)   Prec@1 86.719 (80.144)   Prec@5 99.219 (98.987)   [2019-11-23 10:58:56]
  Epoch: [008][200/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.5689 (0.5790)   Prec@1 75.781 (80.107)   Prec@5 98.438 (98.954)   [2019-11-23 10:59:01]
  Epoch: [008][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.6733 (0.5750)   Prec@1 75.781 (80.230)   Prec@5 99.219 (98.959)   [2019-11-23 10:59:06]
  **Train** Prec@1 80.346 Prec@5 98.948 Error@1 19.654
  **Test** Prec@1 77.110 Prec@5 98.790 Error@1 22.890
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 10:59:13] [Epoch=009/200] [Need: 01:10:40] [LR=0.0100][M=0.90] [Best : Accuracy=77.11, Error=22.89]
  Epoch: [009][000/391]   Time 0.260 (0.260)   Data 0.186 (0.186)   Loss 0.6741 (0.6741)   Prec@1 73.438 (73.438)   Prec@5 99.219 (99.219)   [2019-11-23 10:59:13]
  Epoch: [009][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4902 (0.5442)   Prec@1 84.375 (81.335)   Prec@5 97.656 (99.072)   [2019-11-23 10:59:18]
  Epoch: [009][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5949 (0.5406)   Prec@1 79.688 (81.444)   Prec@5 98.438 (99.133)   [2019-11-23 10:59:23]
  Epoch: [009][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.5867 (0.5420)   Prec@1 80.469 (81.525)   Prec@5 98.438 (99.099)   [2019-11-23 10:59:28]
  **Train** Prec@1 81.296 Prec@5 99.066 Error@1 18.704
  **Test** Prec@1 74.580 Prec@5 98.230 Error@1 25.420

==>>[2019-11-23 10:59:34] [Epoch=010/200] [Need: 01:10:03] [LR=0.0100][M=0.90] [Best : Accuracy=77.11, Error=22.89]
  Epoch: [010][000/391]   Time 0.253 (0.253)   Data 0.181 (0.181)   Loss 0.5418 (0.5418)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-23 10:59:34]
  Epoch: [010][100/391]   Time 0.066 (0.055)   Data 0.000 (0.002)   Loss 0.4131 (0.5170)   Prec@1 84.375 (81.915)   Prec@5 99.219 (99.165)   [2019-11-23 10:59:40]
  Epoch: [010][200/391]   Time 0.037 (0.053)   Data 0.000 (0.001)   Loss 0.4067 (0.5338)   Prec@1 87.500 (81.440)   Prec@5 99.219 (99.044)   [2019-11-23 10:59:45]
  Epoch: [010][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.3371 (0.5325)   Prec@1 90.625 (81.465)   Prec@5 99.219 (99.081)   [2019-11-23 10:59:50]
  **Train** Prec@1 81.460 Prec@5 99.080 Error@1 18.540
  **Test** Prec@1 75.950 Prec@5 98.530 Error@1 24.050

==>>[2019-11-23 10:59:56] [Epoch=011/200] [Need: 01:09:42] [LR=0.0100][M=0.90] [Best : Accuracy=77.11, Error=22.89]
  Epoch: [011][000/391]   Time 0.268 (0.268)   Data 0.191 (0.191)   Loss 0.4182 (0.4182)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 10:59:57]
  Epoch: [011][100/391]   Time 0.072 (0.056)   Data 0.000 (0.002)   Loss 0.5415 (0.5084)   Prec@1 78.906 (82.720)   Prec@5 100.000 (99.172)   [2019-11-23 11:00:02]
  Epoch: [011][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.6824 (0.5124)   Prec@1 78.906 (82.435)   Prec@5 99.219 (99.110)   [2019-11-23 11:00:07]
  Epoch: [011][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4031 (0.5173)   Prec@1 85.938 (82.270)   Prec@5 98.438 (99.115)   [2019-11-23 11:00:12]
  **Train** Prec@1 82.174 Prec@5 99.074 Error@1 17.826
  **Test** Prec@1 79.980 Prec@5 98.700 Error@1 20.020
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:00:19] [Epoch=012/200] [Need: 01:09:22] [LR=0.0100][M=0.90] [Best : Accuracy=79.98, Error=20.02]
  Epoch: [012][000/391]   Time 0.268 (0.268)   Data 0.210 (0.210)   Loss 0.4363 (0.4363)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 11:00:19]
  Epoch: [012][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.5032 (0.5012)   Prec@1 82.031 (82.890)   Prec@5 99.219 (99.056)   [2019-11-23 11:00:24]
  Epoch: [012][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.5080 (0.4959)   Prec@1 78.906 (82.886)   Prec@5 99.219 (99.125)   [2019-11-23 11:00:29]
  Epoch: [012][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3178 (0.5037)   Prec@1 89.062 (82.691)   Prec@5 100.000 (99.154)   [2019-11-23 11:00:35]
  **Train** Prec@1 82.764 Prec@5 99.126 Error@1 17.236
  **Test** Prec@1 79.210 Prec@5 98.560 Error@1 20.790

==>>[2019-11-23 11:00:41] [Epoch=013/200] [Need: 01:09:03] [LR=0.0100][M=0.90] [Best : Accuracy=79.98, Error=20.02]
  Epoch: [013][000/391]   Time 0.260 (0.260)   Data 0.179 (0.179)   Loss 0.5862 (0.5862)   Prec@1 78.906 (78.906)   Prec@5 98.438 (98.438)   [2019-11-23 11:00:41]
  Epoch: [013][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.6412 (0.5012)   Prec@1 78.906 (82.758)   Prec@5 100.000 (99.149)   [2019-11-23 11:00:46]
  Epoch: [013][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4629 (0.5007)   Prec@1 82.031 (82.696)   Prec@5 99.219 (99.176)   [2019-11-23 11:00:52]
  Epoch: [013][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.5210 (0.5044)   Prec@1 80.469 (82.543)   Prec@5 97.656 (99.172)   [2019-11-23 11:00:57]
  **Train** Prec@1 82.770 Prec@5 99.164 Error@1 17.230
  **Test** Prec@1 76.850 Prec@5 98.690 Error@1 23.150

==>>[2019-11-23 11:01:03] [Epoch=014/200] [Need: 01:08:44] [LR=0.0100][M=0.90] [Best : Accuracy=79.98, Error=20.02]
  Epoch: [014][000/391]   Time 0.250 (0.250)   Data 0.190 (0.190)   Loss 0.5042 (0.5042)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 11:01:04]
  Epoch: [014][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.6075 (0.4823)   Prec@1 81.250 (83.338)   Prec@5 98.438 (99.211)   [2019-11-23 11:01:09]
  Epoch: [014][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4733 (0.4923)   Prec@1 80.469 (82.949)   Prec@5 99.219 (99.203)   [2019-11-23 11:01:14]
  Epoch: [014][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.5513 (0.4947)   Prec@1 82.031 (82.867)   Prec@5 99.219 (99.214)   [2019-11-23 11:01:19]
  **Train** Prec@1 82.988 Prec@5 99.208 Error@1 17.012
  **Test** Prec@1 76.460 Prec@5 98.360 Error@1 23.540

==>>[2019-11-23 11:01:25] [Epoch=015/200] [Need: 01:08:18] [LR=0.0100][M=0.90] [Best : Accuracy=79.98, Error=20.02]
  Epoch: [015][000/391]   Time 0.256 (0.256)   Data 0.183 (0.183)   Loss 0.5780 (0.5780)   Prec@1 80.469 (80.469)   Prec@5 100.000 (100.000)   [2019-11-23 11:01:25]
  Epoch: [015][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3472 (0.4533)   Prec@1 89.062 (84.027)   Prec@5 99.219 (99.327)   [2019-11-23 11:01:31]
  Epoch: [015][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5289 (0.4715)   Prec@1 80.469 (83.516)   Prec@5 100.000 (99.219)   [2019-11-23 11:01:36]
  Epoch: [015][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4765 (0.4760)   Prec@1 84.375 (83.446)   Prec@5 99.219 (99.219)   [2019-11-23 11:01:41]
  **Train** Prec@1 83.336 Prec@5 99.192 Error@1 16.664
  **Test** Prec@1 78.240 Prec@5 98.930 Error@1 21.760

==>>[2019-11-23 11:01:47] [Epoch=016/200] [Need: 01:07:52] [LR=0.0100][M=0.90] [Best : Accuracy=79.98, Error=20.02]
  Epoch: [016][000/391]   Time 0.258 (0.258)   Data 0.201 (0.201)   Loss 0.4522 (0.4522)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2019-11-23 11:01:47]
  Epoch: [016][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.4278 (0.4693)   Prec@1 85.938 (83.926)   Prec@5 99.219 (99.196)   [2019-11-23 11:01:52]
  Epoch: [016][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.5313 (0.4753)   Prec@1 79.688 (83.609)   Prec@5 99.219 (99.207)   [2019-11-23 11:01:57]
  Epoch: [016][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4059 (0.4765)   Prec@1 86.719 (83.690)   Prec@5 100.000 (99.201)   [2019-11-23 11:02:02]
  **Train** Prec@1 83.740 Prec@5 99.196 Error@1 16.260
  **Test** Prec@1 80.530 Prec@5 98.720 Error@1 19.470
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:02:09] [Epoch=017/200] [Need: 01:07:26] [LR=0.0100][M=0.90] [Best : Accuracy=80.53, Error=19.47]
  Epoch: [017][000/391]   Time 0.256 (0.256)   Data 0.185 (0.185)   Loss 0.3125 (0.3125)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 11:02:09]
  Epoch: [017][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4896 (0.4517)   Prec@1 82.031 (84.360)   Prec@5 98.438 (99.428)   [2019-11-23 11:02:14]
  Epoch: [017][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.5704 (0.4574)   Prec@1 81.250 (84.247)   Prec@5 98.438 (99.289)   [2019-11-23 11:02:19]
  Epoch: [017][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4371 (0.4669)   Prec@1 84.375 (83.921)   Prec@5 99.219 (99.271)   [2019-11-23 11:02:24]
  **Train** Prec@1 84.012 Prec@5 99.304 Error@1 15.988
  **Test** Prec@1 79.790 Prec@5 99.100 Error@1 20.210

==>>[2019-11-23 11:02:31] [Epoch=018/200] [Need: 01:07:01] [LR=0.0100][M=0.90] [Best : Accuracy=80.53, Error=19.47]
  Epoch: [018][000/391]   Time 0.251 (0.251)   Data 0.195 (0.195)   Loss 0.3312 (0.3312)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 11:02:31]
  Epoch: [018][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.3926 (0.4379)   Prec@1 86.719 (85.087)   Prec@5 98.438 (99.335)   [2019-11-23 11:02:36]
  Epoch: [018][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4393 (0.4482)   Prec@1 83.594 (84.515)   Prec@5 99.219 (99.366)   [2019-11-23 11:02:41]
  Epoch: [018][300/391]   Time 0.077 (0.050)   Data 0.000 (0.001)   Loss 0.4541 (0.4524)   Prec@1 82.812 (84.352)   Prec@5 100.000 (99.382)   [2019-11-23 11:02:46]
  **Train** Prec@1 84.252 Prec@5 99.378 Error@1 15.748
  **Test** Prec@1 78.870 Prec@5 98.780 Error@1 21.130

==>>[2019-11-23 11:02:52] [Epoch=019/200] [Need: 01:06:35] [LR=0.0100][M=0.90] [Best : Accuracy=80.53, Error=19.47]
  Epoch: [019][000/391]   Time 0.244 (0.244)   Data 0.177 (0.177)   Loss 0.5160 (0.5160)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2019-11-23 11:02:53]
  Epoch: [019][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.3577 (0.4597)   Prec@1 88.281 (84.236)   Prec@5 100.000 (99.126)   [2019-11-23 11:02:58]
  Epoch: [019][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.5238 (0.4520)   Prec@1 80.469 (84.387)   Prec@5 100.000 (99.246)   [2019-11-23 11:03:03]
  Epoch: [019][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5502 (0.4496)   Prec@1 78.125 (84.442)   Prec@5 99.219 (99.286)   [2019-11-23 11:03:08]
  **Train** Prec@1 84.258 Prec@5 99.310 Error@1 15.742
  **Test** Prec@1 81.160 Prec@5 99.050 Error@1 18.840
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:03:14] [Epoch=020/200] [Need: 01:06:13] [LR=0.0100][M=0.90] [Best : Accuracy=81.16, Error=18.84]
  Epoch: [020][000/391]   Time 0.249 (0.249)   Data 0.192 (0.192)   Loss 0.4301 (0.4301)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 11:03:15]
  Epoch: [020][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.4218 (0.4508)   Prec@1 85.156 (84.344)   Prec@5 100.000 (99.358)   [2019-11-23 11:03:20]
  Epoch: [020][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.4281 (0.4444)   Prec@1 86.719 (84.744)   Prec@5 98.438 (99.285)   [2019-11-23 11:03:25]
  Epoch: [020][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4917 (0.4480)   Prec@1 85.156 (84.702)   Prec@5 97.656 (99.273)   [2019-11-23 11:03:30]
  **Train** Prec@1 84.604 Prec@5 99.290 Error@1 15.396
  **Test** Prec@1 78.530 Prec@5 98.550 Error@1 21.470

==>>[2019-11-23 11:03:36] [Epoch=021/200] [Need: 01:05:50] [LR=0.0100][M=0.90] [Best : Accuracy=81.16, Error=18.84]
  Epoch: [021][000/391]   Time 0.257 (0.257)   Data 0.201 (0.201)   Loss 0.5023 (0.5023)   Prec@1 80.469 (80.469)   Prec@5 100.000 (100.000)   [2019-11-23 11:03:37]
  Epoch: [021][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.6385 (0.4402)   Prec@1 77.344 (84.824)   Prec@5 100.000 (99.366)   [2019-11-23 11:03:42]
  Epoch: [021][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.6102 (0.4440)   Prec@1 75.781 (84.830)   Prec@5 99.219 (99.320)   [2019-11-23 11:03:47]
  Epoch: [021][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4927 (0.4431)   Prec@1 83.594 (84.798)   Prec@5 100.000 (99.289)   [2019-11-23 11:03:52]
  **Train** Prec@1 84.654 Prec@5 99.314 Error@1 15.346
  **Test** Prec@1 79.340 Prec@5 98.550 Error@1 20.660

==>>[2019-11-23 11:03:58] [Epoch=022/200] [Need: 01:05:27] [LR=0.0100][M=0.90] [Best : Accuracy=81.16, Error=18.84]
  Epoch: [022][000/391]   Time 0.257 (0.257)   Data 0.198 (0.198)   Loss 0.4047 (0.4047)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 11:03:59]
  Epoch: [022][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.5118 (0.4288)   Prec@1 84.375 (85.179)   Prec@5 99.219 (99.335)   [2019-11-23 11:04:03]
  Epoch: [022][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5654 (0.4290)   Prec@1 78.906 (85.218)   Prec@5 100.000 (99.390)   [2019-11-23 11:04:09]
  Epoch: [022][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.3689 (0.4322)   Prec@1 86.719 (85.151)   Prec@5 99.219 (99.364)   [2019-11-23 11:04:14]
  **Train** Prec@1 85.074 Prec@5 99.360 Error@1 14.926
  **Test** Prec@1 79.680 Prec@5 98.840 Error@1 20.320

==>>[2019-11-23 11:04:20] [Epoch=023/200] [Need: 01:05:03] [LR=0.0100][M=0.90] [Best : Accuracy=81.16, Error=18.84]
  Epoch: [023][000/391]   Time 0.271 (0.271)   Data 0.206 (0.206)   Loss 0.4007 (0.4007)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 11:04:20]
  Epoch: [023][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.3826 (0.4126)   Prec@1 87.500 (85.744)   Prec@5 100.000 (99.404)   [2019-11-23 11:04:26]
  Epoch: [023][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3594 (0.4239)   Prec@1 89.062 (85.494)   Prec@5 100.000 (99.394)   [2019-11-23 11:04:31]
  Epoch: [023][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.4598 (0.4270)   Prec@1 84.375 (85.317)   Prec@5 98.438 (99.398)   [2019-11-23 11:04:36]
  **Train** Prec@1 85.058 Prec@5 99.402 Error@1 14.942
  **Test** Prec@1 78.010 Prec@5 98.150 Error@1 21.990

==>>[2019-11-23 11:04:42] [Epoch=024/200] [Need: 01:04:43] [LR=0.0100][M=0.90] [Best : Accuracy=81.16, Error=18.84]
  Epoch: [024][000/391]   Time 0.255 (0.255)   Data 0.195 (0.195)   Loss 0.4158 (0.4158)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2019-11-23 11:04:43]
  Epoch: [024][100/391]   Time 0.073 (0.055)   Data 0.000 (0.002)   Loss 0.4967 (0.4257)   Prec@1 82.812 (85.249)   Prec@5 100.000 (99.366)   [2019-11-23 11:04:48]
  Epoch: [024][200/391]   Time 0.079 (0.054)   Data 0.000 (0.001)   Loss 0.4530 (0.4219)   Prec@1 84.375 (85.483)   Prec@5 99.219 (99.366)   [2019-11-23 11:04:53]
  Epoch: [024][300/391]   Time 0.056 (0.054)   Data 0.000 (0.001)   Loss 0.6367 (0.4288)   Prec@1 77.344 (85.203)   Prec@5 98.438 (99.351)   [2019-11-23 11:04:59]
  **Train** Prec@1 85.200 Prec@5 99.364 Error@1 14.800
  **Test** Prec@1 81.530 Prec@5 99.080 Error@1 18.470
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:05:05] [Epoch=025/200] [Need: 01:04:26] [LR=0.0100][M=0.90] [Best : Accuracy=81.53, Error=18.47]
  Epoch: [025][000/391]   Time 0.262 (0.262)   Data 0.187 (0.187)   Loss 0.3383 (0.3383)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 11:05:06]
  Epoch: [025][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.3349 (0.4108)   Prec@1 86.719 (85.682)   Prec@5 100.000 (99.397)   [2019-11-23 11:05:11]
  Epoch: [025][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4252 (0.4166)   Prec@1 83.594 (85.576)   Prec@5 100.000 (99.339)   [2019-11-23 11:05:16]
  Epoch: [025][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.2301 (0.4204)   Prec@1 92.188 (85.335)   Prec@5 100.000 (99.377)   [2019-11-23 11:05:21]
  **Train** Prec@1 85.338 Prec@5 99.368 Error@1 14.662
  **Test** Prec@1 81.290 Prec@5 99.170 Error@1 18.710

==>>[2019-11-23 11:05:27] [Epoch=026/200] [Need: 01:04:04] [LR=0.0100][M=0.90] [Best : Accuracy=81.53, Error=18.47]
  Epoch: [026][000/391]   Time 0.258 (0.258)   Data 0.204 (0.204)   Loss 0.3773 (0.3773)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 11:05:28]
  Epoch: [026][100/391]   Time 0.078 (0.056)   Data 0.000 (0.002)   Loss 0.3664 (0.4150)   Prec@1 88.281 (85.783)   Prec@5 99.219 (99.528)   [2019-11-23 11:05:33]
  Epoch: [026][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.4268 (0.4195)   Prec@1 86.719 (85.584)   Prec@5 100.000 (99.471)   [2019-11-23 11:05:38]
  Epoch: [026][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4839 (0.4192)   Prec@1 79.688 (85.577)   Prec@5 99.219 (99.481)   [2019-11-23 11:05:43]
  **Train** Prec@1 85.556 Prec@5 99.480 Error@1 14.444
  **Test** Prec@1 79.560 Prec@5 98.130 Error@1 20.440

==>>[2019-11-23 11:05:50] [Epoch=027/200] [Need: 01:03:44] [LR=0.0100][M=0.90] [Best : Accuracy=81.53, Error=18.47]
  Epoch: [027][000/391]   Time 0.262 (0.262)   Data 0.194 (0.194)   Loss 0.4448 (0.4448)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2019-11-23 11:05:50]
  Epoch: [027][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.2833 (0.3967)   Prec@1 90.625 (86.216)   Prec@5 100.000 (99.505)   [2019-11-23 11:05:55]
  Epoch: [027][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.5284 (0.4082)   Prec@1 82.031 (85.751)   Prec@5 100.000 (99.499)   [2019-11-23 11:06:00]
  Epoch: [027][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.3289 (0.4174)   Prec@1 89.062 (85.608)   Prec@5 100.000 (99.445)   [2019-11-23 11:06:05]
  **Train** Prec@1 85.616 Prec@5 99.450 Error@1 14.384
  **Test** Prec@1 82.740 Prec@5 99.250 Error@1 17.260
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:06:12] [Epoch=028/200] [Need: 01:03:22] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [028][000/391]   Time 0.268 (0.268)   Data 0.211 (0.211)   Loss 0.4291 (0.4291)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 11:06:12]
  Epoch: [028][100/391]   Time 0.049 (0.052)   Data 0.000 (0.002)   Loss 0.3278 (0.4008)   Prec@1 90.625 (85.984)   Prec@5 100.000 (99.435)   [2019-11-23 11:06:17]
  Epoch: [028][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.5117 (0.4073)   Prec@1 82.031 (85.883)   Prec@5 99.219 (99.448)   [2019-11-23 11:06:22]
  Epoch: [028][300/391]   Time 0.062 (0.052)   Data 0.000 (0.001)   Loss 0.4522 (0.4140)   Prec@1 82.031 (85.603)   Prec@5 100.000 (99.385)   [2019-11-23 11:06:27]
  **Train** Prec@1 85.696 Prec@5 99.400 Error@1 14.304
  **Test** Prec@1 80.470 Prec@5 98.870 Error@1 19.530

==>>[2019-11-23 11:06:34] [Epoch=029/200] [Need: 01:03:00] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [029][000/391]   Time 0.256 (0.256)   Data 0.190 (0.190)   Loss 0.4747 (0.4747)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-23 11:06:34]
  Epoch: [029][100/391]   Time 0.045 (0.048)   Data 0.000 (0.002)   Loss 0.4890 (0.4044)   Prec@1 80.469 (86.123)   Prec@5 99.219 (99.397)   [2019-11-23 11:06:39]
  Epoch: [029][200/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.4608 (0.4067)   Prec@1 85.156 (86.077)   Prec@5 100.000 (99.456)   [2019-11-23 11:06:44]
  Epoch: [029][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.5144 (0.4098)   Prec@1 83.594 (86.010)   Prec@5 98.438 (99.473)   [2019-11-23 11:06:50]
  **Train** Prec@1 85.980 Prec@5 99.468 Error@1 14.020
  **Test** Prec@1 76.480 Prec@5 98.620 Error@1 23.520

==>>[2019-11-23 11:06:56] [Epoch=030/200] [Need: 01:02:36] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [030][000/391]   Time 0.257 (0.257)   Data 0.199 (0.199)   Loss 0.4384 (0.4384)   Prec@1 82.031 (82.031)   Prec@5 100.000 (100.000)   [2019-11-23 11:06:56]
  Epoch: [030][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4104 (0.3998)   Prec@1 83.594 (85.783)   Prec@5 99.219 (99.528)   [2019-11-23 11:07:01]
  Epoch: [030][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4094 (0.4113)   Prec@1 87.500 (85.708)   Prec@5 100.000 (99.499)   [2019-11-23 11:07:06]
  Epoch: [030][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.4923 (0.4097)   Prec@1 82.031 (85.681)   Prec@5 100.000 (99.447)   [2019-11-23 11:07:11]
  **Train** Prec@1 85.636 Prec@5 99.446 Error@1 14.364
  **Test** Prec@1 78.250 Prec@5 98.940 Error@1 21.750

==>>[2019-11-23 11:07:18] [Epoch=031/200] [Need: 01:02:15] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [031][000/391]   Time 0.247 (0.247)   Data 0.191 (0.191)   Loss 0.4173 (0.4173)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:07:18]
  Epoch: [031][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.3485 (0.3972)   Prec@1 89.062 (86.239)   Prec@5 99.219 (99.505)   [2019-11-23 11:07:23]
  Epoch: [031][200/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.3791 (0.4044)   Prec@1 87.500 (85.976)   Prec@5 98.438 (99.487)   [2019-11-23 11:07:29]
  Epoch: [031][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.5305 (0.4110)   Prec@1 82.031 (85.753)   Prec@5 99.219 (99.478)   [2019-11-23 11:07:34]
  **Train** Prec@1 85.838 Prec@5 99.456 Error@1 14.162
  **Test** Prec@1 80.280 Prec@5 98.540 Error@1 19.720

==>>[2019-11-23 11:07:40] [Epoch=032/200] [Need: 01:01:53] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [032][000/391]   Time 0.264 (0.264)   Data 0.190 (0.190)   Loss 0.4634 (0.4634)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2019-11-23 11:07:41]
  Epoch: [032][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.3464 (0.3910)   Prec@1 86.719 (86.750)   Prec@5 100.000 (99.466)   [2019-11-23 11:07:45]
  Epoch: [032][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.4141 (0.3865)   Prec@1 83.594 (86.824)   Prec@5 99.219 (99.499)   [2019-11-23 11:07:51]
  Epoch: [032][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3313 (0.3956)   Prec@1 89.062 (86.527)   Prec@5 99.219 (99.434)   [2019-11-23 11:07:56]
  **Train** Prec@1 86.162 Prec@5 99.454 Error@1 13.838
  **Test** Prec@1 78.730 Prec@5 99.200 Error@1 21.270

==>>[2019-11-23 11:08:02] [Epoch=033/200] [Need: 01:01:29] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [033][000/391]   Time 0.273 (0.273)   Data 0.210 (0.210)   Loss 0.3919 (0.3919)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-23 11:08:02]
  Epoch: [033][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.3476 (0.3777)   Prec@1 87.500 (86.657)   Prec@5 98.438 (99.528)   [2019-11-23 11:08:08]
  Epoch: [033][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4514 (0.3931)   Prec@1 84.375 (86.295)   Prec@5 99.219 (99.499)   [2019-11-23 11:08:12]
  Epoch: [033][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2369 (0.3928)   Prec@1 93.750 (86.361)   Prec@5 99.219 (99.489)   [2019-11-23 11:08:17]
  **Train** Prec@1 86.220 Prec@5 99.492 Error@1 13.780
  **Test** Prec@1 82.490 Prec@5 99.000 Error@1 17.510

==>>[2019-11-23 11:08:24] [Epoch=034/200] [Need: 01:01:08] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [034][000/391]   Time 0.263 (0.263)   Data 0.192 (0.192)   Loss 0.2760 (0.2760)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 11:08:24]
  Epoch: [034][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.5906 (0.3909)   Prec@1 82.031 (86.270)   Prec@5 100.000 (99.505)   [2019-11-23 11:08:30]
  Epoch: [034][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3102 (0.3905)   Prec@1 90.625 (86.311)   Prec@5 100.000 (99.514)   [2019-11-23 11:08:34]
  Epoch: [034][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.4837 (0.3897)   Prec@1 82.031 (86.384)   Prec@5 99.219 (99.507)   [2019-11-23 11:08:39]
  **Train** Prec@1 86.286 Prec@5 99.500 Error@1 13.714
  **Test** Prec@1 79.770 Prec@5 98.740 Error@1 20.230

==>>[2019-11-23 11:08:46] [Epoch=035/200] [Need: 01:00:46] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [035][000/391]   Time 0.245 (0.245)   Data 0.189 (0.189)   Loss 0.2858 (0.2858)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 11:08:47]
  Epoch: [035][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.3882 (0.3822)   Prec@1 85.938 (86.951)   Prec@5 100.000 (99.582)   [2019-11-23 11:08:52]
  Epoch: [035][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3752 (0.3892)   Prec@1 85.156 (86.614)   Prec@5 100.000 (99.514)   [2019-11-23 11:08:57]
  Epoch: [035][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5051 (0.3859)   Prec@1 83.594 (86.742)   Prec@5 98.438 (99.504)   [2019-11-23 11:09:02]
  **Train** Prec@1 86.474 Prec@5 99.472 Error@1 13.526
  **Test** Prec@1 76.620 Prec@5 99.020 Error@1 23.380

==>>[2019-11-23 11:09:09] [Epoch=036/200] [Need: 01:00:24] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [036][000/391]   Time 0.256 (0.256)   Data 0.199 (0.199)   Loss 0.3591 (0.3591)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 11:09:09]
  Epoch: [036][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.4765 (0.3874)   Prec@1 78.906 (86.525)   Prec@5 100.000 (99.559)   [2019-11-23 11:09:14]
  Epoch: [036][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.3394 (0.3800)   Prec@1 86.719 (86.812)   Prec@5 100.000 (99.600)   [2019-11-23 11:09:19]
  Epoch: [036][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.3685 (0.3879)   Prec@1 86.719 (86.485)   Prec@5 99.219 (99.512)   [2019-11-23 11:09:23]
  **Train** Prec@1 86.370 Prec@5 99.478 Error@1 13.630
  **Test** Prec@1 82.230 Prec@5 99.150 Error@1 17.770

==>>[2019-11-23 11:09:30] [Epoch=037/200] [Need: 00:59:58] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [037][000/391]   Time 0.256 (0.256)   Data 0.183 (0.183)   Loss 0.2732 (0.2732)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 11:09:30]
  Epoch: [037][100/391]   Time 0.046 (0.057)   Data 0.000 (0.002)   Loss 0.3082 (0.3759)   Prec@1 87.500 (87.198)   Prec@5 98.438 (99.505)   [2019-11-23 11:09:35]
  Epoch: [037][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.2936 (0.3850)   Prec@1 91.406 (86.727)   Prec@5 100.000 (99.526)   [2019-11-23 11:09:40]
  Epoch: [037][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.3577 (0.3904)   Prec@1 86.719 (86.503)   Prec@5 100.000 (99.489)   [2019-11-23 11:09:45]
  **Train** Prec@1 86.512 Prec@5 99.488 Error@1 13.488
  **Test** Prec@1 82.130 Prec@5 98.970 Error@1 17.870

==>>[2019-11-23 11:09:52] [Epoch=038/200] [Need: 00:59:36] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [038][000/391]   Time 0.267 (0.267)   Data 0.210 (0.210)   Loss 0.2571 (0.2571)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:09:52]
  Epoch: [038][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.3841 (0.3619)   Prec@1 88.281 (87.577)   Prec@5 100.000 (99.567)   [2019-11-23 11:09:57]
  Epoch: [038][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.3459 (0.3776)   Prec@1 89.844 (86.929)   Prec@5 99.219 (99.499)   [2019-11-23 11:10:03]
  Epoch: [038][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.5130 (0.3856)   Prec@1 82.812 (86.747)   Prec@5 99.219 (99.458)   [2019-11-23 11:10:08]
  **Train** Prec@1 86.628 Prec@5 99.444 Error@1 13.372
  **Test** Prec@1 82.050 Prec@5 99.200 Error@1 17.950

==>>[2019-11-23 11:10:14] [Epoch=039/200] [Need: 00:59:16] [LR=0.0100][M=0.90] [Best : Accuracy=82.74, Error=17.26]
  Epoch: [039][000/391]   Time 0.266 (0.266)   Data 0.197 (0.197)   Loss 0.3915 (0.3915)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2019-11-23 11:10:15]
  Epoch: [039][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.4603 (0.3757)   Prec@1 80.469 (86.982)   Prec@5 99.219 (99.559)   [2019-11-23 11:10:20]
  Epoch: [039][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3844 (0.3807)   Prec@1 87.500 (86.820)   Prec@5 99.219 (99.530)   [2019-11-23 11:10:25]
  Epoch: [039][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.3864 (0.3841)   Prec@1 88.281 (86.568)   Prec@5 100.000 (99.559)   [2019-11-23 11:10:30]
  **Train** Prec@1 86.578 Prec@5 99.528 Error@1 13.422
  **Test** Prec@1 84.630 Prec@5 99.260 Error@1 15.370
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:10:37] [Epoch=040/200] [Need: 00:58:55] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [040][000/391]   Time 0.264 (0.264)   Data 0.202 (0.202)   Loss 0.3663 (0.3663)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 11:10:37]
  Epoch: [040][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.3053 (0.3619)   Prec@1 90.625 (87.399)   Prec@5 99.219 (99.528)   [2019-11-23 11:10:42]
  Epoch: [040][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4232 (0.3780)   Prec@1 84.375 (86.719)   Prec@5 99.219 (99.510)   [2019-11-23 11:10:47]
  Epoch: [040][300/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.4738 (0.3798)   Prec@1 80.469 (86.646)   Prec@5 99.219 (99.530)   [2019-11-23 11:10:53]
  **Train** Prec@1 86.664 Prec@5 99.522 Error@1 13.336
  **Test** Prec@1 81.930 Prec@5 99.210 Error@1 18.070

==>>[2019-11-23 11:11:00] [Epoch=041/200] [Need: 00:58:36] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [041][000/391]   Time 0.256 (0.256)   Data 0.194 (0.194)   Loss 0.3915 (0.3915)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:11:00]
  Epoch: [041][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.3845 (0.3716)   Prec@1 85.156 (86.982)   Prec@5 99.219 (99.567)   [2019-11-23 11:11:05]
  Epoch: [041][200/391]   Time 0.047 (0.054)   Data 0.000 (0.001)   Loss 0.4020 (0.3748)   Prec@1 83.594 (86.831)   Prec@5 100.000 (99.565)   [2019-11-23 11:11:10]
  Epoch: [041][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3819 (0.3764)   Prec@1 85.938 (86.807)   Prec@5 99.219 (99.556)   [2019-11-23 11:11:15]
  **Train** Prec@1 86.692 Prec@5 99.518 Error@1 13.308
  **Test** Prec@1 82.640 Prec@5 99.110 Error@1 17.360

==>>[2019-11-23 11:11:22] [Epoch=042/200] [Need: 00:58:13] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [042][000/391]   Time 0.267 (0.267)   Data 0.209 (0.209)   Loss 0.3551 (0.3551)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:11:22]
  Epoch: [042][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.4247 (0.3626)   Prec@1 85.938 (87.941)   Prec@5 100.000 (99.466)   [2019-11-23 11:11:27]
  Epoch: [042][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.4036 (0.3603)   Prec@1 88.281 (87.718)   Prec@5 99.219 (99.471)   [2019-11-23 11:11:32]
  Epoch: [042][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.4013 (0.3722)   Prec@1 88.281 (87.303)   Prec@5 100.000 (99.473)   [2019-11-23 11:11:37]
  **Train** Prec@1 87.166 Prec@5 99.472 Error@1 12.834
  **Test** Prec@1 80.480 Prec@5 98.990 Error@1 19.520

==>>[2019-11-23 11:11:43] [Epoch=043/200] [Need: 00:57:50] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [043][000/391]   Time 0.247 (0.247)   Data 0.182 (0.182)   Loss 0.3407 (0.3407)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:11:44]
  Epoch: [043][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.2404 (0.3626)   Prec@1 91.406 (87.601)   Prec@5 100.000 (99.598)   [2019-11-23 11:11:49]
  Epoch: [043][200/391]   Time 0.036 (0.053)   Data 0.000 (0.001)   Loss 0.2959 (0.3686)   Prec@1 90.625 (87.205)   Prec@5 100.000 (99.588)   [2019-11-23 11:11:54]
  Epoch: [043][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3196 (0.3737)   Prec@1 89.844 (87.111)   Prec@5 100.000 (99.512)   [2019-11-23 11:11:59]
  **Train** Prec@1 86.954 Prec@5 99.498 Error@1 13.046
  **Test** Prec@1 84.290 Prec@5 99.390 Error@1 15.710

==>>[2019-11-23 11:12:06] [Epoch=044/200] [Need: 00:57:29] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [044][000/391]   Time 0.282 (0.282)   Data 0.219 (0.219)   Loss 0.2665 (0.2665)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 11:12:06]
  Epoch: [044][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.4042 (0.3632)   Prec@1 85.156 (87.237)   Prec@5 100.000 (99.459)   [2019-11-23 11:12:11]
  Epoch: [044][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.3390 (0.3746)   Prec@1 85.938 (86.863)   Prec@5 100.000 (99.530)   [2019-11-23 11:12:16]
  Epoch: [044][300/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.5461 (0.3770)   Prec@1 82.812 (86.742)   Prec@5 98.438 (99.522)   [2019-11-23 11:12:21]
  **Train** Prec@1 86.802 Prec@5 99.524 Error@1 13.198
  **Test** Prec@1 83.810 Prec@5 99.300 Error@1 16.190

==>>[2019-11-23 11:12:28] [Epoch=045/200] [Need: 00:57:07] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [045][000/391]   Time 0.254 (0.254)   Data 0.188 (0.188)   Loss 0.3550 (0.3550)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 11:12:28]
  Epoch: [045][100/391]   Time 0.065 (0.056)   Data 0.000 (0.002)   Loss 0.5244 (0.3696)   Prec@1 83.594 (87.446)   Prec@5 99.219 (99.520)   [2019-11-23 11:12:34]
  Epoch: [045][200/391]   Time 0.052 (0.055)   Data 0.000 (0.001)   Loss 0.3847 (0.3783)   Prec@1 87.500 (87.115)   Prec@5 99.219 (99.549)   [2019-11-23 11:12:39]
  Epoch: [045][300/391]   Time 0.046 (0.055)   Data 0.000 (0.001)   Loss 0.3897 (0.3776)   Prec@1 87.500 (87.085)   Prec@5 99.219 (99.561)   [2019-11-23 11:12:44]
  **Train** Prec@1 87.134 Prec@5 99.554 Error@1 12.866
  **Test** Prec@1 80.970 Prec@5 98.960 Error@1 19.030

==>>[2019-11-23 11:12:51] [Epoch=046/200] [Need: 00:56:47] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [046][000/391]   Time 0.253 (0.253)   Data 0.189 (0.189)   Loss 0.4961 (0.4961)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2019-11-23 11:12:51]
  Epoch: [046][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.3256 (0.3780)   Prec@1 86.719 (86.726)   Prec@5 99.219 (99.613)   [2019-11-23 11:12:56]
  Epoch: [046][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.4293 (0.3769)   Prec@1 87.500 (86.933)   Prec@5 98.438 (99.565)   [2019-11-23 11:13:01]
  Epoch: [046][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3439 (0.3727)   Prec@1 85.156 (87.015)   Prec@5 99.219 (99.559)   [2019-11-23 11:13:06]
  **Train** Prec@1 87.112 Prec@5 99.560 Error@1 12.888
  **Test** Prec@1 80.630 Prec@5 98.720 Error@1 19.370

==>>[2019-11-23 11:13:13] [Epoch=047/200] [Need: 00:56:26] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [047][000/391]   Time 0.264 (0.264)   Data 0.181 (0.181)   Loss 0.3219 (0.3219)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:13:14]
  Epoch: [047][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3760 (0.3585)   Prec@1 85.156 (87.570)   Prec@5 100.000 (99.520)   [2019-11-23 11:13:19]
  Epoch: [047][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3063 (0.3748)   Prec@1 87.500 (87.170)   Prec@5 100.000 (99.452)   [2019-11-23 11:13:24]
  Epoch: [047][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3235 (0.3753)   Prec@1 90.625 (87.121)   Prec@5 100.000 (99.486)   [2019-11-23 11:13:29]
  **Train** Prec@1 87.034 Prec@5 99.514 Error@1 12.966
  **Test** Prec@1 84.200 Prec@5 99.270 Error@1 15.800

==>>[2019-11-23 11:13:36] [Epoch=048/200] [Need: 00:56:04] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [048][000/391]   Time 0.248 (0.248)   Data 0.196 (0.196)   Loss 0.3763 (0.3763)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2019-11-23 11:13:36]
  Epoch: [048][100/391]   Time 0.060 (0.053)   Data 0.000 (0.002)   Loss 0.3182 (0.3568)   Prec@1 89.844 (87.307)   Prec@5 99.219 (99.567)   [2019-11-23 11:13:41]
  Epoch: [048][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3600 (0.3684)   Prec@1 85.938 (87.014)   Prec@5 100.000 (99.565)   [2019-11-23 11:13:46]
  Epoch: [048][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3847 (0.3701)   Prec@1 88.281 (87.033)   Prec@5 99.219 (99.535)   [2019-11-23 11:13:51]
  **Train** Prec@1 87.116 Prec@5 99.538 Error@1 12.884
  **Test** Prec@1 84.360 Prec@5 99.390 Error@1 15.640

==>>[2019-11-23 11:13:58] [Epoch=049/200] [Need: 00:55:43] [LR=0.0100][M=0.90] [Best : Accuracy=84.63, Error=15.37]
  Epoch: [049][000/391]   Time 0.267 (0.267)   Data 0.180 (0.180)   Loss 0.3396 (0.3396)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 11:13:58]
  Epoch: [049][100/391]   Time 0.056 (0.057)   Data 0.000 (0.002)   Loss 0.3060 (0.3733)   Prec@1 91.406 (87.067)   Prec@5 100.000 (99.497)   [2019-11-23 11:14:04]
  Epoch: [049][200/391]   Time 0.072 (0.054)   Data 0.000 (0.001)   Loss 0.4995 (0.3706)   Prec@1 85.938 (87.037)   Prec@5 99.219 (99.545)   [2019-11-23 11:14:09]
  Epoch: [049][300/391]   Time 0.083 (0.053)   Data 0.000 (0.001)   Loss 0.2997 (0.3708)   Prec@1 90.625 (87.126)   Prec@5 100.000 (99.528)   [2019-11-23 11:14:14]
  **Train** Prec@1 87.188 Prec@5 99.530 Error@1 12.812
  **Test** Prec@1 85.130 Prec@5 99.350 Error@1 14.870
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:14:21] [Epoch=050/200] [Need: 00:55:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [050][000/391]   Time 0.257 (0.257)   Data 0.200 (0.200)   Loss 0.2849 (0.2849)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:14:21]
  Epoch: [050][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.2505 (0.3560)   Prec@1 91.406 (87.693)   Prec@5 99.219 (99.590)   [2019-11-23 11:14:26]
  Epoch: [050][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3070 (0.3597)   Prec@1 87.500 (87.628)   Prec@5 99.219 (99.553)   [2019-11-23 11:14:31]
  Epoch: [050][300/391]   Time 0.073 (0.052)   Data 0.000 (0.001)   Loss 0.4111 (0.3613)   Prec@1 85.938 (87.682)   Prec@5 99.219 (99.515)   [2019-11-23 11:14:37]
  **Train** Prec@1 87.496 Prec@5 99.500 Error@1 12.504
  **Test** Prec@1 82.350 Prec@5 99.140 Error@1 17.650

==>>[2019-11-23 11:14:43] [Epoch=051/200] [Need: 00:55:00] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [051][000/391]   Time 0.264 (0.264)   Data 0.180 (0.180)   Loss 0.2830 (0.2830)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:14:43]
  Epoch: [051][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.3240 (0.3610)   Prec@1 91.406 (87.577)   Prec@5 100.000 (99.636)   [2019-11-23 11:14:48]
  Epoch: [051][200/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 0.3582 (0.3656)   Prec@1 87.500 (87.438)   Prec@5 100.000 (99.596)   [2019-11-23 11:14:54]
  Epoch: [051][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3442 (0.3670)   Prec@1 86.719 (87.381)   Prec@5 100.000 (99.554)   [2019-11-23 11:14:59]
  **Train** Prec@1 87.396 Prec@5 99.550 Error@1 12.604
  **Test** Prec@1 79.040 Prec@5 98.900 Error@1 20.960

==>>[2019-11-23 11:15:05] [Epoch=052/200] [Need: 00:54:40] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [052][000/391]   Time 0.267 (0.267)   Data 0.184 (0.184)   Loss 0.4284 (0.4284)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:15:06]
  Epoch: [052][100/391]   Time 0.062 (0.057)   Data 0.000 (0.002)   Loss 0.3486 (0.3526)   Prec@1 87.500 (87.693)   Prec@5 100.000 (99.474)   [2019-11-23 11:15:11]
  Epoch: [052][200/391]   Time 0.082 (0.054)   Data 0.000 (0.001)   Loss 0.4420 (0.3655)   Prec@1 83.594 (87.329)   Prec@5 99.219 (99.425)   [2019-11-23 11:15:16]
  Epoch: [052][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4520 (0.3645)   Prec@1 83.594 (87.469)   Prec@5 100.000 (99.452)   [2019-11-23 11:15:21]
  **Train** Prec@1 87.292 Prec@5 99.460 Error@1 12.708
  **Test** Prec@1 81.450 Prec@5 98.980 Error@1 18.550

==>>[2019-11-23 11:15:29] [Epoch=053/200] [Need: 00:54:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [053][000/391]   Time 0.267 (0.267)   Data 0.211 (0.211)   Loss 0.2818 (0.2818)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 11:15:29]
  Epoch: [053][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.3046 (0.3606)   Prec@1 89.844 (87.191)   Prec@5 100.000 (99.520)   [2019-11-23 11:15:34]
  Epoch: [053][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.2642 (0.3578)   Prec@1 90.625 (87.395)   Prec@5 100.000 (99.553)   [2019-11-23 11:15:39]
  Epoch: [053][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.4703 (0.3610)   Prec@1 81.250 (87.375)   Prec@5 100.000 (99.561)   [2019-11-23 11:15:44]
  **Train** Prec@1 87.360 Prec@5 99.528 Error@1 12.640
  **Test** Prec@1 81.420 Prec@5 99.050 Error@1 18.580

==>>[2019-11-23 11:15:50] [Epoch=054/200] [Need: 00:53:57] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [054][000/391]   Time 0.259 (0.259)   Data 0.204 (0.204)   Loss 0.3410 (0.3410)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2019-11-23 11:15:50]
  Epoch: [054][100/391]   Time 0.041 (0.055)   Data 0.000 (0.002)   Loss 0.3897 (0.3550)   Prec@1 85.938 (87.608)   Prec@5 100.000 (99.536)   [2019-11-23 11:15:56]
  Epoch: [054][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.3080 (0.3548)   Prec@1 89.062 (87.667)   Prec@5 99.219 (99.522)   [2019-11-23 11:16:01]
  Epoch: [054][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3921 (0.3617)   Prec@1 85.938 (87.409)   Prec@5 100.000 (99.533)   [2019-11-23 11:16:06]
  **Train** Prec@1 87.408 Prec@5 99.492 Error@1 12.592
  **Test** Prec@1 83.310 Prec@5 99.280 Error@1 16.690

==>>[2019-11-23 11:16:12] [Epoch=055/200] [Need: 00:53:34] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [055][000/391]   Time 0.277 (0.277)   Data 0.212 (0.212)   Loss 0.3455 (0.3455)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-23 11:16:12]
  Epoch: [055][100/391]   Time 0.057 (0.053)   Data 0.000 (0.002)   Loss 0.3767 (0.3600)   Prec@1 87.500 (87.570)   Prec@5 100.000 (99.575)   [2019-11-23 11:16:17]
  Epoch: [055][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.3096 (0.3573)   Prec@1 89.062 (87.667)   Prec@5 99.219 (99.537)   [2019-11-23 11:16:23]
  Epoch: [055][300/391]   Time 0.077 (0.053)   Data 0.000 (0.001)   Loss 0.3690 (0.3630)   Prec@1 89.062 (87.464)   Prec@5 100.000 (99.535)   [2019-11-23 11:16:28]
  **Train** Prec@1 87.520 Prec@5 99.556 Error@1 12.480
  **Test** Prec@1 77.910 Prec@5 98.580 Error@1 22.090

==>>[2019-11-23 11:16:35] [Epoch=056/200] [Need: 00:53:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [056][000/391]   Time 0.264 (0.264)   Data 0.182 (0.182)   Loss 0.3427 (0.3427)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 11:16:35]
  Epoch: [056][100/391]   Time 0.046 (0.056)   Data 0.000 (0.002)   Loss 0.3749 (0.3494)   Prec@1 89.062 (88.011)   Prec@5 100.000 (99.590)   [2019-11-23 11:16:40]
  Epoch: [056][200/391]   Time 0.063 (0.053)   Data 0.000 (0.001)   Loss 0.2866 (0.3628)   Prec@1 91.406 (87.570)   Prec@5 100.000 (99.580)   [2019-11-23 11:16:45]
  Epoch: [056][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.2671 (0.3676)   Prec@1 93.750 (87.349)   Prec@5 99.219 (99.567)   [2019-11-23 11:16:51]
  **Train** Prec@1 87.386 Prec@5 99.560 Error@1 12.614
  **Test** Prec@1 83.430 Prec@5 98.960 Error@1 16.570

==>>[2019-11-23 11:16:57] [Epoch=057/200] [Need: 00:52:52] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [057][000/391]   Time 0.254 (0.254)   Data 0.198 (0.198)   Loss 0.3670 (0.3670)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 11:16:58]
  Epoch: [057][100/391]   Time 0.046 (0.058)   Data 0.000 (0.002)   Loss 0.4322 (0.3453)   Prec@1 84.375 (87.871)   Prec@5 99.219 (99.652)   [2019-11-23 11:17:03]
  Epoch: [057][200/391]   Time 0.076 (0.055)   Data 0.000 (0.001)   Loss 0.3251 (0.3551)   Prec@1 85.938 (87.659)   Prec@5 99.219 (99.615)   [2019-11-23 11:17:08]
  Epoch: [057][300/391]   Time 0.038 (0.055)   Data 0.000 (0.001)   Loss 0.3869 (0.3555)   Prec@1 85.156 (87.731)   Prec@5 100.000 (99.595)   [2019-11-23 11:17:14]
  **Train** Prec@1 87.602 Prec@5 99.596 Error@1 12.398
  **Test** Prec@1 80.100 Prec@5 99.170 Error@1 19.900

==>>[2019-11-23 11:17:20] [Epoch=058/200] [Need: 00:52:31] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [058][000/391]   Time 0.264 (0.264)   Data 0.199 (0.199)   Loss 0.3831 (0.3831)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:17:20]
  Epoch: [058][100/391]   Time 0.056 (0.049)   Data 0.000 (0.002)   Loss 0.3436 (0.3372)   Prec@1 89.844 (88.258)   Prec@5 98.438 (99.613)   [2019-11-23 11:17:25]
  Epoch: [058][200/391]   Time 0.072 (0.049)   Data 0.000 (0.001)   Loss 0.3245 (0.3467)   Prec@1 88.281 (87.912)   Prec@5 99.219 (99.615)   [2019-11-23 11:17:30]
  Epoch: [058][300/391]   Time 0.057 (0.049)   Data 0.000 (0.001)   Loss 0.2742 (0.3556)   Prec@1 89.062 (87.702)   Prec@5 98.438 (99.598)   [2019-11-23 11:17:35]
  **Train** Prec@1 87.668 Prec@5 99.610 Error@1 12.332
  **Test** Prec@1 83.370 Prec@5 99.260 Error@1 16.630

==>>[2019-11-23 11:17:42] [Epoch=059/200] [Need: 00:52:07] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [059][000/391]   Time 0.268 (0.268)   Data 0.188 (0.188)   Loss 0.4335 (0.4335)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-23 11:17:42]
  Epoch: [059][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.3774 (0.3456)   Prec@1 86.719 (88.041)   Prec@5 100.000 (99.652)   [2019-11-23 11:17:47]
  Epoch: [059][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3841 (0.3423)   Prec@1 89.062 (88.219)   Prec@5 100.000 (99.642)   [2019-11-23 11:17:52]
  Epoch: [059][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4154 (0.3595)   Prec@1 86.719 (87.726)   Prec@5 99.219 (99.582)   [2019-11-23 11:17:57]
  **Train** Prec@1 87.552 Prec@5 99.590 Error@1 12.448
  **Test** Prec@1 82.930 Prec@5 99.080 Error@1 17.070

==>>[2019-11-23 11:18:04] [Epoch=060/200] [Need: 00:51:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [060][000/391]   Time 0.240 (0.240)   Data 0.174 (0.174)   Loss 0.3166 (0.3166)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 11:18:04]
  Epoch: [060][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.3743 (0.3372)   Prec@1 86.719 (88.397)   Prec@5 100.000 (99.644)   [2019-11-23 11:18:09]
  Epoch: [060][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3779 (0.3435)   Prec@1 85.156 (88.134)   Prec@5 100.000 (99.584)   [2019-11-23 11:18:14]
  Epoch: [060][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.3659 (0.3486)   Prec@1 86.719 (87.975)   Prec@5 100.000 (99.567)   [2019-11-23 11:18:19]
  **Train** Prec@1 87.952 Prec@5 99.580 Error@1 12.048
  **Test** Prec@1 82.500 Prec@5 99.100 Error@1 17.500

==>>[2019-11-23 11:18:26] [Epoch=061/200] [Need: 00:51:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [061][000/391]   Time 0.271 (0.271)   Data 0.197 (0.197)   Loss 0.2773 (0.2773)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-23 11:18:27]
  Epoch: [061][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.3275 (0.3439)   Prec@1 88.281 (88.351)   Prec@5 100.000 (99.582)   [2019-11-23 11:18:32]
  Epoch: [061][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3959 (0.3496)   Prec@1 85.938 (87.865)   Prec@5 98.438 (99.604)   [2019-11-23 11:18:37]
  Epoch: [061][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.3151 (0.3534)   Prec@1 86.719 (87.811)   Prec@5 100.000 (99.561)   [2019-11-23 11:18:42]
  **Train** Prec@1 87.852 Prec@5 99.564 Error@1 12.148
  **Test** Prec@1 83.290 Prec@5 99.120 Error@1 16.710

==>>[2019-11-23 11:18:49] [Epoch=062/200] [Need: 00:51:01] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [062][000/391]   Time 0.258 (0.258)   Data 0.203 (0.203)   Loss 0.3383 (0.3383)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 11:18:49]
  Epoch: [062][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.5270 (0.3399)   Prec@1 82.031 (88.475)   Prec@5 98.438 (99.590)   [2019-11-23 11:18:54]
  Epoch: [062][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4082 (0.3447)   Prec@1 85.938 (88.215)   Prec@5 100.000 (99.607)   [2019-11-23 11:18:59]
  Epoch: [062][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.3094 (0.3496)   Prec@1 90.625 (87.959)   Prec@5 100.000 (99.600)   [2019-11-23 11:19:04]
  **Train** Prec@1 87.908 Prec@5 99.592 Error@1 12.092
  **Test** Prec@1 80.350 Prec@5 99.010 Error@1 19.650

==>>[2019-11-23 11:19:10] [Epoch=063/200] [Need: 00:50:38] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [063][000/391]   Time 0.265 (0.265)   Data 0.203 (0.203)   Loss 0.3109 (0.3109)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 11:19:10]
  Epoch: [063][100/391]   Time 0.078 (0.058)   Data 0.000 (0.002)   Loss 0.4403 (0.3361)   Prec@1 85.938 (88.444)   Prec@5 98.438 (99.722)   [2019-11-23 11:19:16]
  Epoch: [063][200/391]   Time 0.054 (0.056)   Data 0.000 (0.001)   Loss 0.4258 (0.3449)   Prec@1 85.156 (88.130)   Prec@5 98.438 (99.662)   [2019-11-23 11:19:21]
  Epoch: [063][300/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.4993 (0.3517)   Prec@1 83.594 (87.895)   Prec@5 99.219 (99.608)   [2019-11-23 11:19:26]
  **Train** Prec@1 87.796 Prec@5 99.586 Error@1 12.204
  **Test** Prec@1 84.440 Prec@5 99.040 Error@1 15.560

==>>[2019-11-23 11:19:33] [Epoch=064/200] [Need: 00:50:17] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [064][000/391]   Time 0.259 (0.259)   Data 0.200 (0.200)   Loss 0.3219 (0.3219)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-23 11:19:33]
  Epoch: [064][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3899 (0.3506)   Prec@1 89.062 (87.554)   Prec@5 99.219 (99.652)   [2019-11-23 11:19:38]
  Epoch: [064][200/391]   Time 0.058 (0.054)   Data 0.000 (0.001)   Loss 0.3279 (0.3491)   Prec@1 91.406 (87.823)   Prec@5 98.438 (99.592)   [2019-11-23 11:19:44]
  Epoch: [064][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4928 (0.3571)   Prec@1 78.906 (87.692)   Prec@5 97.656 (99.535)   [2019-11-23 11:19:49]
  **Train** Prec@1 87.740 Prec@5 99.548 Error@1 12.260
  **Test** Prec@1 83.720 Prec@5 99.170 Error@1 16.280

==>>[2019-11-23 11:19:56] [Epoch=065/200] [Need: 00:49:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [065][000/391]   Time 0.255 (0.255)   Data 0.196 (0.196)   Loss 0.3545 (0.3545)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:19:56]
  Epoch: [065][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.2933 (0.3423)   Prec@1 89.844 (88.397)   Prec@5 100.000 (99.636)   [2019-11-23 11:20:01]
  Epoch: [065][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.3008 (0.3445)   Prec@1 85.938 (88.270)   Prec@5 100.000 (99.639)   [2019-11-23 11:20:07]
  Epoch: [065][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2856 (0.3481)   Prec@1 88.281 (88.157)   Prec@5 100.000 (99.600)   [2019-11-23 11:20:12]
  **Train** Prec@1 88.172 Prec@5 99.604 Error@1 11.828
  **Test** Prec@1 82.170 Prec@5 99.270 Error@1 17.830

==>>[2019-11-23 11:20:18] [Epoch=066/200] [Need: 00:49:35] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [066][000/391]   Time 0.277 (0.277)   Data 0.216 (0.216)   Loss 0.3867 (0.3867)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-23 11:20:19]
  Epoch: [066][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.5451 (0.3509)   Prec@1 81.250 (87.933)   Prec@5 99.219 (99.544)   [2019-11-23 11:20:24]
  Epoch: [066][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.3481 (0.3550)   Prec@1 87.500 (87.725)   Prec@5 98.438 (99.502)   [2019-11-23 11:20:29]
  Epoch: [066][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.3021 (0.3562)   Prec@1 92.188 (87.715)   Prec@5 100.000 (99.530)   [2019-11-23 11:20:34]
  **Train** Prec@1 87.736 Prec@5 99.550 Error@1 12.264
  **Test** Prec@1 80.820 Prec@5 98.500 Error@1 19.180

==>>[2019-11-23 11:20:40] [Epoch=067/200] [Need: 00:49:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [067][000/391]   Time 0.260 (0.260)   Data 0.200 (0.200)   Loss 0.4071 (0.4071)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-23 11:20:40]
  Epoch: [067][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.4197 (0.3406)   Prec@1 85.156 (88.188)   Prec@5 99.219 (99.621)   [2019-11-23 11:20:46]
  Epoch: [067][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.3050 (0.3524)   Prec@1 89.844 (87.830)   Prec@5 99.219 (99.572)   [2019-11-23 11:20:51]
  Epoch: [067][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3748 (0.3515)   Prec@1 85.938 (87.835)   Prec@5 99.219 (99.605)   [2019-11-23 11:20:56]
  **Train** Prec@1 87.802 Prec@5 99.594 Error@1 12.198
  **Test** Prec@1 80.280 Prec@5 98.920 Error@1 19.720

==>>[2019-11-23 11:21:02] [Epoch=068/200] [Need: 00:48:49] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [068][000/391]   Time 0.254 (0.254)   Data 0.193 (0.193)   Loss 0.2590 (0.2590)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 11:21:03]
  Epoch: [068][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3099 (0.3464)   Prec@1 86.719 (87.995)   Prec@5 100.000 (99.667)   [2019-11-23 11:21:08]
  Epoch: [068][200/391]   Time 0.074 (0.053)   Data 0.000 (0.001)   Loss 0.4113 (0.3511)   Prec@1 85.938 (87.916)   Prec@5 99.219 (99.619)   [2019-11-23 11:21:13]
  Epoch: [068][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2408 (0.3461)   Prec@1 90.625 (88.055)   Prec@5 100.000 (99.611)   [2019-11-23 11:21:18]
  **Train** Prec@1 88.046 Prec@5 99.610 Error@1 11.954
  **Test** Prec@1 81.150 Prec@5 98.270 Error@1 18.850

==>>[2019-11-23 11:21:24] [Epoch=069/200] [Need: 00:48:27] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [069][000/391]   Time 0.252 (0.252)   Data 0.190 (0.190)   Loss 0.2047 (0.2047)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:21:25]
  Epoch: [069][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.3545 (0.3406)   Prec@1 87.500 (88.088)   Prec@5 99.219 (99.675)   [2019-11-23 11:21:30]
  Epoch: [069][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3946 (0.3430)   Prec@1 86.719 (88.118)   Prec@5 100.000 (99.635)   [2019-11-23 11:21:35]
  Epoch: [069][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3331 (0.3463)   Prec@1 89.844 (87.928)   Prec@5 99.219 (99.621)   [2019-11-23 11:21:40]
  **Train** Prec@1 87.760 Prec@5 99.592 Error@1 12.240
  **Test** Prec@1 83.800 Prec@5 99.340 Error@1 16.200

==>>[2019-11-23 11:21:46] [Epoch=070/200] [Need: 00:48:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [070][000/391]   Time 0.265 (0.265)   Data 0.190 (0.190)   Loss 0.3083 (0.3083)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 11:21:47]
  Epoch: [070][100/391]   Time 0.081 (0.056)   Data 0.000 (0.002)   Loss 0.1776 (0.3285)   Prec@1 94.531 (88.807)   Prec@5 100.000 (99.675)   [2019-11-23 11:21:52]
  Epoch: [070][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.2472 (0.3442)   Prec@1 94.531 (88.223)   Prec@5 100.000 (99.650)   [2019-11-23 11:21:56]
  Epoch: [070][300/391]   Time 0.047 (0.049)   Data 0.000 (0.001)   Loss 0.3776 (0.3450)   Prec@1 85.156 (88.232)   Prec@5 100.000 (99.644)   [2019-11-23 11:22:01]
  **Train** Prec@1 88.178 Prec@5 99.626 Error@1 11.822
  **Test** Prec@1 80.870 Prec@5 99.060 Error@1 19.130

==>>[2019-11-23 11:22:08] [Epoch=071/200] [Need: 00:47:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [071][000/391]   Time 0.264 (0.264)   Data 0.192 (0.192)   Loss 0.2755 (0.2755)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-23 11:22:08]
  Epoch: [071][100/391]   Time 0.057 (0.054)   Data 0.000 (0.002)   Loss 0.4200 (0.3489)   Prec@1 84.375 (87.794)   Prec@5 100.000 (99.683)   [2019-11-23 11:22:13]
  Epoch: [071][200/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.3247 (0.3436)   Prec@1 87.500 (87.920)   Prec@5 99.219 (99.646)   [2019-11-23 11:22:18]
  Epoch: [071][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2599 (0.3489)   Prec@1 89.062 (87.843)   Prec@5 100.000 (99.595)   [2019-11-23 11:22:24]
  **Train** Prec@1 87.810 Prec@5 99.596 Error@1 12.190
  **Test** Prec@1 82.240 Prec@5 98.860 Error@1 17.760

==>>[2019-11-23 11:22:30] [Epoch=072/200] [Need: 00:47:19] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [072][000/391]   Time 0.254 (0.254)   Data 0.197 (0.197)   Loss 0.3050 (0.3050)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 11:22:30]
  Epoch: [072][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.3323 (0.3229)   Prec@1 88.281 (88.776)   Prec@5 99.219 (99.536)   [2019-11-23 11:22:36]
  Epoch: [072][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.2668 (0.3331)   Prec@1 92.188 (88.402)   Prec@5 98.438 (99.576)   [2019-11-23 11:22:41]
  Epoch: [072][300/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 0.4428 (0.3428)   Prec@1 79.688 (88.024)   Prec@5 100.000 (99.569)   [2019-11-23 11:22:46]
  **Train** Prec@1 87.834 Prec@5 99.564 Error@1 12.166
  **Test** Prec@1 83.070 Prec@5 98.440 Error@1 16.930

==>>[2019-11-23 11:22:53] [Epoch=073/200] [Need: 00:46:58] [LR=0.0100][M=0.90] [Best : Accuracy=85.13, Error=14.87]
  Epoch: [073][000/391]   Time 0.272 (0.272)   Data 0.203 (0.203)   Loss 0.3720 (0.3720)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2019-11-23 11:22:53]
  Epoch: [073][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.3719 (0.3372)   Prec@1 86.719 (88.127)   Prec@5 99.219 (99.644)   [2019-11-23 11:22:59]
  Epoch: [073][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.2688 (0.3432)   Prec@1 89.844 (88.036)   Prec@5 100.000 (99.631)   [2019-11-23 11:23:04]
  Epoch: [073][300/391]   Time 0.082 (0.054)   Data 0.000 (0.001)   Loss 0.2967 (0.3432)   Prec@1 88.281 (88.006)   Prec@5 100.000 (99.593)   [2019-11-23 11:23:09]
  **Train** Prec@1 88.026 Prec@5 99.602 Error@1 11.974
  **Test** Prec@1 85.420 Prec@5 99.480 Error@1 14.580
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:23:16] [Epoch=074/200] [Need: 00:46:36] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [074][000/391]   Time 0.249 (0.249)   Data 0.181 (0.181)   Loss 0.3734 (0.3734)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-23 11:23:16]
  Epoch: [074][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.4097 (0.3254)   Prec@1 88.281 (88.529)   Prec@5 100.000 (99.706)   [2019-11-23 11:23:21]
  Epoch: [074][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.3936 (0.3312)   Prec@1 86.719 (88.546)   Prec@5 99.219 (99.743)   [2019-11-23 11:23:26]
  Epoch: [074][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.3628 (0.3400)   Prec@1 86.719 (88.315)   Prec@5 100.000 (99.673)   [2019-11-23 11:23:31]
  **Train** Prec@1 88.198 Prec@5 99.656 Error@1 11.802
  **Test** Prec@1 84.470 Prec@5 99.090 Error@1 15.530

==>>[2019-11-23 11:23:37] [Epoch=075/200] [Need: 00:46:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [075][000/391]   Time 0.265 (0.265)   Data 0.182 (0.182)   Loss 0.3849 (0.3849)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-23 11:23:37]
  Epoch: [075][100/391]   Time 0.040 (0.052)   Data 0.000 (0.002)   Loss 0.2843 (0.3292)   Prec@1 87.500 (88.761)   Prec@5 100.000 (99.613)   [2019-11-23 11:23:42]
  Epoch: [075][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.3783 (0.3354)   Prec@1 87.500 (88.526)   Prec@5 100.000 (99.615)   [2019-11-23 11:23:47]
  Epoch: [075][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.3839 (0.3413)   Prec@1 88.281 (88.312)   Prec@5 99.219 (99.585)   [2019-11-23 11:23:52]
  **Train** Prec@1 88.224 Prec@5 99.586 Error@1 11.776
  **Test** Prec@1 84.370 Prec@5 99.290 Error@1 15.630

==>>[2019-11-23 11:23:59] [Epoch=076/200] [Need: 00:45:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [076][000/391]   Time 0.239 (0.239)   Data 0.178 (0.178)   Loss 0.2965 (0.2965)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 11:23:59]
  Epoch: [076][100/391]   Time 0.053 (0.057)   Data 0.000 (0.002)   Loss 0.2850 (0.3319)   Prec@1 92.969 (88.405)   Prec@5 100.000 (99.644)   [2019-11-23 11:24:04]
  Epoch: [076][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3081 (0.3400)   Prec@1 89.062 (88.157)   Prec@5 100.000 (99.658)   [2019-11-23 11:24:10]
  Epoch: [076][300/391]   Time 0.077 (0.054)   Data 0.000 (0.001)   Loss 0.2874 (0.3393)   Prec@1 90.625 (88.232)   Prec@5 100.000 (99.647)   [2019-11-23 11:24:15]
  **Train** Prec@1 88.070 Prec@5 99.628 Error@1 11.930
  **Test** Prec@1 82.260 Prec@5 99.300 Error@1 17.740

==>>[2019-11-23 11:24:22] [Epoch=077/200] [Need: 00:45:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [077][000/391]   Time 0.252 (0.252)   Data 0.183 (0.183)   Loss 0.2505 (0.2505)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 11:24:22]
  Epoch: [077][100/391]   Time 0.043 (0.060)   Data 0.000 (0.002)   Loss 0.3887 (0.3312)   Prec@1 86.719 (88.304)   Prec@5 100.000 (99.644)   [2019-11-23 11:24:28]
  Epoch: [077][200/391]   Time 0.051 (0.056)   Data 0.000 (0.001)   Loss 0.3581 (0.3312)   Prec@1 88.281 (88.448)   Prec@5 99.219 (99.588)   [2019-11-23 11:24:33]
  Epoch: [077][300/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.2598 (0.3337)   Prec@1 88.281 (88.359)   Prec@5 100.000 (99.618)   [2019-11-23 11:24:38]
  **Train** Prec@1 88.262 Prec@5 99.600 Error@1 11.738
  **Test** Prec@1 83.300 Prec@5 99.150 Error@1 16.700

==>>[2019-11-23 11:24:44] [Epoch=078/200] [Need: 00:45:08] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [078][000/391]   Time 0.276 (0.276)   Data 0.189 (0.189)   Loss 0.3418 (0.3418)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-23 11:24:45]
  Epoch: [078][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.4573 (0.3197)   Prec@1 85.156 (89.202)   Prec@5 97.656 (99.698)   [2019-11-23 11:24:50]
  Epoch: [078][200/391]   Time 0.049 (0.054)   Data 0.000 (0.001)   Loss 0.3466 (0.3309)   Prec@1 88.281 (88.491)   Prec@5 99.219 (99.646)   [2019-11-23 11:24:55]
  Epoch: [078][300/391]   Time 0.065 (0.052)   Data 0.000 (0.001)   Loss 0.3321 (0.3314)   Prec@1 89.062 (88.551)   Prec@5 100.000 (99.621)   [2019-11-23 11:25:00]
  **Train** Prec@1 88.236 Prec@5 99.614 Error@1 11.764
  **Test** Prec@1 84.200 Prec@5 99.220 Error@1 15.800

==>>[2019-11-23 11:25:07] [Epoch=079/200] [Need: 00:44:46] [LR=0.0100][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [079][000/391]   Time 0.254 (0.254)   Data 0.199 (0.199)   Loss 0.3061 (0.3061)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-23 11:25:07]
  Epoch: [079][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.4051 (0.3281)   Prec@1 89.062 (88.382)   Prec@5 99.219 (99.675)   [2019-11-23 11:25:12]
  Epoch: [079][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.3630 (0.3310)   Prec@1 84.375 (88.429)   Prec@5 100.000 (99.677)   [2019-11-23 11:25:18]
  Epoch: [079][300/391]   Time 0.050 (0.054)   Data 0.000 (0.001)   Loss 0.3017 (0.3384)   Prec@1 88.281 (88.180)   Prec@5 99.219 (99.650)   [2019-11-23 11:25:23]
  **Train** Prec@1 88.062 Prec@5 99.632 Error@1 11.938
  **Test** Prec@1 84.410 Prec@5 99.120 Error@1 15.590

==>>[2019-11-23 11:25:29] [Epoch=080/200] [Need: 00:44:24] [LR=0.0010][M=0.90] [Best : Accuracy=85.42, Error=14.58]
  Epoch: [080][000/391]   Time 0.255 (0.255)   Data 0.180 (0.180)   Loss 0.4351 (0.4351)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2019-11-23 11:25:30]
  Epoch: [080][100/391]   Time 0.039 (0.053)   Data 0.000 (0.002)   Loss 0.3336 (0.2702)   Prec@1 86.719 (90.625)   Prec@5 100.000 (99.791)   [2019-11-23 11:25:35]
  Epoch: [080][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1872 (0.2572)   Prec@1 94.531 (91.177)   Prec@5 100.000 (99.817)   [2019-11-23 11:25:40]
  Epoch: [080][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.2226 (0.2505)   Prec@1 91.406 (91.393)   Prec@5 100.000 (99.824)   [2019-11-23 11:25:45]
  **Train** Prec@1 91.620 Prec@5 99.802 Error@1 8.380
  **Test** Prec@1 89.000 Prec@5 99.600 Error@1 11.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:25:52] [Epoch=081/200] [Need: 00:44:03] [LR=0.0010][M=0.90] [Best : Accuracy=89.00, Error=11.00]
  Epoch: [081][000/391]   Time 0.260 (0.260)   Data 0.202 (0.202)   Loss 0.2264 (0.2264)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-23 11:25:52]
  Epoch: [081][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.2475 (0.2174)   Prec@1 92.969 (92.551)   Prec@5 99.219 (99.799)   [2019-11-23 11:25:57]
  Epoch: [081][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.2897 (0.2198)   Prec@1 92.188 (92.514)   Prec@5 100.000 (99.817)   [2019-11-23 11:26:02]
  Epoch: [081][300/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.2018 (0.2153)   Prec@1 92.969 (92.624)   Prec@5 100.000 (99.834)   [2019-11-23 11:26:08]
  **Train** Prec@1 92.582 Prec@5 99.846 Error@1 7.418
  **Test** Prec@1 89.220 Prec@5 99.610 Error@1 10.780
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:26:15] [Epoch=082/200] [Need: 00:43:41] [LR=0.0010][M=0.90] [Best : Accuracy=89.22, Error=10.78]
  Epoch: [082][000/391]   Time 0.242 (0.242)   Data 0.172 (0.172)   Loss 0.1538 (0.1538)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:26:15]
  Epoch: [082][100/391]   Time 0.048 (0.057)   Data 0.000 (0.002)   Loss 0.3287 (0.2012)   Prec@1 89.062 (93.077)   Prec@5 100.000 (99.838)   [2019-11-23 11:26:20]
  Epoch: [082][200/391]   Time 0.052 (0.055)   Data 0.000 (0.001)   Loss 0.2702 (0.2059)   Prec@1 90.625 (92.910)   Prec@5 100.000 (99.837)   [2019-11-23 11:26:26]
  Epoch: [082][300/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.1447 (0.2073)   Prec@1 94.531 (92.893)   Prec@5 100.000 (99.829)   [2019-11-23 11:26:31]
  **Train** Prec@1 92.954 Prec@5 99.828 Error@1 7.046
  **Test** Prec@1 89.240 Prec@5 99.630 Error@1 10.760
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:26:37] [Epoch=083/200] [Need: 00:43:19] [LR=0.0010][M=0.90] [Best : Accuracy=89.24, Error=10.76]
  Epoch: [083][000/391]   Time 0.252 (0.252)   Data 0.197 (0.197)   Loss 0.1991 (0.1991)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-23 11:26:38]
  Epoch: [083][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.1498 (0.2027)   Prec@1 95.312 (93.015)   Prec@5 100.000 (99.853)   [2019-11-23 11:26:43]
  Epoch: [083][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.2884 (0.1989)   Prec@1 89.844 (93.081)   Prec@5 99.219 (99.845)   [2019-11-23 11:26:48]
  Epoch: [083][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1835 (0.1971)   Prec@1 95.312 (93.122)   Prec@5 99.219 (99.849)   [2019-11-23 11:26:53]
  **Train** Prec@1 93.082 Prec@5 99.844 Error@1 6.918
  **Test** Prec@1 89.240 Prec@5 99.560 Error@1 10.760
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:27:00] [Epoch=084/200] [Need: 00:42:58] [LR=0.0010][M=0.90] [Best : Accuracy=89.24, Error=10.76]
  Epoch: [084][000/391]   Time 0.260 (0.260)   Data 0.205 (0.205)   Loss 0.1865 (0.1865)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:27:01]
  Epoch: [084][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.1570 (0.1887)   Prec@1 96.094 (93.425)   Prec@5 99.219 (99.915)   [2019-11-23 11:27:06]
  Epoch: [084][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1882 (0.1907)   Prec@1 93.750 (93.373)   Prec@5 100.000 (99.891)   [2019-11-23 11:27:11]
  Epoch: [084][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.2717 (0.1936)   Prec@1 91.406 (93.239)   Prec@5 98.438 (99.862)   [2019-11-23 11:27:16]
  **Train** Prec@1 93.122 Prec@5 99.860 Error@1 6.878
  **Test** Prec@1 89.210 Prec@5 99.610 Error@1 10.790

==>>[2019-11-23 11:27:22] [Epoch=085/200] [Need: 00:42:36] [LR=0.0010][M=0.90] [Best : Accuracy=89.24, Error=10.76]
  Epoch: [085][000/391]   Time 0.269 (0.269)   Data 0.183 (0.183)   Loss 0.1976 (0.1976)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2019-11-23 11:27:23]
  Epoch: [085][100/391]   Time 0.069 (0.056)   Data 0.000 (0.002)   Loss 0.1715 (0.1927)   Prec@1 94.531 (93.356)   Prec@5 100.000 (99.884)   [2019-11-23 11:27:28]
  Epoch: [085][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.1407 (0.1857)   Prec@1 96.094 (93.571)   Prec@5 100.000 (99.891)   [2019-11-23 11:27:33]
  Epoch: [085][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.1456 (0.1871)   Prec@1 95.312 (93.514)   Prec@5 100.000 (99.878)   [2019-11-23 11:27:38]
  **Train** Prec@1 93.450 Prec@5 99.880 Error@1 6.550
  **Test** Prec@1 89.650 Prec@5 99.540 Error@1 10.350
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:27:44] [Epoch=086/200] [Need: 00:42:13] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [086][000/391]   Time 0.252 (0.252)   Data 0.188 (0.188)   Loss 0.1767 (0.1767)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:27:45]
  Epoch: [086][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1761 (0.1707)   Prec@1 93.750 (93.967)   Prec@5 100.000 (99.915)   [2019-11-23 11:27:50]
  Epoch: [086][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2234 (0.1816)   Prec@1 91.406 (93.556)   Prec@5 99.219 (99.876)   [2019-11-23 11:27:54]
  Epoch: [086][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.2451 (0.1850)   Prec@1 92.188 (93.545)   Prec@5 100.000 (99.857)   [2019-11-23 11:27:59]
  **Train** Prec@1 93.474 Prec@5 99.862 Error@1 6.526
  **Test** Prec@1 89.360 Prec@5 99.600 Error@1 10.640

==>>[2019-11-23 11:28:06] [Epoch=087/200] [Need: 00:41:50] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [087][000/391]   Time 0.265 (0.265)   Data 0.206 (0.206)   Loss 0.1403 (0.1403)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:28:06]
  Epoch: [087][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1843 (0.1787)   Prec@1 94.531 (93.796)   Prec@5 100.000 (99.845)   [2019-11-23 11:28:11]
  Epoch: [087][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1737 (0.1799)   Prec@1 93.750 (93.773)   Prec@5 100.000 (99.864)   [2019-11-23 11:28:16]
  Epoch: [087][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.1034 (0.1802)   Prec@1 97.656 (93.724)   Prec@5 100.000 (99.875)   [2019-11-23 11:28:21]
  **Train** Prec@1 93.654 Prec@5 99.882 Error@1 6.346
  **Test** Prec@1 89.210 Prec@5 99.560 Error@1 10.790

==>>[2019-11-23 11:28:28] [Epoch=088/200] [Need: 00:41:28] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [088][000/391]   Time 0.269 (0.269)   Data 0.185 (0.185)   Loss 0.1245 (0.1245)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:28:28]
  Epoch: [088][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.1989 (0.1826)   Prec@1 90.625 (93.572)   Prec@5 99.219 (99.899)   [2019-11-23 11:28:33]
  Epoch: [088][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.1869 (0.1798)   Prec@1 92.969 (93.657)   Prec@5 100.000 (99.907)   [2019-11-23 11:28:39]
  Epoch: [088][300/391]   Time 0.060 (0.054)   Data 0.000 (0.001)   Loss 0.1874 (0.1789)   Prec@1 92.969 (93.716)   Prec@5 100.000 (99.904)   [2019-11-23 11:28:44]
  **Train** Prec@1 93.772 Prec@5 99.896 Error@1 6.228
  **Test** Prec@1 89.000 Prec@5 99.570 Error@1 11.000

==>>[2019-11-23 11:28:50] [Epoch=089/200] [Need: 00:41:06] [LR=0.0010][M=0.90] [Best : Accuracy=89.65, Error=10.35]
  Epoch: [089][000/391]   Time 0.267 (0.267)   Data 0.204 (0.204)   Loss 0.2793 (0.2793)   Prec@1 93.750 (93.750)   Prec@5 98.438 (98.438)   [2019-11-23 11:28:51]
  Epoch: [089][100/391]   Time 0.056 (0.054)   Data 0.000 (0.002)   Loss 0.1928 (0.1751)   Prec@1 93.750 (93.897)   Prec@5 100.000 (99.861)   [2019-11-23 11:28:56]
  Epoch: [089][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.2056 (0.1786)   Prec@1 92.969 (93.867)   Prec@5 100.000 (99.868)   [2019-11-23 11:29:01]
  Epoch: [089][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.1554 (0.1749)   Prec@1 96.094 (93.971)   Prec@5 100.000 (99.891)   [2019-11-23 11:29:06]
  **Train** Prec@1 93.944 Prec@5 99.896 Error@1 6.056
  **Test** Prec@1 89.770 Prec@5 99.640 Error@1 10.230
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:29:13] [Epoch=090/200] [Need: 00:40:44] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [090][000/391]   Time 0.269 (0.269)   Data 0.183 (0.183)   Loss 0.2442 (0.2442)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:29:13]
  Epoch: [090][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.0730 (0.1628)   Prec@1 98.438 (94.400)   Prec@5 100.000 (99.907)   [2019-11-23 11:29:18]
  Epoch: [090][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1887 (0.1633)   Prec@1 94.531 (94.275)   Prec@5 100.000 (99.934)   [2019-11-23 11:29:23]
  Epoch: [090][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.2844 (0.1665)   Prec@1 92.188 (94.207)   Prec@5 100.000 (99.922)   [2019-11-23 11:29:28]
  **Train** Prec@1 94.200 Prec@5 99.910 Error@1 5.800
  **Test** Prec@1 89.660 Prec@5 99.590 Error@1 10.340

==>>[2019-11-23 11:29:35] [Epoch=091/200] [Need: 00:40:21] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [091][000/391]   Time 0.264 (0.264)   Data 0.179 (0.179)   Loss 0.2119 (0.2119)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:29:35]
  Epoch: [091][100/391]   Time 0.055 (0.056)   Data 0.000 (0.002)   Loss 0.1564 (0.1657)   Prec@1 95.312 (94.291)   Prec@5 100.000 (99.915)   [2019-11-23 11:29:41]
  Epoch: [091][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1285 (0.1668)   Prec@1 94.531 (94.123)   Prec@5 100.000 (99.911)   [2019-11-23 11:29:46]
  Epoch: [091][300/391]   Time 0.054 (0.054)   Data 0.000 (0.001)   Loss 0.2147 (0.1669)   Prec@1 89.844 (94.085)   Prec@5 100.000 (99.912)   [2019-11-23 11:29:51]
  **Train** Prec@1 94.076 Prec@5 99.906 Error@1 5.924
  **Test** Prec@1 89.220 Prec@5 99.610 Error@1 10.780

==>>[2019-11-23 11:29:58] [Epoch=092/200] [Need: 00:40:00] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [092][000/391]   Time 0.259 (0.259)   Data 0.194 (0.194)   Loss 0.1182 (0.1182)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:29:58]
  Epoch: [092][100/391]   Time 0.051 (0.058)   Data 0.000 (0.002)   Loss 0.1684 (0.1607)   Prec@1 93.750 (94.322)   Prec@5 100.000 (99.930)   [2019-11-23 11:30:03]
  Epoch: [092][200/391]   Time 0.061 (0.055)   Data 0.000 (0.001)   Loss 0.2047 (0.1653)   Prec@1 93.750 (94.150)   Prec@5 99.219 (99.930)   [2019-11-23 11:30:09]
  Epoch: [092][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1617 (0.1642)   Prec@1 94.531 (94.215)   Prec@5 100.000 (99.930)   [2019-11-23 11:30:14]
  **Train** Prec@1 94.184 Prec@5 99.922 Error@1 5.816
  **Test** Prec@1 89.380 Prec@5 99.560 Error@1 10.620

==>>[2019-11-23 11:30:20] [Epoch=093/200] [Need: 00:39:38] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [093][000/391]   Time 0.245 (0.245)   Data 0.185 (0.185)   Loss 0.1386 (0.1386)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.219)   [2019-11-23 11:30:21]
  Epoch: [093][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.1728 (0.1498)   Prec@1 95.312 (94.756)   Prec@5 100.000 (99.923)   [2019-11-23 11:30:26]
  Epoch: [093][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.2635 (0.1569)   Prec@1 91.406 (94.613)   Prec@5 98.438 (99.899)   [2019-11-23 11:30:31]
  Epoch: [093][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1634 (0.1645)   Prec@1 96.094 (94.303)   Prec@5 100.000 (99.896)   [2019-11-23 11:30:36]
  **Train** Prec@1 94.324 Prec@5 99.900 Error@1 5.676
  **Test** Prec@1 89.370 Prec@5 99.590 Error@1 10.630

==>>[2019-11-23 11:30:43] [Epoch=094/200] [Need: 00:39:17] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [094][000/391]   Time 0.261 (0.261)   Data 0.196 (0.196)   Loss 0.1993 (0.1993)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:30:43]
  Epoch: [094][100/391]   Time 0.057 (0.053)   Data 0.000 (0.002)   Loss 0.1731 (0.1578)   Prec@1 92.188 (94.616)   Prec@5 100.000 (99.923)   [2019-11-23 11:30:48]
  Epoch: [094][200/391]   Time 0.046 (0.054)   Data 0.000 (0.001)   Loss 0.1386 (0.1598)   Prec@1 93.750 (94.527)   Prec@5 100.000 (99.911)   [2019-11-23 11:30:54]
  Epoch: [094][300/391]   Time 0.077 (0.054)   Data 0.000 (0.001)   Loss 0.1862 (0.1617)   Prec@1 93.750 (94.381)   Prec@5 100.000 (99.899)   [2019-11-23 11:30:59]
  **Train** Prec@1 94.354 Prec@5 99.908 Error@1 5.646
  **Test** Prec@1 89.370 Prec@5 99.600 Error@1 10.630

==>>[2019-11-23 11:31:06] [Epoch=095/200] [Need: 00:38:55] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [095][000/391]   Time 0.260 (0.260)   Data 0.180 (0.180)   Loss 0.1389 (0.1389)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:31:06]
  Epoch: [095][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1155 (0.1477)   Prec@1 96.094 (94.763)   Prec@5 100.000 (99.954)   [2019-11-23 11:31:12]
  Epoch: [095][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.1109 (0.1556)   Prec@1 96.094 (94.621)   Prec@5 100.000 (99.922)   [2019-11-23 11:31:17]
  Epoch: [095][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.2129 (0.1575)   Prec@1 94.531 (94.526)   Prec@5 99.219 (99.899)   [2019-11-23 11:31:22]
  **Train** Prec@1 94.346 Prec@5 99.890 Error@1 5.654
  **Test** Prec@1 88.940 Prec@5 99.450 Error@1 11.060

==>>[2019-11-23 11:31:29] [Epoch=096/200] [Need: 00:38:33] [LR=0.0010][M=0.90] [Best : Accuracy=89.77, Error=10.23]
  Epoch: [096][000/391]   Time 0.257 (0.257)   Data 0.191 (0.191)   Loss 0.1668 (0.1668)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:31:29]
  Epoch: [096][100/391]   Time 0.048 (0.054)   Data 0.000 (0.002)   Loss 0.0937 (0.1519)   Prec@1 96.875 (94.740)   Prec@5 100.000 (99.930)   [2019-11-23 11:31:34]
  Epoch: [096][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.1065 (0.1529)   Prec@1 97.656 (94.788)   Prec@5 100.000 (99.918)   [2019-11-23 11:31:39]
  Epoch: [096][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.1355 (0.1528)   Prec@1 95.312 (94.744)   Prec@5 100.000 (99.922)   [2019-11-23 11:31:45]
  **Train** Prec@1 94.678 Prec@5 99.922 Error@1 5.322
  **Test** Prec@1 89.960 Prec@5 99.650 Error@1 10.040
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:31:51] [Epoch=097/200] [Need: 00:38:12] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [097][000/391]   Time 0.265 (0.265)   Data 0.207 (0.207)   Loss 0.2346 (0.2346)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:31:52]
  Epoch: [097][100/391]   Time 0.056 (0.056)   Data 0.000 (0.002)   Loss 0.0971 (0.1495)   Prec@1 96.094 (94.810)   Prec@5 100.000 (99.907)   [2019-11-23 11:31:57]
  Epoch: [097][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.1886 (0.1532)   Prec@1 92.188 (94.667)   Prec@5 99.219 (99.938)   [2019-11-23 11:32:02]
  Epoch: [097][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1051 (0.1570)   Prec@1 96.875 (94.516)   Prec@5 100.000 (99.912)   [2019-11-23 11:32:07]
  **Train** Prec@1 94.494 Prec@5 99.916 Error@1 5.506
  **Test** Prec@1 89.650 Prec@5 99.630 Error@1 10.350

==>>[2019-11-23 11:32:14] [Epoch=098/200] [Need: 00:37:49] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [098][000/391]   Time 0.270 (0.270)   Data 0.190 (0.190)   Loss 0.1474 (0.1474)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:32:14]
  Epoch: [098][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.2634 (0.1468)   Prec@1 89.062 (94.910)   Prec@5 100.000 (99.884)   [2019-11-23 11:32:19]
  Epoch: [098][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1670 (0.1498)   Prec@1 93.750 (94.621)   Prec@5 100.000 (99.914)   [2019-11-23 11:32:24]
  Epoch: [098][300/391]   Time 0.056 (0.053)   Data 0.000 (0.001)   Loss 0.1225 (0.1544)   Prec@1 95.312 (94.433)   Prec@5 100.000 (99.912)   [2019-11-23 11:32:30]
  **Train** Prec@1 94.532 Prec@5 99.904 Error@1 5.468
  **Test** Prec@1 89.530 Prec@5 99.650 Error@1 10.470

==>>[2019-11-23 11:32:36] [Epoch=099/200] [Need: 00:37:27] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [099][000/391]   Time 0.266 (0.266)   Data 0.180 (0.180)   Loss 0.1198 (0.1198)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:32:36]
  Epoch: [099][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.2253 (0.1446)   Prec@1 92.188 (94.895)   Prec@5 100.000 (99.946)   [2019-11-23 11:32:42]
  Epoch: [099][200/391]   Time 0.038 (0.053)   Data 0.000 (0.001)   Loss 0.1134 (0.1444)   Prec@1 96.875 (94.978)   Prec@5 100.000 (99.946)   [2019-11-23 11:32:47]
  Epoch: [099][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.1014 (0.1478)   Prec@1 95.312 (94.778)   Prec@5 100.000 (99.938)   [2019-11-23 11:32:52]
  **Train** Prec@1 94.734 Prec@5 99.942 Error@1 5.266
  **Test** Prec@1 89.220 Prec@5 99.560 Error@1 10.780

==>>[2019-11-23 11:32:58] [Epoch=100/200] [Need: 00:37:05] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [100][000/391]   Time 0.260 (0.260)   Data 0.195 (0.195)   Loss 0.2348 (0.2348)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:32:58]
  Epoch: [100][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.0905 (0.1449)   Prec@1 98.438 (94.879)   Prec@5 100.000 (99.946)   [2019-11-23 11:33:04]
  Epoch: [100][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.1433 (0.1462)   Prec@1 95.312 (94.900)   Prec@5 100.000 (99.926)   [2019-11-23 11:33:09]
  Epoch: [100][300/391]   Time 0.067 (0.053)   Data 0.000 (0.001)   Loss 0.1868 (0.1483)   Prec@1 95.312 (94.778)   Prec@5 100.000 (99.940)   [2019-11-23 11:33:14]
  **Train** Prec@1 94.746 Prec@5 99.932 Error@1 5.254
  **Test** Prec@1 89.930 Prec@5 99.660 Error@1 10.070

==>>[2019-11-23 11:33:21] [Epoch=101/200] [Need: 00:36:43] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [101][000/391]   Time 0.284 (0.284)   Data 0.225 (0.225)   Loss 0.1663 (0.1663)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:33:21]
  Epoch: [101][100/391]   Time 0.065 (0.051)   Data 0.000 (0.002)   Loss 0.0358 (0.1440)   Prec@1 99.219 (95.204)   Prec@5 100.000 (99.892)   [2019-11-23 11:33:26]
  Epoch: [101][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.1397 (0.1464)   Prec@1 94.531 (95.037)   Prec@5 100.000 (99.899)   [2019-11-23 11:33:31]
  Epoch: [101][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1507 (0.1465)   Prec@1 95.312 (94.970)   Prec@5 100.000 (99.912)   [2019-11-23 11:33:36]
  **Train** Prec@1 94.894 Prec@5 99.914 Error@1 5.106
  **Test** Prec@1 89.340 Prec@5 99.620 Error@1 10.660

==>>[2019-11-23 11:33:43] [Epoch=102/200] [Need: 00:36:20] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [102][000/391]   Time 0.256 (0.256)   Data 0.198 (0.198)   Loss 0.1483 (0.1483)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:33:43]
  Epoch: [102][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1645 (0.1377)   Prec@1 92.188 (95.258)   Prec@5 100.000 (99.899)   [2019-11-23 11:33:48]
  Epoch: [102][200/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.1503 (0.1423)   Prec@1 92.969 (94.978)   Prec@5 100.000 (99.930)   [2019-11-23 11:33:53]
  Epoch: [102][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.1383 (0.1429)   Prec@1 94.531 (94.921)   Prec@5 100.000 (99.933)   [2019-11-23 11:33:58]
  **Train** Prec@1 94.870 Prec@5 99.932 Error@1 5.130
  **Test** Prec@1 89.030 Prec@5 99.500 Error@1 10.970

==>>[2019-11-23 11:34:05] [Epoch=103/200] [Need: 00:35:58] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [103][000/391]   Time 0.261 (0.261)   Data 0.197 (0.197)   Loss 0.0670 (0.0670)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:34:05]
  Epoch: [103][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.2371 (0.1447)   Prec@1 91.406 (95.042)   Prec@5 100.000 (99.899)   [2019-11-23 11:34:10]
  Epoch: [103][200/391]   Time 0.084 (0.053)   Data 0.000 (0.001)   Loss 0.1875 (0.1471)   Prec@1 94.531 (94.850)   Prec@5 99.219 (99.914)   [2019-11-23 11:34:15]
  Epoch: [103][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0536 (0.1439)   Prec@1 98.438 (94.858)   Prec@5 100.000 (99.927)   [2019-11-23 11:34:20]
  **Train** Prec@1 94.868 Prec@5 99.928 Error@1 5.132
  **Test** Prec@1 89.840 Prec@5 99.590 Error@1 10.160

==>>[2019-11-23 11:34:27] [Epoch=104/200] [Need: 00:35:35] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [104][000/391]   Time 0.252 (0.252)   Data 0.174 (0.174)   Loss 0.0533 (0.0533)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:34:27]
  Epoch: [104][100/391]   Time 0.069 (0.057)   Data 0.000 (0.002)   Loss 0.1077 (0.1408)   Prec@1 94.531 (94.841)   Prec@5 100.000 (99.930)   [2019-11-23 11:34:32]
  Epoch: [104][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.1106 (0.1418)   Prec@1 95.312 (94.815)   Prec@5 100.000 (99.946)   [2019-11-23 11:34:37]
  Epoch: [104][300/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.1456 (0.1438)   Prec@1 95.312 (94.773)   Prec@5 99.219 (99.938)   [2019-11-23 11:34:42]
  **Train** Prec@1 94.748 Prec@5 99.940 Error@1 5.252
  **Test** Prec@1 89.750 Prec@5 99.580 Error@1 10.250

==>>[2019-11-23 11:34:49] [Epoch=105/200] [Need: 00:35:13] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [105][000/391]   Time 0.260 (0.260)   Data 0.198 (0.198)   Loss 0.2174 (0.2174)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:34:50]
  Epoch: [105][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.1348 (0.1390)   Prec@1 95.312 (95.073)   Prec@5 100.000 (99.961)   [2019-11-23 11:34:55]
  Epoch: [105][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.1821 (0.1385)   Prec@1 93.750 (95.095)   Prec@5 100.000 (99.957)   [2019-11-23 11:35:00]
  Epoch: [105][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.1522 (0.1396)   Prec@1 96.094 (95.061)   Prec@5 100.000 (99.948)   [2019-11-23 11:35:05]
  **Train** Prec@1 95.082 Prec@5 99.946 Error@1 4.918
  **Test** Prec@1 89.540 Prec@5 99.650 Error@1 10.460

==>>[2019-11-23 11:35:12] [Epoch=106/200] [Need: 00:34:52] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [106][000/391]   Time 0.249 (0.249)   Data 0.188 (0.188)   Loss 0.0655 (0.0655)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:35:13]
  Epoch: [106][100/391]   Time 0.046 (0.057)   Data 0.000 (0.002)   Loss 0.2421 (0.1409)   Prec@1 91.406 (94.926)   Prec@5 100.000 (99.954)   [2019-11-23 11:35:18]
  Epoch: [106][200/391]   Time 0.044 (0.056)   Data 0.000 (0.001)   Loss 0.1085 (0.1389)   Prec@1 97.656 (95.068)   Prec@5 100.000 (99.946)   [2019-11-23 11:35:23]
  Epoch: [106][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1168 (0.1396)   Prec@1 96.094 (95.040)   Prec@5 100.000 (99.935)   [2019-11-23 11:35:29]
  **Train** Prec@1 94.892 Prec@5 99.938 Error@1 5.108
  **Test** Prec@1 89.380 Prec@5 99.600 Error@1 10.620

==>>[2019-11-23 11:35:35] [Epoch=107/200] [Need: 00:34:30] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [107][000/391]   Time 0.277 (0.277)   Data 0.218 (0.218)   Loss 0.1368 (0.1368)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:35:35]
  Epoch: [107][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.1888 (0.1265)   Prec@1 92.969 (95.591)   Prec@5 100.000 (99.954)   [2019-11-23 11:35:41]
  Epoch: [107][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.1527 (0.1335)   Prec@1 92.969 (95.285)   Prec@5 100.000 (99.946)   [2019-11-23 11:35:46]
  Epoch: [107][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1350 (0.1363)   Prec@1 96.094 (95.196)   Prec@5 100.000 (99.948)   [2019-11-23 11:35:51]
  **Train** Prec@1 95.086 Prec@5 99.956 Error@1 4.914
  **Test** Prec@1 89.650 Prec@5 99.580 Error@1 10.350

==>>[2019-11-23 11:35:58] [Epoch=108/200] [Need: 00:34:08] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [108][000/391]   Time 0.259 (0.259)   Data 0.194 (0.194)   Loss 0.1018 (0.1018)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:35:58]
  Epoch: [108][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.1343 (0.1287)   Prec@1 95.312 (95.514)   Prec@5 100.000 (99.938)   [2019-11-23 11:36:03]
  Epoch: [108][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1334 (0.1330)   Prec@1 92.969 (95.297)   Prec@5 100.000 (99.922)   [2019-11-23 11:36:08]
  Epoch: [108][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1771 (0.1343)   Prec@1 92.969 (95.165)   Prec@5 100.000 (99.938)   [2019-11-23 11:36:13]
  **Train** Prec@1 95.100 Prec@5 99.946 Error@1 4.900
  **Test** Prec@1 89.850 Prec@5 99.600 Error@1 10.150

==>>[2019-11-23 11:36:20] [Epoch=109/200] [Need: 00:33:46] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [109][000/391]   Time 0.280 (0.280)   Data 0.218 (0.218)   Loss 0.1107 (0.1107)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:36:20]
  Epoch: [109][100/391]   Time 0.049 (0.055)   Data 0.000 (0.002)   Loss 0.1103 (0.1255)   Prec@1 95.312 (95.444)   Prec@5 100.000 (99.938)   [2019-11-23 11:36:25]
  Epoch: [109][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1291 (0.1333)   Prec@1 96.875 (95.312)   Prec@5 100.000 (99.934)   [2019-11-23 11:36:31]
  Epoch: [109][300/391]   Time 0.066 (0.054)   Data 0.000 (0.001)   Loss 0.1728 (0.1361)   Prec@1 93.750 (95.178)   Prec@5 100.000 (99.938)   [2019-11-23 11:36:36]
  **Train** Prec@1 95.164 Prec@5 99.944 Error@1 4.836
  **Test** Prec@1 89.790 Prec@5 99.590 Error@1 10.210

==>>[2019-11-23 11:36:43] [Epoch=110/200] [Need: 00:33:24] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [110][000/391]   Time 0.287 (0.287)   Data 0.228 (0.228)   Loss 0.1264 (0.1264)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:36:43]
  Epoch: [110][100/391]   Time 0.082 (0.053)   Data 0.000 (0.002)   Loss 0.1050 (0.1327)   Prec@1 97.656 (95.282)   Prec@5 100.000 (99.923)   [2019-11-23 11:36:48]
  Epoch: [110][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1229 (0.1348)   Prec@1 96.094 (95.211)   Prec@5 100.000 (99.942)   [2019-11-23 11:36:53]
  Epoch: [110][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0618 (0.1343)   Prec@1 97.656 (95.268)   Prec@5 100.000 (99.945)   [2019-11-23 11:36:59]
  **Train** Prec@1 95.224 Prec@5 99.946 Error@1 4.776
  **Test** Prec@1 89.100 Prec@5 99.590 Error@1 10.900

==>>[2019-11-23 11:37:05] [Epoch=111/200] [Need: 00:33:02] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [111][000/391]   Time 0.264 (0.264)   Data 0.186 (0.186)   Loss 0.1257 (0.1257)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:37:05]
  Epoch: [111][100/391]   Time 0.082 (0.052)   Data 0.000 (0.002)   Loss 0.1741 (0.1286)   Prec@1 95.312 (95.467)   Prec@5 100.000 (99.938)   [2019-11-23 11:37:10]
  Epoch: [111][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.1765 (0.1283)   Prec@1 92.969 (95.445)   Prec@5 100.000 (99.946)   [2019-11-23 11:37:16]
  Epoch: [111][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1589 (0.1321)   Prec@1 93.750 (95.232)   Prec@5 100.000 (99.953)   [2019-11-23 11:37:21]
  **Train** Prec@1 95.146 Prec@5 99.948 Error@1 4.854
  **Test** Prec@1 89.470 Prec@5 99.640 Error@1 10.530

==>>[2019-11-23 11:37:27] [Epoch=112/200] [Need: 00:32:39] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [112][000/391]   Time 0.249 (0.249)   Data 0.181 (0.181)   Loss 0.0947 (0.0947)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:37:27]
  Epoch: [112][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.1966 (0.1294)   Prec@1 94.531 (95.475)   Prec@5 100.000 (99.938)   [2019-11-23 11:37:33]
  Epoch: [112][200/391]   Time 0.056 (0.053)   Data 0.000 (0.001)   Loss 0.1280 (0.1321)   Prec@1 95.312 (95.375)   Prec@5 100.000 (99.942)   [2019-11-23 11:37:38]
  Epoch: [112][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1188 (0.1332)   Prec@1 95.312 (95.349)   Prec@5 100.000 (99.935)   [2019-11-23 11:37:43]
  **Train** Prec@1 95.288 Prec@5 99.934 Error@1 4.712
  **Test** Prec@1 89.300 Prec@5 99.590 Error@1 10.700

==>>[2019-11-23 11:37:49] [Epoch=113/200] [Need: 00:32:17] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [113][000/391]   Time 0.263 (0.263)   Data 0.198 (0.198)   Loss 0.1130 (0.1130)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:37:49]
  Epoch: [113][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1420 (0.1334)   Prec@1 96.094 (95.050)   Prec@5 100.000 (99.954)   [2019-11-23 11:37:54]
  Epoch: [113][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.1056 (0.1319)   Prec@1 96.875 (95.122)   Prec@5 100.000 (99.969)   [2019-11-23 11:37:59]
  Epoch: [113][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.0968 (0.1318)   Prec@1 97.656 (95.157)   Prec@5 100.000 (99.961)   [2019-11-23 11:38:04]
  **Train** Prec@1 95.126 Prec@5 99.962 Error@1 4.874
  **Test** Prec@1 88.730 Prec@5 99.660 Error@1 11.270

==>>[2019-11-23 11:38:11] [Epoch=114/200] [Need: 00:31:54] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [114][000/391]   Time 0.273 (0.273)   Data 0.182 (0.182)   Loss 0.1836 (0.1836)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:38:11]
  Epoch: [114][100/391]   Time 0.048 (0.055)   Data 0.000 (0.002)   Loss 0.1473 (0.1324)   Prec@1 94.531 (95.065)   Prec@5 100.000 (99.930)   [2019-11-23 11:38:16]
  Epoch: [114][200/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.2004 (0.1333)   Prec@1 93.750 (95.103)   Prec@5 100.000 (99.942)   [2019-11-23 11:38:21]
  Epoch: [114][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.1519 (0.1331)   Prec@1 96.094 (95.115)   Prec@5 99.219 (99.948)   [2019-11-23 11:38:27]
  **Train** Prec@1 95.166 Prec@5 99.952 Error@1 4.834
  **Test** Prec@1 89.050 Prec@5 99.500 Error@1 10.950

==>>[2019-11-23 11:38:33] [Epoch=115/200] [Need: 00:31:32] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [115][000/391]   Time 0.247 (0.247)   Data 0.186 (0.186)   Loss 0.1008 (0.1008)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:38:34]
  Epoch: [115][100/391]   Time 0.047 (0.052)   Data 0.000 (0.002)   Loss 0.1580 (0.1368)   Prec@1 92.188 (94.964)   Prec@5 100.000 (99.946)   [2019-11-23 11:38:39]
  Epoch: [115][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1167 (0.1326)   Prec@1 94.531 (95.126)   Prec@5 100.000 (99.953)   [2019-11-23 11:38:44]
  Epoch: [115][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.1079 (0.1320)   Prec@1 95.312 (95.162)   Prec@5 100.000 (99.961)   [2019-11-23 11:38:49]
  **Train** Prec@1 95.184 Prec@5 99.958 Error@1 4.816
  **Test** Prec@1 89.090 Prec@5 99.610 Error@1 10.910

==>>[2019-11-23 11:38:56] [Epoch=116/200] [Need: 00:31:10] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [116][000/391]   Time 0.261 (0.261)   Data 0.205 (0.205)   Loss 0.2402 (0.2402)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-23 11:38:56]
  Epoch: [116][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.1403 (0.1234)   Prec@1 94.531 (95.653)   Prec@5 100.000 (99.969)   [2019-11-23 11:39:01]
  Epoch: [116][200/391]   Time 0.038 (0.054)   Data 0.000 (0.001)   Loss 0.0966 (0.1249)   Prec@1 97.656 (95.550)   Prec@5 100.000 (99.977)   [2019-11-23 11:39:07]
  Epoch: [116][300/391]   Time 0.058 (0.054)   Data 0.000 (0.001)   Loss 0.1585 (0.1265)   Prec@1 95.312 (95.481)   Prec@5 100.000 (99.969)   [2019-11-23 11:39:12]
  **Train** Prec@1 95.432 Prec@5 99.972 Error@1 4.568
  **Test** Prec@1 89.640 Prec@5 99.590 Error@1 10.360

==>>[2019-11-23 11:39:18] [Epoch=117/200] [Need: 00:30:48] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [117][000/391]   Time 0.256 (0.256)   Data 0.200 (0.200)   Loss 0.1919 (0.1919)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2019-11-23 11:39:18]
  Epoch: [117][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0938 (0.1246)   Prec@1 96.094 (95.498)   Prec@5 100.000 (99.907)   [2019-11-23 11:39:23]
  Epoch: [117][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1589 (0.1298)   Prec@1 94.531 (95.398)   Prec@5 100.000 (99.918)   [2019-11-23 11:39:29]
  Epoch: [117][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1472 (0.1312)   Prec@1 94.531 (95.385)   Prec@5 100.000 (99.917)   [2019-11-23 11:39:34]
  **Train** Prec@1 95.344 Prec@5 99.926 Error@1 4.656
  **Test** Prec@1 88.610 Prec@5 99.670 Error@1 11.390

==>>[2019-11-23 11:39:41] [Epoch=118/200] [Need: 00:30:26] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [118][000/391]   Time 0.259 (0.259)   Data 0.200 (0.200)   Loss 0.1269 (0.1269)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:39:41]
  Epoch: [118][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1742 (0.1259)   Prec@1 93.750 (95.514)   Prec@5 100.000 (99.969)   [2019-11-23 11:39:46]
  Epoch: [118][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1035 (0.1275)   Prec@1 95.312 (95.406)   Prec@5 100.000 (99.949)   [2019-11-23 11:39:51]
  Epoch: [118][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0684 (0.1269)   Prec@1 98.438 (95.419)   Prec@5 100.000 (99.953)   [2019-11-23 11:39:56]
  **Train** Prec@1 95.390 Prec@5 99.962 Error@1 4.610
  **Test** Prec@1 89.020 Prec@5 99.590 Error@1 10.980

==>>[2019-11-23 11:40:03] [Epoch=119/200] [Need: 00:30:03] [LR=0.0010][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [119][000/391]   Time 0.255 (0.255)   Data 0.192 (0.192)   Loss 0.1445 (0.1445)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:40:03]
  Epoch: [119][100/391]   Time 0.084 (0.056)   Data 0.000 (0.002)   Loss 0.1150 (0.1178)   Prec@1 97.656 (95.962)   Prec@5 100.000 (99.961)   [2019-11-23 11:40:08]
  Epoch: [119][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.1060 (0.1199)   Prec@1 96.094 (95.759)   Prec@5 100.000 (99.969)   [2019-11-23 11:40:14]
  Epoch: [119][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0757 (0.1226)   Prec@1 96.875 (95.655)   Prec@5 100.000 (99.958)   [2019-11-23 11:40:19]
  **Train** Prec@1 95.626 Prec@5 99.960 Error@1 4.374
  **Test** Prec@1 89.180 Prec@5 99.560 Error@1 10.820

==>>[2019-11-23 11:40:25] [Epoch=120/200] [Need: 00:29:41] [LR=0.0001][M=0.90] [Best : Accuracy=89.96, Error=10.04]
  Epoch: [120][000/391]   Time 0.261 (0.261)   Data 0.190 (0.190)   Loss 0.0986 (0.0986)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:40:25]
  Epoch: [120][100/391]   Time 0.047 (0.056)   Data 0.000 (0.002)   Loss 0.0641 (0.1172)   Prec@1 97.656 (95.831)   Prec@5 100.000 (99.961)   [2019-11-23 11:40:30]
  Epoch: [120][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0848 (0.1098)   Prec@1 96.875 (96.086)   Prec@5 100.000 (99.973)   [2019-11-23 11:40:35]
  Epoch: [120][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0736 (0.1099)   Prec@1 97.656 (96.096)   Prec@5 100.000 (99.958)   [2019-11-23 11:40:40]
  **Train** Prec@1 96.176 Prec@5 99.956 Error@1 3.824
  **Test** Prec@1 90.490 Prec@5 99.710 Error@1 9.510
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:40:47] [Epoch=121/200] [Need: 00:29:18] [LR=0.0001][M=0.90] [Best : Accuracy=90.49, Error=9.51]
  Epoch: [121][000/391]   Time 0.263 (0.263)   Data 0.196 (0.196)   Loss 0.0763 (0.0763)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:40:47]
  Epoch: [121][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0872 (0.1025)   Prec@1 95.312 (96.334)   Prec@5 100.000 (99.946)   [2019-11-23 11:40:52]
  Epoch: [121][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1549 (0.1022)   Prec@1 93.750 (96.374)   Prec@5 100.000 (99.957)   [2019-11-23 11:40:57]
  Epoch: [121][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.1021 (0.1007)   Prec@1 96.094 (96.480)   Prec@5 100.000 (99.961)   [2019-11-23 11:41:02]
  **Train** Prec@1 96.466 Prec@5 99.956 Error@1 3.534
  **Test** Prec@1 90.320 Prec@5 99.550 Error@1 9.680

==>>[2019-11-23 11:41:08] [Epoch=122/200] [Need: 00:28:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.49, Error=9.51]
  Epoch: [122][000/391]   Time 0.273 (0.273)   Data 0.189 (0.189)   Loss 0.0918 (0.0918)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:41:09]
  Epoch: [122][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.1674 (0.1010)   Prec@1 93.750 (96.504)   Prec@5 100.000 (99.992)   [2019-11-23 11:41:14]
  Epoch: [122][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0518 (0.0993)   Prec@1 99.219 (96.479)   Prec@5 100.000 (99.981)   [2019-11-23 11:41:19]
  Epoch: [122][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0892 (0.0982)   Prec@1 96.875 (96.548)   Prec@5 100.000 (99.982)   [2019-11-23 11:41:24]
  **Train** Prec@1 96.532 Prec@5 99.976 Error@1 3.468
  **Test** Prec@1 90.400 Prec@5 99.650 Error@1 9.600

==>>[2019-11-23 11:41:31] [Epoch=123/200] [Need: 00:28:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.49, Error=9.51]
  Epoch: [123][000/391]   Time 0.250 (0.250)   Data 0.179 (0.179)   Loss 0.0543 (0.0543)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:41:31]
  Epoch: [123][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.0704 (0.0995)   Prec@1 97.656 (96.519)   Prec@5 100.000 (99.969)   [2019-11-23 11:41:36]
  Epoch: [123][200/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.0755 (0.0977)   Prec@1 96.875 (96.560)   Prec@5 100.000 (99.965)   [2019-11-23 11:41:41]
  Epoch: [123][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0998 (0.0984)   Prec@1 96.094 (96.530)   Prec@5 100.000 (99.964)   [2019-11-23 11:41:46]
  **Train** Prec@1 96.570 Prec@5 99.958 Error@1 3.430
  **Test** Prec@1 90.370 Prec@5 99.680 Error@1 9.630

==>>[2019-11-23 11:41:53] [Epoch=124/200] [Need: 00:28:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.49, Error=9.51]
  Epoch: [124][000/391]   Time 0.244 (0.244)   Data 0.188 (0.188)   Loss 0.1094 (0.1094)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:41:53]
  Epoch: [124][100/391]   Time 0.041 (0.055)   Data 0.000 (0.002)   Loss 0.1019 (0.0911)   Prec@1 96.094 (96.844)   Prec@5 100.000 (99.977)   [2019-11-23 11:41:59]
  Epoch: [124][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.0504 (0.0934)   Prec@1 98.438 (96.704)   Prec@5 100.000 (99.969)   [2019-11-23 11:42:04]
  Epoch: [124][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.0818 (0.0934)   Prec@1 98.438 (96.730)   Prec@5 100.000 (99.971)   [2019-11-23 11:42:09]
  **Train** Prec@1 96.716 Prec@5 99.974 Error@1 3.284
  **Test** Prec@1 90.580 Prec@5 99.620 Error@1 9.420
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:42:16] [Epoch=125/200] [Need: 00:27:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.58, Error=9.42]
  Epoch: [125][000/391]   Time 0.250 (0.250)   Data 0.193 (0.193)   Loss 0.0719 (0.0719)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:42:16]
  Epoch: [125][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0578 (0.0934)   Prec@1 98.438 (96.697)   Prec@5 100.000 (100.000)   [2019-11-23 11:42:21]
  Epoch: [125][200/391]   Time 0.066 (0.054)   Data 0.000 (0.001)   Loss 0.1210 (0.0954)   Prec@1 94.531 (96.622)   Prec@5 100.000 (99.984)   [2019-11-23 11:42:27]
  Epoch: [125][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0940 (0.0961)   Prec@1 98.438 (96.618)   Prec@5 100.000 (99.987)   [2019-11-23 11:42:32]
  **Train** Prec@1 96.646 Prec@5 99.982 Error@1 3.354
  **Test** Prec@1 90.590 Prec@5 99.700 Error@1 9.410
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:42:39] [Epoch=126/200] [Need: 00:27:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.59, Error=9.41]
  Epoch: [126][000/391]   Time 0.264 (0.264)   Data 0.182 (0.182)   Loss 0.0941 (0.0941)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:42:39]
  Epoch: [126][100/391]   Time 0.054 (0.053)   Data 0.000 (0.002)   Loss 0.0308 (0.0964)   Prec@1 100.000 (96.705)   Prec@5 100.000 (99.977)   [2019-11-23 11:42:44]
  Epoch: [126][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0785 (0.0963)   Prec@1 97.656 (96.692)   Prec@5 100.000 (99.953)   [2019-11-23 11:42:49]
  Epoch: [126][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0761 (0.0960)   Prec@1 98.438 (96.750)   Prec@5 100.000 (99.953)   [2019-11-23 11:42:54]
  **Train** Prec@1 96.742 Prec@5 99.962 Error@1 3.258
  **Test** Prec@1 90.660 Prec@5 99.650 Error@1 9.340
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:43:01] [Epoch=127/200] [Need: 00:27:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [127][000/391]   Time 0.248 (0.248)   Data 0.185 (0.185)   Loss 0.1114 (0.1114)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:43:01]
  Epoch: [127][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0780 (0.0872)   Prec@1 97.656 (96.921)   Prec@5 100.000 (99.977)   [2019-11-23 11:43:06]
  Epoch: [127][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.0919 (0.0926)   Prec@1 97.656 (96.735)   Prec@5 100.000 (99.973)   [2019-11-23 11:43:11]
  Epoch: [127][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.1356 (0.0929)   Prec@1 96.094 (96.761)   Prec@5 100.000 (99.977)   [2019-11-23 11:43:16]
  **Train** Prec@1 96.696 Prec@5 99.978 Error@1 3.304
  **Test** Prec@1 90.350 Prec@5 99.660 Error@1 9.650

==>>[2019-11-23 11:43:23] [Epoch=128/200] [Need: 00:26:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [128][000/391]   Time 0.240 (0.240)   Data 0.176 (0.176)   Loss 0.1553 (0.1553)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:43:23]
  Epoch: [128][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.1039 (0.0938)   Prec@1 97.656 (96.713)   Prec@5 99.219 (99.961)   [2019-11-23 11:43:28]
  Epoch: [128][200/391]   Time 0.049 (0.054)   Data 0.000 (0.001)   Loss 0.0921 (0.0947)   Prec@1 96.875 (96.681)   Prec@5 100.000 (99.946)   [2019-11-23 11:43:33]
  Epoch: [128][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0759 (0.0948)   Prec@1 97.656 (96.709)   Prec@5 100.000 (99.958)   [2019-11-23 11:43:39]
  **Train** Prec@1 96.758 Prec@5 99.966 Error@1 3.242
  **Test** Prec@1 90.370 Prec@5 99.680 Error@1 9.630

==>>[2019-11-23 11:43:45] [Epoch=129/200] [Need: 00:26:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [129][000/391]   Time 0.263 (0.263)   Data 0.205 (0.205)   Loss 0.0680 (0.0680)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:43:45]
  Epoch: [129][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.0366 (0.0902)   Prec@1 99.219 (96.937)   Prec@5 100.000 (99.977)   [2019-11-23 11:43:50]
  Epoch: [129][200/391]   Time 0.059 (0.050)   Data 0.000 (0.001)   Loss 0.0358 (0.0920)   Prec@1 98.438 (96.782)   Prec@5 100.000 (99.977)   [2019-11-23 11:43:55]
  Epoch: [129][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0355 (0.0952)   Prec@1 99.219 (96.639)   Prec@5 100.000 (99.974)   [2019-11-23 11:44:00]
  **Train** Prec@1 96.606 Prec@5 99.962 Error@1 3.394
  **Test** Prec@1 90.410 Prec@5 99.730 Error@1 9.590

==>>[2019-11-23 11:44:07] [Epoch=130/200] [Need: 00:25:58] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [130][000/391]   Time 0.262 (0.262)   Data 0.191 (0.191)   Loss 0.0896 (0.0896)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:44:07]
  Epoch: [130][100/391]   Time 0.046 (0.058)   Data 0.000 (0.002)   Loss 0.1455 (0.0877)   Prec@1 94.531 (96.968)   Prec@5 100.000 (99.969)   [2019-11-23 11:44:13]
  Epoch: [130][200/391]   Time 0.054 (0.055)   Data 0.000 (0.001)   Loss 0.0503 (0.0891)   Prec@1 98.438 (96.828)   Prec@5 100.000 (99.965)   [2019-11-23 11:44:18]
  Epoch: [130][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0826 (0.0894)   Prec@1 98.438 (96.831)   Prec@5 100.000 (99.974)   [2019-11-23 11:44:23]
  **Train** Prec@1 96.802 Prec@5 99.974 Error@1 3.198
  **Test** Prec@1 90.650 Prec@5 99.650 Error@1 9.350

==>>[2019-11-23 11:44:30] [Epoch=131/200] [Need: 00:25:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [131][000/391]   Time 0.261 (0.261)   Data 0.182 (0.182)   Loss 0.0751 (0.0751)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:44:30]
  Epoch: [131][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.1560 (0.0894)   Prec@1 96.875 (96.921)   Prec@5 99.219 (99.992)   [2019-11-23 11:44:35]
  Epoch: [131][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0791 (0.0931)   Prec@1 96.875 (96.782)   Prec@5 100.000 (99.981)   [2019-11-23 11:44:41]
  Epoch: [131][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0849 (0.0908)   Prec@1 97.656 (96.833)   Prec@5 100.000 (99.984)   [2019-11-23 11:44:46]
  **Train** Prec@1 96.810 Prec@5 99.978 Error@1 3.190
  **Test** Prec@1 90.580 Prec@5 99.660 Error@1 9.420

==>>[2019-11-23 11:44:52] [Epoch=132/200] [Need: 00:25:14] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [132][000/391]   Time 0.249 (0.249)   Data 0.187 (0.187)   Loss 0.0804 (0.0804)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:44:53]
  Epoch: [132][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.0894 (0.0910)   Prec@1 96.094 (96.774)   Prec@5 100.000 (99.985)   [2019-11-23 11:44:58]
  Epoch: [132][200/391]   Time 0.072 (0.052)   Data 0.000 (0.001)   Loss 0.2039 (0.0917)   Prec@1 92.969 (96.844)   Prec@5 100.000 (99.969)   [2019-11-23 11:45:03]
  Epoch: [132][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.0533 (0.0899)   Prec@1 96.875 (96.896)   Prec@5 100.000 (99.971)   [2019-11-23 11:45:08]
  **Train** Prec@1 96.772 Prec@5 99.972 Error@1 3.228
  **Test** Prec@1 90.510 Prec@5 99.700 Error@1 9.490

==>>[2019-11-23 11:45:15] [Epoch=133/200] [Need: 00:24:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [133][000/391]   Time 0.260 (0.260)   Data 0.182 (0.182)   Loss 0.0456 (0.0456)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:45:15]
  Epoch: [133][100/391]   Time 0.082 (0.060)   Data 0.000 (0.002)   Loss 0.0945 (0.0850)   Prec@1 96.875 (97.061)   Prec@5 100.000 (99.985)   [2019-11-23 11:45:21]
  Epoch: [133][200/391]   Time 0.086 (0.056)   Data 0.000 (0.001)   Loss 0.0699 (0.0890)   Prec@1 97.656 (96.871)   Prec@5 100.000 (99.988)   [2019-11-23 11:45:26]
  Epoch: [133][300/391]   Time 0.047 (0.055)   Data 0.000 (0.001)   Loss 0.0940 (0.0895)   Prec@1 96.875 (96.883)   Prec@5 100.000 (99.977)   [2019-11-23 11:45:31]
  **Train** Prec@1 96.866 Prec@5 99.972 Error@1 3.134
  **Test** Prec@1 90.500 Prec@5 99.630 Error@1 9.500

==>>[2019-11-23 11:45:38] [Epoch=134/200] [Need: 00:24:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [134][000/391]   Time 0.255 (0.255)   Data 0.180 (0.180)   Loss 0.0660 (0.0660)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:45:38]
  Epoch: [134][100/391]   Time 0.048 (0.057)   Data 0.000 (0.002)   Loss 0.1173 (0.0907)   Prec@1 93.750 (96.674)   Prec@5 100.000 (99.992)   [2019-11-23 11:45:43]
  Epoch: [134][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.0763 (0.0913)   Prec@1 96.094 (96.755)   Prec@5 100.000 (99.981)   [2019-11-23 11:45:48]
  Epoch: [134][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1036 (0.0910)   Prec@1 96.875 (96.771)   Prec@5 100.000 (99.982)   [2019-11-23 11:45:53]
  **Train** Prec@1 96.804 Prec@5 99.968 Error@1 3.196
  **Test** Prec@1 90.360 Prec@5 99.630 Error@1 9.640

==>>[2019-11-23 11:45:59] [Epoch=135/200] [Need: 00:24:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [135][000/391]   Time 0.262 (0.262)   Data 0.197 (0.197)   Loss 0.0776 (0.0776)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:46:00]
  Epoch: [135][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.0486 (0.0832)   Prec@1 98.438 (97.177)   Prec@5 100.000 (99.969)   [2019-11-23 11:46:05]
  Epoch: [135][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1214 (0.0858)   Prec@1 96.094 (96.999)   Prec@5 100.000 (99.973)   [2019-11-23 11:46:10]
  Epoch: [135][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0879 (0.0873)   Prec@1 97.656 (96.940)   Prec@5 100.000 (99.961)   [2019-11-23 11:46:15]
  **Train** Prec@1 96.886 Prec@5 99.966 Error@1 3.114
  **Test** Prec@1 90.560 Prec@5 99.610 Error@1 9.440

==>>[2019-11-23 11:46:22] [Epoch=136/200] [Need: 00:23:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [136][000/391]   Time 0.256 (0.256)   Data 0.181 (0.181)   Loss 0.1300 (0.1300)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:46:22]
  Epoch: [136][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1179 (0.0890)   Prec@1 92.969 (96.929)   Prec@5 100.000 (99.954)   [2019-11-23 11:46:27]
  Epoch: [136][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.0716 (0.0871)   Prec@1 97.656 (97.058)   Prec@5 100.000 (99.973)   [2019-11-23 11:46:32]
  Epoch: [136][300/391]   Time 0.080 (0.052)   Data 0.000 (0.001)   Loss 0.0721 (0.0891)   Prec@1 97.656 (96.893)   Prec@5 100.000 (99.974)   [2019-11-23 11:46:37]
  **Train** Prec@1 96.816 Prec@5 99.974 Error@1 3.184
  **Test** Prec@1 90.410 Prec@5 99.660 Error@1 9.590

==>>[2019-11-23 11:46:44] [Epoch=137/200] [Need: 00:23:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [137][000/391]   Time 0.251 (0.251)   Data 0.197 (0.197)   Loss 0.1072 (0.1072)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:46:44]
  Epoch: [137][100/391]   Time 0.057 (0.055)   Data 0.000 (0.002)   Loss 0.0385 (0.0864)   Prec@1 99.219 (96.945)   Prec@5 100.000 (99.969)   [2019-11-23 11:46:50]
  Epoch: [137][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.0659 (0.0860)   Prec@1 97.656 (97.003)   Prec@5 100.000 (99.977)   [2019-11-23 11:46:55]
  Epoch: [137][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1089 (0.0887)   Prec@1 96.875 (96.937)   Prec@5 100.000 (99.969)   [2019-11-23 11:47:00]
  **Train** Prec@1 96.868 Prec@5 99.970 Error@1 3.132
  **Test** Prec@1 90.440 Prec@5 99.680 Error@1 9.560

==>>[2019-11-23 11:47:06] [Epoch=138/200] [Need: 00:23:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [138][000/391]   Time 0.277 (0.277)   Data 0.211 (0.211)   Loss 0.0875 (0.0875)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:47:07]
  Epoch: [138][100/391]   Time 0.047 (0.056)   Data 0.000 (0.002)   Loss 0.0765 (0.0960)   Prec@1 98.438 (96.542)   Prec@5 100.000 (99.992)   [2019-11-23 11:47:12]
  Epoch: [138][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.1095 (0.0923)   Prec@1 94.531 (96.723)   Prec@5 100.000 (99.984)   [2019-11-23 11:47:17]
  Epoch: [138][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.1138 (0.0918)   Prec@1 94.531 (96.753)   Prec@5 100.000 (99.984)   [2019-11-23 11:47:22]
  **Train** Prec@1 96.788 Prec@5 99.984 Error@1 3.212
  **Test** Prec@1 90.420 Prec@5 99.650 Error@1 9.580

==>>[2019-11-23 11:47:29] [Epoch=139/200] [Need: 00:22:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [139][000/391]   Time 0.249 (0.249)   Data 0.183 (0.183)   Loss 0.0456 (0.0456)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:47:29]
  Epoch: [139][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0415 (0.0842)   Prec@1 99.219 (96.844)   Prec@5 100.000 (99.969)   [2019-11-23 11:47:34]
  Epoch: [139][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0543 (0.0873)   Prec@1 98.438 (96.840)   Prec@5 100.000 (99.973)   [2019-11-23 11:47:39]
  Epoch: [139][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0527 (0.0871)   Prec@1 97.656 (96.927)   Prec@5 100.000 (99.971)   [2019-11-23 11:47:44]
  **Train** Prec@1 96.928 Prec@5 99.972 Error@1 3.072
  **Test** Prec@1 90.250 Prec@5 99.630 Error@1 9.750

==>>[2019-11-23 11:47:50] [Epoch=140/200] [Need: 00:22:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.66, Error=9.34]
  Epoch: [140][000/391]   Time 0.274 (0.274)   Data 0.197 (0.197)   Loss 0.0914 (0.0914)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:47:51]
  Epoch: [140][100/391]   Time 0.071 (0.057)   Data 0.000 (0.002)   Loss 0.0834 (0.0915)   Prec@1 96.875 (96.720)   Prec@5 100.000 (99.969)   [2019-11-23 11:47:56]
  Epoch: [140][200/391]   Time 0.053 (0.055)   Data 0.000 (0.001)   Loss 0.0532 (0.0905)   Prec@1 99.219 (96.782)   Prec@5 100.000 (99.969)   [2019-11-23 11:48:01]
  Epoch: [140][300/391]   Time 0.084 (0.054)   Data 0.000 (0.001)   Loss 0.0400 (0.0883)   Prec@1 98.438 (96.865)   Prec@5 100.000 (99.966)   [2019-11-23 11:48:07]
  **Train** Prec@1 96.872 Prec@5 99.968 Error@1 3.128
  **Test** Prec@1 90.670 Prec@5 99.700 Error@1 9.330
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:48:13] [Epoch=141/200] [Need: 00:21:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [141][000/391]   Time 0.256 (0.256)   Data 0.209 (0.209)   Loss 0.0868 (0.0868)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:48:14]
  Epoch: [141][100/391]   Time 0.037 (0.052)   Data 0.000 (0.002)   Loss 0.0827 (0.0893)   Prec@1 96.875 (96.983)   Prec@5 100.000 (99.985)   [2019-11-23 11:48:19]
  Epoch: [141][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1206 (0.0880)   Prec@1 95.312 (96.945)   Prec@5 100.000 (99.969)   [2019-11-23 11:48:24]
  Epoch: [141][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0284 (0.0883)   Prec@1 100.000 (96.880)   Prec@5 100.000 (99.964)   [2019-11-23 11:48:28]
  **Train** Prec@1 96.852 Prec@5 99.964 Error@1 3.148
  **Test** Prec@1 90.350 Prec@5 99.650 Error@1 9.650

==>>[2019-11-23 11:48:35] [Epoch=142/200] [Need: 00:21:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [142][000/391]   Time 0.251 (0.251)   Data 0.181 (0.181)   Loss 0.0931 (0.0931)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:48:35]
  Epoch: [142][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.1726 (0.0919)   Prec@1 94.531 (96.836)   Prec@5 100.000 (99.930)   [2019-11-23 11:48:41]
  Epoch: [142][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0643 (0.0860)   Prec@1 97.656 (97.042)   Prec@5 100.000 (99.965)   [2019-11-23 11:48:45]
  Epoch: [142][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0834 (0.0864)   Prec@1 95.312 (96.979)   Prec@5 100.000 (99.977)   [2019-11-23 11:48:51]
  **Train** Prec@1 96.966 Prec@5 99.976 Error@1 3.034
  **Test** Prec@1 90.540 Prec@5 99.690 Error@1 9.460

==>>[2019-11-23 11:48:57] [Epoch=143/200] [Need: 00:21:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [143][000/391]   Time 0.256 (0.256)   Data 0.197 (0.197)   Loss 0.0707 (0.0707)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:48:58]
  Epoch: [143][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0677 (0.0881)   Prec@1 98.438 (97.161)   Prec@5 100.000 (99.954)   [2019-11-23 11:49:03]
  Epoch: [143][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0867 (0.0891)   Prec@1 96.875 (97.030)   Prec@5 100.000 (99.969)   [2019-11-23 11:49:08]
  Epoch: [143][300/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.0993 (0.0886)   Prec@1 97.656 (96.974)   Prec@5 100.000 (99.971)   [2019-11-23 11:49:13]
  **Train** Prec@1 96.976 Prec@5 99.968 Error@1 3.024
  **Test** Prec@1 90.180 Prec@5 99.650 Error@1 9.820

==>>[2019-11-23 11:49:19] [Epoch=144/200] [Need: 00:20:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [144][000/391]   Time 0.258 (0.258)   Data 0.199 (0.199)   Loss 0.0698 (0.0698)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:49:20]
  Epoch: [144][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.1407 (0.0879)   Prec@1 94.531 (96.898)   Prec@5 100.000 (99.977)   [2019-11-23 11:49:25]
  Epoch: [144][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.0624 (0.0872)   Prec@1 96.875 (96.949)   Prec@5 100.000 (99.988)   [2019-11-23 11:49:30]
  Epoch: [144][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0951 (0.0873)   Prec@1 97.656 (96.917)   Prec@5 100.000 (99.992)   [2019-11-23 11:49:35]
  **Train** Prec@1 96.908 Prec@5 99.992 Error@1 3.092
  **Test** Prec@1 90.510 Prec@5 99.680 Error@1 9.490

==>>[2019-11-23 11:49:42] [Epoch=145/200] [Need: 00:20:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [145][000/391]   Time 0.263 (0.263)   Data 0.208 (0.208)   Loss 0.0761 (0.0761)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:49:42]
  Epoch: [145][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.1023 (0.0875)   Prec@1 95.312 (96.921)   Prec@5 100.000 (99.961)   [2019-11-23 11:49:47]
  Epoch: [145][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0683 (0.0869)   Prec@1 97.656 (96.929)   Prec@5 100.000 (99.965)   [2019-11-23 11:49:52]
  Epoch: [145][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0733 (0.0878)   Prec@1 97.656 (96.815)   Prec@5 100.000 (99.966)   [2019-11-23 11:49:57]
  **Train** Prec@1 96.746 Prec@5 99.968 Error@1 3.254
  **Test** Prec@1 90.410 Prec@5 99.680 Error@1 9.590

==>>[2019-11-23 11:50:04] [Epoch=146/200] [Need: 00:20:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [146][000/391]   Time 0.260 (0.260)   Data 0.190 (0.190)   Loss 0.0310 (0.0310)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 11:50:04]
  Epoch: [146][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.0364 (0.0854)   Prec@1 99.219 (97.006)   Prec@5 100.000 (99.985)   [2019-11-23 11:50:09]
  Epoch: [146][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.0913 (0.0859)   Prec@1 97.656 (96.984)   Prec@5 100.000 (99.984)   [2019-11-23 11:50:14]
  Epoch: [146][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1000 (0.0848)   Prec@1 95.312 (97.002)   Prec@5 100.000 (99.987)   [2019-11-23 11:50:19]
  **Train** Prec@1 96.966 Prec@5 99.988 Error@1 3.034
  **Test** Prec@1 90.340 Prec@5 99.650 Error@1 9.660

==>>[2019-11-23 11:50:26] [Epoch=147/200] [Need: 00:19:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [147][000/391]   Time 0.253 (0.253)   Data 0.188 (0.188)   Loss 0.0943 (0.0943)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:50:26]
  Epoch: [147][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.1243 (0.0836)   Prec@1 94.531 (97.115)   Prec@5 100.000 (99.992)   [2019-11-23 11:50:31]
  Epoch: [147][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0888 (0.0844)   Prec@1 96.094 (97.030)   Prec@5 100.000 (99.996)   [2019-11-23 11:50:36]
  Epoch: [147][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0943 (0.0832)   Prec@1 96.094 (97.135)   Prec@5 100.000 (99.987)   [2019-11-23 11:50:41]
  **Train** Prec@1 97.038 Prec@5 99.982 Error@1 2.962
  **Test** Prec@1 90.110 Prec@5 99.590 Error@1 9.890

==>>[2019-11-23 11:50:47] [Epoch=148/200] [Need: 00:19:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [148][000/391]   Time 0.255 (0.255)   Data 0.183 (0.183)   Loss 0.0402 (0.0402)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:50:48]
  Epoch: [148][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.0678 (0.0844)   Prec@1 96.875 (96.883)   Prec@5 100.000 (99.977)   [2019-11-23 11:50:53]
  Epoch: [148][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0436 (0.0849)   Prec@1 97.656 (96.836)   Prec@5 100.000 (99.984)   [2019-11-23 11:50:58]
  Epoch: [148][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1039 (0.0855)   Prec@1 96.875 (96.841)   Prec@5 100.000 (99.987)   [2019-11-23 11:51:03]
  **Train** Prec@1 96.848 Prec@5 99.984 Error@1 3.152
  **Test** Prec@1 90.400 Prec@5 99.660 Error@1 9.600

==>>[2019-11-23 11:51:10] [Epoch=149/200] [Need: 00:18:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.67, Error=9.33]
  Epoch: [149][000/391]   Time 0.256 (0.256)   Data 0.199 (0.199)   Loss 0.0995 (0.0995)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 11:51:10]
  Epoch: [149][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0541 (0.0836)   Prec@1 97.656 (97.061)   Prec@5 100.000 (100.000)   [2019-11-23 11:51:15]
  Epoch: [149][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.0822 (0.0858)   Prec@1 96.875 (96.980)   Prec@5 100.000 (99.984)   [2019-11-23 11:51:20]
  Epoch: [149][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1005 (0.0861)   Prec@1 96.875 (96.958)   Prec@5 100.000 (99.979)   [2019-11-23 11:51:26]
  **Train** Prec@1 96.990 Prec@5 99.976 Error@1 3.010
  **Test** Prec@1 90.680 Prec@5 99.650 Error@1 9.320
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:51:32] [Epoch=150/200] [Need: 00:18:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [150][000/391]   Time 0.242 (0.242)   Data 0.194 (0.194)   Loss 0.1096 (0.1096)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:51:32]
  Epoch: [150][100/391]   Time 0.059 (0.055)   Data 0.000 (0.002)   Loss 0.0693 (0.0871)   Prec@1 97.656 (96.983)   Prec@5 100.000 (99.954)   [2019-11-23 11:51:38]
  Epoch: [150][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.1351 (0.0881)   Prec@1 95.312 (96.995)   Prec@5 100.000 (99.965)   [2019-11-23 11:51:43]
  Epoch: [150][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1039 (0.0869)   Prec@1 96.094 (97.018)   Prec@5 100.000 (99.977)   [2019-11-23 11:51:48]
  **Train** Prec@1 96.944 Prec@5 99.978 Error@1 3.056
  **Test** Prec@1 90.520 Prec@5 99.600 Error@1 9.480

==>>[2019-11-23 11:51:55] [Epoch=151/200] [Need: 00:18:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [151][000/391]   Time 0.293 (0.293)   Data 0.235 (0.235)   Loss 0.0998 (0.0998)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:51:55]
  Epoch: [151][100/391]   Time 0.051 (0.053)   Data 0.000 (0.003)   Loss 0.0934 (0.0848)   Prec@1 95.312 (96.968)   Prec@5 100.000 (99.985)   [2019-11-23 11:52:00]
  Epoch: [151][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1440 (0.0828)   Prec@1 95.312 (97.073)   Prec@5 100.000 (99.988)   [2019-11-23 11:52:05]
  Epoch: [151][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0304 (0.0843)   Prec@1 100.000 (97.059)   Prec@5 100.000 (99.987)   [2019-11-23 11:52:10]
  **Train** Prec@1 97.002 Prec@5 99.990 Error@1 2.998
  **Test** Prec@1 90.570 Prec@5 99.640 Error@1 9.430

==>>[2019-11-23 11:52:17] [Epoch=152/200] [Need: 00:17:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [152][000/391]   Time 0.246 (0.246)   Data 0.178 (0.178)   Loss 0.1131 (0.1131)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:52:17]
  Epoch: [152][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1102 (0.0897)   Prec@1 96.094 (96.952)   Prec@5 100.000 (99.969)   [2019-11-23 11:52:22]
  Epoch: [152][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0727 (0.0865)   Prec@1 97.656 (96.972)   Prec@5 100.000 (99.977)   [2019-11-23 11:52:27]
  Epoch: [152][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.1390 (0.0860)   Prec@1 96.094 (97.002)   Prec@5 100.000 (99.982)   [2019-11-23 11:52:32]
  **Train** Prec@1 96.944 Prec@5 99.976 Error@1 3.056
  **Test** Prec@1 90.560 Prec@5 99.690 Error@1 9.440

==>>[2019-11-23 11:52:39] [Epoch=153/200] [Need: 00:17:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [153][000/391]   Time 0.269 (0.269)   Data 0.206 (0.206)   Loss 0.0544 (0.0544)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:52:39]
  Epoch: [153][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0536 (0.0854)   Prec@1 98.438 (96.798)   Prec@5 100.000 (99.977)   [2019-11-23 11:52:44]
  Epoch: [153][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0966 (0.0842)   Prec@1 97.656 (96.941)   Prec@5 100.000 (99.977)   [2019-11-23 11:52:49]
  Epoch: [153][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0526 (0.0874)   Prec@1 98.438 (96.865)   Prec@5 100.000 (99.979)   [2019-11-23 11:52:54]
  **Train** Prec@1 96.912 Prec@5 99.982 Error@1 3.088
  **Test** Prec@1 90.430 Prec@5 99.640 Error@1 9.570

==>>[2019-11-23 11:53:00] [Epoch=154/200] [Need: 00:17:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [154][000/391]   Time 0.255 (0.255)   Data 0.187 (0.187)   Loss 0.0492 (0.0492)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:53:01]
  Epoch: [154][100/391]   Time 0.068 (0.057)   Data 0.000 (0.002)   Loss 0.0574 (0.0862)   Prec@1 98.438 (97.014)   Prec@5 100.000 (99.969)   [2019-11-23 11:53:06]
  Epoch: [154][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0872 (0.0859)   Prec@1 96.875 (96.875)   Prec@5 100.000 (99.984)   [2019-11-23 11:53:11]
  Epoch: [154][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0883 (0.0860)   Prec@1 96.875 (96.898)   Prec@5 100.000 (99.987)   [2019-11-23 11:53:16]
  **Train** Prec@1 96.982 Prec@5 99.984 Error@1 3.018
  **Test** Prec@1 90.550 Prec@5 99.640 Error@1 9.450

==>>[2019-11-23 11:53:23] [Epoch=155/200] [Need: 00:16:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [155][000/391]   Time 0.262 (0.262)   Data 0.206 (0.206)   Loss 0.0563 (0.0563)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:53:23]
  Epoch: [155][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.0914 (0.0796)   Prec@1 96.875 (97.099)   Prec@5 100.000 (99.985)   [2019-11-23 11:53:29]
  Epoch: [155][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0701 (0.0835)   Prec@1 97.656 (96.992)   Prec@5 100.000 (99.977)   [2019-11-23 11:53:34]
  Epoch: [155][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0615 (0.0841)   Prec@1 98.438 (97.023)   Prec@5 100.000 (99.974)   [2019-11-23 11:53:39]
  **Train** Prec@1 96.996 Prec@5 99.974 Error@1 3.004
  **Test** Prec@1 90.250 Prec@5 99.640 Error@1 9.750

==>>[2019-11-23 11:53:46] [Epoch=156/200] [Need: 00:16:19] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [156][000/391]   Time 0.270 (0.270)   Data 0.206 (0.206)   Loss 0.0812 (0.0812)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:53:46]
  Epoch: [156][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.2038 (0.0812)   Prec@1 94.531 (97.184)   Prec@5 100.000 (100.000)   [2019-11-23 11:53:51]
  Epoch: [156][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.0342 (0.0810)   Prec@1 98.438 (97.167)   Prec@5 100.000 (99.992)   [2019-11-23 11:53:56]
  Epoch: [156][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0482 (0.0812)   Prec@1 98.438 (97.166)   Prec@5 100.000 (99.984)   [2019-11-23 11:54:01]
  **Train** Prec@1 97.074 Prec@5 99.976 Error@1 2.926
  **Test** Prec@1 89.890 Prec@5 99.510 Error@1 10.110

==>>[2019-11-23 11:54:08] [Epoch=157/200] [Need: 00:15:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [157][000/391]   Time 0.273 (0.273)   Data 0.216 (0.216)   Loss 0.1146 (0.1146)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 11:54:08]
  Epoch: [157][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0471 (0.0857)   Prec@1 98.438 (96.821)   Prec@5 100.000 (99.992)   [2019-11-23 11:54:13]
  Epoch: [157][200/391]   Time 0.046 (0.054)   Data 0.000 (0.001)   Loss 0.0991 (0.0872)   Prec@1 97.656 (96.809)   Prec@5 100.000 (99.984)   [2019-11-23 11:54:19]
  Epoch: [157][300/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.0600 (0.0857)   Prec@1 98.438 (96.878)   Prec@5 100.000 (99.982)   [2019-11-23 11:54:24]
  **Train** Prec@1 96.832 Prec@5 99.982 Error@1 3.168
  **Test** Prec@1 90.120 Prec@5 99.600 Error@1 9.880

==>>[2019-11-23 11:54:30] [Epoch=158/200] [Need: 00:15:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [158][000/391]   Time 0.261 (0.261)   Data 0.198 (0.198)   Loss 0.0733 (0.0733)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-23 11:54:30]
  Epoch: [158][100/391]   Time 0.044 (0.058)   Data 0.000 (0.002)   Loss 0.1054 (0.0863)   Prec@1 96.094 (97.153)   Prec@5 99.219 (99.961)   [2019-11-23 11:54:36]
  Epoch: [158][200/391]   Time 0.042 (0.055)   Data 0.000 (0.001)   Loss 0.0417 (0.0848)   Prec@1 98.438 (97.089)   Prec@5 100.000 (99.973)   [2019-11-23 11:54:41]
  Epoch: [158][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1539 (0.0832)   Prec@1 93.750 (97.096)   Prec@5 100.000 (99.974)   [2019-11-23 11:54:46]
  **Train** Prec@1 97.074 Prec@5 99.980 Error@1 2.926
  **Test** Prec@1 90.400 Prec@5 99.660 Error@1 9.600

==>>[2019-11-23 11:54:52] [Epoch=159/200] [Need: 00:15:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [159][000/391]   Time 0.274 (0.274)   Data 0.215 (0.215)   Loss 0.0671 (0.0671)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:54:53]
  Epoch: [159][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.0843 (0.0771)   Prec@1 96.094 (97.231)   Prec@5 100.000 (99.969)   [2019-11-23 11:54:58]
  Epoch: [159][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.0859 (0.0808)   Prec@1 95.312 (97.112)   Prec@5 100.000 (99.969)   [2019-11-23 11:55:03]
  Epoch: [159][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0530 (0.0842)   Prec@1 98.438 (97.010)   Prec@5 100.000 (99.958)   [2019-11-23 11:55:09]
  **Train** Prec@1 97.022 Prec@5 99.968 Error@1 2.978
  **Test** Prec@1 90.350 Prec@5 99.660 Error@1 9.650

==>>[2019-11-23 11:55:15] [Epoch=160/200] [Need: 00:14:50] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [160][000/391]   Time 0.259 (0.259)   Data 0.184 (0.184)   Loss 0.0714 (0.0714)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:55:15]
  Epoch: [160][100/391]   Time 0.058 (0.055)   Data 0.000 (0.002)   Loss 0.0629 (0.0861)   Prec@1 98.438 (96.968)   Prec@5 100.000 (99.985)   [2019-11-23 11:55:20]
  Epoch: [160][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0888 (0.0838)   Prec@1 96.875 (97.062)   Prec@5 100.000 (99.981)   [2019-11-23 11:55:25]
  Epoch: [160][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0832 (0.0810)   Prec@1 96.875 (97.166)   Prec@5 100.000 (99.982)   [2019-11-23 11:55:31]
  **Train** Prec@1 97.148 Prec@5 99.984 Error@1 2.852
  **Test** Prec@1 90.320 Prec@5 99.650 Error@1 9.680

==>>[2019-11-23 11:55:37] [Epoch=161/200] [Need: 00:14:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [161][000/391]   Time 0.254 (0.254)   Data 0.187 (0.187)   Loss 0.1626 (0.1626)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 11:55:37]
  Epoch: [161][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0450 (0.0809)   Prec@1 97.656 (97.324)   Prec@5 100.000 (99.969)   [2019-11-23 11:55:42]
  Epoch: [161][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0715 (0.0804)   Prec@1 97.656 (97.233)   Prec@5 100.000 (99.977)   [2019-11-23 11:55:48]
  Epoch: [161][300/391]   Time 0.065 (0.052)   Data 0.000 (0.001)   Loss 0.1028 (0.0790)   Prec@1 97.656 (97.288)   Prec@5 99.219 (99.979)   [2019-11-23 11:55:53]
  **Train** Prec@1 97.194 Prec@5 99.978 Error@1 2.806
  **Test** Prec@1 90.720 Prec@5 99.680 Error@1 9.280
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 11:55:59] [Epoch=162/200] [Need: 00:14:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [162][000/391]   Time 0.263 (0.263)   Data 0.203 (0.203)   Loss 0.0674 (0.0674)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 11:55:59]
  Epoch: [162][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.1028 (0.0814)   Prec@1 97.656 (97.099)   Prec@5 100.000 (100.000)   [2019-11-23 11:56:05]
  Epoch: [162][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1162 (0.0806)   Prec@1 96.094 (97.205)   Prec@5 100.000 (99.992)   [2019-11-23 11:56:10]
  Epoch: [162][300/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.0743 (0.0800)   Prec@1 96.875 (97.179)   Prec@5 100.000 (99.992)   [2019-11-23 11:56:15]
  **Train** Prec@1 97.174 Prec@5 99.992 Error@1 2.826
  **Test** Prec@1 90.480 Prec@5 99.660 Error@1 9.520

==>>[2019-11-23 11:56:21] [Epoch=163/200] [Need: 00:13:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [163][000/391]   Time 0.259 (0.259)   Data 0.184 (0.184)   Loss 0.1202 (0.1202)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 11:56:22]
  Epoch: [163][100/391]   Time 0.082 (0.057)   Data 0.000 (0.002)   Loss 0.0597 (0.0785)   Prec@1 98.438 (97.285)   Prec@5 100.000 (99.992)   [2019-11-23 11:56:27]
  Epoch: [163][200/391]   Time 0.047 (0.055)   Data 0.000 (0.001)   Loss 0.1163 (0.0819)   Prec@1 96.875 (97.143)   Prec@5 100.000 (99.988)   [2019-11-23 11:56:32]
  Epoch: [163][300/391]   Time 0.083 (0.054)   Data 0.000 (0.001)   Loss 0.0915 (0.0820)   Prec@1 97.656 (97.145)   Prec@5 100.000 (99.987)   [2019-11-23 11:56:38]
  **Train** Prec@1 97.118 Prec@5 99.984 Error@1 2.882
  **Test** Prec@1 90.330 Prec@5 99.640 Error@1 9.670

==>>[2019-11-23 11:56:44] [Epoch=164/200] [Need: 00:13:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [164][000/391]   Time 0.272 (0.272)   Data 0.180 (0.180)   Loss 0.0349 (0.0349)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:56:44]
  Epoch: [164][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0379 (0.0795)   Prec@1 98.438 (97.146)   Prec@5 100.000 (99.992)   [2019-11-23 11:56:49]
  Epoch: [164][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0902 (0.0784)   Prec@1 96.094 (97.155)   Prec@5 100.000 (99.981)   [2019-11-23 11:56:54]
  Epoch: [164][300/391]   Time 0.066 (0.052)   Data 0.000 (0.001)   Loss 0.1572 (0.0793)   Prec@1 96.094 (97.163)   Prec@5 100.000 (99.984)   [2019-11-23 11:56:59]
  **Train** Prec@1 97.158 Prec@5 99.984 Error@1 2.842
  **Test** Prec@1 90.440 Prec@5 99.710 Error@1 9.560

==>>[2019-11-23 11:57:06] [Epoch=165/200] [Need: 00:12:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [165][000/391]   Time 0.258 (0.258)   Data 0.182 (0.182)   Loss 0.0797 (0.0797)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:57:06]
  Epoch: [165][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0815 (0.0774)   Prec@1 96.875 (97.208)   Prec@5 100.000 (99.985)   [2019-11-23 11:57:12]
  Epoch: [165][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1206 (0.0782)   Prec@1 96.094 (97.194)   Prec@5 100.000 (99.981)   [2019-11-23 11:57:16]
  Epoch: [165][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0750 (0.0781)   Prec@1 96.875 (97.207)   Prec@5 100.000 (99.984)   [2019-11-23 11:57:22]
  **Train** Prec@1 97.166 Prec@5 99.986 Error@1 2.834
  **Test** Prec@1 90.330 Prec@5 99.640 Error@1 9.670

==>>[2019-11-23 11:57:28] [Epoch=166/200] [Need: 00:12:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [166][000/391]   Time 0.261 (0.261)   Data 0.196 (0.196)   Loss 0.0262 (0.0262)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:57:29]
  Epoch: [166][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.0334 (0.0780)   Prec@1 100.000 (97.393)   Prec@5 100.000 (99.985)   [2019-11-23 11:57:34]
  Epoch: [166][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.0408 (0.0785)   Prec@1 99.219 (97.322)   Prec@5 100.000 (99.988)   [2019-11-23 11:57:39]
  Epoch: [166][300/391]   Time 0.068 (0.052)   Data 0.000 (0.001)   Loss 0.0477 (0.0798)   Prec@1 99.219 (97.249)   Prec@5 100.000 (99.979)   [2019-11-23 11:57:44]
  **Train** Prec@1 97.186 Prec@5 99.984 Error@1 2.814
  **Test** Prec@1 90.450 Prec@5 99.700 Error@1 9.550

==>>[2019-11-23 11:57:51] [Epoch=167/200] [Need: 00:12:14] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [167][000/391]   Time 0.266 (0.266)   Data 0.210 (0.210)   Loss 0.0605 (0.0605)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:57:51]
  Epoch: [167][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.0606 (0.0776)   Prec@1 98.438 (97.246)   Prec@5 100.000 (100.000)   [2019-11-23 11:57:56]
  Epoch: [167][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0863 (0.0775)   Prec@1 96.875 (97.229)   Prec@5 100.000 (100.000)   [2019-11-23 11:58:01]
  Epoch: [167][300/391]   Time 0.074 (0.052)   Data 0.000 (0.001)   Loss 0.0555 (0.0776)   Prec@1 98.438 (97.275)   Prec@5 100.000 (99.997)   [2019-11-23 11:58:07]
  **Train** Prec@1 97.298 Prec@5 99.994 Error@1 2.702
  **Test** Prec@1 90.530 Prec@5 99.670 Error@1 9.470

==>>[2019-11-23 11:58:13] [Epoch=168/200] [Need: 00:11:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [168][000/391]   Time 0.264 (0.264)   Data 0.199 (0.199)   Loss 0.0576 (0.0576)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:58:13]
  Epoch: [168][100/391]   Time 0.058 (0.056)   Data 0.000 (0.002)   Loss 0.0627 (0.0748)   Prec@1 98.438 (97.316)   Prec@5 100.000 (99.992)   [2019-11-23 11:58:19]
  Epoch: [168][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0474 (0.0764)   Prec@1 98.438 (97.198)   Prec@5 100.000 (99.988)   [2019-11-23 11:58:24]
  Epoch: [168][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0463 (0.0781)   Prec@1 97.656 (97.186)   Prec@5 100.000 (99.987)   [2019-11-23 11:58:28]
  **Train** Prec@1 97.200 Prec@5 99.984 Error@1 2.800
  **Test** Prec@1 90.480 Prec@5 99.640 Error@1 9.520

==>>[2019-11-23 11:58:35] [Epoch=169/200] [Need: 00:11:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [169][000/391]   Time 0.251 (0.251)   Data 0.183 (0.183)   Loss 0.1047 (0.1047)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 11:58:35]
  Epoch: [169][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0213 (0.0788)   Prec@1 100.000 (97.184)   Prec@5 100.000 (99.985)   [2019-11-23 11:58:40]
  Epoch: [169][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1164 (0.0760)   Prec@1 94.531 (97.330)   Prec@5 100.000 (99.984)   [2019-11-23 11:58:45]
  Epoch: [169][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0474 (0.0775)   Prec@1 99.219 (97.277)   Prec@5 100.000 (99.984)   [2019-11-23 11:58:50]
  **Train** Prec@1 97.284 Prec@5 99.988 Error@1 2.716
  **Test** Prec@1 90.100 Prec@5 99.640 Error@1 9.900

==>>[2019-11-23 11:58:57] [Epoch=170/200] [Need: 00:11:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [170][000/391]   Time 0.275 (0.275)   Data 0.208 (0.208)   Loss 0.0359 (0.0359)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:58:57]
  Epoch: [170][100/391]   Time 0.049 (0.053)   Data 0.000 (0.002)   Loss 0.0672 (0.0760)   Prec@1 97.656 (97.339)   Prec@5 100.000 (99.969)   [2019-11-23 11:59:02]
  Epoch: [170][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0838 (0.0790)   Prec@1 96.875 (97.233)   Prec@5 100.000 (99.981)   [2019-11-23 11:59:07]
  Epoch: [170][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0525 (0.0791)   Prec@1 98.438 (97.220)   Prec@5 100.000 (99.984)   [2019-11-23 11:59:12]
  **Train** Prec@1 97.180 Prec@5 99.984 Error@1 2.820
  **Test** Prec@1 90.470 Prec@5 99.630 Error@1 9.530

==>>[2019-11-23 11:59:19] [Epoch=171/200] [Need: 00:10:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [171][000/391]   Time 0.252 (0.252)   Data 0.187 (0.187)   Loss 0.0842 (0.0842)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 11:59:19]
  Epoch: [171][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1338 (0.0828)   Prec@1 96.094 (97.068)   Prec@5 100.000 (99.977)   [2019-11-23 11:59:24]
  Epoch: [171][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.1150 (0.0795)   Prec@1 95.312 (97.163)   Prec@5 100.000 (99.981)   [2019-11-23 11:59:29]
  Epoch: [171][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0980 (0.0784)   Prec@1 96.875 (97.215)   Prec@5 100.000 (99.982)   [2019-11-23 11:59:34]
  **Train** Prec@1 97.246 Prec@5 99.984 Error@1 2.754
  **Test** Prec@1 90.330 Prec@5 99.630 Error@1 9.670

==>>[2019-11-23 11:59:40] [Epoch=172/200] [Need: 00:10:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [172][000/391]   Time 0.251 (0.251)   Data 0.183 (0.183)   Loss 0.0507 (0.0507)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 11:59:41]
  Epoch: [172][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0870 (0.0808)   Prec@1 96.875 (97.177)   Prec@5 100.000 (99.969)   [2019-11-23 11:59:46]
  Epoch: [172][200/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.0993 (0.0794)   Prec@1 96.875 (97.139)   Prec@5 100.000 (99.984)   [2019-11-23 11:59:51]
  Epoch: [172][300/391]   Time 0.064 (0.052)   Data 0.000 (0.001)   Loss 0.0743 (0.0796)   Prec@1 96.094 (97.155)   Prec@5 100.000 (99.979)   [2019-11-23 11:59:56]
  **Train** Prec@1 97.114 Prec@5 99.980 Error@1 2.886
  **Test** Prec@1 90.410 Prec@5 99.640 Error@1 9.590

==>>[2019-11-23 12:00:03] [Epoch=173/200] [Need: 00:10:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [173][000/391]   Time 0.253 (0.253)   Data 0.187 (0.187)   Loss 0.0896 (0.0896)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-23 12:00:03]
  Epoch: [173][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.0335 (0.0754)   Prec@1 100.000 (97.316)   Prec@5 100.000 (99.985)   [2019-11-23 12:00:08]
  Epoch: [173][200/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 0.0384 (0.0789)   Prec@1 98.438 (97.225)   Prec@5 100.000 (99.988)   [2019-11-23 12:00:14]
  Epoch: [173][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0374 (0.0799)   Prec@1 99.219 (97.166)   Prec@5 100.000 (99.984)   [2019-11-23 12:00:19]
  **Train** Prec@1 97.142 Prec@5 99.988 Error@1 2.858
  **Test** Prec@1 90.670 Prec@5 99.680 Error@1 9.330

==>>[2019-11-23 12:00:25] [Epoch=174/200] [Need: 00:09:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [174][000/391]   Time 0.267 (0.267)   Data 0.203 (0.203)   Loss 0.0912 (0.0912)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 12:00:25]
  Epoch: [174][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0695 (0.0770)   Prec@1 97.656 (97.161)   Prec@5 100.000 (99.985)   [2019-11-23 12:00:31]
  Epoch: [174][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0905 (0.0788)   Prec@1 95.312 (97.112)   Prec@5 100.000 (99.977)   [2019-11-23 12:00:36]
  Epoch: [174][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0716 (0.0801)   Prec@1 97.656 (97.153)   Prec@5 100.000 (99.974)   [2019-11-23 12:00:41]
  **Train** Prec@1 97.156 Prec@5 99.980 Error@1 2.844
  **Test** Prec@1 90.480 Prec@5 99.720 Error@1 9.520

==>>[2019-11-23 12:00:48] [Epoch=175/200] [Need: 00:09:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [175][000/391]   Time 0.254 (0.254)   Data 0.189 (0.189)   Loss 0.0835 (0.0835)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:00:48]
  Epoch: [175][100/391]   Time 0.083 (0.057)   Data 0.000 (0.002)   Loss 0.0429 (0.0753)   Prec@1 98.438 (97.401)   Prec@5 100.000 (99.977)   [2019-11-23 12:00:54]
  Epoch: [175][200/391]   Time 0.054 (0.054)   Data 0.000 (0.001)   Loss 0.0666 (0.0786)   Prec@1 96.875 (97.303)   Prec@5 100.000 (99.973)   [2019-11-23 12:00:59]
  Epoch: [175][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.0645 (0.0785)   Prec@1 96.875 (97.308)   Prec@5 100.000 (99.974)   [2019-11-23 12:01:04]
  **Train** Prec@1 97.298 Prec@5 99.980 Error@1 2.702
  **Test** Prec@1 90.600 Prec@5 99.680 Error@1 9.400

==>>[2019-11-23 12:01:10] [Epoch=176/200] [Need: 00:08:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [176][000/391]   Time 0.258 (0.258)   Data 0.182 (0.182)   Loss 0.1231 (0.1231)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 12:01:10]
  Epoch: [176][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0793 (0.0786)   Prec@1 97.656 (97.192)   Prec@5 100.000 (99.977)   [2019-11-23 12:01:15]
  Epoch: [176][200/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.0370 (0.0776)   Prec@1 98.438 (97.151)   Prec@5 100.000 (99.977)   [2019-11-23 12:01:21]
  Epoch: [176][300/391]   Time 0.072 (0.053)   Data 0.000 (0.001)   Loss 0.0912 (0.0778)   Prec@1 97.656 (97.207)   Prec@5 100.000 (99.982)   [2019-11-23 12:01:26]
  **Train** Prec@1 97.228 Prec@5 99.984 Error@1 2.772
  **Test** Prec@1 90.450 Prec@5 99.650 Error@1 9.550

==>>[2019-11-23 12:01:32] [Epoch=177/200] [Need: 00:08:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [177][000/391]   Time 0.277 (0.277)   Data 0.199 (0.199)   Loss 0.0609 (0.0609)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:01:32]
  Epoch: [177][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0887 (0.0776)   Prec@1 96.094 (97.416)   Prec@5 100.000 (99.969)   [2019-11-23 12:01:37]
  Epoch: [177][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.1045 (0.0775)   Prec@1 95.312 (97.338)   Prec@5 100.000 (99.969)   [2019-11-23 12:01:42]
  Epoch: [177][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0531 (0.0779)   Prec@1 98.438 (97.314)   Prec@5 100.000 (99.971)   [2019-11-23 12:01:47]
  **Train** Prec@1 97.220 Prec@5 99.978 Error@1 2.780
  **Test** Prec@1 90.520 Prec@5 99.670 Error@1 9.480

==>>[2019-11-23 12:01:54] [Epoch=178/200] [Need: 00:08:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [178][000/391]   Time 0.254 (0.254)   Data 0.195 (0.195)   Loss 0.1326 (0.1326)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:01:54]
  Epoch: [178][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.1199 (0.0818)   Prec@1 94.531 (97.192)   Prec@5 100.000 (99.992)   [2019-11-23 12:01:59]
  Epoch: [178][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1300 (0.0795)   Prec@1 95.312 (97.299)   Prec@5 100.000 (99.988)   [2019-11-23 12:02:04]
  Epoch: [178][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0283 (0.0787)   Prec@1 99.219 (97.288)   Prec@5 100.000 (99.987)   [2019-11-23 12:02:09]
  **Train** Prec@1 97.286 Prec@5 99.982 Error@1 2.714
  **Test** Prec@1 90.590 Prec@5 99.640 Error@1 9.410

==>>[2019-11-23 12:02:16] [Epoch=179/200] [Need: 00:07:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [179][000/391]   Time 0.256 (0.256)   Data 0.200 (0.200)   Loss 0.0846 (0.0846)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:02:16]
  Epoch: [179][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0367 (0.0791)   Prec@1 98.438 (97.146)   Prec@5 100.000 (100.000)   [2019-11-23 12:02:22]
  Epoch: [179][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0911 (0.0773)   Prec@1 96.094 (97.236)   Prec@5 100.000 (100.000)   [2019-11-23 12:02:26]
  Epoch: [179][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0695 (0.0785)   Prec@1 97.656 (97.238)   Prec@5 100.000 (99.997)   [2019-11-23 12:02:31]
  **Train** Prec@1 97.172 Prec@5 99.996 Error@1 2.828
  **Test** Prec@1 90.390 Prec@5 99.710 Error@1 9.610

==>>[2019-11-23 12:02:38] [Epoch=180/200] [Need: 00:07:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [180][000/391]   Time 0.262 (0.262)   Data 0.204 (0.204)   Loss 0.0216 (0.0216)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 12:02:38]
  Epoch: [180][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.0670 (0.0745)   Prec@1 97.656 (97.502)   Prec@5 100.000 (99.969)   [2019-11-23 12:02:43]
  Epoch: [180][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1139 (0.0784)   Prec@1 96.094 (97.248)   Prec@5 100.000 (99.981)   [2019-11-23 12:02:48]
  Epoch: [180][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0680 (0.0778)   Prec@1 97.656 (97.238)   Prec@5 100.000 (99.982)   [2019-11-23 12:02:53]
  **Train** Prec@1 97.208 Prec@5 99.986 Error@1 2.792
  **Test** Prec@1 90.050 Prec@5 99.700 Error@1 9.950

==>>[2019-11-23 12:03:00] [Epoch=181/200] [Need: 00:07:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [181][000/391]   Time 0.250 (0.250)   Data 0.201 (0.201)   Loss 0.0752 (0.0752)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:03:00]
  Epoch: [181][100/391]   Time 0.055 (0.054)   Data 0.000 (0.002)   Loss 0.0422 (0.0762)   Prec@1 98.438 (97.440)   Prec@5 100.000 (99.977)   [2019-11-23 12:03:06]
  Epoch: [181][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0466 (0.0761)   Prec@1 99.219 (97.330)   Prec@5 100.000 (99.984)   [2019-11-23 12:03:11]
  Epoch: [181][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0652 (0.0772)   Prec@1 97.656 (97.270)   Prec@5 100.000 (99.987)   [2019-11-23 12:03:15]
  **Train** Prec@1 97.280 Prec@5 99.990 Error@1 2.720
  **Test** Prec@1 90.530 Prec@5 99.660 Error@1 9.470

==>>[2019-11-23 12:03:22] [Epoch=182/200] [Need: 00:06:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [182][000/391]   Time 0.245 (0.245)   Data 0.190 (0.190)   Loss 0.1260 (0.1260)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-23 12:03:22]
  Epoch: [182][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.0488 (0.0731)   Prec@1 97.656 (97.339)   Prec@5 100.000 (99.992)   [2019-11-23 12:03:27]
  Epoch: [182][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0419 (0.0780)   Prec@1 99.219 (97.143)   Prec@5 100.000 (99.992)   [2019-11-23 12:03:32]
  Epoch: [182][300/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0657 (0.0773)   Prec@1 96.875 (97.194)   Prec@5 100.000 (99.995)   [2019-11-23 12:03:37]
  **Train** Prec@1 97.230 Prec@5 99.988 Error@1 2.770
  **Test** Prec@1 90.770 Prec@5 99.700 Error@1 9.230
=> Obtain best accuracy, and update the best model

==>>[2019-11-23 12:03:44] [Epoch=183/200] [Need: 00:06:18] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [183][000/391]   Time 0.259 (0.259)   Data 0.199 (0.199)   Loss 0.0449 (0.0449)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 12:03:44]
  Epoch: [183][100/391]   Time 0.060 (0.056)   Data 0.000 (0.002)   Loss 0.0514 (0.0770)   Prec@1 98.438 (97.432)   Prec@5 100.000 (99.985)   [2019-11-23 12:03:50]
  Epoch: [183][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0317 (0.0806)   Prec@1 99.219 (97.155)   Prec@5 100.000 (99.981)   [2019-11-23 12:03:54]
  Epoch: [183][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.0687 (0.0778)   Prec@1 98.438 (97.316)   Prec@5 100.000 (99.979)   [2019-11-23 12:03:59]
  **Train** Prec@1 97.308 Prec@5 99.982 Error@1 2.692
  **Test** Prec@1 90.570 Prec@5 99.640 Error@1 9.430

==>>[2019-11-23 12:04:06] [Epoch=184/200] [Need: 00:05:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [184][000/391]   Time 0.267 (0.267)   Data 0.199 (0.199)   Loss 0.0716 (0.0716)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 12:04:06]
  Epoch: [184][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.1347 (0.0786)   Prec@1 95.312 (97.022)   Prec@5 100.000 (99.969)   [2019-11-23 12:04:11]
  Epoch: [184][200/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0477 (0.0773)   Prec@1 98.438 (97.240)   Prec@5 100.000 (99.973)   [2019-11-23 12:04:16]
  Epoch: [184][300/391]   Time 0.060 (0.050)   Data 0.000 (0.001)   Loss 0.1177 (0.0784)   Prec@1 94.531 (97.238)   Prec@5 100.000 (99.977)   [2019-11-23 12:04:21]
  **Train** Prec@1 97.208 Prec@5 99.980 Error@1 2.792
  **Test** Prec@1 90.480 Prec@5 99.740 Error@1 9.520

==>>[2019-11-23 12:04:28] [Epoch=185/200] [Need: 00:05:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [185][000/391]   Time 0.256 (0.256)   Data 0.198 (0.198)   Loss 0.0545 (0.0545)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-23 12:04:28]
  Epoch: [185][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0534 (0.0763)   Prec@1 98.438 (97.370)   Prec@5 100.000 (99.992)   [2019-11-23 12:04:33]
  Epoch: [185][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.1066 (0.0774)   Prec@1 96.094 (97.213)   Prec@5 100.000 (99.996)   [2019-11-23 12:04:38]
  Epoch: [185][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.1070 (0.0772)   Prec@1 95.312 (97.223)   Prec@5 100.000 (99.995)   [2019-11-23 12:04:43]
  **Train** Prec@1 97.258 Prec@5 99.990 Error@1 2.742
  **Test** Prec@1 90.320 Prec@5 99.560 Error@1 9.680

==>>[2019-11-23 12:04:50] [Epoch=186/200] [Need: 00:05:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [186][000/391]   Time 0.267 (0.267)   Data 0.209 (0.209)   Loss 0.0849 (0.0849)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:04:50]
  Epoch: [186][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0551 (0.0754)   Prec@1 99.219 (97.362)   Prec@5 100.000 (99.977)   [2019-11-23 12:04:55]
  Epoch: [186][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0289 (0.0767)   Prec@1 98.438 (97.334)   Prec@5 100.000 (99.984)   [2019-11-23 12:05:00]
  Epoch: [186][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0777 (0.0768)   Prec@1 96.875 (97.316)   Prec@5 100.000 (99.990)   [2019-11-23 12:05:05]
  **Train** Prec@1 97.332 Prec@5 99.990 Error@1 2.668
  **Test** Prec@1 90.310 Prec@5 99.650 Error@1 9.690

==>>[2019-11-23 12:05:12] [Epoch=187/200] [Need: 00:04:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [187][000/391]   Time 0.254 (0.254)   Data 0.188 (0.188)   Loss 0.0946 (0.0946)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 12:05:12]
  Epoch: [187][100/391]   Time 0.072 (0.052)   Data 0.000 (0.002)   Loss 0.1310 (0.0749)   Prec@1 93.750 (97.231)   Prec@5 100.000 (99.961)   [2019-11-23 12:05:17]
  Epoch: [187][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1113 (0.0781)   Prec@1 96.875 (97.147)   Prec@5 100.000 (99.977)   [2019-11-23 12:05:22]
  Epoch: [187][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0518 (0.0787)   Prec@1 97.656 (97.109)   Prec@5 100.000 (99.984)   [2019-11-23 12:05:27]
  **Train** Prec@1 97.144 Prec@5 99.986 Error@1 2.856
  **Test** Prec@1 90.340 Prec@5 99.690 Error@1 9.660

==>>[2019-11-23 12:05:33] [Epoch=188/200] [Need: 00:04:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [188][000/391]   Time 0.259 (0.259)   Data 0.191 (0.191)   Loss 0.0343 (0.0343)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-23 12:05:33]
  Epoch: [188][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0614 (0.0743)   Prec@1 96.875 (97.393)   Prec@5 100.000 (99.969)   [2019-11-23 12:05:39]
  Epoch: [188][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0305 (0.0780)   Prec@1 99.219 (97.201)   Prec@5 100.000 (99.973)   [2019-11-23 12:05:44]
  Epoch: [188][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0805 (0.0769)   Prec@1 97.656 (97.251)   Prec@5 100.000 (99.982)   [2019-11-23 12:05:48]
  **Train** Prec@1 97.176 Prec@5 99.980 Error@1 2.824
  **Test** Prec@1 90.470 Prec@5 99.670 Error@1 9.530

==>>[2019-11-23 12:05:55] [Epoch=189/200] [Need: 00:04:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [189][000/391]   Time 0.262 (0.262)   Data 0.206 (0.206)   Loss 0.0690 (0.0690)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:05:56]
  Epoch: [189][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1030 (0.0746)   Prec@1 96.094 (97.556)   Prec@5 100.000 (99.977)   [2019-11-23 12:06:01]
  Epoch: [189][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0812 (0.0769)   Prec@1 96.875 (97.388)   Prec@5 100.000 (99.988)   [2019-11-23 12:06:06]
  Epoch: [189][300/391]   Time 0.075 (0.049)   Data 0.000 (0.001)   Loss 0.0695 (0.0774)   Prec@1 98.438 (97.417)   Prec@5 100.000 (99.992)   [2019-11-23 12:06:10]
  **Train** Prec@1 97.350 Prec@5 99.986 Error@1 2.650
  **Test** Prec@1 90.160 Prec@5 99.690 Error@1 9.840

==>>[2019-11-23 12:06:17] [Epoch=190/200] [Need: 00:03:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [190][000/391]   Time 0.259 (0.259)   Data 0.201 (0.201)   Loss 0.0438 (0.0438)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 12:06:17]
  Epoch: [190][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.0951 (0.0797)   Prec@1 95.312 (97.308)   Prec@5 100.000 (99.969)   [2019-11-23 12:06:22]
  Epoch: [190][200/391]   Time 0.056 (0.049)   Data 0.000 (0.001)   Loss 0.1245 (0.0782)   Prec@1 96.875 (97.283)   Prec@5 100.000 (99.981)   [2019-11-23 12:06:27]
  Epoch: [190][300/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.0900 (0.0769)   Prec@1 98.438 (97.301)   Prec@5 100.000 (99.982)   [2019-11-23 12:06:32]
  **Train** Prec@1 97.310 Prec@5 99.980 Error@1 2.690
  **Test** Prec@1 90.410 Prec@5 99.670 Error@1 9.590

==>>[2019-11-23 12:06:39] [Epoch=191/200] [Need: 00:03:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [191][000/391]   Time 0.255 (0.255)   Data 0.180 (0.180)   Loss 0.0428 (0.0428)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 12:06:39]
  Epoch: [191][100/391]   Time 0.054 (0.051)   Data 0.000 (0.002)   Loss 0.0657 (0.0720)   Prec@1 96.875 (97.416)   Prec@5 100.000 (99.992)   [2019-11-23 12:06:44]
  Epoch: [191][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.1166 (0.0764)   Prec@1 93.750 (97.252)   Prec@5 100.000 (99.988)   [2019-11-23 12:06:49]
  Epoch: [191][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0544 (0.0765)   Prec@1 97.656 (97.327)   Prec@5 100.000 (99.992)   [2019-11-23 12:06:54]
  **Train** Prec@1 97.308 Prec@5 99.986 Error@1 2.692
  **Test** Prec@1 90.570 Prec@5 99.640 Error@1 9.430

==>>[2019-11-23 12:07:01] [Epoch=192/200] [Need: 00:02:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [192][000/391]   Time 0.262 (0.262)   Data 0.199 (0.199)   Loss 0.0593 (0.0593)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 12:07:01]
  Epoch: [192][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.0524 (0.0729)   Prec@1 98.438 (97.447)   Prec@5 100.000 (99.992)   [2019-11-23 12:07:06]
  Epoch: [192][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.1395 (0.0765)   Prec@1 94.531 (97.345)   Prec@5 100.000 (99.988)   [2019-11-23 12:07:11]
  Epoch: [192][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.1184 (0.0782)   Prec@1 96.875 (97.262)   Prec@5 100.000 (99.992)   [2019-11-23 12:07:16]
  **Train** Prec@1 97.238 Prec@5 99.986 Error@1 2.762
  **Test** Prec@1 90.490 Prec@5 99.670 Error@1 9.510

==>>[2019-11-23 12:07:23] [Epoch=193/200] [Need: 00:02:35] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [193][000/391]   Time 0.260 (0.260)   Data 0.194 (0.194)   Loss 0.1120 (0.1120)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-23 12:07:23]
  Epoch: [193][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1086 (0.0749)   Prec@1 97.656 (97.316)   Prec@5 100.000 (99.985)   [2019-11-23 12:07:28]
  Epoch: [193][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.1226 (0.0768)   Prec@1 95.312 (97.233)   Prec@5 100.000 (99.981)   [2019-11-23 12:07:33]
  Epoch: [193][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.1345 (0.0775)   Prec@1 95.312 (97.210)   Prec@5 100.000 (99.982)   [2019-11-23 12:07:38]
  **Train** Prec@1 97.286 Prec@5 99.982 Error@1 2.714
  **Test** Prec@1 90.380 Prec@5 99.640 Error@1 9.620

==>>[2019-11-23 12:07:45] [Epoch=194/200] [Need: 00:02:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [194][000/391]   Time 0.264 (0.264)   Data 0.181 (0.181)   Loss 0.0651 (0.0651)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-23 12:07:45]
  Epoch: [194][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0852 (0.0755)   Prec@1 98.438 (97.285)   Prec@5 100.000 (99.992)   [2019-11-23 12:07:50]
  Epoch: [194][200/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.0577 (0.0755)   Prec@1 97.656 (97.287)   Prec@5 100.000 (99.992)   [2019-11-23 12:07:55]
  Epoch: [194][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0422 (0.0758)   Prec@1 99.219 (97.246)   Prec@5 100.000 (99.992)   [2019-11-23 12:08:00]
  **Train** Prec@1 97.194 Prec@5 99.990 Error@1 2.806
  **Test** Prec@1 90.570 Prec@5 99.600 Error@1 9.430

==>>[2019-11-23 12:08:07] [Epoch=195/200] [Need: 00:01:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [195][000/391]   Time 0.254 (0.254)   Data 0.190 (0.190)   Loss 0.0795 (0.0795)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-23 12:08:07]
  Epoch: [195][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.1174 (0.0780)   Prec@1 96.094 (97.246)   Prec@5 100.000 (99.992)   [2019-11-23 12:08:12]
  Epoch: [195][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.1233 (0.0761)   Prec@1 95.312 (97.310)   Prec@5 100.000 (99.977)   [2019-11-23 12:08:17]
  Epoch: [195][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0665 (0.0776)   Prec@1 97.656 (97.249)   Prec@5 100.000 (99.982)   [2019-11-23 12:08:22]
  **Train** Prec@1 97.264 Prec@5 99.978 Error@1 2.736
  **Test** Prec@1 90.600 Prec@5 99.710 Error@1 9.400

==>>[2019-11-23 12:08:29] [Epoch=196/200] [Need: 00:01:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [196][000/391]   Time 0.250 (0.250)   Data 0.191 (0.191)   Loss 0.0686 (0.0686)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 12:08:29]
  Epoch: [196][100/391]   Time 0.058 (0.052)   Data 0.000 (0.002)   Loss 0.0954 (0.0755)   Prec@1 96.875 (97.393)   Prec@5 100.000 (99.992)   [2019-11-23 12:08:34]
  Epoch: [196][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.1611 (0.0765)   Prec@1 93.750 (97.256)   Prec@5 100.000 (99.988)   [2019-11-23 12:08:39]
  Epoch: [196][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0983 (0.0776)   Prec@1 96.875 (97.179)   Prec@5 100.000 (99.982)   [2019-11-23 12:08:45]
  **Train** Prec@1 97.208 Prec@5 99.982 Error@1 2.792
  **Test** Prec@1 90.540 Prec@5 99.690 Error@1 9.460

==>>[2019-11-23 12:08:51] [Epoch=197/200] [Need: 00:01:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [197][000/391]   Time 0.268 (0.268)   Data 0.207 (0.207)   Loss 0.1240 (0.1240)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-23 12:08:52]
  Epoch: [197][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0622 (0.0744)   Prec@1 97.656 (97.254)   Prec@5 100.000 (99.992)   [2019-11-23 12:08:57]
  Epoch: [197][200/391]   Time 0.062 (0.053)   Data 0.000 (0.001)   Loss 0.0470 (0.0739)   Prec@1 99.219 (97.268)   Prec@5 100.000 (99.996)   [2019-11-23 12:09:02]
  Epoch: [197][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0519 (0.0751)   Prec@1 97.656 (97.251)   Prec@5 100.000 (99.982)   [2019-11-23 12:09:07]
  **Train** Prec@1 97.220 Prec@5 99.982 Error@1 2.780
  **Test** Prec@1 90.550 Prec@5 99.610 Error@1 9.450

==>>[2019-11-23 12:09:13] [Epoch=198/200] [Need: 00:00:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [198][000/391]   Time 0.284 (0.284)   Data 0.214 (0.214)   Loss 0.0938 (0.0938)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-23 12:09:14]
  Epoch: [198][100/391]   Time 0.054 (0.052)   Data 0.000 (0.002)   Loss 0.1403 (0.0681)   Prec@1 96.094 (97.563)   Prec@5 99.219 (99.985)   [2019-11-23 12:09:19]
  Epoch: [198][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.0636 (0.0742)   Prec@1 97.656 (97.380)   Prec@5 100.000 (99.965)   [2019-11-23 12:09:24]
  Epoch: [198][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0730 (0.0751)   Prec@1 96.094 (97.337)   Prec@5 100.000 (99.974)   [2019-11-23 12:09:29]
  **Train** Prec@1 97.358 Prec@5 99.972 Error@1 2.642
  **Test** Prec@1 90.300 Prec@5 99.650 Error@1 9.700

==>>[2019-11-23 12:09:35] [Epoch=199/200] [Need: 00:00:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.77, Error=9.23]
  Epoch: [199][000/391]   Time 0.265 (0.265)   Data 0.194 (0.194)   Loss 0.0795 (0.0795)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-23 12:09:36]
  Epoch: [199][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.0386 (0.0747)   Prec@1 98.438 (97.486)   Prec@5 100.000 (99.992)   [2019-11-23 12:09:41]
  Epoch: [199][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.0858 (0.0772)   Prec@1 96.875 (97.306)   Prec@5 100.000 (99.984)   [2019-11-23 12:09:46]
  Epoch: [199][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0874 (0.0764)   Prec@1 96.094 (97.308)   Prec@5 100.000 (99.984)   [2019-11-23 12:09:51]
  **Train** Prec@1 97.312 Prec@5 99.984 Error@1 2.688
  **Test** Prec@1 90.290 Prec@5 99.660 Error@1 9.710
