save path : ./save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_6bit_reg0.0
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 4], 'input_num_bits': 6, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.8, 'output_grain_size': [1, 4], 'output_num_bits': 6, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.8, 'res_grain_size': [1, 4], 'res_num_bits': 6, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_6bit_reg0.0', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-22 02:34:40] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.641 (1.641)   Data 0.143 (0.143)   Loss 3.6841 (3.6841)   Prec@1 8.594 (8.594)   Prec@5 48.438 (48.438)   [2019-11-22 02:34:41]
  Epoch: [000][100/391]   Time 0.043 (0.065)   Data 0.000 (0.002)   Loss 1.7342 (1.9515)   Prec@1 32.031 (27.939)   Prec@5 85.938 (81.173)   [2019-11-22 02:34:46]
  Epoch: [000][200/391]   Time 0.044 (0.059)   Data 0.000 (0.001)   Loss 1.5317 (1.7836)   Prec@1 39.844 (33.792)   Prec@5 92.969 (85.638)   [2019-11-22 02:34:51]
  Epoch: [000][300/391]   Time 0.044 (0.055)   Data 0.000 (0.001)   Loss 1.2115 (1.6563)   Prec@1 57.812 (38.681)   Prec@5 94.531 (88.188)   [2019-11-22 02:34:56]
  **Train** Prec@1 42.104 Prec@5 89.618 Error@1 57.896
  **Test** Prec@1 53.350 Prec@5 94.870 Error@1 46.650
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:35:02] [Epoch=001/200] [Need: 01:15:08] [LR=0.0100][M=0.90] [Best : Accuracy=53.35, Error=46.65]
  Epoch: [001][000/391]   Time 0.222 (0.222)   Data 0.156 (0.156)   Loss 1.2365 (1.2365)   Prec@1 53.125 (53.125)   Prec@5 96.094 (96.094)   [2019-11-22 02:35:03]
  Epoch: [001][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 1.1681 (1.1712)   Prec@1 57.031 (57.248)   Prec@5 97.656 (95.552)   [2019-11-22 02:35:08]
  Epoch: [001][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 1.0554 (1.1275)   Prec@1 58.594 (59.083)   Prec@5 96.875 (95.880)   [2019-11-22 02:35:13]
  Epoch: [001][300/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.9817 (1.1022)   Prec@1 64.844 (60.281)   Prec@5 96.875 (96.000)   [2019-11-22 02:35:17]
  **Train** Prec@1 61.516 Prec@5 96.186 Error@1 38.484
  **Test** Prec@1 60.660 Prec@5 96.140 Error@1 39.340
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:35:24] [Epoch=002/200] [Need: 01:12:17] [LR=0.0100][M=0.90] [Best : Accuracy=60.66, Error=39.34]
  Epoch: [002][000/391]   Time 0.218 (0.218)   Data 0.161 (0.161)   Loss 0.9651 (0.9651)   Prec@1 67.969 (67.969)   Prec@5 95.312 (95.312)   [2019-11-22 02:35:24]
  Epoch: [002][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.9535 (0.9249)   Prec@1 66.406 (66.832)   Prec@5 97.656 (97.362)   [2019-11-22 02:35:29]
  Epoch: [002][200/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 1.0076 (0.8928)   Prec@1 64.844 (68.225)   Prec@5 99.219 (97.575)   [2019-11-22 02:35:34]
  Epoch: [002][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.7608 (0.8736)   Prec@1 71.094 (69.108)   Prec@5 97.656 (97.628)   [2019-11-22 02:35:39]
  **Train** Prec@1 69.676 Prec@5 97.672 Error@1 30.324
  **Test** Prec@1 72.320 Prec@5 97.980 Error@1 27.680
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:35:46] [Epoch=003/200] [Need: 01:11:54] [LR=0.0100][M=0.90] [Best : Accuracy=72.32, Error=27.68]
  Epoch: [003][000/391]   Time 0.226 (0.226)   Data 0.161 (0.161)   Loss 1.0313 (1.0313)   Prec@1 62.500 (62.500)   Prec@5 96.094 (96.094)   [2019-11-22 02:35:46]
  Epoch: [003][100/391]   Time 0.074 (0.054)   Data 0.000 (0.002)   Loss 0.7660 (0.7666)   Prec@1 73.438 (73.623)   Prec@5 100.000 (98.043)   [2019-11-22 02:35:51]
  Epoch: [003][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.7529 (0.7583)   Prec@1 75.000 (73.904)   Prec@5 96.094 (98.134)   [2019-11-22 02:35:56]
  Epoch: [003][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5751 (0.7515)   Prec@1 78.906 (74.055)   Prec@5 99.219 (98.134)   [2019-11-22 02:36:01]
  **Train** Prec@1 74.276 Prec@5 98.164 Error@1 25.724
  **Test** Prec@1 73.500 Prec@5 98.110 Error@1 26.500
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:36:08] [Epoch=004/200] [Need: 01:11:37] [LR=0.0100][M=0.90] [Best : Accuracy=73.50, Error=26.50]
  Epoch: [004][000/391]   Time 0.226 (0.226)   Data 0.169 (0.169)   Loss 0.6864 (0.6864)   Prec@1 78.906 (78.906)   Prec@5 97.656 (97.656)   [2019-11-22 02:36:08]
  Epoch: [004][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.6110 (0.7048)   Prec@1 81.250 (75.472)   Prec@5 96.875 (98.182)   [2019-11-22 02:36:13]
  Epoch: [004][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.5973 (0.6945)   Prec@1 76.562 (75.762)   Prec@5 100.000 (98.321)   [2019-11-22 02:36:18]
  Epoch: [004][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.5968 (0.6871)   Prec@1 78.906 (75.903)   Prec@5 99.219 (98.448)   [2019-11-22 02:36:23]
  **Train** Prec@1 76.312 Prec@5 98.514 Error@1 23.688
  **Test** Prec@1 71.760 Prec@5 98.080 Error@1 28.240

==>>[2019-11-22 02:36:29] [Epoch=005/200] [Need: 01:11:14] [LR=0.0100][M=0.90] [Best : Accuracy=73.50, Error=26.50]
  Epoch: [005][000/391]   Time 0.236 (0.236)   Data 0.165 (0.165)   Loss 0.5965 (0.5965)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-22 02:36:30]
  Epoch: [005][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.4992 (0.6325)   Prec@1 85.156 (77.924)   Prec@5 98.438 (98.685)   [2019-11-22 02:36:35]
  Epoch: [005][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.6009 (0.6384)   Prec@1 81.250 (77.900)   Prec@5 99.219 (98.651)   [2019-11-22 02:36:40]
  Epoch: [005][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.6266 (0.6302)   Prec@1 80.469 (78.252)   Prec@5 98.438 (98.656)   [2019-11-22 02:36:45]
  **Train** Prec@1 78.496 Prec@5 98.704 Error@1 21.504
  **Test** Prec@1 75.040 Prec@5 97.850 Error@1 24.960
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:36:51] [Epoch=006/200] [Need: 01:10:46] [LR=0.0100][M=0.90] [Best : Accuracy=75.04, Error=24.96]
  Epoch: [006][000/391]   Time 0.226 (0.226)   Data 0.171 (0.171)   Loss 0.5091 (0.5091)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2019-11-22 02:36:51]
  Epoch: [006][100/391]   Time 0.059 (0.054)   Data 0.000 (0.002)   Loss 0.5679 (0.5994)   Prec@1 78.125 (79.076)   Prec@5 99.219 (98.878)   [2019-11-22 02:36:57]
  Epoch: [006][200/391]   Time 0.053 (0.055)   Data 0.000 (0.001)   Loss 0.7625 (0.5973)   Prec@1 71.875 (79.248)   Prec@5 98.438 (98.830)   [2019-11-22 02:37:02]
  Epoch: [006][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.6597 (0.5980)   Prec@1 77.344 (79.270)   Prec@5 98.438 (98.855)   [2019-11-22 02:37:07]
  **Train** Prec@1 79.446 Prec@5 98.854 Error@1 20.554
  **Test** Prec@1 78.500 Prec@5 98.770 Error@1 21.500
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:37:13] [Epoch=007/200] [Need: 01:10:34] [LR=0.0100][M=0.90] [Best : Accuracy=78.50, Error=21.50]
  Epoch: [007][000/391]   Time 0.218 (0.218)   Data 0.156 (0.156)   Loss 0.5956 (0.5956)   Prec@1 78.906 (78.906)   Prec@5 97.656 (97.656)   [2019-11-22 02:37:14]
  Epoch: [007][100/391]   Time 0.056 (0.052)   Data 0.000 (0.002)   Loss 0.7060 (0.5611)   Prec@1 75.781 (80.422)   Prec@5 98.438 (99.025)   [2019-11-22 02:37:19]
  Epoch: [007][200/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.6883 (0.5543)   Prec@1 76.562 (80.710)   Prec@5 97.656 (98.993)   [2019-11-22 02:37:24]
  Epoch: [007][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.5828 (0.5584)   Prec@1 76.562 (80.635)   Prec@5 99.219 (98.998)   [2019-11-22 02:37:29]
  **Train** Prec@1 80.668 Prec@5 99.000 Error@1 19.332
  **Test** Prec@1 76.180 Prec@5 98.340 Error@1 23.820

==>>[2019-11-22 02:37:35] [Epoch=008/200] [Need: 01:09:55] [LR=0.0100][M=0.90] [Best : Accuracy=78.50, Error=21.50]
  Epoch: [008][000/391]   Time 0.228 (0.228)   Data 0.166 (0.166)   Loss 0.5434 (0.5434)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-22 02:37:35]
  Epoch: [008][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.5309 (0.5553)   Prec@1 82.031 (81.204)   Prec@5 98.438 (99.141)   [2019-11-22 02:37:40]
  Epoch: [008][200/391]   Time 0.054 (0.054)   Data 0.000 (0.001)   Loss 0.4988 (0.5461)   Prec@1 80.469 (81.242)   Prec@5 100.000 (99.141)   [2019-11-22 02:37:46]
  Epoch: [008][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.6900 (0.5402)   Prec@1 71.094 (81.437)   Prec@5 100.000 (99.146)   [2019-11-22 02:37:50]
  **Train** Prec@1 81.490 Prec@5 99.138 Error@1 18.510
  **Test** Prec@1 80.220 Prec@5 98.900 Error@1 19.780
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:37:57] [Epoch=009/200] [Need: 01:09:34] [LR=0.0100][M=0.90] [Best : Accuracy=80.22, Error=19.78]
  Epoch: [009][000/391]   Time 0.231 (0.231)   Data 0.172 (0.172)   Loss 0.7809 (0.7809)   Prec@1 74.219 (74.219)   Prec@5 97.656 (97.656)   [2019-11-22 02:37:57]
  Epoch: [009][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.4804 (0.5147)   Prec@1 79.688 (82.348)   Prec@5 99.219 (99.196)   [2019-11-22 02:38:02]
  Epoch: [009][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.4848 (0.5123)   Prec@1 83.594 (82.354)   Prec@5 99.219 (99.184)   [2019-11-22 02:38:07]
  Epoch: [009][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.6259 (0.5150)   Prec@1 81.250 (82.151)   Prec@5 97.656 (99.177)   [2019-11-22 02:38:12]
  **Train** Prec@1 81.982 Prec@5 99.128 Error@1 18.018
  **Test** Prec@1 77.460 Prec@5 99.010 Error@1 22.540

==>>[2019-11-22 02:38:18] [Epoch=010/200] [Need: 01:09:04] [LR=0.0100][M=0.90] [Best : Accuracy=80.22, Error=19.78]
  Epoch: [010][000/391]   Time 0.207 (0.207)   Data 0.141 (0.141)   Loss 0.4635 (0.4635)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 02:38:18]
  Epoch: [010][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.3497 (0.4863)   Prec@1 85.156 (82.774)   Prec@5 100.000 (99.335)   [2019-11-22 02:38:23]
  Epoch: [010][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4099 (0.5031)   Prec@1 84.375 (82.490)   Prec@5 99.219 (99.195)   [2019-11-22 02:38:28]
  Epoch: [010][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3859 (0.5018)   Prec@1 87.500 (82.667)   Prec@5 98.438 (99.219)   [2019-11-22 02:38:33]
  **Train** Prec@1 82.740 Prec@5 99.214 Error@1 17.260
  **Test** Prec@1 80.730 Prec@5 98.880 Error@1 19.270
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:38:40] [Epoch=011/200] [Need: 01:08:39] [LR=0.0100][M=0.90] [Best : Accuracy=80.73, Error=19.27]
  Epoch: [011][000/391]   Time 0.243 (0.243)   Data 0.160 (0.160)   Loss 0.3835 (0.3835)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 02:38:40]
  Epoch: [011][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.5763 (0.4751)   Prec@1 78.125 (83.795)   Prec@5 98.438 (99.343)   [2019-11-22 02:38:45]
  Epoch: [011][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.6232 (0.4841)   Prec@1 80.469 (83.298)   Prec@5 98.438 (99.273)   [2019-11-22 02:38:50]
  Epoch: [011][300/391]   Time 0.066 (0.052)   Data 0.000 (0.001)   Loss 0.4057 (0.4868)   Prec@1 87.500 (83.129)   Prec@5 97.656 (99.224)   [2019-11-22 02:38:55]
  **Train** Prec@1 83.134 Prec@5 99.222 Error@1 16.866
  **Test** Prec@1 81.600 Prec@5 98.960 Error@1 18.400
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:39:02] [Epoch=012/200] [Need: 01:08:26] [LR=0.0100][M=0.90] [Best : Accuracy=81.60, Error=18.40]
  Epoch: [012][000/391]   Time 0.234 (0.234)   Data 0.172 (0.172)   Loss 0.3433 (0.3433)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 02:39:02]
  Epoch: [012][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.5877 (0.4602)   Prec@1 80.469 (84.189)   Prec@5 100.000 (99.296)   [2019-11-22 02:39:07]
  Epoch: [012][200/391]   Time 0.073 (0.053)   Data 0.000 (0.001)   Loss 0.3642 (0.4649)   Prec@1 89.844 (84.064)   Prec@5 100.000 (99.308)   [2019-11-22 02:39:12]
  Epoch: [012][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3890 (0.4677)   Prec@1 86.719 (83.848)   Prec@5 100.000 (99.310)   [2019-11-22 02:39:18]
  **Train** Prec@1 83.764 Prec@5 99.278 Error@1 16.236
  **Test** Prec@1 78.650 Prec@5 98.440 Error@1 21.350

==>>[2019-11-22 02:39:24] [Epoch=013/200] [Need: 01:08:14] [LR=0.0100][M=0.90] [Best : Accuracy=81.60, Error=18.40]
  Epoch: [013][000/391]   Time 0.240 (0.240)   Data 0.180 (0.180)   Loss 0.5361 (0.5361)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 02:39:25]
  Epoch: [013][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.5074 (0.4610)   Prec@1 82.812 (84.228)   Prec@5 100.000 (99.304)   [2019-11-22 02:39:30]
  Epoch: [013][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5064 (0.4558)   Prec@1 84.375 (84.414)   Prec@5 99.219 (99.285)   [2019-11-22 02:39:35]
  Epoch: [013][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.5061 (0.4611)   Prec@1 82.812 (84.227)   Prec@5 100.000 (99.268)   [2019-11-22 02:39:40]
  **Train** Prec@1 84.222 Prec@5 99.240 Error@1 15.778
  **Test** Prec@1 81.010 Prec@5 99.120 Error@1 18.990

==>>[2019-11-22 02:39:46] [Epoch=014/200] [Need: 01:07:54] [LR=0.0100][M=0.90] [Best : Accuracy=81.60, Error=18.40]
  Epoch: [014][000/391]   Time 0.223 (0.223)   Data 0.157 (0.157)   Loss 0.4397 (0.4397)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2019-11-22 02:39:47]
  Epoch: [014][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.4078 (0.4349)   Prec@1 87.500 (85.002)   Prec@5 99.219 (99.373)   [2019-11-22 02:39:52]
  Epoch: [014][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.4976 (0.4516)   Prec@1 82.812 (84.433)   Prec@5 98.438 (99.359)   [2019-11-22 02:39:57]
  Epoch: [014][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.5501 (0.4567)   Prec@1 83.594 (84.227)   Prec@5 100.000 (99.354)   [2019-11-22 02:40:02]
  **Train** Prec@1 84.246 Prec@5 99.342 Error@1 15.754
  **Test** Prec@1 78.720 Prec@5 98.600 Error@1 21.280

==>>[2019-11-22 02:40:09] [Epoch=015/200] [Need: 01:07:35] [LR=0.0100][M=0.90] [Best : Accuracy=81.60, Error=18.40]
  Epoch: [015][000/391]   Time 0.228 (0.228)   Data 0.171 (0.171)   Loss 0.5230 (0.5230)   Prec@1 80.469 (80.469)   Prec@5 99.219 (99.219)   [2019-11-22 02:40:09]
  Epoch: [015][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.3186 (0.4179)   Prec@1 88.281 (85.520)   Prec@5 100.000 (99.505)   [2019-11-22 02:40:14]
  Epoch: [015][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5721 (0.4405)   Prec@1 78.906 (84.639)   Prec@5 100.000 (99.343)   [2019-11-22 02:40:19]
  Epoch: [015][300/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.5126 (0.4423)   Prec@1 84.375 (84.648)   Prec@5 99.219 (99.349)   [2019-11-22 02:40:24]
  **Train** Prec@1 84.618 Prec@5 99.312 Error@1 15.382
  **Test** Prec@1 79.610 Prec@5 99.020 Error@1 20.390

==>>[2019-11-22 02:40:30] [Epoch=016/200] [Need: 01:07:11] [LR=0.0100][M=0.90] [Best : Accuracy=81.60, Error=18.40]
  Epoch: [016][000/391]   Time 0.222 (0.222)   Data 0.157 (0.157)   Loss 0.5030 (0.5030)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-22 02:40:31]
  Epoch: [016][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.3883 (0.4175)   Prec@1 86.719 (85.381)   Prec@5 100.000 (99.435)   [2019-11-22 02:40:36]
  Epoch: [016][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.6024 (0.4386)   Prec@1 76.562 (84.768)   Prec@5 96.875 (99.378)   [2019-11-22 02:40:40]
  Epoch: [016][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.3488 (0.4419)   Prec@1 88.281 (84.629)   Prec@5 99.219 (99.372)   [2019-11-22 02:40:45]
  **Train** Prec@1 84.776 Prec@5 99.334 Error@1 15.224
  **Test** Prec@1 82.300 Prec@5 99.190 Error@1 17.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:40:52] [Epoch=017/200] [Need: 01:06:42] [LR=0.0100][M=0.90] [Best : Accuracy=82.30, Error=17.70]
  Epoch: [017][000/391]   Time 0.228 (0.228)   Data 0.173 (0.173)   Loss 0.2594 (0.2594)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:40:52]
  Epoch: [017][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.4919 (0.4238)   Prec@1 86.719 (85.520)   Prec@5 99.219 (99.296)   [2019-11-22 02:40:57]
  Epoch: [017][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.6310 (0.4253)   Prec@1 80.469 (85.316)   Prec@5 97.656 (99.296)   [2019-11-22 02:41:03]
  Epoch: [017][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.5915 (0.4335)   Prec@1 81.250 (84.993)   Prec@5 97.656 (99.304)   [2019-11-22 02:41:07]
  **Train** Prec@1 85.024 Prec@5 99.326 Error@1 14.976
  **Test** Prec@1 76.530 Prec@5 98.500 Error@1 23.470

==>>[2019-11-22 02:41:14] [Epoch=018/200] [Need: 01:06:23] [LR=0.0100][M=0.90] [Best : Accuracy=82.30, Error=17.70]
  Epoch: [018][000/391]   Time 0.220 (0.220)   Data 0.154 (0.154)   Loss 0.3749 (0.3749)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 02:41:14]
  Epoch: [018][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.3923 (0.4054)   Prec@1 87.500 (86.092)   Prec@5 97.656 (99.366)   [2019-11-22 02:41:19]
  Epoch: [018][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.4034 (0.4129)   Prec@1 84.375 (85.770)   Prec@5 99.219 (99.401)   [2019-11-22 02:41:24]
  Epoch: [018][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4609 (0.4183)   Prec@1 86.719 (85.520)   Prec@5 98.438 (99.400)   [2019-11-22 02:41:29]
  **Train** Prec@1 85.428 Prec@5 99.410 Error@1 14.572
  **Test** Prec@1 81.630 Prec@5 99.140 Error@1 18.370

==>>[2019-11-22 02:41:36] [Epoch=019/200] [Need: 01:06:00] [LR=0.0100][M=0.90] [Best : Accuracy=82.30, Error=17.70]
  Epoch: [019][000/391]   Time 0.231 (0.231)   Data 0.175 (0.175)   Loss 0.5080 (0.5080)   Prec@1 81.250 (81.250)   Prec@5 100.000 (100.000)   [2019-11-22 02:41:36]
  Epoch: [019][100/391]   Time 0.056 (0.054)   Data 0.000 (0.002)   Loss 0.3899 (0.4152)   Prec@1 86.719 (85.845)   Prec@5 100.000 (99.404)   [2019-11-22 02:41:41]
  Epoch: [019][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.4861 (0.4159)   Prec@1 81.250 (85.693)   Prec@5 100.000 (99.370)   [2019-11-22 02:41:46]
  Epoch: [019][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.4539 (0.4175)   Prec@1 82.812 (85.595)   Prec@5 100.000 (99.374)   [2019-11-22 02:41:52]
  **Train** Prec@1 85.496 Prec@5 99.364 Error@1 14.504
  **Test** Prec@1 82.000 Prec@5 98.800 Error@1 18.000

==>>[2019-11-22 02:41:58] [Epoch=020/200] [Need: 01:05:42] [LR=0.0100][M=0.90] [Best : Accuracy=82.30, Error=17.70]
  Epoch: [020][000/391]   Time 0.231 (0.231)   Data 0.163 (0.163)   Loss 0.4191 (0.4191)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 02:41:58]
  Epoch: [020][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.3201 (0.4092)   Prec@1 91.406 (85.798)   Prec@5 100.000 (99.435)   [2019-11-22 02:42:04]
  Epoch: [020][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.5052 (0.4024)   Prec@1 82.812 (86.058)   Prec@5 99.219 (99.456)   [2019-11-22 02:42:08]
  Epoch: [020][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.5372 (0.4082)   Prec@1 78.906 (85.828)   Prec@5 99.219 (99.393)   [2019-11-22 02:42:14]
  **Train** Prec@1 85.756 Prec@5 99.412 Error@1 14.244
  **Test** Prec@1 80.910 Prec@5 99.140 Error@1 19.090

==>>[2019-11-22 02:42:20] [Epoch=021/200] [Need: 01:05:25] [LR=0.0100][M=0.90] [Best : Accuracy=82.30, Error=17.70]
  Epoch: [021][000/391]   Time 0.238 (0.238)   Data 0.174 (0.174)   Loss 0.4915 (0.4915)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 02:42:21]
  Epoch: [021][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.6438 (0.3978)   Prec@1 79.688 (86.518)   Prec@5 100.000 (99.459)   [2019-11-22 02:42:26]
  Epoch: [021][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.4490 (0.4010)   Prec@1 81.250 (86.443)   Prec@5 99.219 (99.456)   [2019-11-22 02:42:31]
  Epoch: [021][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.5619 (0.4028)   Prec@1 79.688 (86.303)   Prec@5 100.000 (99.419)   [2019-11-22 02:42:36]
  **Train** Prec@1 86.060 Prec@5 99.418 Error@1 13.940
  **Test** Prec@1 83.300 Prec@5 99.310 Error@1 16.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:42:42] [Epoch=022/200] [Need: 01:05:04] [LR=0.0100][M=0.90] [Best : Accuracy=83.30, Error=16.70]
  Epoch: [022][000/391]   Time 0.238 (0.238)   Data 0.179 (0.179)   Loss 0.4035 (0.4035)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 02:42:43]
  Epoch: [022][100/391]   Time 0.081 (0.054)   Data 0.000 (0.002)   Loss 0.3847 (0.4046)   Prec@1 87.500 (85.961)   Prec@5 100.000 (99.435)   [2019-11-22 02:42:48]
  Epoch: [022][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.4391 (0.4008)   Prec@1 85.156 (86.116)   Prec@5 100.000 (99.483)   [2019-11-22 02:42:53]
  Epoch: [022][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4032 (0.4037)   Prec@1 83.594 (86.026)   Prec@5 100.000 (99.468)   [2019-11-22 02:42:58]
  **Train** Prec@1 86.016 Prec@5 99.444 Error@1 13.984
  **Test** Prec@1 82.230 Prec@5 99.240 Error@1 17.770

==>>[2019-11-22 02:43:04] [Epoch=023/200] [Need: 01:04:40] [LR=0.0100][M=0.90] [Best : Accuracy=83.30, Error=16.70]
  Epoch: [023][000/391]   Time 0.237 (0.237)   Data 0.150 (0.150)   Loss 0.3885 (0.3885)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 02:43:04]
  Epoch: [023][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.4036 (0.3763)   Prec@1 86.719 (87.144)   Prec@5 100.000 (99.482)   [2019-11-22 02:43:10]
  Epoch: [023][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.3601 (0.3881)   Prec@1 86.719 (86.575)   Prec@5 99.219 (99.506)   [2019-11-22 02:43:15]
  Epoch: [023][300/391]   Time 0.056 (0.054)   Data 0.000 (0.001)   Loss 0.3661 (0.3930)   Prec@1 89.062 (86.376)   Prec@5 98.438 (99.447)   [2019-11-22 02:43:20]
  **Train** Prec@1 86.134 Prec@5 99.472 Error@1 13.866
  **Test** Prec@1 80.390 Prec@5 98.700 Error@1 19.610

==>>[2019-11-22 02:43:27] [Epoch=024/200] [Need: 01:04:26] [LR=0.0100][M=0.90] [Best : Accuracy=83.30, Error=16.70]
  Epoch: [024][000/391]   Time 0.241 (0.241)   Data 0.177 (0.177)   Loss 0.4573 (0.4573)   Prec@1 82.812 (82.812)   Prec@5 98.438 (98.438)   [2019-11-22 02:43:27]
  Epoch: [024][100/391]   Time 0.061 (0.052)   Data 0.000 (0.002)   Loss 0.4193 (0.3963)   Prec@1 85.156 (86.371)   Prec@5 100.000 (99.528)   [2019-11-22 02:43:32]
  Epoch: [024][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4374 (0.3882)   Prec@1 85.938 (86.645)   Prec@5 100.000 (99.557)   [2019-11-22 02:43:37]
  Epoch: [024][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.6212 (0.3947)   Prec@1 76.562 (86.337)   Prec@5 97.656 (99.543)   [2019-11-22 02:43:42]
  **Train** Prec@1 86.240 Prec@5 99.538 Error@1 13.760
  **Test** Prec@1 82.140 Prec@5 99.200 Error@1 17.860

==>>[2019-11-22 02:43:49] [Epoch=025/200] [Need: 01:04:03] [LR=0.0100][M=0.90] [Best : Accuracy=83.30, Error=16.70]
  Epoch: [025][000/391]   Time 0.253 (0.253)   Data 0.182 (0.182)   Loss 0.2845 (0.2845)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:43:49]
  Epoch: [025][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.3757 (0.3726)   Prec@1 85.156 (86.989)   Prec@5 100.000 (99.497)   [2019-11-22 02:43:54]
  Epoch: [025][200/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.3774 (0.3815)   Prec@1 84.375 (86.505)   Prec@5 100.000 (99.483)   [2019-11-22 02:43:59]
  Epoch: [025][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.2856 (0.3853)   Prec@1 89.062 (86.464)   Prec@5 100.000 (99.533)   [2019-11-22 02:44:04]
  **Train** Prec@1 86.448 Prec@5 99.502 Error@1 13.552
  **Test** Prec@1 84.410 Prec@5 99.290 Error@1 15.590
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:44:11] [Epoch=026/200] [Need: 01:03:41] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [026][000/391]   Time 0.229 (0.229)   Data 0.148 (0.148)   Loss 0.2668 (0.2668)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:44:11]
  Epoch: [026][100/391]   Time 0.049 (0.053)   Data 0.000 (0.002)   Loss 0.3055 (0.3666)   Prec@1 92.969 (87.384)   Prec@5 100.000 (99.613)   [2019-11-22 02:44:16]
  Epoch: [026][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3585 (0.3840)   Prec@1 86.719 (86.715)   Prec@5 99.219 (99.468)   [2019-11-22 02:44:21]
  Epoch: [026][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.4032 (0.3854)   Prec@1 86.719 (86.656)   Prec@5 99.219 (99.463)   [2019-11-22 02:44:26]
  **Train** Prec@1 86.610 Prec@5 99.438 Error@1 13.390
  **Test** Prec@1 82.350 Prec@5 98.900 Error@1 17.650

==>>[2019-11-22 02:44:33] [Epoch=027/200] [Need: 01:03:19] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [027][000/391]   Time 0.232 (0.232)   Data 0.151 (0.151)   Loss 0.3995 (0.3995)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 02:44:33]
  Epoch: [027][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.3112 (0.3621)   Prec@1 89.844 (87.322)   Prec@5 100.000 (99.629)   [2019-11-22 02:44:38]
  Epoch: [027][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4233 (0.3805)   Prec@1 84.375 (86.629)   Prec@5 99.219 (99.576)   [2019-11-22 02:44:43]
  Epoch: [027][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.2743 (0.3849)   Prec@1 89.062 (86.545)   Prec@5 100.000 (99.520)   [2019-11-22 02:44:48]
  **Train** Prec@1 86.442 Prec@5 99.532 Error@1 13.558
  **Test** Prec@1 80.380 Prec@5 99.180 Error@1 19.620

==>>[2019-11-22 02:44:55] [Epoch=028/200] [Need: 01:02:57] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [028][000/391]   Time 0.218 (0.218)   Data 0.167 (0.167)   Loss 0.4269 (0.4269)   Prec@1 85.156 (85.156)   Prec@5 98.438 (98.438)   [2019-11-22 02:44:55]
  Epoch: [028][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.3501 (0.3669)   Prec@1 93.750 (87.229)   Prec@5 99.219 (99.559)   [2019-11-22 02:45:00]
  Epoch: [028][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.5514 (0.3743)   Prec@1 78.906 (87.006)   Prec@5 100.000 (99.530)   [2019-11-22 02:45:05]
  Epoch: [028][300/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.3315 (0.3805)   Prec@1 89.062 (86.887)   Prec@5 100.000 (99.481)   [2019-11-22 02:45:10]
  **Train** Prec@1 86.918 Prec@5 99.486 Error@1 13.082
  **Test** Prec@1 82.760 Prec@5 99.220 Error@1 17.240

==>>[2019-11-22 02:45:17] [Epoch=029/200] [Need: 01:02:38] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [029][000/391]   Time 0.245 (0.245)   Data 0.167 (0.167)   Loss 0.3709 (0.3709)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 02:45:17]
  Epoch: [029][100/391]   Time 0.077 (0.051)   Data 0.000 (0.002)   Loss 0.4949 (0.3712)   Prec@1 84.375 (86.943)   Prec@5 99.219 (99.652)   [2019-11-22 02:45:22]
  Epoch: [029][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.4689 (0.3733)   Prec@1 81.250 (87.018)   Prec@5 100.000 (99.631)   [2019-11-22 02:45:27]
  Epoch: [029][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.3741 (0.3774)   Prec@1 87.500 (86.900)   Prec@5 100.000 (99.603)   [2019-11-22 02:45:32]
  **Train** Prec@1 86.948 Prec@5 99.596 Error@1 13.052
  **Test** Prec@1 82.450 Prec@5 99.030 Error@1 17.550

==>>[2019-11-22 02:45:39] [Epoch=030/200] [Need: 01:02:14] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [030][000/391]   Time 0.238 (0.238)   Data 0.162 (0.162)   Loss 0.3599 (0.3599)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 02:45:39]
  Epoch: [030][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.3230 (0.3697)   Prec@1 86.719 (87.098)   Prec@5 99.219 (99.582)   [2019-11-22 02:45:44]
  Epoch: [030][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3435 (0.3781)   Prec@1 88.281 (86.882)   Prec@5 100.000 (99.526)   [2019-11-22 02:45:49]
  Epoch: [030][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.3981 (0.3749)   Prec@1 83.594 (86.958)   Prec@5 100.000 (99.567)   [2019-11-22 02:45:54]
  **Train** Prec@1 86.952 Prec@5 99.546 Error@1 13.048
  **Test** Prec@1 82.900 Prec@5 99.310 Error@1 17.100

==>>[2019-11-22 02:46:01] [Epoch=031/200] [Need: 01:01:50] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [031][000/391]   Time 0.230 (0.230)   Data 0.168 (0.168)   Loss 0.4128 (0.4128)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 02:46:01]
  Epoch: [031][100/391]   Time 0.057 (0.054)   Data 0.000 (0.002)   Loss 0.2367 (0.3610)   Prec@1 90.625 (87.477)   Prec@5 100.000 (99.575)   [2019-11-22 02:46:06]
  Epoch: [031][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2943 (0.3710)   Prec@1 86.719 (87.243)   Prec@5 100.000 (99.522)   [2019-11-22 02:46:11]
  Epoch: [031][300/391]   Time 0.080 (0.051)   Data 0.000 (0.001)   Loss 0.3901 (0.3745)   Prec@1 86.719 (86.986)   Prec@5 99.219 (99.520)   [2019-11-22 02:46:16]
  **Train** Prec@1 87.034 Prec@5 99.532 Error@1 12.966
  **Test** Prec@1 83.550 Prec@5 99.200 Error@1 16.450

==>>[2019-11-22 02:46:22] [Epoch=032/200] [Need: 01:01:28] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [032][000/391]   Time 0.229 (0.229)   Data 0.160 (0.160)   Loss 0.3374 (0.3374)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-22 02:46:23]
  Epoch: [032][100/391]   Time 0.046 (0.050)   Data 0.000 (0.002)   Loss 0.4200 (0.3500)   Prec@1 88.281 (87.809)   Prec@5 99.219 (99.575)   [2019-11-22 02:46:28]
  Epoch: [032][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3335 (0.3518)   Prec@1 89.062 (87.834)   Prec@5 100.000 (99.615)   [2019-11-22 02:46:33]
  Epoch: [032][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.3340 (0.3620)   Prec@1 88.281 (87.560)   Prec@5 100.000 (99.585)   [2019-11-22 02:46:38]
  **Train** Prec@1 87.434 Prec@5 99.600 Error@1 12.566
  **Test** Prec@1 84.150 Prec@5 99.290 Error@1 15.850

==>>[2019-11-22 02:46:44] [Epoch=033/200] [Need: 01:01:05] [LR=0.0100][M=0.90] [Best : Accuracy=84.41, Error=15.59]
  Epoch: [033][000/391]   Time 0.215 (0.215)   Data 0.150 (0.150)   Loss 0.3808 (0.3808)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 02:46:44]
  Epoch: [033][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.3811 (0.3475)   Prec@1 84.375 (87.848)   Prec@5 99.219 (99.621)   [2019-11-22 02:46:50]
  Epoch: [033][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4341 (0.3553)   Prec@1 85.938 (87.554)   Prec@5 98.438 (99.615)   [2019-11-22 02:46:55]
  Epoch: [033][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3204 (0.3606)   Prec@1 86.719 (87.477)   Prec@5 100.000 (99.564)   [2019-11-22 02:46:59]
  **Train** Prec@1 87.304 Prec@5 99.560 Error@1 12.696
  **Test** Prec@1 84.430 Prec@5 99.360 Error@1 15.570
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:47:06] [Epoch=034/200] [Need: 01:00:42] [LR=0.0100][M=0.90] [Best : Accuracy=84.43, Error=15.57]
  Epoch: [034][000/391]   Time 0.227 (0.227)   Data 0.166 (0.166)   Loss 0.3441 (0.3441)   Prec@1 89.062 (89.062)   Prec@5 98.438 (98.438)   [2019-11-22 02:47:06]
  Epoch: [034][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.5054 (0.3487)   Prec@1 82.812 (87.825)   Prec@5 98.438 (99.559)   [2019-11-22 02:47:11]
  Epoch: [034][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4137 (0.3535)   Prec@1 83.594 (87.760)   Prec@5 99.219 (99.549)   [2019-11-22 02:47:17]
  Epoch: [034][300/391]   Time 0.057 (0.053)   Data 0.000 (0.001)   Loss 0.4217 (0.3578)   Prec@1 84.375 (87.544)   Prec@5 100.000 (99.546)   [2019-11-22 02:47:22]
  **Train** Prec@1 87.508 Prec@5 99.550 Error@1 12.492
  **Test** Prec@1 82.280 Prec@5 99.270 Error@1 17.720

==>>[2019-11-22 02:47:28] [Epoch=035/200] [Need: 01:00:23] [LR=0.0100][M=0.90] [Best : Accuracy=84.43, Error=15.57]
  Epoch: [035][000/391]   Time 0.237 (0.237)   Data 0.150 (0.150)   Loss 0.2918 (0.2918)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:47:29]
  Epoch: [035][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.2064 (0.3490)   Prec@1 92.969 (87.887)   Prec@5 100.000 (99.691)   [2019-11-22 02:47:34]
  Epoch: [035][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3277 (0.3546)   Prec@1 87.500 (87.570)   Prec@5 100.000 (99.666)   [2019-11-22 02:47:39]
  Epoch: [035][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.5321 (0.3556)   Prec@1 85.156 (87.710)   Prec@5 96.875 (99.629)   [2019-11-22 02:47:44]
  **Train** Prec@1 87.512 Prec@5 99.590 Error@1 12.488
  **Test** Prec@1 82.980 Prec@5 99.220 Error@1 17.020

==>>[2019-11-22 02:47:51] [Epoch=036/200] [Need: 01:00:02] [LR=0.0100][M=0.90] [Best : Accuracy=84.43, Error=15.57]
  Epoch: [036][000/391]   Time 0.228 (0.228)   Data 0.171 (0.171)   Loss 0.3035 (0.3035)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:47:51]
  Epoch: [036][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5442 (0.3498)   Prec@1 78.906 (87.755)   Prec@5 100.000 (99.606)   [2019-11-22 02:47:56]
  Epoch: [036][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.3206 (0.3470)   Prec@1 89.844 (88.032)   Prec@5 100.000 (99.627)   [2019-11-22 02:48:01]
  Epoch: [036][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.2618 (0.3587)   Prec@1 92.188 (87.715)   Prec@5 100.000 (99.559)   [2019-11-22 02:48:06]
  **Train** Prec@1 87.702 Prec@5 99.542 Error@1 12.298
  **Test** Prec@1 84.330 Prec@5 99.180 Error@1 15.670

==>>[2019-11-22 02:48:12] [Epoch=037/200] [Need: 00:59:37] [LR=0.0100][M=0.90] [Best : Accuracy=84.43, Error=15.57]
  Epoch: [037][000/391]   Time 0.233 (0.233)   Data 0.165 (0.165)   Loss 0.2363 (0.2363)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:48:12]
  Epoch: [037][100/391]   Time 0.059 (0.049)   Data 0.000 (0.002)   Loss 0.2889 (0.3421)   Prec@1 87.500 (88.127)   Prec@5 99.219 (99.683)   [2019-11-22 02:48:17]
  Epoch: [037][200/391]   Time 0.073 (0.050)   Data 0.000 (0.001)   Loss 0.3108 (0.3451)   Prec@1 86.719 (87.982)   Prec@5 100.000 (99.650)   [2019-11-22 02:48:22]
  Epoch: [037][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.2730 (0.3505)   Prec@1 90.625 (87.866)   Prec@5 100.000 (99.647)   [2019-11-22 02:48:27]
  **Train** Prec@1 87.834 Prec@5 99.652 Error@1 12.166
  **Test** Prec@1 85.090 Prec@5 99.370 Error@1 14.910
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:48:33] [Epoch=038/200] [Need: 00:59:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [038][000/391]   Time 0.231 (0.231)   Data 0.173 (0.173)   Loss 0.2238 (0.2238)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 02:48:33]
  Epoch: [038][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.3111 (0.3303)   Prec@1 88.281 (88.660)   Prec@5 100.000 (99.528)   [2019-11-22 02:48:39]
  Epoch: [038][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3188 (0.3439)   Prec@1 90.625 (87.900)   Prec@5 99.219 (99.572)   [2019-11-22 02:48:44]
  Epoch: [038][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.4318 (0.3506)   Prec@1 85.156 (87.747)   Prec@5 100.000 (99.554)   [2019-11-22 02:48:48]
  **Train** Prec@1 87.614 Prec@5 99.548 Error@1 12.386
  **Test** Prec@1 82.710 Prec@5 99.290 Error@1 17.290

==>>[2019-11-22 02:48:55] [Epoch=039/200] [Need: 00:58:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [039][000/391]   Time 0.235 (0.235)   Data 0.152 (0.152)   Loss 0.3758 (0.3758)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 02:48:55]
  Epoch: [039][100/391]   Time 0.056 (0.052)   Data 0.000 (0.002)   Loss 0.3062 (0.3387)   Prec@1 88.281 (88.413)   Prec@5 100.000 (99.660)   [2019-11-22 02:49:00]
  Epoch: [039][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2865 (0.3449)   Prec@1 90.625 (88.137)   Prec@5 99.219 (99.604)   [2019-11-22 02:49:05]
  Epoch: [039][300/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.3326 (0.3495)   Prec@1 89.062 (87.949)   Prec@5 100.000 (99.595)   [2019-11-22 02:49:10]
  **Train** Prec@1 87.946 Prec@5 99.600 Error@1 12.054
  **Test** Prec@1 83.900 Prec@5 99.220 Error@1 16.100

==>>[2019-11-22 02:49:16] [Epoch=040/200] [Need: 00:58:25] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [040][000/391]   Time 0.247 (0.247)   Data 0.159 (0.159)   Loss 0.2833 (0.2833)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 02:49:17]
  Epoch: [040][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.3060 (0.3428)   Prec@1 89.844 (88.204)   Prec@5 100.000 (99.505)   [2019-11-22 02:49:22]
  Epoch: [040][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4992 (0.3526)   Prec@1 84.375 (87.757)   Prec@5 100.000 (99.502)   [2019-11-22 02:49:27]
  Epoch: [040][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.3581 (0.3510)   Prec@1 89.844 (87.773)   Prec@5 100.000 (99.569)   [2019-11-22 02:49:32]
  **Train** Prec@1 87.994 Prec@5 99.572 Error@1 12.006
  **Test** Prec@1 84.250 Prec@5 99.240 Error@1 15.750

==>>[2019-11-22 02:49:38] [Epoch=041/200] [Need: 00:58:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [041][000/391]   Time 0.210 (0.210)   Data 0.140 (0.140)   Loss 0.4684 (0.4684)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 02:49:38]
  Epoch: [041][100/391]   Time 0.073 (0.054)   Data 0.000 (0.002)   Loss 0.3717 (0.3472)   Prec@1 85.156 (88.041)   Prec@5 99.219 (99.567)   [2019-11-22 02:49:44]
  Epoch: [041][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.2876 (0.3455)   Prec@1 89.062 (88.106)   Prec@5 100.000 (99.600)   [2019-11-22 02:49:49]
  Epoch: [041][300/391]   Time 0.083 (0.053)   Data 0.000 (0.001)   Loss 0.3407 (0.3504)   Prec@1 88.281 (87.897)   Prec@5 100.000 (99.613)   [2019-11-22 02:49:54]
  **Train** Prec@1 87.922 Prec@5 99.586 Error@1 12.078
  **Test** Prec@1 82.740 Prec@5 99.290 Error@1 17.260

==>>[2019-11-22 02:50:00] [Epoch=042/200] [Need: 00:57:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [042][000/391]   Time 0.230 (0.230)   Data 0.151 (0.151)   Loss 0.4357 (0.4357)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2019-11-22 02:50:00]
  Epoch: [042][100/391]   Time 0.057 (0.054)   Data 0.000 (0.002)   Loss 0.5409 (0.3311)   Prec@1 87.500 (88.800)   Prec@5 100.000 (99.559)   [2019-11-22 02:50:05]
  Epoch: [042][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.3996 (0.3286)   Prec@1 88.281 (88.755)   Prec@5 99.219 (99.615)   [2019-11-22 02:50:10]
  Epoch: [042][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.4299 (0.3406)   Prec@1 81.250 (88.294)   Prec@5 100.000 (99.585)   [2019-11-22 02:50:15]
  **Train** Prec@1 88.158 Prec@5 99.578 Error@1 11.842
  **Test** Prec@1 84.370 Prec@5 99.480 Error@1 15.630

==>>[2019-11-22 02:50:22] [Epoch=043/200] [Need: 00:57:18] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [043][000/391]   Time 0.228 (0.228)   Data 0.160 (0.160)   Loss 0.3333 (0.3333)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 02:50:22]
  Epoch: [043][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.2473 (0.3240)   Prec@1 89.844 (88.591)   Prec@5 100.000 (99.722)   [2019-11-22 02:50:27]
  Epoch: [043][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3258 (0.3316)   Prec@1 89.062 (88.293)   Prec@5 99.219 (99.670)   [2019-11-22 02:50:32]
  Epoch: [043][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.3690 (0.3369)   Prec@1 90.625 (88.263)   Prec@5 100.000 (99.629)   [2019-11-22 02:50:37]
  **Train** Prec@1 88.062 Prec@5 99.604 Error@1 11.938
  **Test** Prec@1 82.480 Prec@5 99.260 Error@1 17.520

==>>[2019-11-22 02:50:43] [Epoch=044/200] [Need: 00:56:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [044][000/391]   Time 0.219 (0.219)   Data 0.159 (0.159)   Loss 0.3481 (0.3481)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 02:50:44]
  Epoch: [044][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.4473 (0.3322)   Prec@1 83.594 (88.335)   Prec@5 100.000 (99.582)   [2019-11-22 02:50:49]
  Epoch: [044][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.2628 (0.3391)   Prec@1 89.844 (88.211)   Prec@5 100.000 (99.588)   [2019-11-22 02:50:55]
  Epoch: [044][300/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.4312 (0.3419)   Prec@1 86.719 (88.289)   Prec@5 100.000 (99.605)   [2019-11-22 02:51:00]
  **Train** Prec@1 88.252 Prec@5 99.602 Error@1 11.748
  **Test** Prec@1 84.980 Prec@5 99.480 Error@1 15.020

==>>[2019-11-22 02:51:06] [Epoch=045/200] [Need: 00:56:38] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [045][000/391]   Time 0.224 (0.224)   Data 0.166 (0.166)   Loss 0.3045 (0.3045)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:51:07]
  Epoch: [045][100/391]   Time 0.048 (0.054)   Data 0.000 (0.002)   Loss 0.4817 (0.3266)   Prec@1 82.031 (88.691)   Prec@5 100.000 (99.698)   [2019-11-22 02:51:12]
  Epoch: [045][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3307 (0.3368)   Prec@1 87.500 (88.437)   Prec@5 99.219 (99.689)   [2019-11-22 02:51:17]
  Epoch: [045][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.4032 (0.3397)   Prec@1 85.156 (88.341)   Prec@5 99.219 (99.663)   [2019-11-22 02:51:22]
  **Train** Prec@1 88.280 Prec@5 99.670 Error@1 11.720
  **Test** Prec@1 83.430 Prec@5 99.060 Error@1 16.570

==>>[2019-11-22 02:51:28] [Epoch=046/200] [Need: 00:56:16] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [046][000/391]   Time 0.243 (0.243)   Data 0.186 (0.186)   Loss 0.3758 (0.3758)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-22 02:51:28]
  Epoch: [046][100/391]   Time 0.083 (0.054)   Data 0.000 (0.002)   Loss 0.2518 (0.3284)   Prec@1 92.969 (88.683)   Prec@5 100.000 (99.644)   [2019-11-22 02:51:34]
  Epoch: [046][200/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.2968 (0.3344)   Prec@1 91.406 (88.600)   Prec@5 97.656 (99.580)   [2019-11-22 02:51:39]
  Epoch: [046][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.3528 (0.3321)   Prec@1 88.281 (88.575)   Prec@5 99.219 (99.598)   [2019-11-22 02:51:44]
  **Train** Prec@1 88.586 Prec@5 99.614 Error@1 11.414
  **Test** Prec@1 84.510 Prec@5 99.110 Error@1 15.490

==>>[2019-11-22 02:51:51] [Epoch=047/200] [Need: 00:55:55] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [047][000/391]   Time 0.221 (0.221)   Data 0.151 (0.151)   Loss 0.1497 (0.1497)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 02:51:51]
  Epoch: [047][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.1949 (0.3133)   Prec@1 92.969 (89.186)   Prec@5 100.000 (99.714)   [2019-11-22 02:51:56]
  Epoch: [047][200/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.3579 (0.3244)   Prec@1 88.281 (88.790)   Prec@5 100.000 (99.658)   [2019-11-22 02:52:01]
  Epoch: [047][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3482 (0.3332)   Prec@1 85.156 (88.427)   Prec@5 100.000 (99.639)   [2019-11-22 02:52:06]
  **Train** Prec@1 88.410 Prec@5 99.644 Error@1 11.590
  **Test** Prec@1 84.830 Prec@5 99.330 Error@1 15.170

==>>[2019-11-22 02:52:12] [Epoch=048/200] [Need: 00:55:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [048][000/391]   Time 0.229 (0.229)   Data 0.164 (0.164)   Loss 0.2323 (0.2323)   Prec@1 92.969 (92.969)   Prec@5 98.438 (98.438)   [2019-11-22 02:52:13]
  Epoch: [048][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.3001 (0.3191)   Prec@1 90.625 (88.977)   Prec@5 100.000 (99.691)   [2019-11-22 02:52:18]
  Epoch: [048][200/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 0.3504 (0.3275)   Prec@1 89.062 (88.767)   Prec@5 100.000 (99.654)   [2019-11-22 02:52:23]
  Epoch: [048][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3423 (0.3285)   Prec@1 86.719 (88.694)   Prec@5 100.000 (99.631)   [2019-11-22 02:52:28]
  **Train** Prec@1 88.502 Prec@5 99.620 Error@1 11.498
  **Test** Prec@1 84.840 Prec@5 99.450 Error@1 15.160

==>>[2019-11-22 02:52:35] [Epoch=049/200] [Need: 00:55:13] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [049][000/391]   Time 0.234 (0.234)   Data 0.177 (0.177)   Loss 0.3653 (0.3653)   Prec@1 89.062 (89.062)   Prec@5 98.438 (98.438)   [2019-11-22 02:52:35]
  Epoch: [049][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.2658 (0.3416)   Prec@1 90.625 (88.026)   Prec@5 100.000 (99.598)   [2019-11-22 02:52:40]
  Epoch: [049][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.4919 (0.3321)   Prec@1 83.594 (88.402)   Prec@5 99.219 (99.592)   [2019-11-22 02:52:45]
  Epoch: [049][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.2246 (0.3312)   Prec@1 90.625 (88.484)   Prec@5 100.000 (99.605)   [2019-11-22 02:52:50]
  **Train** Prec@1 88.370 Prec@5 99.618 Error@1 11.630
  **Test** Prec@1 84.660 Prec@5 99.530 Error@1 15.340

==>>[2019-11-22 02:52:57] [Epoch=050/200] [Need: 00:54:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [050][000/391]   Time 0.226 (0.226)   Data 0.167 (0.167)   Loss 0.2913 (0.2913)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 02:52:57]
  Epoch: [050][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.2622 (0.3283)   Prec@1 92.969 (88.707)   Prec@5 99.219 (99.714)   [2019-11-22 02:53:02]
  Epoch: [050][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3088 (0.3264)   Prec@1 87.500 (88.748)   Prec@5 99.219 (99.646)   [2019-11-22 02:53:07]
  Epoch: [050][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.4628 (0.3261)   Prec@1 84.375 (88.702)   Prec@5 99.219 (99.616)   [2019-11-22 02:53:12]
  **Train** Prec@1 88.688 Prec@5 99.634 Error@1 11.312
  **Test** Prec@1 82.860 Prec@5 99.240 Error@1 17.140

==>>[2019-11-22 02:53:18] [Epoch=051/200] [Need: 00:54:27] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [051][000/391]   Time 0.238 (0.238)   Data 0.183 (0.183)   Loss 0.2245 (0.2245)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 02:53:19]
  Epoch: [051][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.2721 (0.3327)   Prec@1 88.281 (88.459)   Prec@5 100.000 (99.644)   [2019-11-22 02:53:24]
  Epoch: [051][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.2605 (0.3410)   Prec@1 92.188 (88.204)   Prec@5 99.219 (99.677)   [2019-11-22 02:53:28]
  Epoch: [051][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.4613 (0.3369)   Prec@1 85.156 (88.380)   Prec@5 100.000 (99.665)   [2019-11-22 02:53:33]
  **Train** Prec@1 88.320 Prec@5 99.628 Error@1 11.680
  **Test** Prec@1 83.810 Prec@5 99.170 Error@1 16.190

==>>[2019-11-22 02:53:40] [Epoch=052/200] [Need: 00:54:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [052][000/391]   Time 0.222 (0.222)   Data 0.156 (0.156)   Loss 0.3678 (0.3678)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 02:53:40]
  Epoch: [052][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.2420 (0.3159)   Prec@1 89.844 (88.985)   Prec@5 100.000 (99.652)   [2019-11-22 02:53:45]
  Epoch: [052][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3764 (0.3282)   Prec@1 85.938 (88.553)   Prec@5 100.000 (99.662)   [2019-11-22 02:53:50]
  Epoch: [052][300/391]   Time 0.072 (0.051)   Data 0.000 (0.001)   Loss 0.3192 (0.3270)   Prec@1 91.406 (88.697)   Prec@5 99.219 (99.650)   [2019-11-22 02:53:55]
  **Train** Prec@1 88.596 Prec@5 99.662 Error@1 11.404
  **Test** Prec@1 82.970 Prec@5 99.080 Error@1 17.030

==>>[2019-11-22 02:54:02] [Epoch=053/200] [Need: 00:53:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [053][000/391]   Time 0.244 (0.244)   Data 0.186 (0.186)   Loss 0.2362 (0.2362)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:54:02]
  Epoch: [053][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.2325 (0.3231)   Prec@1 92.188 (88.807)   Prec@5 100.000 (99.691)   [2019-11-22 02:54:07]
  Epoch: [053][200/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.2440 (0.3199)   Prec@1 89.844 (88.868)   Prec@5 99.219 (99.681)   [2019-11-22 02:54:12]
  Epoch: [053][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.4684 (0.3286)   Prec@1 84.375 (88.559)   Prec@5 100.000 (99.694)   [2019-11-22 02:54:17]
  **Train** Prec@1 88.458 Prec@5 99.680 Error@1 11.542
  **Test** Prec@1 81.130 Prec@5 98.980 Error@1 18.870

==>>[2019-11-22 02:54:24] [Epoch=054/200] [Need: 00:53:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [054][000/391]   Time 0.217 (0.217)   Data 0.154 (0.154)   Loss 0.2322 (0.2322)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:54:24]
  Epoch: [054][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.3924 (0.3206)   Prec@1 86.719 (88.970)   Prec@5 100.000 (99.629)   [2019-11-22 02:54:29]
  Epoch: [054][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.3286 (0.3197)   Prec@1 86.719 (88.981)   Prec@5 100.000 (99.627)   [2019-11-22 02:54:34]
  Epoch: [054][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4429 (0.3293)   Prec@1 84.375 (88.593)   Prec@5 100.000 (99.647)   [2019-11-22 02:54:39]
  **Train** Prec@1 88.496 Prec@5 99.654 Error@1 11.504
  **Test** Prec@1 83.940 Prec@5 99.210 Error@1 16.060

==>>[2019-11-22 02:54:45] [Epoch=055/200] [Need: 00:52:57] [LR=0.0100][M=0.90] [Best : Accuracy=85.09, Error=14.91]
  Epoch: [055][000/391]   Time 0.223 (0.223)   Data 0.161 (0.161)   Loss 0.3393 (0.3393)   Prec@1 87.500 (87.500)   Prec@5 98.438 (98.438)   [2019-11-22 02:54:45]
  Epoch: [055][100/391]   Time 0.083 (0.055)   Data 0.000 (0.002)   Loss 0.4012 (0.3170)   Prec@1 88.281 (88.931)   Prec@5 100.000 (99.652)   [2019-11-22 02:54:51]
  Epoch: [055][200/391]   Time 0.080 (0.052)   Data 0.000 (0.001)   Loss 0.2765 (0.3197)   Prec@1 89.844 (88.856)   Prec@5 100.000 (99.674)   [2019-11-22 02:54:56]
  Epoch: [055][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3683 (0.3236)   Prec@1 89.062 (88.756)   Prec@5 98.438 (99.660)   [2019-11-22 02:55:01]
  **Train** Prec@1 88.674 Prec@5 99.650 Error@1 11.326
  **Test** Prec@1 86.070 Prec@5 99.440 Error@1 13.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:55:07] [Epoch=056/200] [Need: 00:52:35] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [056][000/391]   Time 0.230 (0.230)   Data 0.162 (0.162)   Loss 0.2575 (0.2575)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:55:07]
  Epoch: [056][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3127 (0.3034)   Prec@1 87.500 (89.434)   Prec@5 100.000 (99.752)   [2019-11-22 02:55:12]
  Epoch: [056][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.3317 (0.3197)   Prec@1 86.719 (88.938)   Prec@5 100.000 (99.724)   [2019-11-22 02:55:17]
  Epoch: [056][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3239 (0.3229)   Prec@1 88.281 (88.808)   Prec@5 99.219 (99.704)   [2019-11-22 02:55:22]
  **Train** Prec@1 88.876 Prec@5 99.688 Error@1 11.124
  **Test** Prec@1 85.780 Prec@5 99.480 Error@1 14.220

==>>[2019-11-22 02:55:29] [Epoch=057/200] [Need: 00:52:13] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [057][000/391]   Time 0.241 (0.241)   Data 0.176 (0.176)   Loss 0.3010 (0.3010)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:55:29]
  Epoch: [057][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.4270 (0.3140)   Prec@1 85.156 (88.861)   Prec@5 100.000 (99.636)   [2019-11-22 02:55:34]
  Epoch: [057][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.2626 (0.3206)   Prec@1 89.844 (88.806)   Prec@5 100.000 (99.658)   [2019-11-22 02:55:39]
  Epoch: [057][300/391]   Time 0.082 (0.051)   Data 0.000 (0.001)   Loss 0.2884 (0.3211)   Prec@1 89.844 (88.946)   Prec@5 100.000 (99.650)   [2019-11-22 02:55:44]
  **Train** Prec@1 88.836 Prec@5 99.632 Error@1 11.164
  **Test** Prec@1 83.480 Prec@5 99.160 Error@1 16.520

==>>[2019-11-22 02:55:51] [Epoch=058/200] [Need: 00:51:51] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [058][000/391]   Time 0.226 (0.226)   Data 0.158 (0.158)   Loss 0.4291 (0.4291)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 02:55:51]
  Epoch: [058][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3350 (0.2980)   Prec@1 87.500 (89.349)   Prec@5 97.656 (99.698)   [2019-11-22 02:55:56]
  Epoch: [058][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2899 (0.3102)   Prec@1 89.844 (88.969)   Prec@5 100.000 (99.708)   [2019-11-22 02:56:01]
  Epoch: [058][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2692 (0.3166)   Prec@1 88.281 (88.863)   Prec@5 99.219 (99.673)   [2019-11-22 02:56:06]
  **Train** Prec@1 88.754 Prec@5 99.658 Error@1 11.246
  **Test** Prec@1 84.600 Prec@5 99.340 Error@1 15.400

==>>[2019-11-22 02:56:12] [Epoch=059/200] [Need: 00:51:29] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [059][000/391]   Time 0.240 (0.240)   Data 0.181 (0.181)   Loss 0.2888 (0.2888)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 02:56:13]
  Epoch: [059][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.3875 (0.3053)   Prec@1 86.719 (89.132)   Prec@5 100.000 (99.706)   [2019-11-22 02:56:18]
  Epoch: [059][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3390 (0.3054)   Prec@1 88.281 (89.234)   Prec@5 100.000 (99.743)   [2019-11-22 02:56:23]
  Epoch: [059][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3373 (0.3229)   Prec@1 89.062 (88.800)   Prec@5 100.000 (99.704)   [2019-11-22 02:56:28]
  **Train** Prec@1 88.788 Prec@5 99.688 Error@1 11.212
  **Test** Prec@1 82.740 Prec@5 99.300 Error@1 17.260

==>>[2019-11-22 02:56:35] [Epoch=060/200] [Need: 00:51:08] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [060][000/391]   Time 0.236 (0.236)   Data 0.160 (0.160)   Loss 0.2518 (0.2518)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 02:56:35]
  Epoch: [060][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.3806 (0.3103)   Prec@1 85.938 (89.325)   Prec@5 100.000 (99.691)   [2019-11-22 02:56:40]
  Epoch: [060][200/391]   Time 0.076 (0.052)   Data 0.000 (0.001)   Loss 0.2729 (0.3129)   Prec@1 90.625 (89.218)   Prec@5 99.219 (99.681)   [2019-11-22 02:56:45]
  Epoch: [060][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3482 (0.3145)   Prec@1 87.500 (89.055)   Prec@5 99.219 (99.696)   [2019-11-22 02:56:50]
  **Train** Prec@1 88.850 Prec@5 99.694 Error@1 11.150
  **Test** Prec@1 82.120 Prec@5 99.100 Error@1 17.880

==>>[2019-11-22 02:56:57] [Epoch=061/200] [Need: 00:50:47] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [061][000/391]   Time 0.220 (0.220)   Data 0.158 (0.158)   Loss 0.3224 (0.3224)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 02:56:57]
  Epoch: [061][100/391]   Time 0.055 (0.054)   Data 0.000 (0.002)   Loss 0.3226 (0.3110)   Prec@1 87.500 (89.349)   Prec@5 99.219 (99.737)   [2019-11-22 02:57:03]
  Epoch: [061][200/391]   Time 0.084 (0.054)   Data 0.000 (0.001)   Loss 0.4095 (0.3101)   Prec@1 85.938 (89.381)   Prec@5 99.219 (99.751)   [2019-11-22 02:57:08]
  Epoch: [061][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3140 (0.3162)   Prec@1 90.625 (89.065)   Prec@5 100.000 (99.714)   [2019-11-22 02:57:13]
  **Train** Prec@1 88.926 Prec@5 99.696 Error@1 11.074
  **Test** Prec@1 84.660 Prec@5 99.310 Error@1 15.340

==>>[2019-11-22 02:57:20] [Epoch=062/200] [Need: 00:50:27] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [062][000/391]   Time 0.227 (0.227)   Data 0.161 (0.161)   Loss 0.3658 (0.3658)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 02:57:20]
  Epoch: [062][100/391]   Time 0.065 (0.054)   Data 0.000 (0.002)   Loss 0.4005 (0.3023)   Prec@1 85.938 (89.496)   Prec@5 99.219 (99.698)   [2019-11-22 02:57:25]
  Epoch: [062][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2559 (0.3117)   Prec@1 88.281 (89.090)   Prec@5 99.219 (99.697)   [2019-11-22 02:57:30]
  Epoch: [062][300/391]   Time 0.069 (0.051)   Data 0.000 (0.001)   Loss 0.2887 (0.3135)   Prec@1 89.062 (89.070)   Prec@5 99.219 (99.704)   [2019-11-22 02:57:35]
  **Train** Prec@1 88.994 Prec@5 99.662 Error@1 11.006
  **Test** Prec@1 81.700 Prec@5 99.090 Error@1 18.300

==>>[2019-11-22 02:57:42] [Epoch=063/200] [Need: 00:50:05] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [063][000/391]   Time 0.231 (0.231)   Data 0.160 (0.160)   Loss 0.2568 (0.2568)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-22 02:57:42]
  Epoch: [063][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.3510 (0.2956)   Prec@1 86.719 (89.735)   Prec@5 99.219 (99.636)   [2019-11-22 02:57:47]
  Epoch: [063][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.3605 (0.3129)   Prec@1 84.375 (89.090)   Prec@5 98.438 (99.635)   [2019-11-22 02:57:52]
  Epoch: [063][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.3587 (0.3152)   Prec@1 87.500 (89.021)   Prec@5 99.219 (99.639)   [2019-11-22 02:57:57]
  **Train** Prec@1 88.826 Prec@5 99.626 Error@1 11.174
  **Test** Prec@1 85.070 Prec@5 99.350 Error@1 14.930

==>>[2019-11-22 02:58:03] [Epoch=064/200] [Need: 00:49:42] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [064][000/391]   Time 0.226 (0.226)   Data 0.169 (0.169)   Loss 0.3748 (0.3748)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 02:58:04]
  Epoch: [064][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.4601 (0.3054)   Prec@1 87.500 (89.542)   Prec@5 99.219 (99.745)   [2019-11-22 02:58:09]
  Epoch: [064][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3422 (0.3106)   Prec@1 88.281 (89.319)   Prec@5 99.219 (99.670)   [2019-11-22 02:58:14]
  Epoch: [064][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.4084 (0.3165)   Prec@1 85.938 (89.156)   Prec@5 98.438 (99.670)   [2019-11-22 02:58:19]
  **Train** Prec@1 89.080 Prec@5 99.670 Error@1 10.920
  **Test** Prec@1 86.010 Prec@5 99.310 Error@1 13.990

==>>[2019-11-22 02:58:25] [Epoch=065/200] [Need: 00:49:20] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [065][000/391]   Time 0.215 (0.215)   Data 0.158 (0.158)   Loss 0.2234 (0.2234)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 02:58:26]
  Epoch: [065][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.2848 (0.3113)   Prec@1 88.281 (89.318)   Prec@5 99.219 (99.698)   [2019-11-22 02:58:31]
  Epoch: [065][200/391]   Time 0.078 (0.054)   Data 0.000 (0.001)   Loss 0.3775 (0.3072)   Prec@1 85.156 (89.467)   Prec@5 100.000 (99.701)   [2019-11-22 02:58:36]
  Epoch: [065][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.2872 (0.3114)   Prec@1 89.844 (89.338)   Prec@5 100.000 (99.686)   [2019-11-22 02:58:41]
  **Train** Prec@1 89.228 Prec@5 99.662 Error@1 10.772
  **Test** Prec@1 85.800 Prec@5 99.230 Error@1 14.200

==>>[2019-11-22 02:58:47] [Epoch=066/200] [Need: 00:48:58] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [066][000/391]   Time 0.227 (0.227)   Data 0.161 (0.161)   Loss 0.2947 (0.2947)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 02:58:47]
  Epoch: [066][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3431 (0.3082)   Prec@1 89.062 (89.527)   Prec@5 100.000 (99.636)   [2019-11-22 02:58:53]
  Epoch: [066][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2946 (0.3194)   Prec@1 89.062 (89.020)   Prec@5 99.219 (99.596)   [2019-11-22 02:58:57]
  Epoch: [066][300/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.1817 (0.3185)   Prec@1 92.969 (89.057)   Prec@5 100.000 (99.605)   [2019-11-22 02:59:02]
  **Train** Prec@1 89.056 Prec@5 99.626 Error@1 10.944
  **Test** Prec@1 83.650 Prec@5 99.380 Error@1 16.350

==>>[2019-11-22 02:59:09] [Epoch=067/200] [Need: 00:48:35] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [067][000/391]   Time 0.232 (0.232)   Data 0.174 (0.174)   Loss 0.4666 (0.4666)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2019-11-22 02:59:09]
  Epoch: [067][100/391]   Time 0.051 (0.050)   Data 0.000 (0.002)   Loss 0.2916 (0.3079)   Prec@1 86.719 (89.225)   Prec@5 100.000 (99.745)   [2019-11-22 02:59:14]
  Epoch: [067][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.1909 (0.3168)   Prec@1 92.188 (89.024)   Prec@5 100.000 (99.716)   [2019-11-22 02:59:19]
  Epoch: [067][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.2582 (0.3169)   Prec@1 92.188 (89.138)   Prec@5 100.000 (99.702)   [2019-11-22 02:59:23]
  **Train** Prec@1 89.018 Prec@5 99.712 Error@1 10.982
  **Test** Prec@1 85.260 Prec@5 99.410 Error@1 14.740

==>>[2019-11-22 02:59:30] [Epoch=068/200] [Need: 00:48:12] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [068][000/391]   Time 0.232 (0.232)   Data 0.161 (0.161)   Loss 0.2134 (0.2134)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 02:59:30]
  Epoch: [068][100/391]   Time 0.084 (0.057)   Data 0.000 (0.002)   Loss 0.2911 (0.3071)   Prec@1 90.625 (89.086)   Prec@5 100.000 (99.714)   [2019-11-22 02:59:36]
  Epoch: [068][200/391]   Time 0.068 (0.053)   Data 0.000 (0.001)   Loss 0.4405 (0.3175)   Prec@1 85.938 (88.794)   Prec@5 99.219 (99.693)   [2019-11-22 02:59:41]
  Epoch: [068][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.1855 (0.3157)   Prec@1 95.312 (88.920)   Prec@5 100.000 (99.686)   [2019-11-22 02:59:46]
  **Train** Prec@1 88.880 Prec@5 99.682 Error@1 11.120
  **Test** Prec@1 83.460 Prec@5 98.760 Error@1 16.540

==>>[2019-11-22 02:59:52] [Epoch=069/200] [Need: 00:47:50] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [069][000/391]   Time 0.224 (0.224)   Data 0.156 (0.156)   Loss 0.1581 (0.1581)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 02:59:52]
  Epoch: [069][100/391]   Time 0.053 (0.057)   Data 0.000 (0.002)   Loss 0.3042 (0.3052)   Prec@1 89.844 (89.117)   Prec@5 99.219 (99.683)   [2019-11-22 02:59:58]
  Epoch: [069][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.2636 (0.3070)   Prec@1 92.969 (89.121)   Prec@5 100.000 (99.705)   [2019-11-22 03:00:03]
  Epoch: [069][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.2673 (0.3114)   Prec@1 92.969 (89.021)   Prec@5 99.219 (99.678)   [2019-11-22 03:00:08]
  **Train** Prec@1 88.838 Prec@5 99.668 Error@1 11.162
  **Test** Prec@1 84.240 Prec@5 99.380 Error@1 15.760

==>>[2019-11-22 03:00:14] [Epoch=070/200] [Need: 00:47:29] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [070][000/391]   Time 0.232 (0.232)   Data 0.164 (0.164)   Loss 0.2989 (0.2989)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 03:00:14]
  Epoch: [070][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.1471 (0.2884)   Prec@1 93.750 (89.960)   Prec@5 100.000 (99.729)   [2019-11-22 03:00:20]
  Epoch: [070][200/391]   Time 0.077 (0.052)   Data 0.000 (0.001)   Loss 0.2200 (0.3077)   Prec@1 91.406 (89.451)   Prec@5 100.000 (99.681)   [2019-11-22 03:00:25]
  Epoch: [070][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3170 (0.3107)   Prec@1 89.062 (89.413)   Prec@5 99.219 (99.663)   [2019-11-22 03:00:30]
  **Train** Prec@1 89.276 Prec@5 99.658 Error@1 10.724
  **Test** Prec@1 84.140 Prec@5 99.250 Error@1 15.860

==>>[2019-11-22 03:00:36] [Epoch=071/200] [Need: 00:47:07] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [071][000/391]   Time 0.228 (0.228)   Data 0.172 (0.172)   Loss 0.2499 (0.2499)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-22 03:00:36]
  Epoch: [071][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.3350 (0.3067)   Prec@1 87.500 (89.619)   Prec@5 100.000 (99.683)   [2019-11-22 03:00:42]
  Epoch: [071][200/391]   Time 0.061 (0.054)   Data 0.000 (0.001)   Loss 0.3845 (0.3021)   Prec@1 89.844 (89.587)   Prec@5 98.438 (99.720)   [2019-11-22 03:00:47]
  Epoch: [071][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.2193 (0.3117)   Prec@1 92.969 (89.086)   Prec@5 100.000 (99.717)   [2019-11-22 03:00:51]
  **Train** Prec@1 89.080 Prec@5 99.696 Error@1 10.920
  **Test** Prec@1 81.480 Prec@5 98.950 Error@1 18.520

==>>[2019-11-22 03:00:58] [Epoch=072/200] [Need: 00:46:45] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [072][000/391]   Time 0.217 (0.217)   Data 0.161 (0.161)   Loss 0.1949 (0.1949)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 03:00:58]
  Epoch: [072][100/391]   Time 0.049 (0.052)   Data 0.000 (0.002)   Loss 0.3922 (0.2898)   Prec@1 87.500 (90.246)   Prec@5 100.000 (99.745)   [2019-11-22 03:01:03]
  Epoch: [072][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.2775 (0.2999)   Prec@1 91.406 (89.673)   Prec@5 99.219 (99.724)   [2019-11-22 03:01:08]
  Epoch: [072][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.4997 (0.3077)   Prec@1 83.594 (89.454)   Prec@5 100.000 (99.683)   [2019-11-22 03:01:13]
  **Train** Prec@1 89.262 Prec@5 99.704 Error@1 10.738
  **Test** Prec@1 85.790 Prec@5 99.150 Error@1 14.210

==>>[2019-11-22 03:01:20] [Epoch=073/200] [Need: 00:46:23] [LR=0.0100][M=0.90] [Best : Accuracy=86.07, Error=13.93]
  Epoch: [073][000/391]   Time 0.253 (0.253)   Data 0.192 (0.192)   Loss 0.2953 (0.2953)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 03:01:20]
  Epoch: [073][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.3034 (0.2904)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.760)   [2019-11-22 03:01:25]
  Epoch: [073][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.3645 (0.3013)   Prec@1 89.062 (89.401)   Prec@5 98.438 (99.701)   [2019-11-22 03:01:31]
  Epoch: [073][300/391]   Time 0.047 (0.054)   Data 0.000 (0.001)   Loss 0.2925 (0.3035)   Prec@1 91.406 (89.358)   Prec@5 99.219 (99.683)   [2019-11-22 03:01:36]
  **Train** Prec@1 89.372 Prec@5 99.682 Error@1 10.628
  **Test** Prec@1 86.610 Prec@5 99.630 Error@1 13.390
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:01:42] [Epoch=074/200] [Need: 00:46:02] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [074][000/391]   Time 0.234 (0.234)   Data 0.152 (0.152)   Loss 0.3203 (0.3203)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-22 03:01:42]
  Epoch: [074][100/391]   Time 0.053 (0.055)   Data 0.002 (0.002)   Loss 0.3670 (0.2839)   Prec@1 85.156 (90.114)   Prec@5 100.000 (99.737)   [2019-11-22 03:01:48]
  Epoch: [074][200/391]   Time 0.048 (0.054)   Data 0.000 (0.001)   Loss 0.3200 (0.2983)   Prec@1 88.281 (89.544)   Prec@5 99.219 (99.755)   [2019-11-22 03:01:53]
  Epoch: [074][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3481 (0.3069)   Prec@1 89.062 (89.322)   Prec@5 100.000 (99.740)   [2019-11-22 03:01:58]
  **Train** Prec@1 89.202 Prec@5 99.722 Error@1 10.798
  **Test** Prec@1 84.480 Prec@5 99.330 Error@1 15.520

==>>[2019-11-22 03:02:04] [Epoch=075/200] [Need: 00:45:40] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [075][000/391]   Time 0.228 (0.228)   Data 0.162 (0.162)   Loss 0.3068 (0.3068)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 03:02:04]
  Epoch: [075][100/391]   Time 0.081 (0.055)   Data 0.000 (0.002)   Loss 0.3706 (0.2924)   Prec@1 83.594 (89.666)   Prec@5 99.219 (99.752)   [2019-11-22 03:02:09]
  Epoch: [075][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.2919 (0.2989)   Prec@1 89.062 (89.576)   Prec@5 99.219 (99.716)   [2019-11-22 03:02:14]
  Epoch: [075][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4093 (0.3073)   Prec@1 87.500 (89.382)   Prec@5 99.219 (99.665)   [2019-11-22 03:02:20]
  **Train** Prec@1 89.378 Prec@5 99.652 Error@1 10.622
  **Test** Prec@1 84.740 Prec@5 99.100 Error@1 15.260

==>>[2019-11-22 03:02:26] [Epoch=076/200] [Need: 00:45:18] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [076][000/391]   Time 0.223 (0.223)   Data 0.160 (0.160)   Loss 0.3943 (0.3943)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 03:02:26]
  Epoch: [076][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.2674 (0.3050)   Prec@1 90.625 (89.395)   Prec@5 100.000 (99.722)   [2019-11-22 03:02:31]
  Epoch: [076][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2526 (0.3059)   Prec@1 90.625 (89.284)   Prec@5 99.219 (99.712)   [2019-11-22 03:02:37]
  Epoch: [076][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3668 (0.3067)   Prec@1 89.062 (89.335)   Prec@5 98.438 (99.676)   [2019-11-22 03:02:42]
  **Train** Prec@1 89.214 Prec@5 99.692 Error@1 10.786
  **Test** Prec@1 84.040 Prec@5 99.280 Error@1 15.960

==>>[2019-11-22 03:02:48] [Epoch=077/200] [Need: 00:44:56] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [077][000/391]   Time 0.224 (0.224)   Data 0.163 (0.163)   Loss 0.1914 (0.1914)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 03:02:48]
  Epoch: [077][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3093 (0.2983)   Prec@1 89.844 (89.581)   Prec@5 100.000 (99.783)   [2019-11-22 03:02:53]
  Epoch: [077][200/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.3061 (0.2972)   Prec@1 89.062 (89.723)   Prec@5 100.000 (99.767)   [2019-11-22 03:02:58]
  Epoch: [077][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.2374 (0.3000)   Prec@1 89.844 (89.584)   Prec@5 100.000 (99.746)   [2019-11-22 03:03:03]
  **Train** Prec@1 89.548 Prec@5 99.722 Error@1 10.452
  **Test** Prec@1 85.640 Prec@5 99.440 Error@1 14.360

==>>[2019-11-22 03:03:10] [Epoch=078/200] [Need: 00:44:34] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [078][000/391]   Time 0.248 (0.248)   Data 0.182 (0.182)   Loss 0.2344 (0.2344)   Prec@1 92.969 (92.969)   Prec@5 98.438 (98.438)   [2019-11-22 03:03:10]
  Epoch: [078][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.4674 (0.2855)   Prec@1 82.031 (90.176)   Prec@5 100.000 (99.791)   [2019-11-22 03:03:15]
  Epoch: [078][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2943 (0.3076)   Prec@1 92.188 (89.315)   Prec@5 99.219 (99.705)   [2019-11-22 03:03:20]
  Epoch: [078][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.2596 (0.3068)   Prec@1 90.625 (89.330)   Prec@5 100.000 (99.678)   [2019-11-22 03:03:26]
  **Train** Prec@1 89.170 Prec@5 99.680 Error@1 10.830
  **Test** Prec@1 82.430 Prec@5 98.850 Error@1 17.570

==>>[2019-11-22 03:03:32] [Epoch=079/200] [Need: 00:44:13] [LR=0.0100][M=0.90] [Best : Accuracy=86.61, Error=13.39]
  Epoch: [079][000/391]   Time 0.221 (0.221)   Data 0.171 (0.171)   Loss 0.2443 (0.2443)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 03:03:32]
  Epoch: [079][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3622 (0.2896)   Prec@1 85.938 (90.091)   Prec@5 99.219 (99.706)   [2019-11-22 03:03:38]
  Epoch: [079][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3035 (0.2979)   Prec@1 92.188 (89.852)   Prec@5 99.219 (99.681)   [2019-11-22 03:03:43]
  Epoch: [079][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.2330 (0.3067)   Prec@1 92.188 (89.480)   Prec@5 100.000 (99.681)   [2019-11-22 03:03:48]
  **Train** Prec@1 89.456 Prec@5 99.674 Error@1 10.544
  **Test** Prec@1 87.000 Prec@5 99.480 Error@1 13.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:03:54] [Epoch=080/200] [Need: 00:43:51] [LR=0.0010][M=0.90] [Best : Accuracy=87.00, Error=13.00]
  Epoch: [080][000/391]   Time 0.231 (0.231)   Data 0.164 (0.164)   Loss 0.3988 (0.3988)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 03:03:55]
  Epoch: [080][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.3294 (0.2416)   Prec@1 88.281 (91.530)   Prec@5 100.000 (99.737)   [2019-11-22 03:04:00]
  Epoch: [080][200/391]   Time 0.078 (0.053)   Data 0.000 (0.001)   Loss 0.1931 (0.2295)   Prec@1 92.188 (92.094)   Prec@5 100.000 (99.798)   [2019-11-22 03:04:05]
  Epoch: [080][300/391]   Time 0.065 (0.052)   Data 0.000 (0.001)   Loss 0.2154 (0.2226)   Prec@1 91.406 (92.348)   Prec@5 100.000 (99.826)   [2019-11-22 03:04:10]
  **Train** Prec@1 92.498 Prec@5 99.826 Error@1 7.502
  **Test** Prec@1 89.980 Prec@5 99.620 Error@1 10.020
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:04:16] [Epoch=081/200] [Need: 00:43:30] [LR=0.0010][M=0.90] [Best : Accuracy=89.98, Error=10.02]
  Epoch: [081][000/391]   Time 0.210 (0.210)   Data 0.146 (0.146)   Loss 0.1809 (0.1809)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 03:04:17]
  Epoch: [081][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.1585 (0.1893)   Prec@1 92.969 (93.309)   Prec@5 100.000 (99.853)   [2019-11-22 03:04:22]
  Epoch: [081][200/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.2128 (0.1859)   Prec@1 92.188 (93.552)   Prec@5 100.000 (99.841)   [2019-11-22 03:04:27]
  Epoch: [081][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1847 (0.1860)   Prec@1 91.406 (93.579)   Prec@5 100.000 (99.844)   [2019-11-22 03:04:32]
  **Train** Prec@1 93.494 Prec@5 99.848 Error@1 6.506
  **Test** Prec@1 89.990 Prec@5 99.730 Error@1 10.010
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:04:39] [Epoch=082/200] [Need: 00:43:08] [LR=0.0010][M=0.90] [Best : Accuracy=89.99, Error=10.01]
  Epoch: [082][000/391]   Time 0.232 (0.232)   Data 0.176 (0.176)   Loss 0.0893 (0.0893)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:04:39]
  Epoch: [082][100/391]   Time 0.078 (0.050)   Data 0.000 (0.002)   Loss 0.3521 (0.1665)   Prec@1 88.281 (94.384)   Prec@5 100.000 (99.892)   [2019-11-22 03:04:44]
  Epoch: [082][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.2201 (0.1743)   Prec@1 91.406 (94.146)   Prec@5 99.219 (99.876)   [2019-11-22 03:04:49]
  Epoch: [082][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.1038 (0.1768)   Prec@1 96.875 (93.921)   Prec@5 100.000 (99.878)   [2019-11-22 03:04:54]
  **Train** Prec@1 93.908 Prec@5 99.880 Error@1 6.092
  **Test** Prec@1 90.300 Prec@5 99.710 Error@1 9.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:05:00] [Epoch=083/200] [Need: 00:42:45] [LR=0.0010][M=0.90] [Best : Accuracy=90.30, Error=9.70]
  Epoch: [083][000/391]   Time 0.230 (0.230)   Data 0.162 (0.162)   Loss 0.1621 (0.1621)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 03:05:00]
  Epoch: [083][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1293 (0.1684)   Prec@1 95.312 (93.827)   Prec@5 100.000 (99.899)   [2019-11-22 03:05:05]
  Epoch: [083][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2606 (0.1684)   Prec@1 92.188 (94.003)   Prec@5 98.438 (99.883)   [2019-11-22 03:05:11]
  Epoch: [083][300/391]   Time 0.082 (0.051)   Data 0.000 (0.001)   Loss 0.2002 (0.1673)   Prec@1 95.312 (94.085)   Prec@5 99.219 (99.886)   [2019-11-22 03:05:15]
  **Train** Prec@1 94.104 Prec@5 99.888 Error@1 5.896
  **Test** Prec@1 90.270 Prec@5 99.700 Error@1 9.730

==>>[2019-11-22 03:05:22] [Epoch=084/200] [Need: 00:42:23] [LR=0.0010][M=0.90] [Best : Accuracy=90.30, Error=9.70]
  Epoch: [084][000/391]   Time 0.233 (0.233)   Data 0.176 (0.176)   Loss 0.1341 (0.1341)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:05:22]
  Epoch: [084][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1360 (0.1592)   Prec@1 95.312 (94.601)   Prec@5 99.219 (99.915)   [2019-11-22 03:05:27]
  Epoch: [084][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.1734 (0.1603)   Prec@1 96.094 (94.613)   Prec@5 99.219 (99.895)   [2019-11-22 03:05:32]
  Epoch: [084][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1678 (0.1614)   Prec@1 95.312 (94.521)   Prec@5 100.000 (99.883)   [2019-11-22 03:05:37]
  **Train** Prec@1 94.464 Prec@5 99.886 Error@1 5.536
  **Test** Prec@1 90.330 Prec@5 99.720 Error@1 9.670
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:05:44] [Epoch=085/200] [Need: 00:42:02] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [085][000/391]   Time 0.227 (0.227)   Data 0.155 (0.155)   Loss 0.1519 (0.1519)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 03:05:44]
  Epoch: [085][100/391]   Time 0.080 (0.055)   Data 0.000 (0.002)   Loss 0.0985 (0.1583)   Prec@1 96.875 (94.493)   Prec@5 100.000 (99.938)   [2019-11-22 03:05:50]
  Epoch: [085][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.1085 (0.1526)   Prec@1 96.875 (94.702)   Prec@5 100.000 (99.953)   [2019-11-22 03:05:55]
  Epoch: [085][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1049 (0.1548)   Prec@1 95.312 (94.640)   Prec@5 100.000 (99.938)   [2019-11-22 03:06:00]
  **Train** Prec@1 94.614 Prec@5 99.926 Error@1 5.386
  **Test** Prec@1 90.320 Prec@5 99.710 Error@1 9.680

==>>[2019-11-22 03:06:06] [Epoch=086/200] [Need: 00:41:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [086][000/391]   Time 0.225 (0.225)   Data 0.161 (0.161)   Loss 0.1433 (0.1433)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:06:07]
  Epoch: [086][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.1258 (0.1402)   Prec@1 96.875 (95.111)   Prec@5 99.219 (99.930)   [2019-11-22 03:06:12]
  Epoch: [086][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.1429 (0.1448)   Prec@1 95.312 (94.854)   Prec@5 100.000 (99.926)   [2019-11-22 03:06:17]
  Epoch: [086][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.1184 (0.1475)   Prec@1 94.531 (94.767)   Prec@5 100.000 (99.920)   [2019-11-22 03:06:22]
  **Train** Prec@1 94.736 Prec@5 99.922 Error@1 5.264
  **Test** Prec@1 90.370 Prec@5 99.770 Error@1 9.630
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:06:29] [Epoch=087/200] [Need: 00:41:19] [LR=0.0010][M=0.90] [Best : Accuracy=90.37, Error=9.63]
  Epoch: [087][000/391]   Time 0.237 (0.237)   Data 0.178 (0.178)   Loss 0.1133 (0.1133)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:06:29]
  Epoch: [087][100/391]   Time 0.040 (0.054)   Data 0.000 (0.002)   Loss 0.1933 (0.1430)   Prec@1 92.969 (95.127)   Prec@5 99.219 (99.892)   [2019-11-22 03:06:34]
  Epoch: [087][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.1418 (0.1464)   Prec@1 96.094 (94.974)   Prec@5 100.000 (99.895)   [2019-11-22 03:06:39]
  Epoch: [087][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.1171 (0.1490)   Prec@1 95.312 (94.871)   Prec@5 100.000 (99.907)   [2019-11-22 03:06:45]
  **Train** Prec@1 94.882 Prec@5 99.912 Error@1 5.118
  **Test** Prec@1 90.480 Prec@5 99.750 Error@1 9.520
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:06:51] [Epoch=088/200] [Need: 00:40:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [088][000/391]   Time 0.219 (0.219)   Data 0.149 (0.149)   Loss 0.1504 (0.1504)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2019-11-22 03:06:51]
  Epoch: [088][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.1606 (0.1412)   Prec@1 94.531 (95.119)   Prec@5 100.000 (99.930)   [2019-11-22 03:06:56]
  Epoch: [088][200/391]   Time 0.073 (0.053)   Data 0.000 (0.001)   Loss 0.0910 (0.1356)   Prec@1 96.875 (95.320)   Prec@5 100.000 (99.942)   [2019-11-22 03:07:02]
  Epoch: [088][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.1485 (0.1367)   Prec@1 94.531 (95.292)   Prec@5 100.000 (99.935)   [2019-11-22 03:07:07]
  **Train** Prec@1 95.232 Prec@5 99.932 Error@1 4.768
  **Test** Prec@1 90.200 Prec@5 99.730 Error@1 9.800

==>>[2019-11-22 03:07:13] [Epoch=089/200] [Need: 00:40:35] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [089][000/391]   Time 0.230 (0.230)   Data 0.163 (0.163)   Loss 0.1388 (0.1388)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:07:13]
  Epoch: [089][100/391]   Time 0.054 (0.052)   Data 0.000 (0.002)   Loss 0.1865 (0.1371)   Prec@1 93.750 (95.243)   Prec@5 100.000 (99.938)   [2019-11-22 03:07:18]
  Epoch: [089][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.1725 (0.1389)   Prec@1 94.531 (95.141)   Prec@5 100.000 (99.926)   [2019-11-22 03:07:23]
  Epoch: [089][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1188 (0.1353)   Prec@1 95.312 (95.284)   Prec@5 100.000 (99.933)   [2019-11-22 03:07:28]
  **Train** Prec@1 95.260 Prec@5 99.934 Error@1 4.740
  **Test** Prec@1 90.340 Prec@5 99.710 Error@1 9.660

==>>[2019-11-22 03:07:35] [Epoch=090/200] [Need: 00:40:13] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [090][000/391]   Time 0.209 (0.209)   Data 0.148 (0.148)   Loss 0.1410 (0.1410)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:07:35]
  Epoch: [090][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.0465 (0.1262)   Prec@1 100.000 (95.258)   Prec@5 100.000 (99.969)   [2019-11-22 03:07:40]
  Epoch: [090][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1900 (0.1292)   Prec@1 92.969 (95.351)   Prec@5 100.000 (99.949)   [2019-11-22 03:07:45]
  Epoch: [090][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.1668 (0.1327)   Prec@1 93.750 (95.300)   Prec@5 100.000 (99.948)   [2019-11-22 03:07:50]
  **Train** Prec@1 95.288 Prec@5 99.942 Error@1 4.712
  **Test** Prec@1 90.490 Prec@5 99.760 Error@1 9.510
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:07:56] [Epoch=091/200] [Need: 00:39:51] [LR=0.0010][M=0.90] [Best : Accuracy=90.49, Error=9.51]
  Epoch: [091][000/391]   Time 0.211 (0.211)   Data 0.150 (0.150)   Loss 0.1524 (0.1524)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:07:56]
  Epoch: [091][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.1258 (0.1294)   Prec@1 94.531 (95.545)   Prec@5 100.000 (99.930)   [2019-11-22 03:08:02]
  Epoch: [091][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.1170 (0.1292)   Prec@1 94.531 (95.534)   Prec@5 100.000 (99.930)   [2019-11-22 03:08:07]
  Epoch: [091][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1796 (0.1304)   Prec@1 92.969 (95.520)   Prec@5 100.000 (99.925)   [2019-11-22 03:08:12]
  **Train** Prec@1 95.488 Prec@5 99.920 Error@1 4.512
  **Test** Prec@1 90.680 Prec@5 99.760 Error@1 9.320
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:08:18] [Epoch=092/200] [Need: 00:39:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [092][000/391]   Time 0.218 (0.218)   Data 0.162 (0.162)   Loss 0.1452 (0.1452)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 03:08:18]
  Epoch: [092][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.1653 (0.1282)   Prec@1 94.531 (95.761)   Prec@5 100.000 (99.961)   [2019-11-22 03:08:23]
  Epoch: [092][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1154 (0.1310)   Prec@1 96.875 (95.519)   Prec@5 100.000 (99.946)   [2019-11-22 03:08:28]
  Epoch: [092][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0895 (0.1282)   Prec@1 97.656 (95.595)   Prec@5 100.000 (99.940)   [2019-11-22 03:08:33]
  **Train** Prec@1 95.570 Prec@5 99.942 Error@1 4.430
  **Test** Prec@1 90.440 Prec@5 99.730 Error@1 9.560

==>>[2019-11-22 03:08:39] [Epoch=093/200] [Need: 00:39:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [093][000/391]   Time 0.230 (0.230)   Data 0.165 (0.165)   Loss 0.0843 (0.0843)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:08:40]
  Epoch: [093][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.0716 (0.1164)   Prec@1 96.875 (95.970)   Prec@5 100.000 (99.930)   [2019-11-22 03:08:45]
  Epoch: [093][200/391]   Time 0.075 (0.054)   Data 0.000 (0.001)   Loss 0.1581 (0.1214)   Prec@1 93.750 (95.752)   Prec@5 100.000 (99.953)   [2019-11-22 03:08:50]
  Epoch: [093][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.1360 (0.1245)   Prec@1 95.312 (95.544)   Prec@5 100.000 (99.961)   [2019-11-22 03:08:55]
  **Train** Prec@1 95.502 Prec@5 99.956 Error@1 4.498
  **Test** Prec@1 90.230 Prec@5 99.770 Error@1 9.770

==>>[2019-11-22 03:09:02] [Epoch=094/200] [Need: 00:38:45] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [094][000/391]   Time 0.234 (0.234)   Data 0.161 (0.161)   Loss 0.1164 (0.1164)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:09:02]
  Epoch: [094][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0995 (0.1128)   Prec@1 97.656 (96.009)   Prec@5 100.000 (99.969)   [2019-11-22 03:09:07]
  Epoch: [094][200/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0723 (0.1169)   Prec@1 96.875 (95.826)   Prec@5 100.000 (99.969)   [2019-11-22 03:09:12]
  Epoch: [094][300/391]   Time 0.058 (0.050)   Data 0.000 (0.001)   Loss 0.1289 (0.1176)   Prec@1 93.750 (95.803)   Prec@5 100.000 (99.958)   [2019-11-22 03:09:17]
  **Train** Prec@1 95.726 Prec@5 99.962 Error@1 4.274
  **Test** Prec@1 90.010 Prec@5 99.780 Error@1 9.990

==>>[2019-11-22 03:09:23] [Epoch=095/200] [Need: 00:38:22] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [095][000/391]   Time 0.226 (0.226)   Data 0.181 (0.181)   Loss 0.0562 (0.0562)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:09:23]
  Epoch: [095][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.1128 (0.1067)   Prec@1 95.312 (96.341)   Prec@5 100.000 (99.961)   [2019-11-22 03:09:29]
  Epoch: [095][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0663 (0.1114)   Prec@1 98.438 (96.102)   Prec@5 100.000 (99.942)   [2019-11-22 03:09:33]
  Epoch: [095][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1231 (0.1163)   Prec@1 95.312 (95.938)   Prec@5 100.000 (99.951)   [2019-11-22 03:09:38]
  **Train** Prec@1 95.894 Prec@5 99.948 Error@1 4.106
  **Test** Prec@1 90.410 Prec@5 99.760 Error@1 9.590

==>>[2019-11-22 03:09:45] [Epoch=096/200] [Need: 00:38:00] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [096][000/391]   Time 0.214 (0.214)   Data 0.157 (0.157)   Loss 0.1020 (0.1020)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:09:45]
  Epoch: [096][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.0785 (0.1196)   Prec@1 96.875 (96.117)   Prec@5 100.000 (99.954)   [2019-11-22 03:09:50]
  Epoch: [096][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0633 (0.1201)   Prec@1 99.219 (96.016)   Prec@5 100.000 (99.946)   [2019-11-22 03:09:56]
  Epoch: [096][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.1158 (0.1200)   Prec@1 96.094 (95.896)   Prec@5 100.000 (99.951)   [2019-11-22 03:10:01]
  **Train** Prec@1 95.918 Prec@5 99.948 Error@1 4.082
  **Test** Prec@1 90.650 Prec@5 99.760 Error@1 9.350

==>>[2019-11-22 03:10:07] [Epoch=097/200] [Need: 00:37:39] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [097][000/391]   Time 0.222 (0.222)   Data 0.166 (0.166)   Loss 0.0725 (0.0725)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:10:08]
  Epoch: [097][100/391]   Time 0.058 (0.055)   Data 0.000 (0.002)   Loss 0.1144 (0.1078)   Prec@1 96.094 (96.326)   Prec@5 100.000 (99.946)   [2019-11-22 03:10:13]
  Epoch: [097][200/391]   Time 0.051 (0.055)   Data 0.000 (0.001)   Loss 0.1204 (0.1094)   Prec@1 95.312 (96.273)   Prec@5 100.000 (99.965)   [2019-11-22 03:10:18]
  Epoch: [097][300/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.0847 (0.1126)   Prec@1 97.656 (96.140)   Prec@5 100.000 (99.953)   [2019-11-22 03:10:23]
  **Train** Prec@1 96.062 Prec@5 99.956 Error@1 3.938
  **Test** Prec@1 90.510 Prec@5 99.760 Error@1 9.490

==>>[2019-11-22 03:10:30] [Epoch=098/200] [Need: 00:37:17] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [098][000/391]   Time 0.232 (0.232)   Data 0.168 (0.168)   Loss 0.1072 (0.1072)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:10:30]
  Epoch: [098][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.1864 (0.1076)   Prec@1 94.531 (96.272)   Prec@5 100.000 (99.899)   [2019-11-22 03:10:35]
  Epoch: [098][200/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.1071 (0.1073)   Prec@1 96.875 (96.226)   Prec@5 100.000 (99.946)   [2019-11-22 03:10:40]
  Epoch: [098][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.1153 (0.1117)   Prec@1 95.312 (96.011)   Prec@5 100.000 (99.948)   [2019-11-22 03:10:45]
  **Train** Prec@1 96.032 Prec@5 99.944 Error@1 3.968
  **Test** Prec@1 90.340 Prec@5 99.720 Error@1 9.660

==>>[2019-11-22 03:10:52] [Epoch=099/200] [Need: 00:36:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [099][000/391]   Time 0.236 (0.236)   Data 0.152 (0.152)   Loss 0.1298 (0.1298)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 03:10:52]
  Epoch: [099][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.1881 (0.1123)   Prec@1 93.750 (96.071)   Prec@5 100.000 (99.923)   [2019-11-22 03:10:57]
  Epoch: [099][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0726 (0.1099)   Prec@1 97.656 (96.117)   Prec@5 100.000 (99.934)   [2019-11-22 03:11:02]
  Epoch: [099][300/391]   Time 0.080 (0.053)   Data 0.000 (0.001)   Loss 0.0691 (0.1089)   Prec@1 96.875 (96.143)   Prec@5 100.000 (99.943)   [2019-11-22 03:11:08]
  **Train** Prec@1 96.086 Prec@5 99.950 Error@1 3.914
  **Test** Prec@1 90.440 Prec@5 99.720 Error@1 9.560

==>>[2019-11-22 03:11:14] [Epoch=100/200] [Need: 00:36:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [100][000/391]   Time 0.224 (0.224)   Data 0.163 (0.163)   Loss 0.0796 (0.0796)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:11:15]
  Epoch: [100][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0795 (0.1038)   Prec@1 96.094 (96.055)   Prec@5 100.000 (99.985)   [2019-11-22 03:11:20]
  Epoch: [100][200/391]   Time 0.037 (0.051)   Data 0.000 (0.001)   Loss 0.1888 (0.1071)   Prec@1 95.312 (96.000)   Prec@5 99.219 (99.977)   [2019-11-22 03:11:24]
  Epoch: [100][300/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.1160 (0.1078)   Prec@1 95.312 (96.057)   Prec@5 100.000 (99.979)   [2019-11-22 03:11:29]
  **Train** Prec@1 96.020 Prec@5 99.972 Error@1 3.980
  **Test** Prec@1 90.500 Prec@5 99.720 Error@1 9.500

==>>[2019-11-22 03:11:36] [Epoch=101/200] [Need: 00:36:12] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [101][000/391]   Time 0.226 (0.226)   Data 0.155 (0.155)   Loss 0.0806 (0.0806)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:11:36]
  Epoch: [101][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0518 (0.0987)   Prec@1 96.875 (96.535)   Prec@5 100.000 (99.969)   [2019-11-22 03:11:42]
  Epoch: [101][200/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.1460 (0.1042)   Prec@1 94.531 (96.389)   Prec@5 100.000 (99.961)   [2019-11-22 03:11:46]
  Epoch: [101][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1389 (0.1049)   Prec@1 95.312 (96.364)   Prec@5 100.000 (99.971)   [2019-11-22 03:11:51]
  **Train** Prec@1 96.246 Prec@5 99.966 Error@1 3.754
  **Test** Prec@1 90.220 Prec@5 99.750 Error@1 9.780

==>>[2019-11-22 03:11:58] [Epoch=102/200] [Need: 00:35:50] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [102][000/391]   Time 0.231 (0.231)   Data 0.147 (0.147)   Loss 0.1442 (0.1442)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 03:11:58]
  Epoch: [102][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1127 (0.1034)   Prec@1 96.094 (96.372)   Prec@5 100.000 (99.961)   [2019-11-22 03:12:03]
  Epoch: [102][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.1361 (0.1033)   Prec@1 95.312 (96.249)   Prec@5 100.000 (99.973)   [2019-11-22 03:12:08]
  Epoch: [102][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1228 (0.1028)   Prec@1 94.531 (96.322)   Prec@5 100.000 (99.977)   [2019-11-22 03:12:13]
  **Train** Prec@1 96.328 Prec@5 99.974 Error@1 3.672
  **Test** Prec@1 90.360 Prec@5 99.740 Error@1 9.640

==>>[2019-11-22 03:12:20] [Epoch=103/200] [Need: 00:35:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [103][000/391]   Time 0.221 (0.221)   Data 0.150 (0.150)   Loss 0.0366 (0.0366)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:12:20]
  Epoch: [103][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.1488 (0.1051)   Prec@1 92.969 (96.303)   Prec@5 100.000 (99.954)   [2019-11-22 03:12:26]
  Epoch: [103][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1024 (0.1048)   Prec@1 97.656 (96.300)   Prec@5 100.000 (99.961)   [2019-11-22 03:12:30]
  Epoch: [103][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0687 (0.1031)   Prec@1 96.875 (96.299)   Prec@5 100.000 (99.961)   [2019-11-22 03:12:35]
  **Train** Prec@1 96.276 Prec@5 99.966 Error@1 3.724
  **Test** Prec@1 90.340 Prec@5 99.750 Error@1 9.660

==>>[2019-11-22 03:12:42] [Epoch=104/200] [Need: 00:35:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [104][000/391]   Time 0.228 (0.228)   Data 0.152 (0.152)   Loss 0.0366 (0.0366)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:12:42]
  Epoch: [104][100/391]   Time 0.047 (0.056)   Data 0.000 (0.002)   Loss 0.0583 (0.0946)   Prec@1 99.219 (96.782)   Prec@5 100.000 (99.954)   [2019-11-22 03:12:47]
  Epoch: [104][200/391]   Time 0.048 (0.054)   Data 0.000 (0.001)   Loss 0.1052 (0.0966)   Prec@1 98.438 (96.642)   Prec@5 100.000 (99.961)   [2019-11-22 03:12:53]
  Epoch: [104][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0663 (0.0965)   Prec@1 96.875 (96.634)   Prec@5 100.000 (99.974)   [2019-11-22 03:12:57]
  **Train** Prec@1 96.558 Prec@5 99.978 Error@1 3.442
  **Test** Prec@1 90.180 Prec@5 99.770 Error@1 9.820

==>>[2019-11-22 03:13:04] [Epoch=105/200] [Need: 00:34:44] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [105][000/391]   Time 0.241 (0.241)   Data 0.151 (0.151)   Loss 0.1458 (0.1458)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:13:04]
  Epoch: [105][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.1476 (0.0967)   Prec@1 92.969 (96.504)   Prec@5 100.000 (99.992)   [2019-11-22 03:13:09]
  Epoch: [105][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0974 (0.0969)   Prec@1 96.094 (96.580)   Prec@5 100.000 (99.981)   [2019-11-22 03:13:14]
  Epoch: [105][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.0970 (0.0983)   Prec@1 93.750 (96.496)   Prec@5 100.000 (99.971)   [2019-11-22 03:13:19]
  **Train** Prec@1 96.442 Prec@5 99.972 Error@1 3.558
  **Test** Prec@1 90.020 Prec@5 99.710 Error@1 9.980

==>>[2019-11-22 03:13:26] [Epoch=106/200] [Need: 00:34:22] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [106][000/391]   Time 0.231 (0.231)   Data 0.172 (0.172)   Loss 0.0916 (0.0916)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:13:26]
  Epoch: [106][100/391]   Time 0.085 (0.055)   Data 0.000 (0.002)   Loss 0.0870 (0.0901)   Prec@1 96.094 (96.728)   Prec@5 100.000 (99.985)   [2019-11-22 03:13:31]
  Epoch: [106][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0636 (0.0924)   Prec@1 97.656 (96.677)   Prec@5 100.000 (99.984)   [2019-11-22 03:13:36]
  Epoch: [106][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1052 (0.0938)   Prec@1 96.875 (96.680)   Prec@5 100.000 (99.969)   [2019-11-22 03:13:41]
  **Train** Prec@1 96.546 Prec@5 99.970 Error@1 3.454
  **Test** Prec@1 90.390 Prec@5 99.730 Error@1 9.610

==>>[2019-11-22 03:13:48] [Epoch=107/200] [Need: 00:34:00] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [107][000/391]   Time 0.225 (0.225)   Data 0.162 (0.162)   Loss 0.1312 (0.1312)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 03:13:48]
  Epoch: [107][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.1313 (0.0873)   Prec@1 94.531 (96.883)   Prec@5 100.000 (99.992)   [2019-11-22 03:13:53]
  Epoch: [107][200/391]   Time 0.078 (0.051)   Data 0.000 (0.001)   Loss 0.1245 (0.0904)   Prec@1 95.312 (96.801)   Prec@5 100.000 (99.973)   [2019-11-22 03:13:58]
  Epoch: [107][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0804 (0.0937)   Prec@1 96.875 (96.641)   Prec@5 100.000 (99.971)   [2019-11-22 03:14:03]
  **Train** Prec@1 96.630 Prec@5 99.976 Error@1 3.370
  **Test** Prec@1 90.330 Prec@5 99.740 Error@1 9.670

==>>[2019-11-22 03:14:10] [Epoch=108/200] [Need: 00:33:39] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [108][000/391]   Time 0.214 (0.214)   Data 0.141 (0.141)   Loss 0.1164 (0.1164)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:14:10]
  Epoch: [108][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0803 (0.0886)   Prec@1 97.656 (96.798)   Prec@5 100.000 (99.954)   [2019-11-22 03:14:15]
  Epoch: [108][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1169 (0.0918)   Prec@1 94.531 (96.696)   Prec@5 100.000 (99.969)   [2019-11-22 03:14:20]
  Epoch: [108][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.0768 (0.0912)   Prec@1 97.656 (96.735)   Prec@5 100.000 (99.979)   [2019-11-22 03:14:25]
  **Train** Prec@1 96.644 Prec@5 99.980 Error@1 3.356
  **Test** Prec@1 90.140 Prec@5 99.660 Error@1 9.860

==>>[2019-11-22 03:14:32] [Epoch=109/200] [Need: 00:33:16] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [109][000/391]   Time 0.227 (0.227)   Data 0.158 (0.158)   Loss 0.0879 (0.0879)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:14:32]
  Epoch: [109][100/391]   Time 0.081 (0.056)   Data 0.000 (0.002)   Loss 0.0486 (0.0854)   Prec@1 98.438 (96.999)   Prec@5 100.000 (99.992)   [2019-11-22 03:14:37]
  Epoch: [109][200/391]   Time 0.083 (0.054)   Data 0.000 (0.001)   Loss 0.0728 (0.0878)   Prec@1 98.438 (96.879)   Prec@5 100.000 (99.973)   [2019-11-22 03:14:43]
  Epoch: [109][300/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.1173 (0.0898)   Prec@1 96.094 (96.805)   Prec@5 100.000 (99.966)   [2019-11-22 03:14:48]
  **Train** Prec@1 96.728 Prec@5 99.972 Error@1 3.272
  **Test** Prec@1 90.540 Prec@5 99.720 Error@1 9.460

==>>[2019-11-22 03:14:55] [Epoch=110/200] [Need: 00:32:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [110][000/391]   Time 0.235 (0.235)   Data 0.165 (0.165)   Loss 0.0832 (0.0832)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:14:55]
  Epoch: [110][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0761 (0.0886)   Prec@1 96.875 (96.836)   Prec@5 100.000 (99.985)   [2019-11-22 03:15:00]
  Epoch: [110][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0679 (0.0914)   Prec@1 97.656 (96.782)   Prec@5 100.000 (99.984)   [2019-11-22 03:15:05]
  Epoch: [110][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1066 (0.0918)   Prec@1 96.094 (96.717)   Prec@5 100.000 (99.990)   [2019-11-22 03:15:10]
  **Train** Prec@1 96.606 Prec@5 99.986 Error@1 3.394
  **Test** Prec@1 89.970 Prec@5 99.740 Error@1 10.030

==>>[2019-11-22 03:15:16] [Epoch=111/200] [Need: 00:32:33] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [111][000/391]   Time 0.230 (0.230)   Data 0.172 (0.172)   Loss 0.0699 (0.0699)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:15:16]
  Epoch: [111][100/391]   Time 0.059 (0.053)   Data 0.000 (0.002)   Loss 0.1011 (0.0897)   Prec@1 96.094 (96.906)   Prec@5 100.000 (99.985)   [2019-11-22 03:15:22]
  Epoch: [111][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.1197 (0.0901)   Prec@1 96.094 (96.875)   Prec@5 100.000 (99.977)   [2019-11-22 03:15:27]
  Epoch: [111][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1142 (0.0922)   Prec@1 95.312 (96.737)   Prec@5 100.000 (99.979)   [2019-11-22 03:15:32]
  **Train** Prec@1 96.772 Prec@5 99.972 Error@1 3.228
  **Test** Prec@1 90.080 Prec@5 99.750 Error@1 9.920

==>>[2019-11-22 03:15:39] [Epoch=112/200] [Need: 00:32:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [112][000/391]   Time 0.232 (0.232)   Data 0.167 (0.167)   Loss 0.0632 (0.0632)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:15:39]
  Epoch: [112][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.0912 (0.0816)   Prec@1 96.875 (97.037)   Prec@5 100.000 (99.977)   [2019-11-22 03:15:44]
  Epoch: [112][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0514 (0.0874)   Prec@1 99.219 (96.832)   Prec@5 100.000 (99.981)   [2019-11-22 03:15:49]
  Epoch: [112][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0588 (0.0901)   Prec@1 97.656 (96.756)   Prec@5 100.000 (99.971)   [2019-11-22 03:15:54]
  **Train** Prec@1 96.682 Prec@5 99.972 Error@1 3.318
  **Test** Prec@1 90.250 Prec@5 99.720 Error@1 9.750

==>>[2019-11-22 03:16:00] [Epoch=113/200] [Need: 00:31:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [113][000/391]   Time 0.239 (0.239)   Data 0.162 (0.162)   Loss 0.1199 (0.1199)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:16:01]
  Epoch: [113][100/391]   Time 0.080 (0.055)   Data 0.000 (0.002)   Loss 0.0978 (0.0834)   Prec@1 93.750 (96.929)   Prec@5 100.000 (99.992)   [2019-11-22 03:16:06]
  Epoch: [113][200/391]   Time 0.082 (0.054)   Data 0.000 (0.001)   Loss 0.0247 (0.0858)   Prec@1 99.219 (96.859)   Prec@5 100.000 (99.973)   [2019-11-22 03:16:11]
  Epoch: [113][300/391]   Time 0.068 (0.053)   Data 0.000 (0.001)   Loss 0.0646 (0.0872)   Prec@1 97.656 (96.870)   Prec@5 100.000 (99.979)   [2019-11-22 03:16:16]
  **Train** Prec@1 96.792 Prec@5 99.974 Error@1 3.208
  **Test** Prec@1 90.410 Prec@5 99.740 Error@1 9.590

==>>[2019-11-22 03:16:23] [Epoch=114/200] [Need: 00:31:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [114][000/391]   Time 0.233 (0.233)   Data 0.177 (0.177)   Loss 0.1047 (0.1047)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 03:16:23]
  Epoch: [114][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.1272 (0.0845)   Prec@1 95.312 (96.921)   Prec@5 99.219 (99.969)   [2019-11-22 03:16:28]
  Epoch: [114][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1182 (0.0844)   Prec@1 96.094 (96.910)   Prec@5 100.000 (99.977)   [2019-11-22 03:16:33]
  Epoch: [114][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0622 (0.0850)   Prec@1 98.438 (96.932)   Prec@5 100.000 (99.984)   [2019-11-22 03:16:38]
  **Train** Prec@1 96.936 Prec@5 99.980 Error@1 3.064
  **Test** Prec@1 90.200 Prec@5 99.710 Error@1 9.800

==>>[2019-11-22 03:16:45] [Epoch=115/200] [Need: 00:31:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [115][000/391]   Time 0.220 (0.220)   Data 0.163 (0.163)   Loss 0.0617 (0.0617)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:16:45]
  Epoch: [115][100/391]   Time 0.058 (0.056)   Data 0.000 (0.002)   Loss 0.1040 (0.0845)   Prec@1 96.875 (97.092)   Prec@5 100.000 (99.992)   [2019-11-22 03:16:50]
  Epoch: [115][200/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 0.0783 (0.0860)   Prec@1 96.875 (97.003)   Prec@5 100.000 (99.984)   [2019-11-22 03:16:56]
  Epoch: [115][300/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.1253 (0.0869)   Prec@1 93.750 (96.911)   Prec@5 100.000 (99.984)   [2019-11-22 03:17:01]
  **Train** Prec@1 96.954 Prec@5 99.984 Error@1 3.046
  **Test** Prec@1 89.990 Prec@5 99.760 Error@1 10.010

==>>[2019-11-22 03:17:07] [Epoch=116/200] [Need: 00:30:44] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [116][000/391]   Time 0.240 (0.240)   Data 0.181 (0.181)   Loss 0.1355 (0.1355)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 03:17:07]
  Epoch: [116][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1118 (0.0803)   Prec@1 94.531 (97.146)   Prec@5 100.000 (99.992)   [2019-11-22 03:17:12]
  Epoch: [116][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0960 (0.0796)   Prec@1 96.875 (97.201)   Prec@5 100.000 (99.981)   [2019-11-22 03:17:18]
  Epoch: [116][300/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.0916 (0.0814)   Prec@1 97.656 (97.114)   Prec@5 100.000 (99.984)   [2019-11-22 03:17:23]
  **Train** Prec@1 97.066 Prec@5 99.986 Error@1 2.934
  **Test** Prec@1 90.010 Prec@5 99.670 Error@1 9.990

==>>[2019-11-22 03:17:29] [Epoch=117/200] [Need: 00:30:22] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [117][000/391]   Time 0.229 (0.229)   Data 0.155 (0.155)   Loss 0.1127 (0.1127)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-22 03:17:30]
  Epoch: [117][100/391]   Time 0.047 (0.055)   Data 0.000 (0.002)   Loss 0.0712 (0.0817)   Prec@1 97.656 (97.184)   Prec@5 100.000 (99.969)   [2019-11-22 03:17:35]
  Epoch: [117][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.1119 (0.0824)   Prec@1 95.312 (97.058)   Prec@5 100.000 (99.977)   [2019-11-22 03:17:40]
  Epoch: [117][300/391]   Time 0.077 (0.053)   Data 0.000 (0.001)   Loss 0.1663 (0.0848)   Prec@1 94.531 (96.945)   Prec@5 99.219 (99.979)   [2019-11-22 03:17:45]
  **Train** Prec@1 96.928 Prec@5 99.982 Error@1 3.072
  **Test** Prec@1 90.230 Prec@5 99.760 Error@1 9.770

==>>[2019-11-22 03:17:52] [Epoch=118/200] [Need: 00:30:01] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [118][000/391]   Time 0.223 (0.223)   Data 0.164 (0.164)   Loss 0.0663 (0.0663)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:17:52]
  Epoch: [118][100/391]   Time 0.050 (0.051)   Data 0.000 (0.002)   Loss 0.0774 (0.0794)   Prec@1 96.875 (97.099)   Prec@5 100.000 (99.985)   [2019-11-22 03:17:57]
  Epoch: [118][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0840 (0.0826)   Prec@1 97.656 (97.023)   Prec@5 100.000 (99.981)   [2019-11-22 03:18:02]
  Epoch: [118][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0602 (0.0819)   Prec@1 97.656 (97.101)   Prec@5 100.000 (99.984)   [2019-11-22 03:18:07]
  **Train** Prec@1 97.116 Prec@5 99.984 Error@1 2.884
  **Test** Prec@1 89.900 Prec@5 99.690 Error@1 10.100

==>>[2019-11-22 03:18:14] [Epoch=119/200] [Need: 00:29:39] [LR=0.0010][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [119][000/391]   Time 0.230 (0.230)   Data 0.149 (0.149)   Loss 0.0518 (0.0518)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:18:14]
  Epoch: [119][100/391]   Time 0.061 (0.050)   Data 0.000 (0.002)   Loss 0.0766 (0.0727)   Prec@1 98.438 (97.393)   Prec@5 100.000 (99.977)   [2019-11-22 03:18:19]
  Epoch: [119][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0640 (0.0757)   Prec@1 96.875 (97.256)   Prec@5 100.000 (99.984)   [2019-11-22 03:18:25]
  Epoch: [119][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0719 (0.0769)   Prec@1 96.875 (97.259)   Prec@5 100.000 (99.974)   [2019-11-22 03:18:30]
  **Train** Prec@1 97.306 Prec@5 99.978 Error@1 2.694
  **Test** Prec@1 90.140 Prec@5 99.750 Error@1 9.860

==>>[2019-11-22 03:18:36] [Epoch=120/200] [Need: 00:29:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [120][000/391]   Time 0.236 (0.236)   Data 0.153 (0.153)   Loss 0.0772 (0.0772)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:18:36]
  Epoch: [120][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.1348 (0.0750)   Prec@1 95.312 (97.262)   Prec@5 100.000 (99.992)   [2019-11-22 03:18:41]
  Epoch: [120][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0525 (0.0742)   Prec@1 98.438 (97.357)   Prec@5 100.000 (99.992)   [2019-11-22 03:18:46]
  Epoch: [120][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0461 (0.0736)   Prec@1 98.438 (97.389)   Prec@5 100.000 (99.990)   [2019-11-22 03:18:51]
  **Train** Prec@1 97.456 Prec@5 99.986 Error@1 2.544
  **Test** Prec@1 90.400 Prec@5 99.750 Error@1 9.600

==>>[2019-11-22 03:18:57] [Epoch=121/200] [Need: 00:28:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [121][000/391]   Time 0.219 (0.219)   Data 0.151 (0.151)   Loss 0.0551 (0.0551)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:18:58]
  Epoch: [121][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.0787 (0.0659)   Prec@1 96.094 (97.819)   Prec@5 100.000 (99.985)   [2019-11-22 03:19:02]
  Epoch: [121][200/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.0749 (0.0668)   Prec@1 97.656 (97.707)   Prec@5 100.000 (99.992)   [2019-11-22 03:19:08]
  Epoch: [121][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1308 (0.0661)   Prec@1 95.312 (97.687)   Prec@5 100.000 (99.992)   [2019-11-22 03:19:13]
  **Train** Prec@1 97.660 Prec@5 99.988 Error@1 2.340
  **Test** Prec@1 90.560 Prec@5 99.710 Error@1 9.440

==>>[2019-11-22 03:19:19] [Epoch=122/200] [Need: 00:28:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [122][000/391]   Time 0.220 (0.220)   Data 0.165 (0.165)   Loss 0.0599 (0.0599)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:19:20]
  Epoch: [122][100/391]   Time 0.059 (0.051)   Data 0.000 (0.002)   Loss 0.0816 (0.0682)   Prec@1 96.875 (97.819)   Prec@5 100.000 (99.969)   [2019-11-22 03:19:25]
  Epoch: [122][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.0804 (0.0688)   Prec@1 98.438 (97.641)   Prec@5 99.219 (99.977)   [2019-11-22 03:19:29]
  Epoch: [122][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0409 (0.0665)   Prec@1 99.219 (97.721)   Prec@5 100.000 (99.984)   [2019-11-22 03:19:35]
  **Train** Prec@1 97.704 Prec@5 99.982 Error@1 2.296
  **Test** Prec@1 90.660 Prec@5 99.750 Error@1 9.340

==>>[2019-11-22 03:19:41] [Epoch=123/200] [Need: 00:28:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [123][000/391]   Time 0.222 (0.222)   Data 0.168 (0.168)   Loss 0.0571 (0.0571)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:19:42]
  Epoch: [123][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.0354 (0.0647)   Prec@1 98.438 (97.556)   Prec@5 100.000 (99.977)   [2019-11-22 03:19:47]
  Epoch: [123][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0567 (0.0635)   Prec@1 99.219 (97.715)   Prec@5 100.000 (99.984)   [2019-11-22 03:19:52]
  Epoch: [123][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0387 (0.0651)   Prec@1 99.219 (97.687)   Prec@5 100.000 (99.982)   [2019-11-22 03:19:57]
  **Train** Prec@1 97.680 Prec@5 99.986 Error@1 2.320
  **Test** Prec@1 90.670 Prec@5 99.740 Error@1 9.330

==>>[2019-11-22 03:20:04] [Epoch=124/200] [Need: 00:27:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [124][000/391]   Time 0.225 (0.225)   Data 0.155 (0.155)   Loss 0.0487 (0.0487)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:04]
  Epoch: [124][100/391]   Time 0.047 (0.052)   Data 0.000 (0.002)   Loss 0.0191 (0.0580)   Prec@1 100.000 (97.997)   Prec@5 100.000 (99.985)   [2019-11-22 03:20:09]
  Epoch: [124][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0494 (0.0621)   Prec@1 97.656 (97.889)   Prec@5 100.000 (99.981)   [2019-11-22 03:20:14]
  Epoch: [124][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0556 (0.0628)   Prec@1 97.656 (97.830)   Prec@5 100.000 (99.984)   [2019-11-22 03:20:19]
  **Train** Prec@1 97.858 Prec@5 99.988 Error@1 2.142
  **Test** Prec@1 90.670 Prec@5 99.740 Error@1 9.330

==>>[2019-11-22 03:20:26] [Epoch=125/200] [Need: 00:27:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.68, Error=9.32]
  Epoch: [125][000/391]   Time 0.225 (0.225)   Data 0.167 (0.167)   Loss 0.0219 (0.0219)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:26]
  Epoch: [125][100/391]   Time 0.069 (0.054)   Data 0.000 (0.002)   Loss 0.0179 (0.0589)   Prec@1 100.000 (98.043)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:31]
  Epoch: [125][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0384 (0.0585)   Prec@1 99.219 (98.053)   Prec@5 100.000 (99.992)   [2019-11-22 03:20:36]
  Epoch: [125][300/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.0505 (0.0605)   Prec@1 99.219 (97.986)   Prec@5 100.000 (99.990)   [2019-11-22 03:20:41]
  **Train** Prec@1 97.950 Prec@5 99.992 Error@1 2.050
  **Test** Prec@1 90.730 Prec@5 99.710 Error@1 9.270
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:20:48] [Epoch=126/200] [Need: 00:27:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.73, Error=9.27]
  Epoch: [126][000/391]   Time 0.220 (0.220)   Data 0.163 (0.163)   Loss 0.0735 (0.0735)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:48]
  Epoch: [126][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0444 (0.0616)   Prec@1 97.656 (97.912)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:53]
  Epoch: [126][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0664 (0.0607)   Prec@1 97.656 (97.983)   Prec@5 100.000 (100.000)   [2019-11-22 03:20:58]
  Epoch: [126][300/391]   Time 0.068 (0.051)   Data 0.000 (0.001)   Loss 0.0517 (0.0608)   Prec@1 98.438 (97.957)   Prec@5 100.000 (99.997)   [2019-11-22 03:21:03]
  **Train** Prec@1 97.930 Prec@5 99.998 Error@1 2.070
  **Test** Prec@1 90.760 Prec@5 99.710 Error@1 9.240
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:21:10] [Epoch=127/200] [Need: 00:26:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.76, Error=9.24]
  Epoch: [127][000/391]   Time 0.222 (0.222)   Data 0.150 (0.150)   Loss 0.0723 (0.0723)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:21:10]
  Epoch: [127][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.0440 (0.0602)   Prec@1 98.438 (97.842)   Prec@5 100.000 (99.992)   [2019-11-22 03:21:15]
  Epoch: [127][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0611 (0.0611)   Prec@1 96.875 (97.812)   Prec@5 100.000 (99.996)   [2019-11-22 03:21:20]
  Epoch: [127][300/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.0487 (0.0602)   Prec@1 98.438 (97.877)   Prec@5 100.000 (99.995)   [2019-11-22 03:21:25]
  **Train** Prec@1 97.918 Prec@5 99.994 Error@1 2.082
  **Test** Prec@1 90.710 Prec@5 99.750 Error@1 9.290

==>>[2019-11-22 03:21:32] [Epoch=128/200] [Need: 00:26:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.76, Error=9.24]
  Epoch: [128][000/391]   Time 0.227 (0.227)   Data 0.174 (0.174)   Loss 0.0789 (0.0789)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:21:32]
  Epoch: [128][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.0981 (0.0604)   Prec@1 96.875 (97.966)   Prec@5 100.000 (99.992)   [2019-11-22 03:21:37]
  Epoch: [128][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0554 (0.0608)   Prec@1 98.438 (97.889)   Prec@5 100.000 (99.996)   [2019-11-22 03:21:42]
  Epoch: [128][300/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.0197 (0.0612)   Prec@1 100.000 (97.859)   Prec@5 100.000 (99.997)   [2019-11-22 03:21:47]
  **Train** Prec@1 97.886 Prec@5 99.994 Error@1 2.114
  **Test** Prec@1 90.800 Prec@5 99.750 Error@1 9.200
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:21:53] [Epoch=129/200] [Need: 00:25:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [129][000/391]   Time 0.220 (0.220)   Data 0.165 (0.165)   Loss 0.0542 (0.0542)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:21:54]
  Epoch: [129][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.0412 (0.0556)   Prec@1 99.219 (98.159)   Prec@5 100.000 (100.000)   [2019-11-22 03:21:59]
  Epoch: [129][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0342 (0.0591)   Prec@1 98.438 (97.979)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:04]
  Epoch: [129][300/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.0329 (0.0595)   Prec@1 98.438 (97.916)   Prec@5 100.000 (99.997)   [2019-11-22 03:22:09]
  **Train** Prec@1 97.836 Prec@5 99.998 Error@1 2.164
  **Test** Prec@1 90.790 Prec@5 99.710 Error@1 9.210

==>>[2019-11-22 03:22:15] [Epoch=130/200] [Need: 00:25:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [130][000/391]   Time 0.224 (0.224)   Data 0.166 (0.166)   Loss 0.0785 (0.0785)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:16]
  Epoch: [130][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0798 (0.0608)   Prec@1 96.094 (97.811)   Prec@5 100.000 (99.992)   [2019-11-22 03:22:21]
  Epoch: [130][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0465 (0.0604)   Prec@1 98.438 (97.847)   Prec@5 100.000 (99.992)   [2019-11-22 03:22:26]
  Epoch: [130][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0247 (0.0610)   Prec@1 99.219 (97.817)   Prec@5 100.000 (99.992)   [2019-11-22 03:22:31]
  **Train** Prec@1 97.816 Prec@5 99.990 Error@1 2.184
  **Test** Prec@1 90.570 Prec@5 99.710 Error@1 9.430

==>>[2019-11-22 03:22:38] [Epoch=131/200] [Need: 00:25:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [131][000/391]   Time 0.236 (0.236)   Data 0.148 (0.148)   Loss 0.0676 (0.0676)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:38]
  Epoch: [131][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0705 (0.0616)   Prec@1 96.875 (97.857)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:43]
  Epoch: [131][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0568 (0.0594)   Prec@1 97.656 (97.936)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:48]
  Epoch: [131][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0780 (0.0582)   Prec@1 96.094 (97.942)   Prec@5 100.000 (100.000)   [2019-11-22 03:22:53]
  **Train** Prec@1 97.952 Prec@5 99.998 Error@1 2.048
  **Test** Prec@1 90.520 Prec@5 99.720 Error@1 9.480

==>>[2019-11-22 03:23:00] [Epoch=132/200] [Need: 00:24:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [132][000/391]   Time 0.238 (0.238)   Data 0.182 (0.182)   Loss 0.0595 (0.0595)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:23:00]
  Epoch: [132][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0812 (0.0593)   Prec@1 96.875 (97.981)   Prec@5 100.000 (100.000)   [2019-11-22 03:23:05]
  Epoch: [132][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0946 (0.0587)   Prec@1 96.094 (98.025)   Prec@5 100.000 (100.000)   [2019-11-22 03:23:10]
  Epoch: [132][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0469 (0.0575)   Prec@1 96.875 (98.059)   Prec@5 100.000 (99.997)   [2019-11-22 03:23:15]
  **Train** Prec@1 98.034 Prec@5 99.996 Error@1 1.966
  **Test** Prec@1 90.660 Prec@5 99.720 Error@1 9.340

==>>[2019-11-22 03:23:22] [Epoch=133/200] [Need: 00:24:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [133][000/391]   Time 0.217 (0.217)   Data 0.151 (0.151)   Loss 0.0332 (0.0332)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:23:22]
  Epoch: [133][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0531 (0.0533)   Prec@1 99.219 (98.229)   Prec@5 100.000 (99.992)   [2019-11-22 03:23:27]
  Epoch: [133][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0577 (0.0570)   Prec@1 99.219 (98.099)   Prec@5 100.000 (99.984)   [2019-11-22 03:23:32]
  Epoch: [133][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0454 (0.0563)   Prec@1 98.438 (98.066)   Prec@5 100.000 (99.984)   [2019-11-22 03:23:37]
  **Train** Prec@1 98.046 Prec@5 99.988 Error@1 1.954
  **Test** Prec@1 90.710 Prec@5 99.730 Error@1 9.290

==>>[2019-11-22 03:23:44] [Epoch=134/200] [Need: 00:24:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [134][000/391]   Time 0.206 (0.206)   Data 0.142 (0.142)   Loss 0.0621 (0.0621)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:23:44]
  Epoch: [134][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.0459 (0.0571)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.992)   [2019-11-22 03:23:49]
  Epoch: [134][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0648 (0.0588)   Prec@1 97.656 (97.948)   Prec@5 100.000 (99.988)   [2019-11-22 03:23:54]
  Epoch: [134][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.0500 (0.0569)   Prec@1 97.656 (98.020)   Prec@5 100.000 (99.992)   [2019-11-22 03:23:59]
  **Train** Prec@1 97.996 Prec@5 99.992 Error@1 2.004
  **Test** Prec@1 90.620 Prec@5 99.720 Error@1 9.380

==>>[2019-11-22 03:24:06] [Epoch=135/200] [Need: 00:23:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [135][000/391]   Time 0.229 (0.229)   Data 0.168 (0.168)   Loss 0.0507 (0.0507)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:06]
  Epoch: [135][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0554 (0.0527)   Prec@1 97.656 (98.213)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:11]
  Epoch: [135][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0829 (0.0554)   Prec@1 96.094 (98.092)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:16]
  Epoch: [135][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0487 (0.0568)   Prec@1 97.656 (98.020)   Prec@5 100.000 (99.992)   [2019-11-22 03:24:21]
  **Train** Prec@1 98.016 Prec@5 99.994 Error@1 1.984
  **Test** Prec@1 90.600 Prec@5 99.770 Error@1 9.400

==>>[2019-11-22 03:24:27] [Epoch=136/200] [Need: 00:23:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [136][000/391]   Time 0.252 (0.252)   Data 0.165 (0.165)   Loss 0.1242 (0.1242)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:28]
  Epoch: [136][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0756 (0.0582)   Prec@1 96.875 (97.973)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:33]
  Epoch: [136][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0346 (0.0573)   Prec@1 99.219 (98.064)   Prec@5 100.000 (99.996)   [2019-11-22 03:24:38]
  Epoch: [136][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0337 (0.0573)   Prec@1 99.219 (98.030)   Prec@5 100.000 (99.995)   [2019-11-22 03:24:43]
  **Train** Prec@1 98.026 Prec@5 99.994 Error@1 1.974
  **Test** Prec@1 90.710 Prec@5 99.750 Error@1 9.290

==>>[2019-11-22 03:24:49] [Epoch=137/200] [Need: 00:23:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [137][000/391]   Time 0.231 (0.231)   Data 0.152 (0.152)   Loss 0.0471 (0.0471)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:24:49]
  Epoch: [137][100/391]   Time 0.066 (0.055)   Data 0.000 (0.002)   Loss 0.0814 (0.0569)   Prec@1 96.094 (98.074)   Prec@5 100.000 (99.977)   [2019-11-22 03:24:54]
  Epoch: [137][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0453 (0.0564)   Prec@1 98.438 (98.053)   Prec@5 100.000 (99.984)   [2019-11-22 03:25:00]
  Epoch: [137][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0410 (0.0575)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.982)   [2019-11-22 03:25:05]
  **Train** Prec@1 97.974 Prec@5 99.986 Error@1 2.026
  **Test** Prec@1 90.610 Prec@5 99.730 Error@1 9.390

==>>[2019-11-22 03:25:11] [Epoch=138/200] [Need: 00:22:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [138][000/391]   Time 0.216 (0.216)   Data 0.168 (0.168)   Loss 0.0853 (0.0853)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:25:11]
  Epoch: [138][100/391]   Time 0.067 (0.055)   Data 0.000 (0.002)   Loss 0.0775 (0.0595)   Prec@1 97.656 (97.966)   Prec@5 100.000 (99.992)   [2019-11-22 03:25:16]
  Epoch: [138][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0350 (0.0585)   Prec@1 98.438 (97.940)   Prec@5 100.000 (99.977)   [2019-11-22 03:25:22]
  Epoch: [138][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0737 (0.0567)   Prec@1 96.875 (98.004)   Prec@5 100.000 (99.984)   [2019-11-22 03:25:27]
  **Train** Prec@1 97.978 Prec@5 99.984 Error@1 2.022
  **Test** Prec@1 90.770 Prec@5 99.740 Error@1 9.230

==>>[2019-11-22 03:25:34] [Epoch=139/200] [Need: 00:22:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [139][000/391]   Time 0.234 (0.234)   Data 0.151 (0.151)   Loss 0.0280 (0.0280)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:25:34]
  Epoch: [139][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.0360 (0.0540)   Prec@1 98.438 (98.198)   Prec@5 100.000 (100.000)   [2019-11-22 03:25:39]
  Epoch: [139][200/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.0369 (0.0568)   Prec@1 97.656 (98.150)   Prec@5 100.000 (99.992)   [2019-11-22 03:25:44]
  Epoch: [139][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0576 (0.0574)   Prec@1 98.438 (98.108)   Prec@5 100.000 (99.992)   [2019-11-22 03:25:49]
  **Train** Prec@1 98.084 Prec@5 99.990 Error@1 1.916
  **Test** Prec@1 90.770 Prec@5 99.730 Error@1 9.230

==>>[2019-11-22 03:25:56] [Epoch=140/200] [Need: 00:21:58] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [140][000/391]   Time 0.240 (0.240)   Data 0.166 (0.166)   Loss 0.0588 (0.0588)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:25:56]
  Epoch: [140][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0452 (0.0580)   Prec@1 99.219 (97.857)   Prec@5 100.000 (99.985)   [2019-11-22 03:26:02]
  Epoch: [140][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0867 (0.0569)   Prec@1 94.531 (97.940)   Prec@5 100.000 (99.992)   [2019-11-22 03:26:07]
  Epoch: [140][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0514 (0.0556)   Prec@1 96.875 (98.046)   Prec@5 100.000 (99.992)   [2019-11-22 03:26:12]
  **Train** Prec@1 98.056 Prec@5 99.994 Error@1 1.944
  **Test** Prec@1 90.540 Prec@5 99.730 Error@1 9.460

==>>[2019-11-22 03:26:18] [Epoch=141/200] [Need: 00:21:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [141][000/391]   Time 0.224 (0.224)   Data 0.170 (0.170)   Loss 0.1110 (0.1110)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:26:18]
  Epoch: [141][100/391]   Time 0.078 (0.053)   Data 0.000 (0.002)   Loss 0.0834 (0.0557)   Prec@1 96.094 (98.074)   Prec@5 100.000 (99.985)   [2019-11-22 03:26:23]
  Epoch: [141][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0777 (0.0550)   Prec@1 98.438 (98.123)   Prec@5 100.000 (99.992)   [2019-11-22 03:26:28]
  Epoch: [141][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0285 (0.0561)   Prec@1 99.219 (98.074)   Prec@5 100.000 (99.995)   [2019-11-22 03:26:34]
  **Train** Prec@1 98.082 Prec@5 99.994 Error@1 1.918
  **Test** Prec@1 90.750 Prec@5 99.750 Error@1 9.250

==>>[2019-11-22 03:26:40] [Epoch=142/200] [Need: 00:21:14] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [142][000/391]   Time 0.225 (0.225)   Data 0.156 (0.156)   Loss 0.0435 (0.0435)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:26:40]
  Epoch: [142][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.0990 (0.0596)   Prec@1 95.312 (97.881)   Prec@5 100.000 (99.992)   [2019-11-22 03:26:45]
  Epoch: [142][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0573 (0.0555)   Prec@1 98.438 (98.037)   Prec@5 100.000 (99.992)   [2019-11-22 03:26:51]
  Epoch: [142][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0822 (0.0553)   Prec@1 96.875 (98.056)   Prec@5 100.000 (99.995)   [2019-11-22 03:26:56]
  **Train** Prec@1 98.114 Prec@5 99.992 Error@1 1.886
  **Test** Prec@1 90.660 Prec@5 99.740 Error@1 9.340

==>>[2019-11-22 03:27:02] [Epoch=143/200] [Need: 00:20:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [143][000/391]   Time 0.238 (0.238)   Data 0.172 (0.172)   Loss 0.0237 (0.0237)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:27:03]
  Epoch: [143][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0306 (0.0551)   Prec@1 98.438 (98.167)   Prec@5 100.000 (99.992)   [2019-11-22 03:27:08]
  Epoch: [143][200/391]   Time 0.062 (0.054)   Data 0.000 (0.001)   Loss 0.1248 (0.0575)   Prec@1 96.875 (97.979)   Prec@5 100.000 (99.996)   [2019-11-22 03:27:13]
  Epoch: [143][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0417 (0.0558)   Prec@1 98.438 (98.040)   Prec@5 100.000 (99.995)   [2019-11-22 03:27:18]
  **Train** Prec@1 98.076 Prec@5 99.996 Error@1 1.924
  **Test** Prec@1 90.720 Prec@5 99.730 Error@1 9.280

==>>[2019-11-22 03:27:24] [Epoch=144/200] [Need: 00:20:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [144][000/391]   Time 0.224 (0.224)   Data 0.173 (0.173)   Loss 0.0493 (0.0493)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:27:25]
  Epoch: [144][100/391]   Time 0.080 (0.056)   Data 0.000 (0.002)   Loss 0.0685 (0.0560)   Prec@1 96.875 (98.074)   Prec@5 100.000 (99.992)   [2019-11-22 03:27:30]
  Epoch: [144][200/391]   Time 0.052 (0.054)   Data 0.000 (0.001)   Loss 0.0605 (0.0561)   Prec@1 97.656 (98.084)   Prec@5 100.000 (99.988)   [2019-11-22 03:27:35]
  Epoch: [144][300/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.0653 (0.0564)   Prec@1 96.875 (98.053)   Prec@5 100.000 (99.990)   [2019-11-22 03:27:40]
  **Train** Prec@1 98.058 Prec@5 99.990 Error@1 1.942
  **Test** Prec@1 90.710 Prec@5 99.730 Error@1 9.290

==>>[2019-11-22 03:27:47] [Epoch=145/200] [Need: 00:20:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [145][000/391]   Time 0.229 (0.229)   Data 0.159 (0.159)   Loss 0.0614 (0.0614)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:27:47]
  Epoch: [145][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.0578 (0.0548)   Prec@1 97.656 (98.120)   Prec@5 100.000 (100.000)   [2019-11-22 03:27:52]
  Epoch: [145][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0282 (0.0536)   Prec@1 99.219 (98.197)   Prec@5 100.000 (100.000)   [2019-11-22 03:27:57]
  Epoch: [145][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0315 (0.0549)   Prec@1 99.219 (98.157)   Prec@5 100.000 (99.992)   [2019-11-22 03:28:02]
  **Train** Prec@1 98.114 Prec@5 99.992 Error@1 1.886
  **Test** Prec@1 90.760 Prec@5 99.730 Error@1 9.240

==>>[2019-11-22 03:28:09] [Epoch=146/200] [Need: 00:19:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [146][000/391]   Time 0.229 (0.229)   Data 0.150 (0.150)   Loss 0.0465 (0.0465)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:28:09]
  Epoch: [146][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0426 (0.0577)   Prec@1 97.656 (97.935)   Prec@5 100.000 (100.000)   [2019-11-22 03:28:14]
  Epoch: [146][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0563 (0.0560)   Prec@1 98.438 (98.022)   Prec@5 100.000 (99.996)   [2019-11-22 03:28:19]
  Epoch: [146][300/391]   Time 0.063 (0.052)   Data 0.000 (0.001)   Loss 0.0684 (0.0558)   Prec@1 97.656 (98.051)   Prec@5 100.000 (99.995)   [2019-11-22 03:28:24]
  **Train** Prec@1 98.054 Prec@5 99.992 Error@1 1.946
  **Test** Prec@1 90.770 Prec@5 99.710 Error@1 9.230

==>>[2019-11-22 03:28:31] [Epoch=147/200] [Need: 00:19:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [147][000/391]   Time 0.209 (0.209)   Data 0.151 (0.151)   Loss 0.0618 (0.0618)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:28:31]
  Epoch: [147][100/391]   Time 0.056 (0.055)   Data 0.000 (0.002)   Loss 0.0650 (0.0564)   Prec@1 98.438 (98.074)   Prec@5 100.000 (99.992)   [2019-11-22 03:28:36]
  Epoch: [147][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0322 (0.0543)   Prec@1 99.219 (98.165)   Prec@5 100.000 (99.992)   [2019-11-22 03:28:41]
  Epoch: [147][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0649 (0.0536)   Prec@1 96.875 (98.149)   Prec@5 100.000 (99.992)   [2019-11-22 03:28:46]
  **Train** Prec@1 98.088 Prec@5 99.992 Error@1 1.912
  **Test** Prec@1 90.820 Prec@5 99.730 Error@1 9.180
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:28:52] [Epoch=148/200] [Need: 00:19:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [148][000/391]   Time 0.224 (0.224)   Data 0.167 (0.167)   Loss 0.0276 (0.0276)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:28:53]
  Epoch: [148][100/391]   Time 0.051 (0.054)   Data 0.000 (0.002)   Loss 0.0677 (0.0512)   Prec@1 97.656 (98.283)   Prec@5 100.000 (99.985)   [2019-11-22 03:28:58]
  Epoch: [148][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0410 (0.0564)   Prec@1 97.656 (98.010)   Prec@5 100.000 (99.988)   [2019-11-22 03:29:03]
  Epoch: [148][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1063 (0.0551)   Prec@1 95.312 (98.053)   Prec@5 100.000 (99.990)   [2019-11-22 03:29:08]
  **Train** Prec@1 98.028 Prec@5 99.992 Error@1 1.972
  **Test** Prec@1 90.670 Prec@5 99.730 Error@1 9.330

==>>[2019-11-22 03:29:14] [Epoch=149/200] [Need: 00:18:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [149][000/391]   Time 0.217 (0.217)   Data 0.155 (0.155)   Loss 0.0755 (0.0755)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:29:14]
  Epoch: [149][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0527 (0.0538)   Prec@1 98.438 (98.205)   Prec@5 100.000 (99.992)   [2019-11-22 03:29:20]
  Epoch: [149][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0413 (0.0545)   Prec@1 98.438 (98.177)   Prec@5 100.000 (99.996)   [2019-11-22 03:29:25]
  Epoch: [149][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0423 (0.0542)   Prec@1 99.219 (98.206)   Prec@5 100.000 (99.990)   [2019-11-22 03:29:30]
  **Train** Prec@1 98.208 Prec@5 99.990 Error@1 1.792
  **Test** Prec@1 90.810 Prec@5 99.740 Error@1 9.190

==>>[2019-11-22 03:29:36] [Epoch=150/200] [Need: 00:18:18] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [150][000/391]   Time 0.230 (0.230)   Data 0.172 (0.172)   Loss 0.0245 (0.0245)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:29:37]
  Epoch: [150][100/391]   Time 0.060 (0.053)   Data 0.000 (0.002)   Loss 0.0744 (0.0537)   Prec@1 97.656 (98.043)   Prec@5 100.000 (99.992)   [2019-11-22 03:29:42]
  Epoch: [150][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0711 (0.0543)   Prec@1 98.438 (98.103)   Prec@5 100.000 (99.984)   [2019-11-22 03:29:47]
  Epoch: [150][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0905 (0.0541)   Prec@1 97.656 (98.147)   Prec@5 100.000 (99.990)   [2019-11-22 03:29:52]
  **Train** Prec@1 98.088 Prec@5 99.992 Error@1 1.912
  **Test** Prec@1 90.580 Prec@5 99.710 Error@1 9.420

==>>[2019-11-22 03:29:59] [Epoch=151/200] [Need: 00:17:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [151][000/391]   Time 0.254 (0.254)   Data 0.194 (0.194)   Loss 0.0696 (0.0696)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:29:59]
  Epoch: [151][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0473 (0.0540)   Prec@1 98.438 (98.144)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:04]
  Epoch: [151][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0472 (0.0509)   Prec@1 98.438 (98.239)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:09]
  Epoch: [151][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0083 (0.0520)   Prec@1 100.000 (98.170)   Prec@5 100.000 (99.995)   [2019-11-22 03:30:15]
  **Train** Prec@1 98.150 Prec@5 99.996 Error@1 1.850
  **Test** Prec@1 90.690 Prec@5 99.690 Error@1 9.310

==>>[2019-11-22 03:30:21] [Epoch=152/200] [Need: 00:17:35] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [152][000/391]   Time 0.232 (0.232)   Data 0.159 (0.159)   Loss 0.0549 (0.0549)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:21]
  Epoch: [152][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0419 (0.0523)   Prec@1 98.438 (98.113)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:26]
  Epoch: [152][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.0644 (0.0526)   Prec@1 97.656 (98.162)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:31]
  Epoch: [152][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0533 (0.0534)   Prec@1 97.656 (98.118)   Prec@5 100.000 (99.997)   [2019-11-22 03:30:36]
  **Train** Prec@1 98.122 Prec@5 99.996 Error@1 1.878
  **Test** Prec@1 90.680 Prec@5 99.740 Error@1 9.320

==>>[2019-11-22 03:30:43] [Epoch=153/200] [Need: 00:17:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [153][000/391]   Time 0.229 (0.229)   Data 0.176 (0.176)   Loss 0.0355 (0.0355)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:43]
  Epoch: [153][100/391]   Time 0.062 (0.054)   Data 0.000 (0.002)   Loss 0.0353 (0.0509)   Prec@1 99.219 (98.337)   Prec@5 100.000 (100.000)   [2019-11-22 03:30:48]
  Epoch: [153][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0546 (0.0526)   Prec@1 96.875 (98.263)   Prec@5 100.000 (99.992)   [2019-11-22 03:30:53]
  Epoch: [153][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0409 (0.0538)   Prec@1 99.219 (98.232)   Prec@5 100.000 (99.990)   [2019-11-22 03:30:58]
  **Train** Prec@1 98.256 Prec@5 99.990 Error@1 1.744
  **Test** Prec@1 90.680 Prec@5 99.730 Error@1 9.320

==>>[2019-11-22 03:31:05] [Epoch=154/200] [Need: 00:16:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [154][000/391]   Time 0.233 (0.233)   Data 0.167 (0.167)   Loss 0.0202 (0.0202)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:05]
  Epoch: [154][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.0959 (0.0500)   Prec@1 96.875 (98.298)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:10]
  Epoch: [154][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0451 (0.0512)   Prec@1 99.219 (98.278)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:15]
  Epoch: [154][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0445 (0.0529)   Prec@1 99.219 (98.227)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:20]
  **Train** Prec@1 98.250 Prec@5 99.998 Error@1 1.750
  **Test** Prec@1 90.790 Prec@5 99.780 Error@1 9.210

==>>[2019-11-22 03:31:27] [Epoch=155/200] [Need: 00:16:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [155][000/391]   Time 0.225 (0.225)   Data 0.151 (0.151)   Loss 0.0223 (0.0223)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:27]
  Epoch: [155][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0744 (0.0506)   Prec@1 96.094 (98.345)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:32]
  Epoch: [155][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1029 (0.0525)   Prec@1 97.656 (98.247)   Prec@5 99.219 (99.992)   [2019-11-22 03:31:37]
  Epoch: [155][300/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0706 (0.0525)   Prec@1 96.875 (98.222)   Prec@5 100.000 (99.995)   [2019-11-22 03:31:43]
  **Train** Prec@1 98.220 Prec@5 99.992 Error@1 1.780
  **Test** Prec@1 90.640 Prec@5 99.760 Error@1 9.360

==>>[2019-11-22 03:31:50] [Epoch=156/200] [Need: 00:16:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [156][000/391]   Time 0.233 (0.233)   Data 0.178 (0.178)   Loss 0.0388 (0.0388)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:31:50]
  Epoch: [156][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1110 (0.0478)   Prec@1 96.094 (98.391)   Prec@5 100.000 (99.992)   [2019-11-22 03:31:55]
  Epoch: [156][200/391]   Time 0.050 (0.054)   Data 0.000 (0.001)   Loss 0.0301 (0.0492)   Prec@1 99.219 (98.329)   Prec@5 100.000 (99.992)   [2019-11-22 03:32:00]
  Epoch: [156][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0629 (0.0501)   Prec@1 96.094 (98.271)   Prec@5 100.000 (99.992)   [2019-11-22 03:32:06]
  **Train** Prec@1 98.206 Prec@5 99.994 Error@1 1.794
  **Test** Prec@1 90.630 Prec@5 99.730 Error@1 9.370

==>>[2019-11-22 03:32:12] [Epoch=157/200] [Need: 00:15:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [157][000/391]   Time 0.225 (0.225)   Data 0.159 (0.159)   Loss 0.0625 (0.0625)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:32:13]
  Epoch: [157][100/391]   Time 0.050 (0.054)   Data 0.000 (0.002)   Loss 0.0164 (0.0524)   Prec@1 100.000 (98.252)   Prec@5 100.000 (99.985)   [2019-11-22 03:32:18]
  Epoch: [157][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0529 (0.0551)   Prec@1 98.438 (98.115)   Prec@5 100.000 (99.988)   [2019-11-22 03:32:23]
  Epoch: [157][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0182 (0.0532)   Prec@1 100.000 (98.188)   Prec@5 100.000 (99.992)   [2019-11-22 03:32:28]
  **Train** Prec@1 98.260 Prec@5 99.990 Error@1 1.740
  **Test** Prec@1 90.570 Prec@5 99.730 Error@1 9.430

==>>[2019-11-22 03:32:34] [Epoch=158/200] [Need: 00:15:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [158][000/391]   Time 0.228 (0.228)   Data 0.160 (0.160)   Loss 0.0518 (0.0518)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:32:35]
  Epoch: [158][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.1510 (0.0527)   Prec@1 94.531 (98.105)   Prec@5 100.000 (100.000)   [2019-11-22 03:32:40]
  Epoch: [158][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0525 (0.0533)   Prec@1 96.875 (98.127)   Prec@5 100.000 (99.996)   [2019-11-22 03:32:45]
  Epoch: [158][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0453 (0.0525)   Prec@1 98.438 (98.144)   Prec@5 100.000 (99.997)   [2019-11-22 03:32:50]
  **Train** Prec@1 98.156 Prec@5 99.996 Error@1 1.844
  **Test** Prec@1 90.680 Prec@5 99.730 Error@1 9.320

==>>[2019-11-22 03:32:56] [Epoch=159/200] [Need: 00:15:01] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [159][000/391]   Time 0.246 (0.246)   Data 0.190 (0.190)   Loss 0.0517 (0.0517)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:32:56]
  Epoch: [159][100/391]   Time 0.084 (0.049)   Data 0.000 (0.002)   Loss 0.0486 (0.0516)   Prec@1 97.656 (98.306)   Prec@5 100.000 (99.985)   [2019-11-22 03:33:01]
  Epoch: [159][200/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.0475 (0.0523)   Prec@1 98.438 (98.228)   Prec@5 100.000 (99.988)   [2019-11-22 03:33:06]
  Epoch: [159][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0257 (0.0521)   Prec@1 99.219 (98.227)   Prec@5 100.000 (99.992)   [2019-11-22 03:33:12]
  **Train** Prec@1 98.224 Prec@5 99.992 Error@1 1.776
  **Test** Prec@1 90.730 Prec@5 99.730 Error@1 9.270

==>>[2019-11-22 03:33:18] [Epoch=160/200] [Need: 00:14:39] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [160][000/391]   Time 0.230 (0.230)   Data 0.159 (0.159)   Loss 0.0911 (0.0911)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:18]
  Epoch: [160][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0394 (0.0505)   Prec@1 99.219 (98.306)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:23]
  Epoch: [160][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0320 (0.0491)   Prec@1 99.219 (98.348)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:28]
  Epoch: [160][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.0425 (0.0491)   Prec@1 98.438 (98.334)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:33]
  **Train** Prec@1 98.254 Prec@5 100.000 Error@1 1.746
  **Test** Prec@1 90.660 Prec@5 99.730 Error@1 9.340

==>>[2019-11-22 03:33:39] [Epoch=161/200] [Need: 00:14:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [161][000/391]   Time 0.228 (0.228)   Data 0.161 (0.161)   Loss 0.0672 (0.0672)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:40]
  Epoch: [161][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0305 (0.0517)   Prec@1 97.656 (98.221)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:45]
  Epoch: [161][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0795 (0.0505)   Prec@1 97.656 (98.290)   Prec@5 100.000 (100.000)   [2019-11-22 03:33:49]
  Epoch: [161][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0507 (0.0498)   Prec@1 98.438 (98.341)   Prec@5 100.000 (99.997)   [2019-11-22 03:33:54]
  **Train** Prec@1 98.312 Prec@5 99.996 Error@1 1.688
  **Test** Prec@1 90.670 Prec@5 99.710 Error@1 9.330

==>>[2019-11-22 03:34:01] [Epoch=162/200] [Need: 00:13:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [162][000/391]   Time 0.234 (0.234)   Data 0.154 (0.154)   Loss 0.0420 (0.0420)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:01]
  Epoch: [162][100/391]   Time 0.080 (0.056)   Data 0.000 (0.002)   Loss 0.0686 (0.0532)   Prec@1 96.094 (98.182)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:06]
  Epoch: [162][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0501 (0.0523)   Prec@1 97.656 (98.228)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:11]
  Epoch: [162][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0404 (0.0519)   Prec@1 99.219 (98.243)   Prec@5 100.000 (99.997)   [2019-11-22 03:34:16]
  **Train** Prec@1 98.310 Prec@5 99.998 Error@1 1.690
  **Test** Prec@1 90.730 Prec@5 99.750 Error@1 9.270

==>>[2019-11-22 03:34:23] [Epoch=163/200] [Need: 00:13:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [163][000/391]   Time 0.224 (0.224)   Data 0.154 (0.154)   Loss 0.0403 (0.0403)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:23]
  Epoch: [163][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0497 (0.0500)   Prec@1 98.438 (98.244)   Prec@5 100.000 (99.985)   [2019-11-22 03:34:28]
  Epoch: [163][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0914 (0.0504)   Prec@1 96.094 (98.239)   Prec@5 100.000 (99.992)   [2019-11-22 03:34:33]
  Epoch: [163][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0392 (0.0497)   Prec@1 98.438 (98.264)   Prec@5 100.000 (99.990)   [2019-11-22 03:34:38]
  **Train** Prec@1 98.282 Prec@5 99.988 Error@1 1.718
  **Test** Prec@1 90.570 Prec@5 99.740 Error@1 9.430

==>>[2019-11-22 03:34:45] [Epoch=164/200] [Need: 00:13:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [164][000/391]   Time 0.241 (0.241)   Data 0.185 (0.185)   Loss 0.0143 (0.0143)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:45]
  Epoch: [164][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0457 (0.0536)   Prec@1 98.438 (98.190)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:50]
  Epoch: [164][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0668 (0.0517)   Prec@1 96.094 (98.204)   Prec@5 100.000 (100.000)   [2019-11-22 03:34:55]
  Epoch: [164][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0630 (0.0500)   Prec@1 97.656 (98.264)   Prec@5 100.000 (100.000)   [2019-11-22 03:35:00]
  **Train** Prec@1 98.240 Prec@5 100.000 Error@1 1.760
  **Test** Prec@1 90.710 Prec@5 99.750 Error@1 9.290

==>>[2019-11-22 03:35:07] [Epoch=165/200] [Need: 00:12:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [165][000/391]   Time 0.222 (0.222)   Data 0.157 (0.157)   Loss 0.0295 (0.0295)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:35:07]
  Epoch: [165][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.0787 (0.0502)   Prec@1 96.875 (98.213)   Prec@5 100.000 (99.992)   [2019-11-22 03:35:12]
  Epoch: [165][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0445 (0.0496)   Prec@1 99.219 (98.228)   Prec@5 100.000 (99.992)   [2019-11-22 03:35:17]
  Epoch: [165][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0218 (0.0483)   Prec@1 99.219 (98.334)   Prec@5 100.000 (99.990)   [2019-11-22 03:35:22]
  **Train** Prec@1 98.296 Prec@5 99.990 Error@1 1.704
  **Test** Prec@1 90.690 Prec@5 99.740 Error@1 9.310

==>>[2019-11-22 03:35:29] [Epoch=166/200] [Need: 00:12:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [166][000/391]   Time 0.211 (0.211)   Data 0.141 (0.141)   Loss 0.0143 (0.0143)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:35:29]
  Epoch: [166][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0677 (0.0467)   Prec@1 96.875 (98.430)   Prec@5 100.000 (99.992)   [2019-11-22 03:35:34]
  Epoch: [166][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0208 (0.0482)   Prec@1 99.219 (98.430)   Prec@5 100.000 (99.996)   [2019-11-22 03:35:39]
  Epoch: [166][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0258 (0.0487)   Prec@1 99.219 (98.414)   Prec@5 100.000 (99.995)   [2019-11-22 03:35:44]
  **Train** Prec@1 98.384 Prec@5 99.996 Error@1 1.616
  **Test** Prec@1 90.710 Prec@5 99.740 Error@1 9.290

==>>[2019-11-22 03:35:51] [Epoch=167/200] [Need: 00:12:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [167][000/391]   Time 0.235 (0.235)   Data 0.161 (0.161)   Loss 0.0269 (0.0269)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:35:51]
  Epoch: [167][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0637 (0.0522)   Prec@1 97.656 (98.151)   Prec@5 100.000 (100.000)   [2019-11-22 03:35:57]
  Epoch: [167][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0392 (0.0511)   Prec@1 99.219 (98.266)   Prec@5 100.000 (99.996)   [2019-11-22 03:36:01]
  Epoch: [167][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0426 (0.0501)   Prec@1 99.219 (98.310)   Prec@5 100.000 (99.997)   [2019-11-22 03:36:06]
  **Train** Prec@1 98.276 Prec@5 99.998 Error@1 1.724
  **Test** Prec@1 90.620 Prec@5 99.710 Error@1 9.380

==>>[2019-11-22 03:36:13] [Epoch=168/200] [Need: 00:11:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [168][000/391]   Time 0.235 (0.235)   Data 0.178 (0.178)   Loss 0.0410 (0.0410)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:36:13]
  Epoch: [168][100/391]   Time 0.077 (0.057)   Data 0.002 (0.002)   Loss 0.0517 (0.0495)   Prec@1 98.438 (98.352)   Prec@5 100.000 (99.985)   [2019-11-22 03:36:19]
  Epoch: [168][200/391]   Time 0.077 (0.055)   Data 0.000 (0.001)   Loss 0.0126 (0.0483)   Prec@1 100.000 (98.418)   Prec@5 100.000 (99.988)   [2019-11-22 03:36:24]
  Epoch: [168][300/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.0335 (0.0482)   Prec@1 98.438 (98.404)   Prec@5 100.000 (99.992)   [2019-11-22 03:36:29]
  **Train** Prec@1 98.398 Prec@5 99.988 Error@1 1.602
  **Test** Prec@1 90.740 Prec@5 99.770 Error@1 9.260

==>>[2019-11-22 03:36:35] [Epoch=169/200] [Need: 00:11:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.82, Error=9.18]
  Epoch: [169][000/391]   Time 0.220 (0.220)   Data 0.160 (0.160)   Loss 0.1504 (0.1504)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:36:35]
  Epoch: [169][100/391]   Time 0.082 (0.054)   Data 0.000 (0.002)   Loss 0.0294 (0.0493)   Prec@1 98.438 (98.314)   Prec@5 100.000 (100.000)   [2019-11-22 03:36:41]
  Epoch: [169][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.0231 (0.0473)   Prec@1 100.000 (98.364)   Prec@5 100.000 (99.996)   [2019-11-22 03:36:46]
  Epoch: [169][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0356 (0.0488)   Prec@1 98.438 (98.318)   Prec@5 100.000 (99.997)   [2019-11-22 03:36:51]
  **Train** Prec@1 98.338 Prec@5 99.998 Error@1 1.662
  **Test** Prec@1 90.900 Prec@5 99.720 Error@1 9.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:36:57] [Epoch=170/200] [Need: 00:10:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [170][000/391]   Time 0.240 (0.240)   Data 0.161 (0.161)   Loss 0.0525 (0.0525)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:36:58]
  Epoch: [170][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0635 (0.0478)   Prec@1 97.656 (98.298)   Prec@5 100.000 (99.985)   [2019-11-22 03:37:03]
  Epoch: [170][200/391]   Time 0.067 (0.053)   Data 0.000 (0.001)   Loss 0.0354 (0.0487)   Prec@1 99.219 (98.294)   Prec@5 100.000 (99.988)   [2019-11-22 03:37:08]
  Epoch: [170][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0318 (0.0486)   Prec@1 99.219 (98.308)   Prec@5 100.000 (99.990)   [2019-11-22 03:37:13]
  **Train** Prec@1 98.266 Prec@5 99.992 Error@1 1.734
  **Test** Prec@1 90.650 Prec@5 99.730 Error@1 9.350

==>>[2019-11-22 03:37:20] [Epoch=171/200] [Need: 00:10:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [171][000/391]   Time 0.240 (0.240)   Data 0.162 (0.162)   Loss 0.0268 (0.0268)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:37:20]
  Epoch: [171][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0701 (0.0489)   Prec@1 96.875 (98.391)   Prec@5 100.000 (100.000)   [2019-11-22 03:37:25]
  Epoch: [171][200/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0868 (0.0489)   Prec@1 95.312 (98.317)   Prec@5 100.000 (100.000)   [2019-11-22 03:37:30]
  Epoch: [171][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0374 (0.0492)   Prec@1 98.438 (98.313)   Prec@5 100.000 (99.997)   [2019-11-22 03:37:35]
  **Train** Prec@1 98.268 Prec@5 99.996 Error@1 1.732
  **Test** Prec@1 90.640 Prec@5 99.750 Error@1 9.360

==>>[2019-11-22 03:37:42] [Epoch=172/200] [Need: 00:10:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [172][000/391]   Time 0.229 (0.229)   Data 0.166 (0.166)   Loss 0.0334 (0.0334)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:37:42]
  Epoch: [172][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0711 (0.0466)   Prec@1 98.438 (98.461)   Prec@5 100.000 (99.992)   [2019-11-22 03:37:47]
  Epoch: [172][200/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.0895 (0.0486)   Prec@1 95.312 (98.321)   Prec@5 100.000 (99.996)   [2019-11-22 03:37:52]
  Epoch: [172][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0479 (0.0487)   Prec@1 98.438 (98.339)   Prec@5 100.000 (99.997)   [2019-11-22 03:37:57]
  **Train** Prec@1 98.280 Prec@5 99.998 Error@1 1.720
  **Test** Prec@1 90.780 Prec@5 99.730 Error@1 9.220

==>>[2019-11-22 03:38:03] [Epoch=173/200] [Need: 00:09:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [173][000/391]   Time 0.229 (0.229)   Data 0.152 (0.152)   Loss 0.0668 (0.0668)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:38:03]
  Epoch: [173][100/391]   Time 0.063 (0.051)   Data 0.000 (0.002)   Loss 0.0476 (0.0461)   Prec@1 98.438 (98.445)   Prec@5 100.000 (99.985)   [2019-11-22 03:38:08]
  Epoch: [173][200/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0189 (0.0490)   Prec@1 100.000 (98.294)   Prec@5 100.000 (99.984)   [2019-11-22 03:38:13]
  Epoch: [173][300/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.0376 (0.0492)   Prec@1 99.219 (98.318)   Prec@5 100.000 (99.987)   [2019-11-22 03:38:18]
  **Train** Prec@1 98.368 Prec@5 99.990 Error@1 1.632
  **Test** Prec@1 90.760 Prec@5 99.730 Error@1 9.240

==>>[2019-11-22 03:38:25] [Epoch=174/200] [Need: 00:09:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [174][000/391]   Time 0.229 (0.229)   Data 0.160 (0.160)   Loss 0.0792 (0.0792)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:38:25]
  Epoch: [174][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0397 (0.0474)   Prec@1 98.438 (98.422)   Prec@5 100.000 (99.985)   [2019-11-22 03:38:30]
  Epoch: [174][200/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.0627 (0.0486)   Prec@1 96.875 (98.375)   Prec@5 100.000 (99.992)   [2019-11-22 03:38:36]
  Epoch: [174][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0215 (0.0485)   Prec@1 99.219 (98.370)   Prec@5 100.000 (99.987)   [2019-11-22 03:38:41]
  **Train** Prec@1 98.324 Prec@5 99.988 Error@1 1.676
  **Test** Prec@1 90.660 Prec@5 99.720 Error@1 9.340

==>>[2019-11-22 03:38:47] [Epoch=175/200] [Need: 00:09:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [175][000/391]   Time 0.232 (0.232)   Data 0.161 (0.161)   Loss 0.0525 (0.0525)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 03:38:47]
  Epoch: [175][100/391]   Time 0.082 (0.047)   Data 0.000 (0.002)   Loss 0.0358 (0.0489)   Prec@1 99.219 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 03:38:52]
  Epoch: [175][200/391]   Time 0.055 (0.049)   Data 0.000 (0.001)   Loss 0.0265 (0.0500)   Prec@1 99.219 (98.309)   Prec@5 100.000 (99.996)   [2019-11-22 03:38:57]
  Epoch: [175][300/391]   Time 0.074 (0.050)   Data 0.000 (0.001)   Loss 0.1536 (0.0506)   Prec@1 95.312 (98.240)   Prec@5 99.219 (99.992)   [2019-11-22 03:39:02]
  **Train** Prec@1 98.244 Prec@5 99.994 Error@1 1.756
  **Test** Prec@1 90.710 Prec@5 99.760 Error@1 9.290

==>>[2019-11-22 03:39:08] [Epoch=176/200] [Need: 00:08:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [176][000/391]   Time 0.218 (0.218)   Data 0.154 (0.154)   Loss 0.0643 (0.0643)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:09]
  Epoch: [176][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0362 (0.0467)   Prec@1 99.219 (98.499)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:14]
  Epoch: [176][200/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0807 (0.0475)   Prec@1 97.656 (98.379)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:19]
  Epoch: [176][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.0339 (0.0481)   Prec@1 99.219 (98.318)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:24]
  **Train** Prec@1 98.312 Prec@5 100.000 Error@1 1.688
  **Test** Prec@1 90.730 Prec@5 99.740 Error@1 9.270

==>>[2019-11-22 03:39:30] [Epoch=177/200] [Need: 00:08:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [177][000/391]   Time 0.235 (0.235)   Data 0.173 (0.173)   Loss 0.0214 (0.0214)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:30]
  Epoch: [177][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0247 (0.0461)   Prec@1 99.219 (98.515)   Prec@5 100.000 (99.985)   [2019-11-22 03:39:36]
  Epoch: [177][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0362 (0.0489)   Prec@1 98.438 (98.387)   Prec@5 100.000 (99.992)   [2019-11-22 03:39:41]
  Epoch: [177][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0664 (0.0482)   Prec@1 97.656 (98.378)   Prec@5 100.000 (99.992)   [2019-11-22 03:39:46]
  **Train** Prec@1 98.330 Prec@5 99.994 Error@1 1.670
  **Test** Prec@1 90.670 Prec@5 99.730 Error@1 9.330

==>>[2019-11-22 03:39:52] [Epoch=178/200] [Need: 00:08:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [178][000/391]   Time 0.224 (0.224)   Data 0.166 (0.166)   Loss 0.1003 (0.1003)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:39:52]
  Epoch: [178][100/391]   Time 0.066 (0.054)   Data 0.000 (0.002)   Loss 0.0332 (0.0537)   Prec@1 99.219 (98.089)   Prec@5 100.000 (99.985)   [2019-11-22 03:39:58]
  Epoch: [178][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0354 (0.0517)   Prec@1 99.219 (98.150)   Prec@5 100.000 (99.992)   [2019-11-22 03:40:03]
  Epoch: [178][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0120 (0.0504)   Prec@1 100.000 (98.240)   Prec@5 100.000 (99.995)   [2019-11-22 03:40:08]
  **Train** Prec@1 98.224 Prec@5 99.988 Error@1 1.776
  **Test** Prec@1 90.740 Prec@5 99.710 Error@1 9.260

==>>[2019-11-22 03:40:14] [Epoch=179/200] [Need: 00:07:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [179][000/391]   Time 0.218 (0.218)   Data 0.149 (0.149)   Loss 0.0686 (0.0686)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-22 03:40:15]
  Epoch: [179][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0145 (0.0478)   Prec@1 100.000 (98.329)   Prec@5 100.000 (99.985)   [2019-11-22 03:40:20]
  Epoch: [179][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0355 (0.0466)   Prec@1 100.000 (98.445)   Prec@5 100.000 (99.988)   [2019-11-22 03:40:25]
  Epoch: [179][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0706 (0.0469)   Prec@1 97.656 (98.435)   Prec@5 99.219 (99.984)   [2019-11-22 03:40:30]
  **Train** Prec@1 98.336 Prec@5 99.984 Error@1 1.664
  **Test** Prec@1 90.810 Prec@5 99.700 Error@1 9.190

==>>[2019-11-22 03:40:37] [Epoch=180/200] [Need: 00:07:19] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [180][000/391]   Time 0.228 (0.228)   Data 0.160 (0.160)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:40:37]
  Epoch: [180][100/391]   Time 0.047 (0.056)   Data 0.000 (0.002)   Loss 0.0245 (0.0472)   Prec@1 98.438 (98.476)   Prec@5 100.000 (100.000)   [2019-11-22 03:40:42]
  Epoch: [180][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.0498 (0.0473)   Prec@1 97.656 (98.406)   Prec@5 100.000 (100.000)   [2019-11-22 03:40:47]
  Epoch: [180][300/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 0.0382 (0.0487)   Prec@1 98.438 (98.367)   Prec@5 100.000 (99.995)   [2019-11-22 03:40:53]
  **Train** Prec@1 98.396 Prec@5 99.996 Error@1 1.604
  **Test** Prec@1 90.680 Prec@5 99.740 Error@1 9.320

==>>[2019-11-22 03:40:59] [Epoch=181/200] [Need: 00:06:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [181][000/391]   Time 0.230 (0.230)   Data 0.163 (0.163)   Loss 0.0733 (0.0733)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:40:59]
  Epoch: [181][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0242 (0.0452)   Prec@1 99.219 (98.492)   Prec@5 100.000 (99.985)   [2019-11-22 03:41:04]
  Epoch: [181][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0418 (0.0472)   Prec@1 98.438 (98.445)   Prec@5 100.000 (99.984)   [2019-11-22 03:41:09]
  Epoch: [181][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0555 (0.0472)   Prec@1 97.656 (98.375)   Prec@5 100.000 (99.990)   [2019-11-22 03:41:14]
  **Train** Prec@1 98.366 Prec@5 99.990 Error@1 1.634
  **Test** Prec@1 90.740 Prec@5 99.730 Error@1 9.260

==>>[2019-11-22 03:41:21] [Epoch=182/200] [Need: 00:06:35] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [182][000/391]   Time 0.236 (0.236)   Data 0.179 (0.179)   Loss 0.0555 (0.0555)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:41:21]
  Epoch: [182][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0501 (0.0479)   Prec@1 97.656 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 03:41:26]
  Epoch: [182][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0213 (0.0489)   Prec@1 99.219 (98.290)   Prec@5 100.000 (100.000)   [2019-11-22 03:41:31]
  Epoch: [182][300/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.0857 (0.0493)   Prec@1 96.875 (98.331)   Prec@5 99.219 (99.997)   [2019-11-22 03:41:36]
  **Train** Prec@1 98.330 Prec@5 99.996 Error@1 1.670
  **Test** Prec@1 90.780 Prec@5 99.720 Error@1 9.220

==>>[2019-11-22 03:41:42] [Epoch=183/200] [Need: 00:06:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [183][000/391]   Time 0.245 (0.245)   Data 0.178 (0.178)   Loss 0.0362 (0.0362)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:41:43]
  Epoch: [183][100/391]   Time 0.042 (0.048)   Data 0.000 (0.002)   Loss 0.0812 (0.0495)   Prec@1 96.094 (98.337)   Prec@5 100.000 (99.992)   [2019-11-22 03:41:47]
  Epoch: [183][200/391]   Time 0.069 (0.049)   Data 0.000 (0.001)   Loss 0.0318 (0.0498)   Prec@1 99.219 (98.298)   Prec@5 100.000 (99.992)   [2019-11-22 03:41:52]
  Epoch: [183][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0466 (0.0478)   Prec@1 98.438 (98.412)   Prec@5 100.000 (99.990)   [2019-11-22 03:41:57]
  **Train** Prec@1 98.462 Prec@5 99.990 Error@1 1.538
  **Test** Prec@1 90.720 Prec@5 99.730 Error@1 9.280

==>>[2019-11-22 03:42:04] [Epoch=184/200] [Need: 00:05:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [184][000/391]   Time 0.225 (0.225)   Data 0.165 (0.165)   Loss 0.0417 (0.0417)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:04]
  Epoch: [184][100/391]   Time 0.057 (0.052)   Data 0.000 (0.002)   Loss 0.0809 (0.0502)   Prec@1 94.531 (98.213)   Prec@5 100.000 (99.985)   [2019-11-22 03:42:09]
  Epoch: [184][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0640 (0.0496)   Prec@1 97.656 (98.270)   Prec@5 100.000 (99.984)   [2019-11-22 03:42:14]
  Epoch: [184][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0704 (0.0488)   Prec@1 97.656 (98.310)   Prec@5 100.000 (99.982)   [2019-11-22 03:42:19]
  **Train** Prec@1 98.360 Prec@5 99.986 Error@1 1.640
  **Test** Prec@1 90.610 Prec@5 99.730 Error@1 9.390

==>>[2019-11-22 03:42:26] [Epoch=185/200] [Need: 00:05:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [185][000/391]   Time 0.231 (0.231)   Data 0.151 (0.151)   Loss 0.0384 (0.0384)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:26]
  Epoch: [185][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0833 (0.0471)   Prec@1 97.656 (98.298)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:31]
  Epoch: [185][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0488 (0.0498)   Prec@1 97.656 (98.197)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:36]
  Epoch: [185][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0398 (0.0482)   Prec@1 98.438 (98.269)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:41]
  **Train** Prec@1 98.330 Prec@5 99.998 Error@1 1.670
  **Test** Prec@1 90.610 Prec@5 99.730 Error@1 9.390

==>>[2019-11-22 03:42:48] [Epoch=186/200] [Need: 00:05:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [186][000/391]   Time 0.223 (0.223)   Data 0.168 (0.168)   Loss 0.0661 (0.0661)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:42:48]
  Epoch: [186][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0263 (0.0476)   Prec@1 99.219 (98.376)   Prec@5 100.000 (99.977)   [2019-11-22 03:42:53]
  Epoch: [186][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0360 (0.0482)   Prec@1 97.656 (98.387)   Prec@5 100.000 (99.977)   [2019-11-22 03:42:58]
  Epoch: [186][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0615 (0.0481)   Prec@1 97.656 (98.365)   Prec@5 100.000 (99.982)   [2019-11-22 03:43:03]
  **Train** Prec@1 98.350 Prec@5 99.984 Error@1 1.650
  **Test** Prec@1 90.720 Prec@5 99.760 Error@1 9.280

==>>[2019-11-22 03:43:09] [Epoch=187/200] [Need: 00:04:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [187][000/391]   Time 0.226 (0.226)   Data 0.151 (0.151)   Loss 0.0610 (0.0610)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:43:10]
  Epoch: [187][100/391]   Time 0.074 (0.052)   Data 0.000 (0.002)   Loss 0.0469 (0.0439)   Prec@1 99.219 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:43:15]
  Epoch: [187][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0673 (0.0469)   Prec@1 97.656 (98.426)   Prec@5 100.000 (100.000)   [2019-11-22 03:43:20]
  Epoch: [187][300/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.0165 (0.0462)   Prec@1 99.219 (98.443)   Prec@5 100.000 (99.997)   [2019-11-22 03:43:25]
  **Train** Prec@1 98.390 Prec@5 99.996 Error@1 1.610
  **Test** Prec@1 90.690 Prec@5 99.750 Error@1 9.310

==>>[2019-11-22 03:43:31] [Epoch=188/200] [Need: 00:04:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [188][000/391]   Time 0.238 (0.238)   Data 0.151 (0.151)   Loss 0.0294 (0.0294)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:43:31]
  Epoch: [188][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0238 (0.0493)   Prec@1 99.219 (98.236)   Prec@5 100.000 (99.992)   [2019-11-22 03:43:36]
  Epoch: [188][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0297 (0.0500)   Prec@1 99.219 (98.263)   Prec@5 100.000 (99.996)   [2019-11-22 03:43:41]
  Epoch: [188][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0282 (0.0484)   Prec@1 99.219 (98.352)   Prec@5 100.000 (99.995)   [2019-11-22 03:43:46]
  **Train** Prec@1 98.352 Prec@5 99.996 Error@1 1.648
  **Test** Prec@1 90.750 Prec@5 99.760 Error@1 9.250

==>>[2019-11-22 03:43:53] [Epoch=189/200] [Need: 00:04:01] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [189][000/391]   Time 0.248 (0.248)   Data 0.181 (0.181)   Loss 0.0539 (0.0539)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:43:53]
  Epoch: [189][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.0856 (0.0466)   Prec@1 96.875 (98.492)   Prec@5 100.000 (99.992)   [2019-11-22 03:43:59]
  Epoch: [189][200/391]   Time 0.054 (0.054)   Data 0.000 (0.001)   Loss 0.0556 (0.0465)   Prec@1 98.438 (98.399)   Prec@5 100.000 (99.996)   [2019-11-22 03:44:04]
  Epoch: [189][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0270 (0.0479)   Prec@1 98.438 (98.365)   Prec@5 100.000 (99.995)   [2019-11-22 03:44:09]
  **Train** Prec@1 98.370 Prec@5 99.994 Error@1 1.630
  **Test** Prec@1 90.750 Prec@5 99.740 Error@1 9.250

==>>[2019-11-22 03:44:15] [Epoch=190/200] [Need: 00:03:39] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [190][000/391]   Time 0.223 (0.223)   Data 0.166 (0.166)   Loss 0.0274 (0.0274)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:44:16]
  Epoch: [190][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0506 (0.0505)   Prec@1 97.656 (98.221)   Prec@5 100.000 (99.985)   [2019-11-22 03:44:21]
  Epoch: [190][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.0715 (0.0478)   Prec@1 97.656 (98.333)   Prec@5 100.000 (99.992)   [2019-11-22 03:44:26]
  Epoch: [190][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0887 (0.0470)   Prec@1 96.875 (98.373)   Prec@5 99.219 (99.987)   [2019-11-22 03:44:31]
  **Train** Prec@1 98.380 Prec@5 99.990 Error@1 1.620
  **Test** Prec@1 90.720 Prec@5 99.720 Error@1 9.280

==>>[2019-11-22 03:44:37] [Epoch=191/200] [Need: 00:03:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [191][000/391]   Time 0.231 (0.231)   Data 0.171 (0.171)   Loss 0.0368 (0.0368)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:44:38]
  Epoch: [191][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0451 (0.0457)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:44:43]
  Epoch: [191][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0380 (0.0477)   Prec@1 99.219 (98.414)   Prec@5 100.000 (100.000)   [2019-11-22 03:44:48]
  Epoch: [191][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0504 (0.0476)   Prec@1 97.656 (98.375)   Prec@5 100.000 (100.000)   [2019-11-22 03:44:53]
  **Train** Prec@1 98.372 Prec@5 100.000 Error@1 1.628
  **Test** Prec@1 90.850 Prec@5 99.700 Error@1 9.150

==>>[2019-11-22 03:44:59] [Epoch=192/200] [Need: 00:02:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [192][000/391]   Time 0.234 (0.234)   Data 0.173 (0.173)   Loss 0.0800 (0.0800)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:00]
  Epoch: [192][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0382 (0.0497)   Prec@1 98.438 (98.337)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:05]
  Epoch: [192][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0387 (0.0499)   Prec@1 98.438 (98.321)   Prec@5 100.000 (99.996)   [2019-11-22 03:45:10]
  Epoch: [192][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0504 (0.0494)   Prec@1 98.438 (98.360)   Prec@5 100.000 (99.997)   [2019-11-22 03:45:15]
  **Train** Prec@1 98.370 Prec@5 99.996 Error@1 1.630
  **Test** Prec@1 90.670 Prec@5 99.720 Error@1 9.330

==>>[2019-11-22 03:45:21] [Epoch=193/200] [Need: 00:02:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [193][000/391]   Time 0.241 (0.241)   Data 0.179 (0.179)   Loss 0.0516 (0.0516)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:21]
  Epoch: [193][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1424 (0.0476)   Prec@1 96.875 (98.407)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:27]
  Epoch: [193][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0245 (0.0464)   Prec@1 100.000 (98.441)   Prec@5 100.000 (99.996)   [2019-11-22 03:45:32]
  Epoch: [193][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0546 (0.0474)   Prec@1 98.438 (98.401)   Prec@5 100.000 (99.992)   [2019-11-22 03:45:37]
  **Train** Prec@1 98.352 Prec@5 99.994 Error@1 1.648
  **Test** Prec@1 90.610 Prec@5 99.730 Error@1 9.390

==>>[2019-11-22 03:45:43] [Epoch=194/200] [Need: 00:02:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [194][000/391]   Time 0.217 (0.217)   Data 0.149 (0.149)   Loss 0.0595 (0.0595)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:44]
  Epoch: [194][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.0487 (0.0427)   Prec@1 97.656 (98.639)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:48]
  Epoch: [194][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.0655 (0.0450)   Prec@1 96.094 (98.523)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:53]
  Epoch: [194][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0382 (0.0462)   Prec@1 97.656 (98.445)   Prec@5 100.000 (100.000)   [2019-11-22 03:45:59]
  **Train** Prec@1 98.462 Prec@5 99.998 Error@1 1.538
  **Test** Prec@1 90.790 Prec@5 99.730 Error@1 9.210

==>>[2019-11-22 03:46:05] [Epoch=195/200] [Need: 00:01:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [195][000/391]   Time 0.221 (0.221)   Data 0.151 (0.151)   Loss 0.0354 (0.0354)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 03:46:05]
  Epoch: [195][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0639 (0.0453)   Prec@1 98.438 (98.492)   Prec@5 100.000 (99.992)   [2019-11-22 03:46:10]
  Epoch: [195][200/391]   Time 0.084 (0.052)   Data 0.000 (0.001)   Loss 0.0344 (0.0454)   Prec@1 98.438 (98.469)   Prec@5 100.000 (99.988)   [2019-11-22 03:46:16]
  Epoch: [195][300/391]   Time 0.079 (0.052)   Data 0.000 (0.001)   Loss 0.0430 (0.0458)   Prec@1 100.000 (98.479)   Prec@5 100.000 (99.990)   [2019-11-22 03:46:21]
  **Train** Prec@1 98.456 Prec@5 99.990 Error@1 1.544
  **Test** Prec@1 90.780 Prec@5 99.700 Error@1 9.220

==>>[2019-11-22 03:46:28] [Epoch=196/200] [Need: 00:01:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [196][000/391]   Time 0.248 (0.248)   Data 0.182 (0.182)   Loss 0.0965 (0.0965)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 03:46:28]
  Epoch: [196][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0232 (0.0469)   Prec@1 100.000 (98.468)   Prec@5 100.000 (99.985)   [2019-11-22 03:46:33]
  Epoch: [196][200/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0770 (0.0457)   Prec@1 96.094 (98.469)   Prec@5 100.000 (99.992)   [2019-11-22 03:46:38]
  Epoch: [196][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0401 (0.0453)   Prec@1 98.438 (98.471)   Prec@5 100.000 (99.992)   [2019-11-22 03:46:43]
  **Train** Prec@1 98.482 Prec@5 99.992 Error@1 1.518
  **Test** Prec@1 90.670 Prec@5 99.740 Error@1 9.330

==>>[2019-11-22 03:46:49] [Epoch=197/200] [Need: 00:01:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [197][000/391]   Time 0.221 (0.221)   Data 0.161 (0.161)   Loss 0.0353 (0.0353)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 03:46:50]
  Epoch: [197][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.0229 (0.0439)   Prec@1 99.219 (98.538)   Prec@5 100.000 (99.992)   [2019-11-22 03:46:55]
  Epoch: [197][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0457 (0.0449)   Prec@1 97.656 (98.472)   Prec@5 100.000 (99.996)   [2019-11-22 03:47:00]
  Epoch: [197][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0381 (0.0458)   Prec@1 97.656 (98.399)   Prec@5 100.000 (99.997)   [2019-11-22 03:47:05]
  **Train** Prec@1 98.344 Prec@5 99.996 Error@1 1.656
  **Test** Prec@1 90.780 Prec@5 99.700 Error@1 9.220

==>>[2019-11-22 03:47:12] [Epoch=198/200] [Need: 00:00:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [198][000/391]   Time 0.226 (0.226)   Data 0.162 (0.162)   Loss 0.0203 (0.0203)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:47:12]
  Epoch: [198][100/391]   Time 0.054 (0.053)   Data 0.000 (0.002)   Loss 0.0625 (0.0430)   Prec@1 98.438 (98.592)   Prec@5 100.000 (100.000)   [2019-11-22 03:47:17]
  Epoch: [198][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0246 (0.0450)   Prec@1 99.219 (98.476)   Prec@5 100.000 (99.996)   [2019-11-22 03:47:22]
  Epoch: [198][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0358 (0.0451)   Prec@1 98.438 (98.492)   Prec@5 100.000 (99.997)   [2019-11-22 03:47:27]
  **Train** Prec@1 98.466 Prec@5 99.992 Error@1 1.534
  **Test** Prec@1 90.820 Prec@5 99.740 Error@1 9.180

==>>[2019-11-22 03:47:33] [Epoch=199/200] [Need: 00:00:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.90, Error=9.10]
  Epoch: [199][000/391]   Time 0.252 (0.252)   Data 0.173 (0.173)   Loss 0.0197 (0.0197)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 03:47:33]
  Epoch: [199][100/391]   Time 0.043 (0.057)   Data 0.000 (0.002)   Loss 0.0180 (0.0494)   Prec@1 99.219 (98.337)   Prec@5 100.000 (100.000)   [2019-11-22 03:47:39]
  Epoch: [199][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.0278 (0.0485)   Prec@1 98.438 (98.418)   Prec@5 100.000 (99.992)   [2019-11-22 03:47:44]
  Epoch: [199][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0908 (0.0478)   Prec@1 99.219 (98.448)   Prec@5 100.000 (99.995)   [2019-11-22 03:47:49]
  **Train** Prec@1 98.414 Prec@5 99.996 Error@1 1.586
  **Test** Prec@1 90.740 Prec@5 99.730 Error@1 9.260
