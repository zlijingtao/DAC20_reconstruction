save path : ./save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_4bit_reg0.0
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 4], 'input_num_bits': 4, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.8, 'output_grain_size': [1, 4], 'output_num_bits': 4, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.8, 'res_grain_size': [1, 4], 'res_num_bits': 4, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_4bit_reg0.0', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-22 01:21:05] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.564 (1.564)   Data 0.136 (0.136)   Loss 3.8113 (3.8113)   Prec@1 8.594 (8.594)   Prec@5 51.562 (51.562)   [2019-11-22 01:21:07]
  Epoch: [000][100/391]   Time 0.051 (0.064)   Data 0.000 (0.001)   Loss 1.7532 (1.9319)   Prec@1 35.156 (29.417)   Prec@5 87.500 (82.008)   [2019-11-22 01:21:12]
  Epoch: [000][200/391]   Time 0.042 (0.056)   Data 0.000 (0.001)   Loss 1.5235 (1.7563)   Prec@1 43.750 (35.281)   Prec@5 91.406 (86.287)   [2019-11-22 01:21:17]
  Epoch: [000][300/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 1.2654 (1.6347)   Prec@1 53.125 (39.852)   Prec@5 95.312 (88.556)   [2019-11-22 01:21:22]
  **Train** Prec@1 43.044 Prec@5 89.830 Error@1 56.956
  **Test** Prec@1 45.820 Prec@5 90.550 Error@1 54.180
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:21:28] [Epoch=001/200] [Need: 01:13:02] [LR=0.0100][M=0.90] [Best : Accuracy=45.82, Error=54.18]
  Epoch: [001][000/391]   Time 0.219 (0.219)   Data 0.162 (0.162)   Loss 1.2117 (1.2117)   Prec@1 54.688 (54.688)   Prec@5 96.094 (96.094)   [2019-11-22 01:21:28]
  Epoch: [001][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 1.1713 (1.1692)   Prec@1 60.156 (57.689)   Prec@5 96.875 (95.444)   [2019-11-22 01:21:33]
  Epoch: [001][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 1.0841 (1.1242)   Prec@1 57.031 (59.690)   Prec@5 96.875 (95.802)   [2019-11-22 01:21:38]
  Epoch: [001][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.9320 (1.1010)   Prec@1 69.531 (60.647)   Prec@5 95.312 (95.938)   [2019-11-22 01:21:42]
  **Train** Prec@1 61.834 Prec@5 96.134 Error@1 38.166
  **Test** Prec@1 58.510 Prec@5 95.850 Error@1 41.490
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:21:49] [Epoch=002/200] [Need: 01:11:13] [LR=0.0100][M=0.90] [Best : Accuracy=58.51, Error=41.49]
  Epoch: [002][000/391]   Time 0.229 (0.229)   Data 0.145 (0.145)   Loss 0.9831 (0.9831)   Prec@1 65.625 (65.625)   Prec@5 94.531 (94.531)   [2019-11-22 01:21:49]
  Epoch: [002][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 1.0237 (0.9186)   Prec@1 67.969 (67.350)   Prec@5 98.438 (97.254)   [2019-11-22 01:21:54]
  Epoch: [002][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 1.0845 (0.8883)   Prec@1 58.594 (68.571)   Prec@5 96.875 (97.536)   [2019-11-22 01:21:59]
  Epoch: [002][300/391]   Time 0.071 (0.051)   Data 0.000 (0.001)   Loss 0.7733 (0.8689)   Prec@1 78.125 (69.523)   Prec@5 96.094 (97.633)   [2019-11-22 01:22:04]
  **Train** Prec@1 70.008 Prec@5 97.690 Error@1 29.992
  **Test** Prec@1 64.480 Prec@5 96.040 Error@1 35.520
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:22:11] [Epoch=003/200] [Need: 01:11:06] [LR=0.0100][M=0.90] [Best : Accuracy=64.48, Error=35.52]
  Epoch: [003][000/391]   Time 0.223 (0.223)   Data 0.153 (0.153)   Loss 0.9164 (0.9164)   Prec@1 63.281 (63.281)   Prec@5 94.531 (94.531)   [2019-11-22 01:22:11]
  Epoch: [003][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.7469 (0.7727)   Prec@1 70.312 (72.788)   Prec@5 99.219 (98.175)   [2019-11-22 01:22:16]
  Epoch: [003][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.7630 (0.7622)   Prec@1 70.312 (73.317)   Prec@5 98.438 (98.278)   [2019-11-22 01:22:21]
  Epoch: [003][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.5159 (0.7568)   Prec@1 83.594 (73.554)   Prec@5 100.000 (98.235)   [2019-11-22 01:22:26]
  **Train** Prec@1 74.048 Prec@5 98.248 Error@1 25.952
  **Test** Prec@1 75.340 Prec@5 98.450 Error@1 24.660
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:22:32] [Epoch=004/200] [Need: 01:10:52] [LR=0.0100][M=0.90] [Best : Accuracy=75.34, Error=24.66]
  Epoch: [004][000/391]   Time 0.223 (0.223)   Data 0.156 (0.156)   Loss 0.6277 (0.6277)   Prec@1 79.688 (79.688)   Prec@5 99.219 (99.219)   [2019-11-22 01:22:33]
  Epoch: [004][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5649 (0.6948)   Prec@1 82.812 (76.222)   Prec@5 98.438 (98.089)   [2019-11-22 01:22:38]
  Epoch: [004][200/391]   Time 0.070 (0.051)   Data 0.000 (0.001)   Loss 0.5537 (0.6852)   Prec@1 80.469 (76.252)   Prec@5 100.000 (98.336)   [2019-11-22 01:22:43]
  Epoch: [004][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.6402 (0.6779)   Prec@1 75.781 (76.407)   Prec@5 99.219 (98.396)   [2019-11-22 01:22:48]
  **Train** Prec@1 76.716 Prec@5 98.464 Error@1 23.284
  **Test** Prec@1 73.260 Prec@5 98.350 Error@1 26.740

==>>[2019-11-22 01:22:54] [Epoch=005/200] [Need: 01:10:14] [LR=0.0100][M=0.90] [Best : Accuracy=75.34, Error=24.66]
  Epoch: [005][000/391]   Time 0.243 (0.243)   Data 0.174 (0.174)   Loss 0.6185 (0.6185)   Prec@1 79.688 (79.688)   Prec@5 98.438 (98.438)   [2019-11-22 01:22:54]
  Epoch: [005][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.5029 (0.6267)   Prec@1 85.938 (78.636)   Prec@5 98.438 (98.747)   [2019-11-22 01:22:59]
  Epoch: [005][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.5947 (0.6302)   Prec@1 83.594 (78.568)   Prec@5 96.875 (98.745)   [2019-11-22 01:23:04]
  Epoch: [005][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.6623 (0.6264)   Prec@1 79.688 (78.618)   Prec@5 96.875 (98.710)   [2019-11-22 01:23:10]
  **Train** Prec@1 78.792 Prec@5 98.772 Error@1 21.208
  **Test** Prec@1 76.010 Prec@5 98.030 Error@1 23.990
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:23:17] [Epoch=006/200] [Need: 01:10:31] [LR=0.0100][M=0.90] [Best : Accuracy=76.01, Error=23.99]
  Epoch: [006][000/391]   Time 0.219 (0.219)   Data 0.137 (0.137)   Loss 0.5174 (0.5174)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-22 01:23:17]
  Epoch: [006][100/391]   Time 0.045 (0.054)   Data 0.000 (0.001)   Loss 0.5523 (0.6061)   Prec@1 83.594 (79.030)   Prec@5 99.219 (98.670)   [2019-11-22 01:23:22]
  Epoch: [006][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.6926 (0.6004)   Prec@1 73.438 (79.310)   Prec@5 99.219 (98.772)   [2019-11-22 01:23:27]
  Epoch: [006][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.6329 (0.5999)   Prec@1 76.562 (79.296)   Prec@5 99.219 (98.832)   [2019-11-22 01:23:32]
  **Train** Prec@1 79.540 Prec@5 98.828 Error@1 20.460
  **Test** Prec@1 78.990 Prec@5 98.620 Error@1 21.010
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:23:39] [Epoch=007/200] [Need: 01:10:22] [LR=0.0100][M=0.90] [Best : Accuracy=78.99, Error=21.01]
  Epoch: [007][000/391]   Time 0.215 (0.215)   Data 0.144 (0.144)   Loss 0.6265 (0.6265)   Prec@1 78.906 (78.906)   Prec@5 98.438 (98.438)   [2019-11-22 01:23:39]
  Epoch: [007][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.5760 (0.5681)   Prec@1 80.469 (80.631)   Prec@5 98.438 (98.933)   [2019-11-22 01:23:44]
  Epoch: [007][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.6081 (0.5588)   Prec@1 78.125 (80.756)   Prec@5 98.438 (98.943)   [2019-11-22 01:23:49]
  Epoch: [007][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.5223 (0.5601)   Prec@1 77.344 (80.539)   Prec@5 100.000 (98.941)   [2019-11-22 01:23:54]
  **Train** Prec@1 80.462 Prec@5 98.946 Error@1 19.538
  **Test** Prec@1 77.520 Prec@5 98.550 Error@1 22.480

==>>[2019-11-22 01:24:00] [Epoch=008/200] [Need: 01:09:45] [LR=0.0100][M=0.90] [Best : Accuracy=78.99, Error=21.01]
  Epoch: [008][000/391]   Time 0.237 (0.237)   Data 0.179 (0.179)   Loss 0.5544 (0.5544)   Prec@1 78.125 (78.125)   Prec@5 100.000 (100.000)   [2019-11-22 01:24:00]
  Epoch: [008][100/391]   Time 0.054 (0.050)   Data 0.000 (0.002)   Loss 0.4585 (0.5425)   Prec@1 86.719 (81.273)   Prec@5 99.219 (99.103)   [2019-11-22 01:24:05]
  Epoch: [008][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.5657 (0.5362)   Prec@1 78.906 (81.413)   Prec@5 100.000 (99.048)   [2019-11-22 01:24:10]
  Epoch: [008][300/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.5569 (0.5344)   Prec@1 82.812 (81.580)   Prec@5 99.219 (99.107)   [2019-11-22 01:24:15]
  **Train** Prec@1 81.582 Prec@5 99.094 Error@1 18.418
  **Test** Prec@1 79.350 Prec@5 99.070 Error@1 20.650
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:24:22] [Epoch=009/200] [Need: 01:09:17] [LR=0.0100][M=0.90] [Best : Accuracy=79.35, Error=20.65]
  Epoch: [009][000/391]   Time 0.214 (0.214)   Data 0.148 (0.148)   Loss 0.6615 (0.6615)   Prec@1 75.000 (75.000)   Prec@5 98.438 (98.438)   [2019-11-22 01:24:22]
  Epoch: [009][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.3978 (0.5172)   Prec@1 87.500 (82.194)   Prec@5 100.000 (99.095)   [2019-11-22 01:24:27]
  Epoch: [009][200/391]   Time 0.083 (0.053)   Data 0.000 (0.001)   Loss 0.4783 (0.5162)   Prec@1 85.938 (82.198)   Prec@5 98.438 (99.087)   [2019-11-22 01:24:32]
  Epoch: [009][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5778 (0.5170)   Prec@1 82.812 (82.148)   Prec@5 98.438 (99.125)   [2019-11-22 01:24:37]
  **Train** Prec@1 81.966 Prec@5 99.098 Error@1 18.034
  **Test** Prec@1 76.110 Prec@5 98.310 Error@1 23.890

==>>[2019-11-22 01:24:44] [Epoch=010/200] [Need: 01:09:00] [LR=0.0100][M=0.90] [Best : Accuracy=79.35, Error=20.65]
  Epoch: [010][000/391]   Time 0.221 (0.221)   Data 0.149 (0.149)   Loss 0.5028 (0.5028)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-22 01:24:44]
  Epoch: [010][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.4906 (0.4945)   Prec@1 84.375 (82.882)   Prec@5 98.438 (99.165)   [2019-11-22 01:24:49]
  Epoch: [010][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.3855 (0.5059)   Prec@1 89.062 (82.552)   Prec@5 98.438 (99.071)   [2019-11-22 01:24:54]
  Epoch: [010][300/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.3676 (0.5070)   Prec@1 85.938 (82.511)   Prec@5 100.000 (99.120)   [2019-11-22 01:24:59]
  **Train** Prec@1 82.526 Prec@5 99.148 Error@1 17.474
  **Test** Prec@1 80.380 Prec@5 98.810 Error@1 19.620
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:25:06] [Epoch=011/200] [Need: 01:08:48] [LR=0.0100][M=0.90] [Best : Accuracy=80.38, Error=19.62]
  Epoch: [011][000/391]   Time 0.223 (0.223)   Data 0.165 (0.165)   Loss 0.3440 (0.3440)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:25:06]
  Epoch: [011][100/391]   Time 0.061 (0.056)   Data 0.000 (0.002)   Loss 0.5984 (0.4768)   Prec@1 78.125 (83.834)   Prec@5 98.438 (99.242)   [2019-11-22 01:25:12]
  Epoch: [011][200/391]   Time 0.059 (0.055)   Data 0.000 (0.001)   Loss 0.5712 (0.4792)   Prec@1 80.469 (83.411)   Prec@5 98.438 (99.215)   [2019-11-22 01:25:17]
  Epoch: [011][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.4544 (0.4861)   Prec@1 86.719 (83.225)   Prec@5 96.875 (99.206)   [2019-11-22 01:25:22]
  **Train** Prec@1 83.268 Prec@5 99.198 Error@1 16.732
  **Test** Prec@1 82.010 Prec@5 98.900 Error@1 17.990
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:25:29] [Epoch=012/200] [Need: 01:08:43] [LR=0.0100][M=0.90] [Best : Accuracy=82.01, Error=17.99]
  Epoch: [012][000/391]   Time 0.234 (0.234)   Data 0.154 (0.154)   Loss 0.3754 (0.3754)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 01:25:29]
  Epoch: [012][100/391]   Time 0.067 (0.054)   Data 0.000 (0.002)   Loss 0.5016 (0.4683)   Prec@1 81.250 (83.617)   Prec@5 100.000 (99.281)   [2019-11-22 01:25:34]
  Epoch: [012][200/391]   Time 0.040 (0.054)   Data 0.000 (0.001)   Loss 0.5773 (0.4767)   Prec@1 75.781 (83.450)   Prec@5 99.219 (99.324)   [2019-11-22 01:25:40]
  Epoch: [012][300/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.3847 (0.4795)   Prec@1 87.500 (83.300)   Prec@5 100.000 (99.317)   [2019-11-22 01:25:44]
  **Train** Prec@1 83.206 Prec@5 99.294 Error@1 16.794
  **Test** Prec@1 75.040 Prec@5 98.040 Error@1 24.960

==>>[2019-11-22 01:25:50] [Epoch=013/200] [Need: 01:08:16] [LR=0.0100][M=0.90] [Best : Accuracy=82.01, Error=17.99]
  Epoch: [013][000/391]   Time 0.219 (0.219)   Data 0.159 (0.159)   Loss 0.4809 (0.4809)   Prec@1 82.812 (82.812)   Prec@5 98.438 (98.438)   [2019-11-22 01:25:51]
  Epoch: [013][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.6019 (0.4551)   Prec@1 78.125 (84.360)   Prec@5 100.000 (99.343)   [2019-11-22 01:25:56]
  Epoch: [013][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4781 (0.4602)   Prec@1 82.031 (84.266)   Prec@5 100.000 (99.339)   [2019-11-22 01:26:01]
  Epoch: [013][300/391]   Time 0.057 (0.049)   Data 0.000 (0.001)   Loss 0.6301 (0.4674)   Prec@1 78.125 (83.887)   Prec@5 98.438 (99.310)   [2019-11-22 01:26:05]
  **Train** Prec@1 83.870 Prec@5 99.254 Error@1 16.130
  **Test** Prec@1 79.440 Prec@5 98.880 Error@1 20.560

==>>[2019-11-22 01:26:12] [Epoch=014/200] [Need: 01:07:45] [LR=0.0100][M=0.90] [Best : Accuracy=82.01, Error=17.99]
  Epoch: [014][000/391]   Time 0.235 (0.235)   Data 0.175 (0.175)   Loss 0.4877 (0.4877)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 01:26:12]
  Epoch: [014][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.4344 (0.4432)   Prec@1 85.156 (84.530)   Prec@5 99.219 (99.366)   [2019-11-22 01:26:17]
  Epoch: [014][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.4563 (0.4543)   Prec@1 84.375 (84.270)   Prec@5 98.438 (99.320)   [2019-11-22 01:26:22]
  Epoch: [014][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.5014 (0.4581)   Prec@1 84.375 (84.167)   Prec@5 99.219 (99.320)   [2019-11-22 01:26:27]
  **Train** Prec@1 84.250 Prec@5 99.302 Error@1 15.750
  **Test** Prec@1 80.760 Prec@5 99.080 Error@1 19.240

==>>[2019-11-22 01:26:33] [Epoch=015/200] [Need: 01:07:18] [LR=0.0100][M=0.90] [Best : Accuracy=82.01, Error=17.99]
  Epoch: [015][000/391]   Time 0.224 (0.224)   Data 0.170 (0.170)   Loss 0.5899 (0.5899)   Prec@1 76.562 (76.562)   Prec@5 98.438 (98.438)   [2019-11-22 01:26:33]
  Epoch: [015][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.3524 (0.4307)   Prec@1 90.625 (85.025)   Prec@5 99.219 (99.428)   [2019-11-22 01:26:38]
  Epoch: [015][200/391]   Time 0.061 (0.051)   Data 0.000 (0.001)   Loss 0.4978 (0.4494)   Prec@1 83.594 (84.488)   Prec@5 99.219 (99.331)   [2019-11-22 01:26:43]
  Epoch: [015][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.4529 (0.4515)   Prec@1 85.938 (84.372)   Prec@5 99.219 (99.336)   [2019-11-22 01:26:48]
  **Train** Prec@1 84.294 Prec@5 99.328 Error@1 15.706
  **Test** Prec@1 82.270 Prec@5 99.210 Error@1 17.730
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:26:55] [Epoch=016/200] [Need: 01:06:55] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [016][000/391]   Time 0.240 (0.240)   Data 0.174 (0.174)   Loss 0.5694 (0.5694)   Prec@1 80.469 (80.469)   Prec@5 99.219 (99.219)   [2019-11-22 01:26:55]
  Epoch: [016][100/391]   Time 0.054 (0.053)   Data 0.000 (0.002)   Loss 0.3922 (0.4356)   Prec@1 85.938 (84.847)   Prec@5 99.219 (99.397)   [2019-11-22 01:27:00]
  Epoch: [016][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.5040 (0.4466)   Prec@1 82.812 (84.499)   Prec@5 99.219 (99.328)   [2019-11-22 01:27:05]
  Epoch: [016][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3543 (0.4522)   Prec@1 87.500 (84.295)   Prec@5 100.000 (99.310)   [2019-11-22 01:27:10]
  **Train** Prec@1 84.472 Prec@5 99.314 Error@1 15.528
  **Test** Prec@1 81.200 Prec@5 99.090 Error@1 18.800

==>>[2019-11-22 01:27:17] [Epoch=017/200] [Need: 01:06:33] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [017][000/391]   Time 0.221 (0.221)   Data 0.149 (0.149)   Loss 0.3110 (0.3110)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 01:27:17]
  Epoch: [017][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.4484 (0.4200)   Prec@1 85.938 (85.365)   Prec@5 99.219 (99.404)   [2019-11-22 01:27:22]
  Epoch: [017][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.5880 (0.4302)   Prec@1 78.906 (85.016)   Prec@5 97.656 (99.390)   [2019-11-22 01:27:27]
  Epoch: [017][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4597 (0.4342)   Prec@1 80.469 (84.930)   Prec@5 100.000 (99.406)   [2019-11-22 01:27:32]
  **Train** Prec@1 84.764 Prec@5 99.400 Error@1 15.236
  **Test** Prec@1 77.150 Prec@5 98.730 Error@1 22.850

==>>[2019-11-22 01:27:38] [Epoch=018/200] [Need: 01:06:10] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [018][000/391]   Time 0.227 (0.227)   Data 0.163 (0.163)   Loss 0.3858 (0.3858)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-22 01:27:39]
  Epoch: [018][100/391]   Time 0.040 (0.053)   Data 0.000 (0.002)   Loss 0.3864 (0.4249)   Prec@1 85.938 (85.435)   Prec@5 99.219 (99.412)   [2019-11-22 01:27:44]
  Epoch: [018][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.4265 (0.4235)   Prec@1 85.938 (85.343)   Prec@5 98.438 (99.382)   [2019-11-22 01:27:49]
  Epoch: [018][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4778 (0.4263)   Prec@1 83.594 (85.307)   Prec@5 98.438 (99.380)   [2019-11-22 01:27:54]
  **Train** Prec@1 85.182 Prec@5 99.392 Error@1 14.818
  **Test** Prec@1 81.630 Prec@5 99.220 Error@1 18.370

==>>[2019-11-22 01:28:01] [Epoch=019/200] [Need: 01:05:53] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [019][000/391]   Time 0.220 (0.220)   Data 0.160 (0.160)   Loss 0.4754 (0.4754)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-22 01:28:01]
  Epoch: [019][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.3561 (0.4126)   Prec@1 89.062 (85.907)   Prec@5 99.219 (99.366)   [2019-11-22 01:28:06]
  Epoch: [019][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.4491 (0.4144)   Prec@1 88.281 (85.743)   Prec@5 100.000 (99.378)   [2019-11-22 01:28:11]
  Epoch: [019][300/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.4142 (0.4185)   Prec@1 85.938 (85.699)   Prec@5 100.000 (99.393)   [2019-11-22 01:28:17]
  **Train** Prec@1 85.514 Prec@5 99.386 Error@1 14.486
  **Test** Prec@1 79.230 Prec@5 98.360 Error@1 20.770

==>>[2019-11-22 01:28:23] [Epoch=020/200] [Need: 01:05:37] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [020][000/391]   Time 0.219 (0.219)   Data 0.161 (0.161)   Loss 0.4350 (0.4350)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 01:28:23]
  Epoch: [020][100/391]   Time 0.037 (0.052)   Data 0.000 (0.002)   Loss 0.3366 (0.4067)   Prec@1 89.844 (85.984)   Prec@5 100.000 (99.497)   [2019-11-22 01:28:29]
  Epoch: [020][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.3863 (0.4111)   Prec@1 85.938 (85.704)   Prec@5 99.219 (99.452)   [2019-11-22 01:28:34]
  Epoch: [020][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.4643 (0.4145)   Prec@1 84.375 (85.662)   Prec@5 97.656 (99.424)   [2019-11-22 01:28:39]
  **Train** Prec@1 85.664 Prec@5 99.458 Error@1 14.336
  **Test** Prec@1 80.360 Prec@5 98.840 Error@1 19.640

==>>[2019-11-22 01:28:45] [Epoch=021/200] [Need: 01:05:17] [LR=0.0100][M=0.90] [Best : Accuracy=82.27, Error=17.73]
  Epoch: [021][000/391]   Time 0.218 (0.218)   Data 0.145 (0.145)   Loss 0.3842 (0.3842)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 01:28:46]
  Epoch: [021][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5536 (0.4058)   Prec@1 83.594 (85.930)   Prec@5 99.219 (99.474)   [2019-11-22 01:28:51]
  Epoch: [021][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.4844 (0.4103)   Prec@1 85.938 (85.685)   Prec@5 98.438 (99.495)   [2019-11-22 01:28:56]
  Epoch: [021][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.5830 (0.4143)   Prec@1 76.562 (85.626)   Prec@5 100.000 (99.455)   [2019-11-22 01:29:01]
  **Train** Prec@1 85.558 Prec@5 99.452 Error@1 14.442
  **Test** Prec@1 84.050 Prec@5 99.260 Error@1 15.950
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:29:07] [Epoch=022/200] [Need: 01:04:55] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [022][000/391]   Time 0.227 (0.227)   Data 0.168 (0.168)   Loss 0.3714 (0.3714)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 01:29:07]
  Epoch: [022][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.5291 (0.4178)   Prec@1 80.469 (85.814)   Prec@5 100.000 (99.412)   [2019-11-22 01:29:12]
  Epoch: [022][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.4927 (0.4097)   Prec@1 82.031 (85.887)   Prec@5 99.219 (99.479)   [2019-11-22 01:29:17]
  Epoch: [022][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3210 (0.4110)   Prec@1 85.938 (85.748)   Prec@5 100.000 (99.471)   [2019-11-22 01:29:23]
  **Train** Prec@1 85.754 Prec@5 99.472 Error@1 14.246
  **Test** Prec@1 78.340 Prec@5 98.590 Error@1 21.660

==>>[2019-11-22 01:29:29] [Epoch=023/200] [Need: 01:04:35] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [023][000/391]   Time 0.224 (0.224)   Data 0.165 (0.165)   Loss 0.3933 (0.3933)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-22 01:29:30]
  Epoch: [023][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3462 (0.3787)   Prec@1 89.062 (86.711)   Prec@5 100.000 (99.559)   [2019-11-22 01:29:35]
  Epoch: [023][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.4502 (0.3935)   Prec@1 86.719 (86.276)   Prec@5 100.000 (99.526)   [2019-11-22 01:29:40]
  Epoch: [023][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4119 (0.3997)   Prec@1 90.625 (86.085)   Prec@5 98.438 (99.517)   [2019-11-22 01:29:45]
  **Train** Prec@1 86.004 Prec@5 99.482 Error@1 13.996
  **Test** Prec@1 81.890 Prec@5 99.070 Error@1 18.110

==>>[2019-11-22 01:29:51] [Epoch=024/200] [Need: 01:04:16] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [024][000/391]   Time 0.226 (0.226)   Data 0.166 (0.166)   Loss 0.3748 (0.3748)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 01:29:52]
  Epoch: [024][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4027 (0.3896)   Prec@1 84.375 (86.355)   Prec@5 98.438 (99.428)   [2019-11-22 01:29:57]
  Epoch: [024][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.5163 (0.3897)   Prec@1 85.156 (86.416)   Prec@5 97.656 (99.448)   [2019-11-22 01:30:02]
  Epoch: [024][300/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.5653 (0.3940)   Prec@1 82.031 (86.423)   Prec@5 100.000 (99.476)   [2019-11-22 01:30:07]
  **Train** Prec@1 86.338 Prec@5 99.486 Error@1 13.662
  **Test** Prec@1 78.240 Prec@5 98.850 Error@1 21.760

==>>[2019-11-22 01:30:13] [Epoch=025/200] [Need: 01:03:53] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [025][000/391]   Time 0.225 (0.225)   Data 0.163 (0.163)   Loss 0.3658 (0.3658)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 01:30:14]
  Epoch: [025][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.4007 (0.3685)   Prec@1 84.375 (87.167)   Prec@5 99.219 (99.590)   [2019-11-22 01:30:19]
  Epoch: [025][200/391]   Time 0.056 (0.054)   Data 0.000 (0.001)   Loss 0.3700 (0.3903)   Prec@1 85.938 (86.396)   Prec@5 100.000 (99.506)   [2019-11-22 01:30:24]
  Epoch: [025][300/391]   Time 0.048 (0.054)   Data 0.000 (0.001)   Loss 0.2883 (0.3949)   Prec@1 90.625 (86.254)   Prec@5 100.000 (99.530)   [2019-11-22 01:30:29]
  **Train** Prec@1 86.368 Prec@5 99.500 Error@1 13.632
  **Test** Prec@1 83.270 Prec@5 99.120 Error@1 16.730

==>>[2019-11-22 01:30:36] [Epoch=026/200] [Need: 01:03:39] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [026][000/391]   Time 0.221 (0.221)   Data 0.154 (0.154)   Loss 0.2216 (0.2216)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 01:30:37]
  Epoch: [026][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.3899 (0.3822)   Prec@1 85.938 (86.819)   Prec@5 100.000 (99.404)   [2019-11-22 01:30:42]
  Epoch: [026][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3068 (0.3942)   Prec@1 88.281 (86.334)   Prec@5 100.000 (99.464)   [2019-11-22 01:30:47]
  Epoch: [026][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3651 (0.3966)   Prec@1 87.500 (86.184)   Prec@5 99.219 (99.471)   [2019-11-22 01:30:52]
  **Train** Prec@1 86.226 Prec@5 99.466 Error@1 13.774
  **Test** Prec@1 81.420 Prec@5 99.110 Error@1 18.580

==>>[2019-11-22 01:30:58] [Epoch=027/200] [Need: 01:03:16] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [027][000/391]   Time 0.226 (0.226)   Data 0.160 (0.160)   Loss 0.3919 (0.3919)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 01:30:58]
  Epoch: [027][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.3217 (0.3756)   Prec@1 88.281 (86.781)   Prec@5 100.000 (99.567)   [2019-11-22 01:31:03]
  Epoch: [027][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.5135 (0.3834)   Prec@1 82.031 (86.583)   Prec@5 99.219 (99.553)   [2019-11-22 01:31:09]
  Epoch: [027][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2604 (0.3903)   Prec@1 90.625 (86.454)   Prec@5 100.000 (99.512)   [2019-11-22 01:31:14]
  **Train** Prec@1 86.484 Prec@5 99.534 Error@1 13.516
  **Test** Prec@1 80.680 Prec@5 99.150 Error@1 19.320

==>>[2019-11-22 01:31:20] [Epoch=028/200] [Need: 01:02:52] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [028][000/391]   Time 0.219 (0.219)   Data 0.158 (0.158)   Loss 0.3907 (0.3907)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 01:31:20]
  Epoch: [028][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.2289 (0.3676)   Prec@1 92.188 (87.345)   Prec@5 99.219 (99.575)   [2019-11-22 01:31:25]
  Epoch: [028][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.4056 (0.3809)   Prec@1 82.031 (86.750)   Prec@5 99.219 (99.580)   [2019-11-22 01:31:31]
  Epoch: [028][300/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.3728 (0.3852)   Prec@1 87.500 (86.667)   Prec@5 99.219 (99.496)   [2019-11-22 01:31:36]
  **Train** Prec@1 86.660 Prec@5 99.492 Error@1 13.340
  **Test** Prec@1 83.000 Prec@5 99.130 Error@1 17.000

==>>[2019-11-22 01:31:42] [Epoch=029/200] [Need: 01:02:34] [LR=0.0100][M=0.90] [Best : Accuracy=84.05, Error=15.95]
  Epoch: [029][000/391]   Time 0.222 (0.222)   Data 0.164 (0.164)   Loss 0.3977 (0.3977)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 01:31:43]
  Epoch: [029][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.4273 (0.3669)   Prec@1 83.594 (87.399)   Prec@5 99.219 (99.536)   [2019-11-22 01:31:48]
  Epoch: [029][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.4147 (0.3724)   Prec@1 85.938 (87.107)   Prec@5 100.000 (99.495)   [2019-11-22 01:31:53]
  Epoch: [029][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.4299 (0.3737)   Prec@1 88.281 (87.056)   Prec@5 99.219 (99.499)   [2019-11-22 01:31:57]
  **Train** Prec@1 86.984 Prec@5 99.482 Error@1 13.016
  **Test** Prec@1 84.910 Prec@5 99.330 Error@1 15.090
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:32:04] [Epoch=030/200] [Need: 01:02:10] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [030][000/391]   Time 0.222 (0.222)   Data 0.159 (0.159)   Loss 0.3994 (0.3994)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 01:32:04]
  Epoch: [030][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.3953 (0.3767)   Prec@1 85.156 (87.005)   Prec@5 99.219 (99.567)   [2019-11-22 01:32:09]
  Epoch: [030][200/391]   Time 0.067 (0.052)   Data 0.000 (0.001)   Loss 0.3544 (0.3781)   Prec@1 88.281 (87.139)   Prec@5 100.000 (99.522)   [2019-11-22 01:32:14]
  Epoch: [030][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4039 (0.3795)   Prec@1 85.938 (87.015)   Prec@5 99.219 (99.535)   [2019-11-22 01:32:19]
  **Train** Prec@1 86.852 Prec@5 99.544 Error@1 13.148
  **Test** Prec@1 84.390 Prec@5 99.490 Error@1 15.610

==>>[2019-11-22 01:32:26] [Epoch=031/200] [Need: 01:01:48] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [031][000/391]   Time 0.235 (0.235)   Data 0.177 (0.177)   Loss 0.3842 (0.3842)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-22 01:32:26]
  Epoch: [031][100/391]   Time 0.072 (0.057)   Data 0.000 (0.002)   Loss 0.2946 (0.3596)   Prec@1 89.844 (87.338)   Prec@5 100.000 (99.582)   [2019-11-22 01:32:32]
  Epoch: [031][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3016 (0.3687)   Prec@1 91.406 (87.076)   Prec@5 100.000 (99.565)   [2019-11-22 01:32:37]
  Epoch: [031][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.4239 (0.3706)   Prec@1 89.062 (87.093)   Prec@5 99.219 (99.587)   [2019-11-22 01:32:42]
  **Train** Prec@1 87.012 Prec@5 99.552 Error@1 12.988
  **Test** Prec@1 82.190 Prec@5 98.800 Error@1 17.810

==>>[2019-11-22 01:32:48] [Epoch=032/200] [Need: 01:01:27] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [032][000/391]   Time 0.221 (0.221)   Data 0.156 (0.156)   Loss 0.4035 (0.4035)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 01:32:48]
  Epoch: [032][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.5161 (0.3639)   Prec@1 86.719 (87.492)   Prec@5 100.000 (99.567)   [2019-11-22 01:32:54]
  Epoch: [032][200/391]   Time 0.063 (0.054)   Data 0.000 (0.001)   Loss 0.4008 (0.3655)   Prec@1 89.844 (87.442)   Prec@5 99.219 (99.541)   [2019-11-22 01:32:59]
  Epoch: [032][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.4216 (0.3699)   Prec@1 85.938 (87.298)   Prec@5 100.000 (99.504)   [2019-11-22 01:33:04]
  **Train** Prec@1 87.084 Prec@5 99.526 Error@1 12.916
  **Test** Prec@1 83.410 Prec@5 99.160 Error@1 16.590

==>>[2019-11-22 01:33:11] [Epoch=033/200] [Need: 01:01:09] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [033][000/391]   Time 0.220 (0.220)   Data 0.152 (0.152)   Loss 0.3504 (0.3504)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:33:11]
  Epoch: [033][100/391]   Time 0.041 (0.055)   Data 0.000 (0.002)   Loss 0.2943 (0.3516)   Prec@1 90.625 (87.554)   Prec@5 99.219 (99.652)   [2019-11-22 01:33:16]
  Epoch: [033][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.4006 (0.3634)   Prec@1 88.281 (87.290)   Prec@5 100.000 (99.654)   [2019-11-22 01:33:21]
  Epoch: [033][300/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.2875 (0.3634)   Prec@1 91.406 (87.370)   Prec@5 98.438 (99.608)   [2019-11-22 01:33:27]
  **Train** Prec@1 87.138 Prec@5 99.590 Error@1 12.862
  **Test** Prec@1 82.970 Prec@5 99.190 Error@1 17.030

==>>[2019-11-22 01:33:33] [Epoch=034/200] [Need: 01:00:49] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [034][000/391]   Time 0.226 (0.226)   Data 0.150 (0.150)   Loss 0.3806 (0.3806)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 01:33:33]
  Epoch: [034][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.3831 (0.3628)   Prec@1 85.938 (87.191)   Prec@5 99.219 (99.590)   [2019-11-22 01:33:38]
  Epoch: [034][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.4054 (0.3668)   Prec@1 82.812 (87.154)   Prec@5 100.000 (99.588)   [2019-11-22 01:33:44]
  Epoch: [034][300/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.4719 (0.3655)   Prec@1 85.156 (87.181)   Prec@5 99.219 (99.582)   [2019-11-22 01:33:49]
  **Train** Prec@1 87.190 Prec@5 99.574 Error@1 12.810
  **Test** Prec@1 82.530 Prec@5 99.100 Error@1 17.470

==>>[2019-11-22 01:33:56] [Epoch=035/200] [Need: 01:00:30] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [035][000/391]   Time 0.230 (0.230)   Data 0.173 (0.173)   Loss 0.2713 (0.2713)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 01:33:56]
  Epoch: [035][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.2605 (0.3395)   Prec@1 92.188 (88.057)   Prec@5 100.000 (99.606)   [2019-11-22 01:34:01]
  Epoch: [035][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3287 (0.3585)   Prec@1 87.500 (87.259)   Prec@5 99.219 (99.596)   [2019-11-22 01:34:06]
  Epoch: [035][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4743 (0.3577)   Prec@1 83.594 (87.456)   Prec@5 98.438 (99.572)   [2019-11-22 01:34:11]
  **Train** Prec@1 87.294 Prec@5 99.558 Error@1 12.706
  **Test** Prec@1 81.860 Prec@5 98.950 Error@1 18.140

==>>[2019-11-22 01:34:18] [Epoch=036/200] [Need: 01:00:08] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [036][000/391]   Time 0.202 (0.202)   Data 0.140 (0.140)   Loss 0.3412 (0.3412)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 01:34:18]
  Epoch: [036][100/391]   Time 0.061 (0.057)   Data 0.000 (0.002)   Loss 0.4421 (0.3656)   Prec@1 82.812 (87.500)   Prec@5 100.000 (99.474)   [2019-11-22 01:34:24]
  Epoch: [036][200/391]   Time 0.043 (0.056)   Data 0.000 (0.001)   Loss 0.2614 (0.3547)   Prec@1 92.188 (87.850)   Prec@5 100.000 (99.580)   [2019-11-22 01:34:29]
  Epoch: [036][300/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 0.3216 (0.3651)   Prec@1 88.281 (87.391)   Prec@5 100.000 (99.520)   [2019-11-22 01:34:34]
  **Train** Prec@1 87.370 Prec@5 99.518 Error@1 12.630
  **Test** Prec@1 84.200 Prec@5 99.170 Error@1 15.800

==>>[2019-11-22 01:34:40] [Epoch=037/200] [Need: 00:59:48] [LR=0.0100][M=0.90] [Best : Accuracy=84.91, Error=15.09]
  Epoch: [037][000/391]   Time 0.242 (0.242)   Data 0.179 (0.179)   Loss 0.3033 (0.3033)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:34:40]
  Epoch: [037][100/391]   Time 0.059 (0.054)   Data 0.000 (0.002)   Loss 0.2670 (0.3529)   Prec@1 91.406 (87.995)   Prec@5 100.000 (99.551)   [2019-11-22 01:34:46]
  Epoch: [037][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3159 (0.3550)   Prec@1 86.719 (87.807)   Prec@5 100.000 (99.588)   [2019-11-22 01:34:51]
  Epoch: [037][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3242 (0.3558)   Prec@1 86.719 (87.734)   Prec@5 100.000 (99.559)   [2019-11-22 01:34:56]
  **Train** Prec@1 87.666 Prec@5 99.548 Error@1 12.334
  **Test** Prec@1 85.050 Prec@5 99.350 Error@1 14.950
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:35:02] [Epoch=038/200] [Need: 00:59:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [038][000/391]   Time 0.226 (0.226)   Data 0.150 (0.150)   Loss 0.2589 (0.2589)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:35:03]
  Epoch: [038][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.2983 (0.3419)   Prec@1 89.062 (88.065)   Prec@5 99.219 (99.606)   [2019-11-22 01:35:08]
  Epoch: [038][200/391]   Time 0.086 (0.052)   Data 0.000 (0.001)   Loss 0.3349 (0.3507)   Prec@1 89.844 (87.741)   Prec@5 99.219 (99.627)   [2019-11-22 01:35:13]
  Epoch: [038][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3832 (0.3560)   Prec@1 85.156 (87.736)   Prec@5 100.000 (99.569)   [2019-11-22 01:35:17]
  **Train** Prec@1 87.592 Prec@5 99.530 Error@1 12.408
  **Test** Prec@1 83.900 Prec@5 99.400 Error@1 16.100

==>>[2019-11-22 01:35:24] [Epoch=039/200] [Need: 00:59:02] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [039][000/391]   Time 0.216 (0.216)   Data 0.159 (0.159)   Loss 0.3716 (0.3716)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2019-11-22 01:35:24]
  Epoch: [039][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3525 (0.3435)   Prec@1 89.062 (88.119)   Prec@5 98.438 (99.559)   [2019-11-22 01:35:29]
  Epoch: [039][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3168 (0.3462)   Prec@1 89.062 (87.928)   Prec@5 99.219 (99.584)   [2019-11-22 01:35:34]
  Epoch: [039][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.3271 (0.3520)   Prec@1 86.719 (87.643)   Prec@5 100.000 (99.598)   [2019-11-22 01:35:39]
  **Train** Prec@1 87.570 Prec@5 99.594 Error@1 12.430
  **Test** Prec@1 83.640 Prec@5 99.200 Error@1 16.360

==>>[2019-11-22 01:35:46] [Epoch=040/200] [Need: 00:58:40] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [040][000/391]   Time 0.220 (0.220)   Data 0.168 (0.168)   Loss 0.3114 (0.3114)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:35:46]
  Epoch: [040][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.3031 (0.3466)   Prec@1 90.625 (88.057)   Prec@5 100.000 (99.621)   [2019-11-22 01:35:51]
  Epoch: [040][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4525 (0.3592)   Prec@1 85.156 (87.644)   Prec@5 99.219 (99.619)   [2019-11-22 01:35:56]
  Epoch: [040][300/391]   Time 0.074 (0.052)   Data 0.000 (0.001)   Loss 0.3553 (0.3556)   Prec@1 86.719 (87.747)   Prec@5 100.000 (99.603)   [2019-11-22 01:36:01]
  **Train** Prec@1 87.822 Prec@5 99.614 Error@1 12.178
  **Test** Prec@1 84.640 Prec@5 99.310 Error@1 15.360

==>>[2019-11-22 01:36:08] [Epoch=041/200] [Need: 00:58:17] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [041][000/391]   Time 0.230 (0.230)   Data 0.174 (0.174)   Loss 0.3390 (0.3390)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:36:08]
  Epoch: [041][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.3904 (0.3559)   Prec@1 84.375 (87.577)   Prec@5 100.000 (99.606)   [2019-11-22 01:36:13]
  Epoch: [041][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.3678 (0.3549)   Prec@1 85.938 (87.807)   Prec@5 100.000 (99.580)   [2019-11-22 01:36:18]
  Epoch: [041][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.3816 (0.3571)   Prec@1 89.062 (87.721)   Prec@5 99.219 (99.618)   [2019-11-22 01:36:23]
  **Train** Prec@1 87.590 Prec@5 99.612 Error@1 12.410
  **Test** Prec@1 84.390 Prec@5 99.270 Error@1 15.610

==>>[2019-11-22 01:36:30] [Epoch=042/200] [Need: 00:57:56] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [042][000/391]   Time 0.219 (0.219)   Data 0.163 (0.163)   Loss 0.3492 (0.3492)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 01:36:30]
  Epoch: [042][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.3600 (0.3469)   Prec@1 91.406 (88.142)   Prec@5 100.000 (99.567)   [2019-11-22 01:36:35]
  Epoch: [042][200/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.3464 (0.3402)   Prec@1 85.938 (88.246)   Prec@5 100.000 (99.607)   [2019-11-22 01:36:40]
  Epoch: [042][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4100 (0.3464)   Prec@1 85.938 (87.991)   Prec@5 100.000 (99.603)   [2019-11-22 01:36:46]
  **Train** Prec@1 87.872 Prec@5 99.602 Error@1 12.128
  **Test** Prec@1 84.730 Prec@5 99.400 Error@1 15.270

==>>[2019-11-22 01:36:52] [Epoch=043/200] [Need: 00:57:35] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [043][000/391]   Time 0.228 (0.228)   Data 0.158 (0.158)   Loss 0.3049 (0.3049)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 01:36:52]
  Epoch: [043][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.2324 (0.3169)   Prec@1 89.062 (89.209)   Prec@5 100.000 (99.722)   [2019-11-22 01:36:57]
  Epoch: [043][200/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.2833 (0.3323)   Prec@1 92.188 (88.542)   Prec@5 99.219 (99.674)   [2019-11-22 01:37:03]
  Epoch: [043][300/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.3167 (0.3365)   Prec@1 89.062 (88.367)   Prec@5 100.000 (99.631)   [2019-11-22 01:37:08]
  **Train** Prec@1 88.166 Prec@5 99.606 Error@1 11.834
  **Test** Prec@1 84.270 Prec@5 99.280 Error@1 15.730

==>>[2019-11-22 01:37:14] [Epoch=044/200] [Need: 00:57:14] [LR=0.0100][M=0.90] [Best : Accuracy=85.05, Error=14.95]
  Epoch: [044][000/391]   Time 0.222 (0.222)   Data 0.147 (0.147)   Loss 0.3823 (0.3823)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 01:37:15]
  Epoch: [044][100/391]   Time 0.051 (0.057)   Data 0.000 (0.002)   Loss 0.4416 (0.3472)   Prec@1 85.156 (87.949)   Prec@5 100.000 (99.590)   [2019-11-22 01:37:20]
  Epoch: [044][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3063 (0.3477)   Prec@1 87.500 (87.935)   Prec@5 100.000 (99.619)   [2019-11-22 01:37:25]
  Epoch: [044][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4846 (0.3500)   Prec@1 88.281 (87.882)   Prec@5 99.219 (99.598)   [2019-11-22 01:37:30]
  **Train** Prec@1 87.870 Prec@5 99.592 Error@1 12.130
  **Test** Prec@1 85.510 Prec@5 99.290 Error@1 14.490
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:37:37] [Epoch=045/200] [Need: 00:56:53] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [045][000/391]   Time 0.211 (0.211)   Data 0.162 (0.162)   Loss 0.2946 (0.2946)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-22 01:37:37]
  Epoch: [045][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.4815 (0.3405)   Prec@1 84.375 (88.219)   Prec@5 99.219 (99.698)   [2019-11-22 01:37:42]
  Epoch: [045][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4057 (0.3429)   Prec@1 85.938 (88.122)   Prec@5 100.000 (99.650)   [2019-11-22 01:37:47]
  Epoch: [045][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.4271 (0.3447)   Prec@1 83.594 (88.045)   Prec@5 99.219 (99.650)   [2019-11-22 01:37:53]
  **Train** Prec@1 88.026 Prec@5 99.636 Error@1 11.974
  **Test** Prec@1 83.680 Prec@5 99.240 Error@1 16.320

==>>[2019-11-22 01:37:59] [Epoch=046/200] [Need: 00:56:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [046][000/391]   Time 0.229 (0.229)   Data 0.149 (0.149)   Loss 0.3701 (0.3701)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 01:37:59]
  Epoch: [046][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.2746 (0.3297)   Prec@1 89.844 (88.653)   Prec@5 99.219 (99.667)   [2019-11-22 01:38:04]
  Epoch: [046][200/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.3793 (0.3397)   Prec@1 89.062 (88.301)   Prec@5 97.656 (99.627)   [2019-11-22 01:38:09]
  Epoch: [046][300/391]   Time 0.062 (0.050)   Data 0.000 (0.001)   Loss 0.3733 (0.3363)   Prec@1 85.156 (88.359)   Prec@5 99.219 (99.634)   [2019-11-22 01:38:14]
  **Train** Prec@1 88.214 Prec@5 99.622 Error@1 11.786
  **Test** Prec@1 82.470 Prec@5 99.110 Error@1 17.530

==>>[2019-11-22 01:38:21] [Epoch=047/200] [Need: 00:56:08] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [047][000/391]   Time 0.227 (0.227)   Data 0.143 (0.143)   Loss 0.1397 (0.1397)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:38:21]
  Epoch: [047][100/391]   Time 0.089 (0.057)   Data 0.000 (0.002)   Loss 0.2596 (0.3269)   Prec@1 90.625 (88.235)   Prec@5 99.219 (99.667)   [2019-11-22 01:38:26]
  Epoch: [047][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3294 (0.3400)   Prec@1 86.719 (87.935)   Prec@5 100.000 (99.627)   [2019-11-22 01:38:31]
  Epoch: [047][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.2511 (0.3409)   Prec@1 92.188 (88.001)   Prec@5 100.000 (99.624)   [2019-11-22 01:38:36]
  **Train** Prec@1 87.870 Prec@5 99.604 Error@1 12.130
  **Test** Prec@1 83.280 Prec@5 99.320 Error@1 16.720

==>>[2019-11-22 01:38:43] [Epoch=048/200] [Need: 00:55:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [048][000/391]   Time 0.241 (0.241)   Data 0.186 (0.186)   Loss 0.2424 (0.2424)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 01:38:43]
  Epoch: [048][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3437 (0.3293)   Prec@1 85.156 (88.753)   Prec@5 99.219 (99.613)   [2019-11-22 01:38:48]
  Epoch: [048][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3993 (0.3361)   Prec@1 86.719 (88.390)   Prec@5 100.000 (99.627)   [2019-11-22 01:38:54]
  Epoch: [048][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.3695 (0.3415)   Prec@1 89.062 (88.242)   Prec@5 100.000 (99.595)   [2019-11-22 01:38:59]
  **Train** Prec@1 88.172 Prec@5 99.576 Error@1 11.828
  **Test** Prec@1 82.890 Prec@5 99.270 Error@1 17.110

==>>[2019-11-22 01:39:05] [Epoch=049/200] [Need: 00:55:27] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [049][000/391]   Time 0.246 (0.246)   Data 0.176 (0.176)   Loss 0.2857 (0.2857)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:39:06]
  Epoch: [049][100/391]   Time 0.047 (0.055)   Data 0.000 (0.002)   Loss 0.2637 (0.3351)   Prec@1 90.625 (88.250)   Prec@5 100.000 (99.636)   [2019-11-22 01:39:11]
  Epoch: [049][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.4268 (0.3377)   Prec@1 86.719 (88.231)   Prec@5 99.219 (99.623)   [2019-11-22 01:39:16]
  Epoch: [049][300/391]   Time 0.056 (0.053)   Data 0.000 (0.001)   Loss 0.3322 (0.3403)   Prec@1 89.062 (88.123)   Prec@5 100.000 (99.621)   [2019-11-22 01:39:21]
  **Train** Prec@1 88.020 Prec@5 99.630 Error@1 11.980
  **Test** Prec@1 85.300 Prec@5 99.470 Error@1 14.700

==>>[2019-11-22 01:39:28] [Epoch=050/200] [Need: 00:55:07] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [050][000/391]   Time 0.218 (0.218)   Data 0.160 (0.160)   Loss 0.2597 (0.2597)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:39:28]
  Epoch: [050][100/391]   Time 0.082 (0.056)   Data 0.000 (0.002)   Loss 0.2501 (0.3313)   Prec@1 90.625 (88.622)   Prec@5 99.219 (99.729)   [2019-11-22 01:39:34]
  Epoch: [050][200/391]   Time 0.045 (0.055)   Data 0.000 (0.001)   Loss 0.2048 (0.3372)   Prec@1 95.312 (88.378)   Prec@5 100.000 (99.689)   [2019-11-22 01:39:39]
  Epoch: [050][300/391]   Time 0.081 (0.054)   Data 0.000 (0.001)   Loss 0.3723 (0.3370)   Prec@1 88.281 (88.333)   Prec@5 99.219 (99.652)   [2019-11-22 01:39:44]
  **Train** Prec@1 88.236 Prec@5 99.630 Error@1 11.764
  **Test** Prec@1 82.130 Prec@5 99.300 Error@1 17.870

==>>[2019-11-22 01:39:51] [Epoch=051/200] [Need: 00:54:47] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [051][000/391]   Time 0.221 (0.221)   Data 0.167 (0.167)   Loss 0.2620 (0.2620)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 01:39:51]
  Epoch: [051][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3976 (0.3255)   Prec@1 82.031 (88.683)   Prec@5 100.000 (99.683)   [2019-11-22 01:39:56]
  Epoch: [051][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.2501 (0.3295)   Prec@1 91.406 (88.674)   Prec@5 100.000 (99.650)   [2019-11-22 01:40:01]
  Epoch: [051][300/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.3196 (0.3329)   Prec@1 89.062 (88.507)   Prec@5 100.000 (99.631)   [2019-11-22 01:40:07]
  **Train** Prec@1 88.344 Prec@5 99.610 Error@1 11.656
  **Test** Prec@1 82.310 Prec@5 99.260 Error@1 17.690

==>>[2019-11-22 01:40:13] [Epoch=052/200] [Need: 00:54:25] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [052][000/391]   Time 0.228 (0.228)   Data 0.165 (0.165)   Loss 0.3945 (0.3945)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 01:40:13]
  Epoch: [052][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.3193 (0.3290)   Prec@1 86.719 (88.506)   Prec@5 100.000 (99.683)   [2019-11-22 01:40:19]
  Epoch: [052][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3691 (0.3422)   Prec@1 85.156 (88.005)   Prec@5 100.000 (99.639)   [2019-11-22 01:40:24]
  Epoch: [052][300/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.3157 (0.3361)   Prec@1 87.500 (88.263)   Prec@5 100.000 (99.650)   [2019-11-22 01:40:29]
  **Train** Prec@1 88.218 Prec@5 99.620 Error@1 11.782
  **Test** Prec@1 82.590 Prec@5 98.750 Error@1 17.410

==>>[2019-11-22 01:40:36] [Epoch=053/200] [Need: 00:54:06] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [053][000/391]   Time 0.229 (0.229)   Data 0.149 (0.149)   Loss 0.2558 (0.2558)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:40:36]
  Epoch: [053][100/391]   Time 0.049 (0.055)   Data 0.000 (0.002)   Loss 0.2675 (0.3249)   Prec@1 89.844 (88.753)   Prec@5 100.000 (99.636)   [2019-11-22 01:40:42]
  Epoch: [053][200/391]   Time 0.083 (0.054)   Data 0.000 (0.001)   Loss 0.2158 (0.3324)   Prec@1 92.969 (88.460)   Prec@5 99.219 (99.646)   [2019-11-22 01:40:47]
  Epoch: [053][300/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.4491 (0.3357)   Prec@1 87.500 (88.349)   Prec@5 100.000 (99.644)   [2019-11-22 01:40:52]
  **Train** Prec@1 88.184 Prec@5 99.646 Error@1 11.816
  **Test** Prec@1 82.380 Prec@5 99.020 Error@1 17.620

==>>[2019-11-22 01:40:59] [Epoch=054/200] [Need: 00:53:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [054][000/391]   Time 0.239 (0.239)   Data 0.173 (0.173)   Loss 0.2857 (0.2857)   Prec@1 89.844 (89.844)   Prec@5 98.438 (98.438)   [2019-11-22 01:40:59]
  Epoch: [054][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.3330 (0.3191)   Prec@1 85.938 (89.093)   Prec@5 99.219 (99.652)   [2019-11-22 01:41:04]
  Epoch: [054][200/391]   Time 0.068 (0.054)   Data 0.000 (0.001)   Loss 0.3421 (0.3223)   Prec@1 86.719 (88.911)   Prec@5 100.000 (99.627)   [2019-11-22 01:41:10]
  Epoch: [054][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4412 (0.3356)   Prec@1 83.594 (88.466)   Prec@5 99.219 (99.593)   [2019-11-22 01:41:15]
  **Train** Prec@1 88.438 Prec@5 99.584 Error@1 11.562
  **Test** Prec@1 84.260 Prec@5 99.290 Error@1 15.740

==>>[2019-11-22 01:41:21] [Epoch=055/200] [Need: 00:53:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [055][000/391]   Time 0.228 (0.228)   Data 0.166 (0.166)   Loss 0.3393 (0.3393)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 01:41:21]
  Epoch: [055][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.3884 (0.3222)   Prec@1 86.719 (89.233)   Prec@5 99.219 (99.729)   [2019-11-22 01:41:27]
  Epoch: [055][200/391]   Time 0.046 (0.055)   Data 0.000 (0.001)   Loss 0.2944 (0.3220)   Prec@1 89.844 (89.008)   Prec@5 100.000 (99.693)   [2019-11-22 01:41:32]
  Epoch: [055][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.3372 (0.3278)   Prec@1 90.625 (88.754)   Prec@5 99.219 (99.686)   [2019-11-22 01:41:37]
  **Train** Prec@1 88.632 Prec@5 99.686 Error@1 11.368
  **Test** Prec@1 85.440 Prec@5 99.410 Error@1 14.560

==>>[2019-11-22 01:41:44] [Epoch=056/200] [Need: 00:53:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [056][000/391]   Time 0.226 (0.226)   Data 0.155 (0.155)   Loss 0.2632 (0.2632)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 01:41:44]
  Epoch: [056][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.2751 (0.3203)   Prec@1 88.281 (88.946)   Prec@5 100.000 (99.752)   [2019-11-22 01:41:49]
  Epoch: [056][200/391]   Time 0.068 (0.054)   Data 0.000 (0.001)   Loss 0.3827 (0.3257)   Prec@1 87.500 (88.763)   Prec@5 100.000 (99.712)   [2019-11-22 01:41:55]
  Epoch: [056][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.2905 (0.3332)   Prec@1 90.625 (88.510)   Prec@5 100.000 (99.678)   [2019-11-22 01:41:59]
  **Train** Prec@1 88.536 Prec@5 99.662 Error@1 11.464
  **Test** Prec@1 83.910 Prec@5 99.120 Error@1 16.090

==>>[2019-11-22 01:42:06] [Epoch=057/200] [Need: 00:52:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [057][000/391]   Time 0.219 (0.219)   Data 0.160 (0.160)   Loss 0.2754 (0.2754)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:42:07]
  Epoch: [057][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.3738 (0.3133)   Prec@1 87.500 (89.341)   Prec@5 99.219 (99.629)   [2019-11-22 01:42:12]
  Epoch: [057][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.3202 (0.3223)   Prec@1 89.062 (88.934)   Prec@5 99.219 (99.674)   [2019-11-22 01:42:17]
  Epoch: [057][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4019 (0.3269)   Prec@1 84.375 (88.847)   Prec@5 99.219 (99.631)   [2019-11-22 01:42:22]
  **Train** Prec@1 88.704 Prec@5 99.604 Error@1 11.296
  **Test** Prec@1 84.790 Prec@5 99.320 Error@1 15.210

==>>[2019-11-22 01:42:28] [Epoch=058/200] [Need: 00:52:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [058][000/391]   Time 0.221 (0.221)   Data 0.163 (0.163)   Loss 0.3161 (0.3161)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 01:42:29]
  Epoch: [058][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.2960 (0.3001)   Prec@1 92.188 (89.403)   Prec@5 99.219 (99.714)   [2019-11-22 01:42:34]
  Epoch: [058][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3479 (0.3117)   Prec@1 89.062 (89.136)   Prec@5 100.000 (99.732)   [2019-11-22 01:42:39]
  Epoch: [058][300/391]   Time 0.086 (0.052)   Data 0.000 (0.001)   Loss 0.2616 (0.3195)   Prec@1 90.625 (88.928)   Prec@5 99.219 (99.709)   [2019-11-22 01:42:44]
  **Train** Prec@1 88.712 Prec@5 99.680 Error@1 11.288
  **Test** Prec@1 84.070 Prec@5 99.440 Error@1 15.930

==>>[2019-11-22 01:42:50] [Epoch=059/200] [Need: 00:51:58] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [059][000/391]   Time 0.245 (0.245)   Data 0.185 (0.185)   Loss 0.4056 (0.4056)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 01:42:51]
  Epoch: [059][100/391]   Time 0.039 (0.051)   Data 0.000 (0.002)   Loss 0.2720 (0.3206)   Prec@1 92.188 (88.676)   Prec@5 100.000 (99.737)   [2019-11-22 01:42:56]
  Epoch: [059][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.4768 (0.3184)   Prec@1 85.938 (88.775)   Prec@5 98.438 (99.720)   [2019-11-22 01:43:01]
  Epoch: [059][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.3822 (0.3269)   Prec@1 89.844 (88.621)   Prec@5 100.000 (99.699)   [2019-11-22 01:43:06]
  **Train** Prec@1 88.462 Prec@5 99.680 Error@1 11.538
  **Test** Prec@1 84.040 Prec@5 99.340 Error@1 15.960

==>>[2019-11-22 01:43:12] [Epoch=060/200] [Need: 00:51:34] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [060][000/391]   Time 0.227 (0.227)   Data 0.149 (0.149)   Loss 0.2938 (0.2938)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 01:43:12]
  Epoch: [060][100/391]   Time 0.057 (0.055)   Data 0.000 (0.002)   Loss 0.4083 (0.3200)   Prec@1 82.812 (89.008)   Prec@5 100.000 (99.714)   [2019-11-22 01:43:18]
  Epoch: [060][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.2886 (0.3186)   Prec@1 87.500 (88.930)   Prec@5 100.000 (99.708)   [2019-11-22 01:43:22]
  Epoch: [060][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.2955 (0.3217)   Prec@1 88.281 (88.816)   Prec@5 100.000 (99.678)   [2019-11-22 01:43:28]
  **Train** Prec@1 88.586 Prec@5 99.660 Error@1 11.414
  **Test** Prec@1 85.030 Prec@5 99.420 Error@1 14.970

==>>[2019-11-22 01:43:34] [Epoch=061/200] [Need: 00:51:12] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [061][000/391]   Time 0.238 (0.238)   Data 0.180 (0.180)   Loss 0.3545 (0.3545)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:43:34]
  Epoch: [061][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.2430 (0.3128)   Prec@1 92.188 (89.179)   Prec@5 100.000 (99.706)   [2019-11-22 01:43:40]
  Epoch: [061][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.4115 (0.3205)   Prec@1 85.938 (88.926)   Prec@5 100.000 (99.681)   [2019-11-22 01:43:45]
  Epoch: [061][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3755 (0.3236)   Prec@1 85.938 (88.953)   Prec@5 99.219 (99.624)   [2019-11-22 01:43:50]
  **Train** Prec@1 88.890 Prec@5 99.640 Error@1 11.110
  **Test** Prec@1 85.420 Prec@5 99.270 Error@1 14.580

==>>[2019-11-22 01:43:56] [Epoch=062/200] [Need: 00:50:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [062][000/391]   Time 0.224 (0.224)   Data 0.152 (0.152)   Loss 0.2363 (0.2363)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:43:56]
  Epoch: [062][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4458 (0.3178)   Prec@1 82.031 (89.032)   Prec@5 100.000 (99.729)   [2019-11-22 01:44:01]
  Epoch: [062][200/391]   Time 0.040 (0.053)   Data 0.000 (0.001)   Loss 0.2437 (0.3248)   Prec@1 90.625 (88.662)   Prec@5 100.000 (99.716)   [2019-11-22 01:44:07]
  Epoch: [062][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.2764 (0.3248)   Prec@1 89.062 (88.733)   Prec@5 100.000 (99.665)   [2019-11-22 01:44:12]
  **Train** Prec@1 88.718 Prec@5 99.654 Error@1 11.282
  **Test** Prec@1 83.770 Prec@5 99.210 Error@1 16.230

==>>[2019-11-22 01:44:18] [Epoch=063/200] [Need: 00:50:28] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [063][000/391]   Time 0.218 (0.218)   Data 0.161 (0.161)   Loss 0.2696 (0.2696)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 01:44:18]
  Epoch: [063][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.2672 (0.3135)   Prec@1 89.062 (88.993)   Prec@5 100.000 (99.667)   [2019-11-22 01:44:23]
  Epoch: [063][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3925 (0.3255)   Prec@1 85.938 (88.518)   Prec@5 98.438 (99.674)   [2019-11-22 01:44:29]
  Epoch: [063][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.3465 (0.3260)   Prec@1 85.938 (88.517)   Prec@5 99.219 (99.673)   [2019-11-22 01:44:34]
  **Train** Prec@1 88.396 Prec@5 99.646 Error@1 11.604
  **Test** Prec@1 85.510 Prec@5 99.350 Error@1 14.490

==>>[2019-11-22 01:44:40] [Epoch=064/200] [Need: 00:50:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [064][000/391]   Time 0.224 (0.224)   Data 0.159 (0.159)   Loss 0.3637 (0.3637)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:44:40]
  Epoch: [064][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.3611 (0.3134)   Prec@1 89.062 (89.233)   Prec@5 100.000 (99.853)   [2019-11-22 01:44:45]
  Epoch: [064][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2080 (0.3145)   Prec@1 91.406 (89.113)   Prec@5 100.000 (99.778)   [2019-11-22 01:44:50]
  Epoch: [064][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.4898 (0.3215)   Prec@1 84.375 (88.909)   Prec@5 99.219 (99.730)   [2019-11-22 01:44:56]
  **Train** Prec@1 88.810 Prec@5 99.706 Error@1 11.190
  **Test** Prec@1 83.240 Prec@5 99.210 Error@1 16.760

==>>[2019-11-22 01:45:02] [Epoch=065/200] [Need: 00:49:44] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [065][000/391]   Time 0.219 (0.219)   Data 0.150 (0.150)   Loss 0.2896 (0.2896)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 01:45:03]
  Epoch: [065][100/391]   Time 0.055 (0.050)   Data 0.000 (0.002)   Loss 0.3072 (0.3213)   Prec@1 88.281 (88.830)   Prec@5 100.000 (99.691)   [2019-11-22 01:45:08]
  Epoch: [065][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.2932 (0.3182)   Prec@1 92.188 (89.113)   Prec@5 100.000 (99.708)   [2019-11-22 01:45:13]
  Epoch: [065][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.2891 (0.3229)   Prec@1 90.625 (88.933)   Prec@5 100.000 (99.694)   [2019-11-22 01:45:18]
  **Train** Prec@1 88.930 Prec@5 99.678 Error@1 11.070
  **Test** Prec@1 84.640 Prec@5 99.450 Error@1 15.360

==>>[2019-11-22 01:45:24] [Epoch=066/200] [Need: 00:49:21] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [066][000/391]   Time 0.213 (0.213)   Data 0.140 (0.140)   Loss 0.3234 (0.3234)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 01:45:25]
  Epoch: [066][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.3598 (0.3121)   Prec@1 89.844 (88.815)   Prec@5 100.000 (99.768)   [2019-11-22 01:45:30]
  Epoch: [066][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.3767 (0.3120)   Prec@1 84.375 (88.903)   Prec@5 100.000 (99.708)   [2019-11-22 01:45:35]
  Epoch: [066][300/391]   Time 0.067 (0.052)   Data 0.000 (0.001)   Loss 0.2825 (0.3148)   Prec@1 92.969 (88.912)   Prec@5 100.000 (99.676)   [2019-11-22 01:45:40]
  **Train** Prec@1 88.900 Prec@5 99.680 Error@1 11.100
  **Test** Prec@1 84.310 Prec@5 99.320 Error@1 15.690

==>>[2019-11-22 01:45:46] [Epoch=067/200] [Need: 00:48:58] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [067][000/391]   Time 0.213 (0.213)   Data 0.146 (0.146)   Loss 0.2736 (0.2736)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 01:45:46]
  Epoch: [067][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.2634 (0.3068)   Prec@1 90.625 (89.248)   Prec@5 100.000 (99.683)   [2019-11-22 01:45:51]
  Epoch: [067][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.2588 (0.3223)   Prec@1 91.406 (88.740)   Prec@5 100.000 (99.619)   [2019-11-22 01:45:57]
  Epoch: [067][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3650 (0.3225)   Prec@1 89.062 (88.787)   Prec@5 100.000 (99.660)   [2019-11-22 01:46:01]
  **Train** Prec@1 88.700 Prec@5 99.648 Error@1 11.300
  **Test** Prec@1 84.870 Prec@5 99.240 Error@1 15.130

==>>[2019-11-22 01:46:08] [Epoch=068/200] [Need: 00:48:37] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [068][000/391]   Time 0.222 (0.222)   Data 0.157 (0.157)   Loss 0.2489 (0.2489)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 01:46:09]
  Epoch: [068][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.3180 (0.3173)   Prec@1 87.500 (88.970)   Prec@5 100.000 (99.745)   [2019-11-22 01:46:14]
  Epoch: [068][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.5450 (0.3159)   Prec@1 82.031 (88.946)   Prec@5 99.219 (99.743)   [2019-11-22 01:46:19]
  Epoch: [068][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.1743 (0.3189)   Prec@1 96.094 (88.891)   Prec@5 100.000 (99.727)   [2019-11-22 01:46:24]
  **Train** Prec@1 88.746 Prec@5 99.714 Error@1 11.254
  **Test** Prec@1 84.180 Prec@5 99.420 Error@1 15.820

==>>[2019-11-22 01:46:30] [Epoch=069/200] [Need: 00:48:14] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [069][000/391]   Time 0.220 (0.220)   Data 0.147 (0.147)   Loss 0.1382 (0.1382)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-22 01:46:30]
  Epoch: [069][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.2525 (0.3101)   Prec@1 92.188 (89.093)   Prec@5 100.000 (99.737)   [2019-11-22 01:46:35]
  Epoch: [069][200/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.2890 (0.3195)   Prec@1 91.406 (88.794)   Prec@5 98.438 (99.654)   [2019-11-22 01:46:40]
  Epoch: [069][300/391]   Time 0.058 (0.050)   Data 0.000 (0.001)   Loss 0.2777 (0.3175)   Prec@1 88.281 (88.813)   Prec@5 99.219 (99.629)   [2019-11-22 01:46:45]
  **Train** Prec@1 88.744 Prec@5 99.628 Error@1 11.256
  **Test** Prec@1 81.510 Prec@5 98.970 Error@1 18.490

==>>[2019-11-22 01:46:52] [Epoch=070/200] [Need: 00:47:51] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [070][000/391]   Time 0.228 (0.228)   Data 0.162 (0.162)   Loss 0.3379 (0.3379)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 01:46:52]
  Epoch: [070][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1833 (0.2905)   Prec@1 92.969 (89.983)   Prec@5 100.000 (99.776)   [2019-11-22 01:46:57]
  Epoch: [070][200/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.3918 (0.3081)   Prec@1 85.938 (89.323)   Prec@5 100.000 (99.716)   [2019-11-22 01:47:02]
  Epoch: [070][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.3645 (0.3167)   Prec@1 86.719 (89.024)   Prec@5 100.000 (99.699)   [2019-11-22 01:47:07]
  **Train** Prec@1 88.910 Prec@5 99.710 Error@1 11.090
  **Test** Prec@1 85.120 Prec@5 99.370 Error@1 14.880

==>>[2019-11-22 01:47:14] [Epoch=071/200] [Need: 00:47:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.51, Error=14.49]
  Epoch: [071][000/391]   Time 0.233 (0.233)   Data 0.175 (0.175)   Loss 0.2797 (0.2797)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 01:47:14]
  Epoch: [071][100/391]   Time 0.039 (0.052)   Data 0.000 (0.002)   Loss 0.3572 (0.3182)   Prec@1 85.938 (88.830)   Prec@5 100.000 (99.652)   [2019-11-22 01:47:19]
  Epoch: [071][200/391]   Time 0.076 (0.053)   Data 0.000 (0.001)   Loss 0.2937 (0.3141)   Prec@1 90.625 (89.028)   Prec@5 100.000 (99.662)   [2019-11-22 01:47:24]
  Epoch: [071][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2289 (0.3199)   Prec@1 93.750 (88.777)   Prec@5 100.000 (99.644)   [2019-11-22 01:47:30]
  **Train** Prec@1 88.744 Prec@5 99.642 Error@1 11.256
  **Test** Prec@1 85.950 Prec@5 99.580 Error@1 14.050
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:47:36] [Epoch=072/200] [Need: 00:47:07] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [072][000/391]   Time 0.233 (0.233)   Data 0.175 (0.175)   Loss 0.2755 (0.2755)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 01:47:36]
  Epoch: [072][100/391]   Time 0.077 (0.053)   Data 0.000 (0.002)   Loss 0.4322 (0.2928)   Prec@1 85.156 (89.573)   Prec@5 99.219 (99.706)   [2019-11-22 01:47:41]
  Epoch: [072][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.2657 (0.3012)   Prec@1 89.844 (89.463)   Prec@5 100.000 (99.685)   [2019-11-22 01:47:46]
  Epoch: [072][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.3736 (0.3124)   Prec@1 85.938 (89.088)   Prec@5 100.000 (99.670)   [2019-11-22 01:47:51]
  **Train** Prec@1 88.990 Prec@5 99.688 Error@1 11.010
  **Test** Prec@1 83.220 Prec@5 98.710 Error@1 16.780

==>>[2019-11-22 01:47:58] [Epoch=073/200] [Need: 00:46:44] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [073][000/391]   Time 0.222 (0.222)   Data 0.157 (0.157)   Loss 0.3331 (0.3331)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 01:47:58]
  Epoch: [073][100/391]   Time 0.050 (0.050)   Data 0.000 (0.002)   Loss 0.3924 (0.3030)   Prec@1 84.375 (89.565)   Prec@5 99.219 (99.783)   [2019-11-22 01:48:03]
  Epoch: [073][200/391]   Time 0.062 (0.051)   Data 0.000 (0.001)   Loss 0.2384 (0.3200)   Prec@1 89.062 (88.919)   Prec@5 100.000 (99.689)   [2019-11-22 01:48:08]
  Epoch: [073][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.2734 (0.3148)   Prec@1 90.625 (89.086)   Prec@5 100.000 (99.686)   [2019-11-22 01:48:13]
  **Train** Prec@1 89.116 Prec@5 99.704 Error@1 10.884
  **Test** Prec@1 84.690 Prec@5 99.560 Error@1 15.310

==>>[2019-11-22 01:48:20] [Epoch=074/200] [Need: 00:46:22] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [074][000/391]   Time 0.231 (0.231)   Data 0.174 (0.174)   Loss 0.3441 (0.3441)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:48:20]
  Epoch: [074][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.3594 (0.2969)   Prec@1 88.281 (89.426)   Prec@5 100.000 (99.675)   [2019-11-22 01:48:25]
  Epoch: [074][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.3834 (0.3064)   Prec@1 89.062 (89.101)   Prec@5 99.219 (99.740)   [2019-11-22 01:48:30]
  Epoch: [074][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4421 (0.3112)   Prec@1 83.594 (88.987)   Prec@5 99.219 (99.702)   [2019-11-22 01:48:35]
  **Train** Prec@1 88.970 Prec@5 99.704 Error@1 11.030
  **Test** Prec@1 83.550 Prec@5 99.260 Error@1 16.450

==>>[2019-11-22 01:48:42] [Epoch=075/200] [Need: 00:45:59] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [075][000/391]   Time 0.226 (0.226)   Data 0.166 (0.166)   Loss 0.2297 (0.2297)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 01:48:42]
  Epoch: [075][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.2693 (0.2957)   Prec@1 89.844 (89.689)   Prec@5 100.000 (99.822)   [2019-11-22 01:48:47]
  Epoch: [075][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.3343 (0.3005)   Prec@1 89.844 (89.541)   Prec@5 100.000 (99.794)   [2019-11-22 01:48:52]
  Epoch: [075][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.3695 (0.3112)   Prec@1 85.938 (89.301)   Prec@5 99.219 (99.722)   [2019-11-22 01:48:57]
  **Train** Prec@1 89.266 Prec@5 99.688 Error@1 10.734
  **Test** Prec@1 85.000 Prec@5 99.500 Error@1 15.000

==>>[2019-11-22 01:49:04] [Epoch=076/200] [Need: 00:45:38] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [076][000/391]   Time 0.233 (0.233)   Data 0.176 (0.176)   Loss 0.3537 (0.3537)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 01:49:04]
  Epoch: [076][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3604 (0.3095)   Prec@1 86.719 (89.140)   Prec@5 100.000 (99.691)   [2019-11-22 01:49:10]
  Epoch: [076][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.3018 (0.3155)   Prec@1 92.188 (88.985)   Prec@5 99.219 (99.674)   [2019-11-22 01:49:14]
  Epoch: [076][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.4218 (0.3111)   Prec@1 85.938 (89.104)   Prec@5 99.219 (99.665)   [2019-11-22 01:49:19]
  **Train** Prec@1 89.044 Prec@5 99.668 Error@1 10.956
  **Test** Prec@1 83.550 Prec@5 99.490 Error@1 16.450

==>>[2019-11-22 01:49:26] [Epoch=077/200] [Need: 00:45:16] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [077][000/391]   Time 0.213 (0.213)   Data 0.147 (0.147)   Loss 0.2147 (0.2147)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:49:26]
  Epoch: [077][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3374 (0.3107)   Prec@1 88.281 (89.132)   Prec@5 100.000 (99.737)   [2019-11-22 01:49:31]
  Epoch: [077][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3771 (0.3043)   Prec@1 87.500 (89.401)   Prec@5 100.000 (99.743)   [2019-11-22 01:49:36]
  Epoch: [077][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3661 (0.3082)   Prec@1 86.719 (89.234)   Prec@5 100.000 (99.761)   [2019-11-22 01:49:42]
  **Train** Prec@1 89.098 Prec@5 99.746 Error@1 10.902
  **Test** Prec@1 85.570 Prec@5 99.210 Error@1 14.430

==>>[2019-11-22 01:49:48] [Epoch=078/200] [Need: 00:44:54] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [078][000/391]   Time 0.239 (0.239)   Data 0.159 (0.159)   Loss 0.2640 (0.2640)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-22 01:49:48]
  Epoch: [078][100/391]   Time 0.055 (0.053)   Data 0.000 (0.002)   Loss 0.3549 (0.2913)   Prec@1 87.500 (89.581)   Prec@5 100.000 (99.745)   [2019-11-22 01:49:53]
  Epoch: [078][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2461 (0.3091)   Prec@1 91.406 (88.996)   Prec@5 99.219 (99.693)   [2019-11-22 01:49:59]
  Epoch: [078][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.2646 (0.3091)   Prec@1 90.625 (89.153)   Prec@5 100.000 (99.696)   [2019-11-22 01:50:04]
  **Train** Prec@1 89.112 Prec@5 99.692 Error@1 10.888
  **Test** Prec@1 85.400 Prec@5 99.390 Error@1 14.600

==>>[2019-11-22 01:50:10] [Epoch=079/200] [Need: 00:44:31] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [079][000/391]   Time 0.229 (0.229)   Data 0.147 (0.147)   Loss 0.2519 (0.2519)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 01:50:10]
  Epoch: [079][100/391]   Time 0.082 (0.057)   Data 0.000 (0.002)   Loss 0.4703 (0.3028)   Prec@1 83.594 (89.356)   Prec@5 98.438 (99.706)   [2019-11-22 01:50:16]
  Epoch: [079][200/391]   Time 0.044 (0.055)   Data 0.000 (0.001)   Loss 0.3787 (0.3048)   Prec@1 88.281 (89.420)   Prec@5 100.000 (99.712)   [2019-11-22 01:50:21]
  Epoch: [079][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2296 (0.3117)   Prec@1 92.969 (89.192)   Prec@5 100.000 (99.696)   [2019-11-22 01:50:26]
  **Train** Prec@1 89.028 Prec@5 99.650 Error@1 10.972
  **Test** Prec@1 83.920 Prec@5 99.510 Error@1 16.080

==>>[2019-11-22 01:50:33] [Epoch=080/200] [Need: 00:44:11] [LR=0.0010][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [080][000/391]   Time 0.248 (0.248)   Data 0.163 (0.163)   Loss 0.4227 (0.4227)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 01:50:33]
  Epoch: [080][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3524 (0.2583)   Prec@1 89.062 (91.290)   Prec@5 99.219 (99.760)   [2019-11-22 01:50:38]
  Epoch: [080][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.1835 (0.2398)   Prec@1 92.969 (91.810)   Prec@5 100.000 (99.786)   [2019-11-22 01:50:43]
  Epoch: [080][300/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.2434 (0.2314)   Prec@1 92.188 (92.050)   Prec@5 100.000 (99.826)   [2019-11-22 01:50:48]
  **Train** Prec@1 92.246 Prec@5 99.822 Error@1 7.754
  **Test** Prec@1 89.690 Prec@5 99.740 Error@1 10.310
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:50:55] [Epoch=081/200] [Need: 00:43:48] [LR=0.0010][M=0.90] [Best : Accuracy=89.69, Error=10.31]
  Epoch: [081][000/391]   Time 0.226 (0.226)   Data 0.149 (0.149)   Loss 0.2127 (0.2127)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 01:50:55]
  Epoch: [081][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.1803 (0.1888)   Prec@1 94.531 (93.549)   Prec@5 100.000 (99.884)   [2019-11-22 01:51:00]
  Epoch: [081][200/391]   Time 0.061 (0.050)   Data 0.000 (0.001)   Loss 0.2759 (0.1896)   Prec@1 92.969 (93.455)   Prec@5 100.000 (99.872)   [2019-11-22 01:51:05]
  Epoch: [081][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1595 (0.1900)   Prec@1 94.531 (93.433)   Prec@5 100.000 (99.875)   [2019-11-22 01:51:10]
  **Train** Prec@1 93.326 Prec@5 99.874 Error@1 6.674
  **Test** Prec@1 89.810 Prec@5 99.760 Error@1 10.190
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:51:16] [Epoch=082/200] [Need: 00:43:25] [LR=0.0010][M=0.90] [Best : Accuracy=89.81, Error=10.19]
  Epoch: [082][000/391]   Time 0.233 (0.233)   Data 0.154 (0.154)   Loss 0.1390 (0.1390)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:51:17]
  Epoch: [082][100/391]   Time 0.054 (0.054)   Data 0.000 (0.002)   Loss 0.3168 (0.1740)   Prec@1 89.062 (93.974)   Prec@5 100.000 (99.923)   [2019-11-22 01:51:22]
  Epoch: [082][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1830 (0.1784)   Prec@1 93.750 (93.909)   Prec@5 100.000 (99.887)   [2019-11-22 01:51:27]
  Epoch: [082][300/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.1489 (0.1794)   Prec@1 95.312 (93.888)   Prec@5 100.000 (99.896)   [2019-11-22 01:51:32]
  **Train** Prec@1 93.890 Prec@5 99.910 Error@1 6.110
  **Test** Prec@1 89.920 Prec@5 99.790 Error@1 10.080
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:51:38] [Epoch=083/200] [Need: 00:43:03] [LR=0.0010][M=0.90] [Best : Accuracy=89.92, Error=10.08]
  Epoch: [083][000/391]   Time 0.222 (0.222)   Data 0.150 (0.150)   Loss 0.1528 (0.1528)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 01:51:39]
  Epoch: [083][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.0893 (0.1677)   Prec@1 96.094 (94.222)   Prec@5 100.000 (99.899)   [2019-11-22 01:51:44]
  Epoch: [083][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2166 (0.1696)   Prec@1 92.188 (94.150)   Prec@5 100.000 (99.891)   [2019-11-22 01:51:48]
  Epoch: [083][300/391]   Time 0.051 (0.049)   Data 0.000 (0.001)   Loss 0.2144 (0.1702)   Prec@1 94.531 (94.173)   Prec@5 98.438 (99.904)   [2019-11-22 01:51:53]
  **Train** Prec@1 94.094 Prec@5 99.904 Error@1 5.906
  **Test** Prec@1 90.080 Prec@5 99.790 Error@1 9.920
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:52:00] [Epoch=084/200] [Need: 00:42:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.08, Error=9.92]
  Epoch: [084][000/391]   Time 0.235 (0.235)   Data 0.149 (0.149)   Loss 0.1493 (0.1493)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 01:52:00]
  Epoch: [084][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1195 (0.1588)   Prec@1 96.875 (94.678)   Prec@5 99.219 (99.938)   [2019-11-22 01:52:05]
  Epoch: [084][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1751 (0.1618)   Prec@1 96.094 (94.450)   Prec@5 100.000 (99.907)   [2019-11-22 01:52:10]
  Epoch: [084][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2546 (0.1620)   Prec@1 92.188 (94.422)   Prec@5 100.000 (99.901)   [2019-11-22 01:52:15]
  **Train** Prec@1 94.282 Prec@5 99.906 Error@1 5.718
  **Test** Prec@1 89.980 Prec@5 99.720 Error@1 10.020

==>>[2019-11-22 01:52:22] [Epoch=085/200] [Need: 00:42:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.08, Error=9.92]
  Epoch: [085][000/391]   Time 0.221 (0.221)   Data 0.162 (0.162)   Loss 0.1421 (0.1421)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:52:22]
  Epoch: [085][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.1141 (0.1600)   Prec@1 96.094 (94.562)   Prec@5 100.000 (99.961)   [2019-11-22 01:52:27]
  Epoch: [085][200/391]   Time 0.059 (0.054)   Data 0.000 (0.001)   Loss 0.1007 (0.1560)   Prec@1 97.656 (94.597)   Prec@5 100.000 (99.949)   [2019-11-22 01:52:33]
  Epoch: [085][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.1015 (0.1586)   Prec@1 96.875 (94.490)   Prec@5 100.000 (99.933)   [2019-11-22 01:52:38]
  **Train** Prec@1 94.502 Prec@5 99.922 Error@1 5.498
  **Test** Prec@1 90.350 Prec@5 99.750 Error@1 9.650
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:52:44] [Epoch=086/200] [Need: 00:41:56] [LR=0.0010][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [086][000/391]   Time 0.242 (0.242)   Data 0.178 (0.178)   Loss 0.1680 (0.1680)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:52:44]
  Epoch: [086][100/391]   Time 0.045 (0.057)   Data 0.000 (0.002)   Loss 0.1564 (0.1409)   Prec@1 94.531 (95.150)   Prec@5 100.000 (99.985)   [2019-11-22 01:52:50]
  Epoch: [086][200/391]   Time 0.047 (0.055)   Data 0.000 (0.001)   Loss 0.1662 (0.1513)   Prec@1 94.531 (94.811)   Prec@5 100.000 (99.949)   [2019-11-22 01:52:55]
  Epoch: [086][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.1636 (0.1539)   Prec@1 92.969 (94.669)   Prec@5 100.000 (99.940)   [2019-11-22 01:53:00]
  **Train** Prec@1 94.676 Prec@5 99.934 Error@1 5.324
  **Test** Prec@1 89.930 Prec@5 99.810 Error@1 10.070

==>>[2019-11-22 01:53:06] [Epoch=087/200] [Need: 00:41:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.35, Error=9.65]
  Epoch: [087][000/391]   Time 0.228 (0.228)   Data 0.172 (0.172)   Loss 0.1098 (0.1098)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 01:53:07]
  Epoch: [087][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1732 (0.1447)   Prec@1 94.531 (95.119)   Prec@5 100.000 (99.899)   [2019-11-22 01:53:12]
  Epoch: [087][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1663 (0.1467)   Prec@1 95.312 (95.025)   Prec@5 100.000 (99.899)   [2019-11-22 01:53:17]
  Epoch: [087][300/391]   Time 0.067 (0.052)   Data 0.000 (0.001)   Loss 0.0944 (0.1466)   Prec@1 96.094 (94.921)   Prec@5 100.000 (99.912)   [2019-11-22 01:53:22]
  **Train** Prec@1 94.888 Prec@5 99.916 Error@1 5.112
  **Test** Prec@1 90.440 Prec@5 99.800 Error@1 9.560
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:53:28] [Epoch=088/200] [Need: 00:41:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [088][000/391]   Time 0.233 (0.233)   Data 0.170 (0.170)   Loss 0.1126 (0.1126)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:53:28]
  Epoch: [088][100/391]   Time 0.069 (0.051)   Data 0.000 (0.002)   Loss 0.1374 (0.1491)   Prec@1 93.750 (94.887)   Prec@5 100.000 (99.899)   [2019-11-22 01:53:33]
  Epoch: [088][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0785 (0.1426)   Prec@1 96.094 (95.029)   Prec@5 100.000 (99.926)   [2019-11-22 01:53:38]
  Epoch: [088][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1064 (0.1418)   Prec@1 96.094 (95.102)   Prec@5 100.000 (99.933)   [2019-11-22 01:53:43]
  **Train** Prec@1 95.036 Prec@5 99.924 Error@1 4.964
  **Test** Prec@1 90.080 Prec@5 99.790 Error@1 9.920

==>>[2019-11-22 01:53:50] [Epoch=089/200] [Need: 00:40:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [089][000/391]   Time 0.241 (0.241)   Data 0.179 (0.179)   Loss 0.1528 (0.1528)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:53:50]
  Epoch: [089][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.1122 (0.1450)   Prec@1 96.875 (95.026)   Prec@5 100.000 (99.907)   [2019-11-22 01:53:55]
  Epoch: [089][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1384 (0.1472)   Prec@1 96.875 (94.916)   Prec@5 100.000 (99.891)   [2019-11-22 01:54:00]
  Epoch: [089][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1380 (0.1434)   Prec@1 92.969 (95.100)   Prec@5 100.000 (99.912)   [2019-11-22 01:54:05]
  **Train** Prec@1 95.046 Prec@5 99.918 Error@1 4.954
  **Test** Prec@1 90.090 Prec@5 99.820 Error@1 9.910

==>>[2019-11-22 01:54:12] [Epoch=090/200] [Need: 00:40:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [090][000/391]   Time 0.250 (0.250)   Data 0.179 (0.179)   Loss 0.1617 (0.1617)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 01:54:12]
  Epoch: [090][100/391]   Time 0.047 (0.057)   Data 0.000 (0.002)   Loss 0.0881 (0.1269)   Prec@1 97.656 (95.568)   Prec@5 100.000 (99.969)   [2019-11-22 01:54:17]
  Epoch: [090][200/391]   Time 0.056 (0.055)   Data 0.000 (0.001)   Loss 0.2254 (0.1340)   Prec@1 92.969 (95.351)   Prec@5 99.219 (99.953)   [2019-11-22 01:54:23]
  Epoch: [090][300/391]   Time 0.041 (0.054)   Data 0.000 (0.001)   Loss 0.2115 (0.1358)   Prec@1 92.969 (95.310)   Prec@5 100.000 (99.938)   [2019-11-22 01:54:28]
  **Train** Prec@1 95.234 Prec@5 99.928 Error@1 4.766
  **Test** Prec@1 90.420 Prec@5 99.730 Error@1 9.580

==>>[2019-11-22 01:54:34] [Epoch=091/200] [Need: 00:40:05] [LR=0.0010][M=0.90] [Best : Accuracy=90.44, Error=9.56]
  Epoch: [091][000/391]   Time 0.245 (0.245)   Data 0.167 (0.167)   Loss 0.1707 (0.1707)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:54:34]
  Epoch: [091][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1159 (0.1306)   Prec@1 96.875 (95.312)   Prec@5 100.000 (99.946)   [2019-11-22 01:54:39]
  Epoch: [091][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1308 (0.1326)   Prec@1 94.531 (95.363)   Prec@5 100.000 (99.926)   [2019-11-22 01:54:44]
  Epoch: [091][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1925 (0.1345)   Prec@1 92.188 (95.271)   Prec@5 100.000 (99.935)   [2019-11-22 01:54:49]
  **Train** Prec@1 95.334 Prec@5 99.934 Error@1 4.666
  **Test** Prec@1 90.480 Prec@5 99.810 Error@1 9.520
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 01:54:56] [Epoch=092/200] [Need: 00:39:43] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [092][000/391]   Time 0.222 (0.222)   Data 0.165 (0.165)   Loss 0.1817 (0.1817)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:54:56]
  Epoch: [092][100/391]   Time 0.054 (0.049)   Data 0.000 (0.002)   Loss 0.1317 (0.1245)   Prec@1 96.094 (95.599)   Prec@5 100.000 (99.954)   [2019-11-22 01:55:01]
  Epoch: [092][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.1156 (0.1305)   Prec@1 95.312 (95.433)   Prec@5 99.219 (99.930)   [2019-11-22 01:55:06]
  Epoch: [092][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.1230 (0.1305)   Prec@1 95.312 (95.422)   Prec@5 100.000 (99.927)   [2019-11-22 01:55:11]
  **Train** Prec@1 95.342 Prec@5 99.936 Error@1 4.658
  **Test** Prec@1 90.080 Prec@5 99.760 Error@1 9.920

==>>[2019-11-22 01:55:18] [Epoch=093/200] [Need: 00:39:20] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [093][000/391]   Time 0.240 (0.240)   Data 0.182 (0.182)   Loss 0.0713 (0.0713)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:55:18]
  Epoch: [093][100/391]   Time 0.083 (0.057)   Data 0.000 (0.002)   Loss 0.1824 (0.1231)   Prec@1 93.750 (95.761)   Prec@5 100.000 (99.946)   [2019-11-22 01:55:23]
  Epoch: [093][200/391]   Time 0.050 (0.054)   Data 0.000 (0.001)   Loss 0.1833 (0.1281)   Prec@1 96.094 (95.577)   Prec@5 100.000 (99.942)   [2019-11-22 01:55:29]
  Epoch: [093][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1138 (0.1305)   Prec@1 96.094 (95.466)   Prec@5 100.000 (99.943)   [2019-11-22 01:55:33]
  **Train** Prec@1 95.450 Prec@5 99.940 Error@1 4.550
  **Test** Prec@1 90.190 Prec@5 99.700 Error@1 9.810

==>>[2019-11-22 01:55:40] [Epoch=094/200] [Need: 00:38:58] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [094][000/391]   Time 0.226 (0.226)   Data 0.159 (0.159)   Loss 0.1252 (0.1252)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:55:40]
  Epoch: [094][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.1081 (0.1206)   Prec@1 95.312 (95.722)   Prec@5 100.000 (99.969)   [2019-11-22 01:55:45]
  Epoch: [094][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0674 (0.1246)   Prec@1 97.656 (95.588)   Prec@5 100.000 (99.961)   [2019-11-22 01:55:50]
  Epoch: [094][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0979 (0.1261)   Prec@1 96.875 (95.541)   Prec@5 100.000 (99.945)   [2019-11-22 01:55:55]
  **Train** Prec@1 95.466 Prec@5 99.940 Error@1 4.534
  **Test** Prec@1 90.210 Prec@5 99.750 Error@1 9.790

==>>[2019-11-22 01:56:02] [Epoch=095/200] [Need: 00:38:36] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [095][000/391]   Time 0.218 (0.218)   Data 0.159 (0.159)   Loss 0.0926 (0.0926)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 01:56:02]
  Epoch: [095][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0855 (0.1135)   Prec@1 97.656 (96.078)   Prec@5 100.000 (99.954)   [2019-11-22 01:56:07]
  Epoch: [095][200/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.0765 (0.1202)   Prec@1 96.875 (95.841)   Prec@5 100.000 (99.949)   [2019-11-22 01:56:12]
  Epoch: [095][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.1127 (0.1229)   Prec@1 95.312 (95.665)   Prec@5 100.000 (99.956)   [2019-11-22 01:56:17]
  **Train** Prec@1 95.604 Prec@5 99.956 Error@1 4.396
  **Test** Prec@1 90.130 Prec@5 99.690 Error@1 9.870

==>>[2019-11-22 01:56:23] [Epoch=096/200] [Need: 00:38:13] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [096][000/391]   Time 0.237 (0.237)   Data 0.168 (0.168)   Loss 0.0888 (0.0888)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:56:23]
  Epoch: [096][100/391]   Time 0.080 (0.052)   Data 0.000 (0.002)   Loss 0.0579 (0.1191)   Prec@1 97.656 (95.900)   Prec@5 100.000 (99.954)   [2019-11-22 01:56:28]
  Epoch: [096][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.1230 (0.1199)   Prec@1 95.312 (95.717)   Prec@5 100.000 (99.938)   [2019-11-22 01:56:33]
  Epoch: [096][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.2040 (0.1215)   Prec@1 93.750 (95.699)   Prec@5 100.000 (99.948)   [2019-11-22 01:56:39]
  **Train** Prec@1 95.732 Prec@5 99.948 Error@1 4.268
  **Test** Prec@1 90.200 Prec@5 99.700 Error@1 9.800

==>>[2019-11-22 01:56:45] [Epoch=097/200] [Need: 00:37:51] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [097][000/391]   Time 0.222 (0.222)   Data 0.161 (0.161)   Loss 0.1654 (0.1654)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 01:56:45]
  Epoch: [097][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.0965 (0.1197)   Prec@1 96.875 (95.777)   Prec@5 100.000 (99.938)   [2019-11-22 01:56:50]
  Epoch: [097][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1441 (0.1204)   Prec@1 94.531 (95.806)   Prec@5 100.000 (99.957)   [2019-11-22 01:56:55]
  Epoch: [097][300/391]   Time 0.060 (0.053)   Data 0.000 (0.001)   Loss 0.0839 (0.1241)   Prec@1 97.656 (95.691)   Prec@5 100.000 (99.956)   [2019-11-22 01:57:01]
  **Train** Prec@1 95.684 Prec@5 99.956 Error@1 4.316
  **Test** Prec@1 90.140 Prec@5 99.730 Error@1 9.860

==>>[2019-11-22 01:57:07] [Epoch=098/200] [Need: 00:37:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [098][000/391]   Time 0.250 (0.250)   Data 0.196 (0.196)   Loss 0.1318 (0.1318)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:57:07]
  Epoch: [098][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.1044 (0.1206)   Prec@1 97.656 (95.823)   Prec@5 100.000 (99.969)   [2019-11-22 01:57:13]
  Epoch: [098][200/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.1079 (0.1182)   Prec@1 96.094 (95.919)   Prec@5 100.000 (99.965)   [2019-11-22 01:57:17]
  Epoch: [098][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0777 (0.1207)   Prec@1 96.094 (95.769)   Prec@5 100.000 (99.964)   [2019-11-22 01:57:23]
  **Train** Prec@1 95.790 Prec@5 99.962 Error@1 4.210
  **Test** Prec@1 90.230 Prec@5 99.740 Error@1 9.770

==>>[2019-11-22 01:57:29] [Epoch=099/200] [Need: 00:37:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [099][000/391]   Time 0.235 (0.235)   Data 0.161 (0.161)   Loss 0.1221 (0.1221)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:57:29]
  Epoch: [099][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.1575 (0.1115)   Prec@1 94.531 (96.024)   Prec@5 100.000 (99.961)   [2019-11-22 01:57:35]
  Epoch: [099][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0995 (0.1146)   Prec@1 98.438 (95.857)   Prec@5 100.000 (99.949)   [2019-11-22 01:57:40]
  Epoch: [099][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0696 (0.1162)   Prec@1 97.656 (95.790)   Prec@5 100.000 (99.956)   [2019-11-22 01:57:44]
  **Train** Prec@1 95.770 Prec@5 99.950 Error@1 4.230
  **Test** Prec@1 90.170 Prec@5 99.760 Error@1 9.830

==>>[2019-11-22 01:57:51] [Epoch=100/200] [Need: 00:36:45] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [100][000/391]   Time 0.220 (0.220)   Data 0.158 (0.158)   Loss 0.0354 (0.0354)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:57:52]
  Epoch: [100][100/391]   Time 0.083 (0.052)   Data 0.000 (0.002)   Loss 0.1224 (0.1099)   Prec@1 93.750 (96.071)   Prec@5 100.000 (99.938)   [2019-11-22 01:57:57]
  Epoch: [100][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.0952 (0.1125)   Prec@1 96.875 (96.035)   Prec@5 100.000 (99.946)   [2019-11-22 01:58:02]
  Epoch: [100][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1076 (0.1128)   Prec@1 94.531 (96.021)   Prec@5 100.000 (99.948)   [2019-11-22 01:58:07]
  **Train** Prec@1 96.030 Prec@5 99.948 Error@1 3.970
  **Test** Prec@1 90.350 Prec@5 99.750 Error@1 9.650

==>>[2019-11-22 01:58:13] [Epoch=101/200] [Need: 00:36:23] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [101][000/391]   Time 0.221 (0.221)   Data 0.148 (0.148)   Loss 0.0793 (0.0793)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 01:58:13]
  Epoch: [101][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.0606 (0.1021)   Prec@1 97.656 (96.527)   Prec@5 100.000 (99.985)   [2019-11-22 01:58:18]
  Epoch: [101][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0782 (0.1056)   Prec@1 96.094 (96.296)   Prec@5 100.000 (99.969)   [2019-11-22 01:58:23]
  Epoch: [101][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1662 (0.1081)   Prec@1 94.531 (96.159)   Prec@5 100.000 (99.971)   [2019-11-22 01:58:28]
  **Train** Prec@1 96.114 Prec@5 99.968 Error@1 3.886
  **Test** Prec@1 90.390 Prec@5 99.760 Error@1 9.610

==>>[2019-11-22 01:58:35] [Epoch=102/200] [Need: 00:36:00] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [102][000/391]   Time 0.221 (0.221)   Data 0.179 (0.179)   Loss 0.1312 (0.1312)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:58:35]
  Epoch: [102][100/391]   Time 0.052 (0.056)   Data 0.000 (0.002)   Loss 0.1092 (0.1039)   Prec@1 96.875 (96.334)   Prec@5 99.219 (99.954)   [2019-11-22 01:58:40]
  Epoch: [102][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.1598 (0.1057)   Prec@1 94.531 (96.230)   Prec@5 100.000 (99.969)   [2019-11-22 01:58:45]
  Epoch: [102][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.1094 (0.1100)   Prec@1 95.312 (96.151)   Prec@5 100.000 (99.966)   [2019-11-22 01:58:50]
  **Train** Prec@1 96.104 Prec@5 99.972 Error@1 3.896
  **Test** Prec@1 90.090 Prec@5 99.730 Error@1 9.910

==>>[2019-11-22 01:58:57] [Epoch=103/200] [Need: 00:35:38] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [103][000/391]   Time 0.211 (0.211)   Data 0.148 (0.148)   Loss 0.0614 (0.0614)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:58:57]
  Epoch: [103][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.1312 (0.1054)   Prec@1 96.094 (96.272)   Prec@5 100.000 (99.977)   [2019-11-22 01:59:02]
  Epoch: [103][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0966 (0.1070)   Prec@1 96.875 (96.296)   Prec@5 100.000 (99.953)   [2019-11-22 01:59:07]
  Epoch: [103][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0742 (0.1086)   Prec@1 96.875 (96.211)   Prec@5 100.000 (99.956)   [2019-11-22 01:59:12]
  **Train** Prec@1 96.166 Prec@5 99.958 Error@1 3.834
  **Test** Prec@1 90.270 Prec@5 99.690 Error@1 9.730

==>>[2019-11-22 01:59:19] [Epoch=104/200] [Need: 00:35:16] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [104][000/391]   Time 0.225 (0.225)   Data 0.162 (0.162)   Loss 0.0644 (0.0644)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:59:19]
  Epoch: [104][100/391]   Time 0.046 (0.056)   Data 0.000 (0.002)   Loss 0.1363 (0.1043)   Prec@1 94.531 (96.264)   Prec@5 100.000 (99.961)   [2019-11-22 01:59:24]
  Epoch: [104][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0775 (0.1053)   Prec@1 96.094 (96.304)   Prec@5 100.000 (99.961)   [2019-11-22 01:59:29]
  Epoch: [104][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.1074 (0.1044)   Prec@1 97.656 (96.356)   Prec@5 100.000 (99.964)   [2019-11-22 01:59:35]
  **Train** Prec@1 96.296 Prec@5 99.960 Error@1 3.704
  **Test** Prec@1 90.240 Prec@5 99.710 Error@1 9.760

==>>[2019-11-22 01:59:41] [Epoch=105/200] [Need: 00:34:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [105][000/391]   Time 0.225 (0.225)   Data 0.151 (0.151)   Loss 0.1676 (0.1676)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 01:59:42]
  Epoch: [105][100/391]   Time 0.044 (0.049)   Data 0.000 (0.002)   Loss 0.1349 (0.1055)   Prec@1 93.750 (96.318)   Prec@5 100.000 (99.977)   [2019-11-22 01:59:46]
  Epoch: [105][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.1546 (0.1049)   Prec@1 93.750 (96.300)   Prec@5 100.000 (99.981)   [2019-11-22 01:59:52]
  Epoch: [105][300/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.1833 (0.1059)   Prec@1 91.406 (96.195)   Prec@5 100.000 (99.979)   [2019-11-22 01:59:57]
  **Train** Prec@1 96.240 Prec@5 99.974 Error@1 3.760
  **Test** Prec@1 89.970 Prec@5 99.720 Error@1 10.030

==>>[2019-11-22 02:00:03] [Epoch=106/200] [Need: 00:34:32] [LR=0.0010][M=0.90] [Best : Accuracy=90.48, Error=9.52]
  Epoch: [106][000/391]   Time 0.243 (0.243)   Data 0.175 (0.175)   Loss 0.0913 (0.0913)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:00:03]
  Epoch: [106][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.1283 (0.0992)   Prec@1 97.656 (96.442)   Prec@5 100.000 (99.985)   [2019-11-22 02:00:08]
  Epoch: [106][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0821 (0.1019)   Prec@1 97.656 (96.350)   Prec@5 100.000 (99.969)   [2019-11-22 02:00:14]
  Epoch: [106][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0887 (0.1038)   Prec@1 96.875 (96.275)   Prec@5 100.000 (99.964)   [2019-11-22 02:00:18]
  **Train** Prec@1 96.248 Prec@5 99.962 Error@1 3.752
  **Test** Prec@1 90.520 Prec@5 99.730 Error@1 9.480
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:00:25] [Epoch=107/200] [Need: 00:34:10] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [107][000/391]   Time 0.215 (0.215)   Data 0.145 (0.145)   Loss 0.0990 (0.0990)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-22 02:00:25]
  Epoch: [107][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0781 (0.0908)   Prec@1 96.875 (96.852)   Prec@5 100.000 (99.977)   [2019-11-22 02:00:30]
  Epoch: [107][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1120 (0.0953)   Prec@1 95.312 (96.611)   Prec@5 100.000 (99.973)   [2019-11-22 02:00:35]
  Epoch: [107][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0949 (0.0985)   Prec@1 95.312 (96.506)   Prec@5 100.000 (99.974)   [2019-11-22 02:00:40]
  **Train** Prec@1 96.390 Prec@5 99.976 Error@1 3.610
  **Test** Prec@1 90.150 Prec@5 99.700 Error@1 9.850

==>>[2019-11-22 02:00:47] [Epoch=108/200] [Need: 00:33:48] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [108][000/391]   Time 0.224 (0.224)   Data 0.148 (0.148)   Loss 0.1175 (0.1175)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:00:47]
  Epoch: [108][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0634 (0.0933)   Prec@1 98.438 (96.666)   Prec@5 100.000 (100.000)   [2019-11-22 02:00:52]
  Epoch: [108][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0823 (0.0978)   Prec@1 97.656 (96.517)   Prec@5 100.000 (99.992)   [2019-11-22 02:00:57]
  Epoch: [108][300/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.1097 (0.0978)   Prec@1 96.094 (96.512)   Prec@5 100.000 (99.984)   [2019-11-22 02:01:02]
  **Train** Prec@1 96.458 Prec@5 99.982 Error@1 3.542
  **Test** Prec@1 90.210 Prec@5 99.750 Error@1 9.790

==>>[2019-11-22 02:01:09] [Epoch=109/200] [Need: 00:33:26] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [109][000/391]   Time 0.235 (0.235)   Data 0.147 (0.147)   Loss 0.0740 (0.0740)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:01:10]
  Epoch: [109][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.0984 (0.0910)   Prec@1 96.875 (96.666)   Prec@5 100.000 (99.985)   [2019-11-22 02:01:15]
  Epoch: [109][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0618 (0.0957)   Prec@1 97.656 (96.471)   Prec@5 100.000 (99.973)   [2019-11-22 02:01:20]
  Epoch: [109][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0828 (0.0974)   Prec@1 96.875 (96.460)   Prec@5 100.000 (99.966)   [2019-11-22 02:01:25]
  **Train** Prec@1 96.384 Prec@5 99.972 Error@1 3.616
  **Test** Prec@1 90.380 Prec@5 99.730 Error@1 9.620

==>>[2019-11-22 02:01:31] [Epoch=110/200] [Need: 00:33:04] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [110][000/391]   Time 0.227 (0.227)   Data 0.151 (0.151)   Loss 0.0900 (0.0900)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:01:31]
  Epoch: [110][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0916 (0.0950)   Prec@1 99.219 (96.643)   Prec@5 100.000 (99.954)   [2019-11-22 02:01:37]
  Epoch: [110][200/391]   Time 0.068 (0.051)   Data 0.000 (0.001)   Loss 0.0832 (0.0952)   Prec@1 96.875 (96.618)   Prec@5 100.000 (99.973)   [2019-11-22 02:01:42]
  Epoch: [110][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0746 (0.0938)   Prec@1 96.875 (96.683)   Prec@5 100.000 (99.977)   [2019-11-22 02:01:46]
  **Train** Prec@1 96.562 Prec@5 99.978 Error@1 3.438
  **Test** Prec@1 90.300 Prec@5 99.750 Error@1 9.700

==>>[2019-11-22 02:01:53] [Epoch=111/200] [Need: 00:32:42] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [111][000/391]   Time 0.225 (0.225)   Data 0.150 (0.150)   Loss 0.0723 (0.0723)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:01:53]
  Epoch: [111][100/391]   Time 0.054 (0.055)   Data 0.000 (0.002)   Loss 0.1078 (0.0934)   Prec@1 96.875 (96.720)   Prec@5 100.000 (99.930)   [2019-11-22 02:01:58]
  Epoch: [111][200/391]   Time 0.055 (0.053)   Data 0.000 (0.001)   Loss 0.1354 (0.0938)   Prec@1 96.094 (96.653)   Prec@5 100.000 (99.957)   [2019-11-22 02:02:04]
  Epoch: [111][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1207 (0.0963)   Prec@1 95.312 (96.543)   Prec@5 100.000 (99.969)   [2019-11-22 02:02:09]
  **Train** Prec@1 96.582 Prec@5 99.962 Error@1 3.418
  **Test** Prec@1 90.480 Prec@5 99.680 Error@1 9.520

==>>[2019-11-22 02:02:15] [Epoch=112/200] [Need: 00:32:20] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [112][000/391]   Time 0.235 (0.235)   Data 0.149 (0.149)   Loss 0.0452 (0.0452)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:02:15]
  Epoch: [112][100/391]   Time 0.060 (0.053)   Data 0.000 (0.002)   Loss 0.0842 (0.0899)   Prec@1 96.875 (96.937)   Prec@5 100.000 (99.985)   [2019-11-22 02:02:20]
  Epoch: [112][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0959 (0.0914)   Prec@1 96.094 (96.739)   Prec@5 100.000 (99.981)   [2019-11-22 02:02:26]
  Epoch: [112][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0884 (0.0954)   Prec@1 96.875 (96.589)   Prec@5 100.000 (99.977)   [2019-11-22 02:02:31]
  **Train** Prec@1 96.576 Prec@5 99.976 Error@1 3.424
  **Test** Prec@1 90.400 Prec@5 99.740 Error@1 9.600

==>>[2019-11-22 02:02:37] [Epoch=113/200] [Need: 00:31:58] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [113][000/391]   Time 0.227 (0.227)   Data 0.173 (0.173)   Loss 0.0904 (0.0904)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 02:02:37]
  Epoch: [113][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0606 (0.0871)   Prec@1 98.438 (96.890)   Prec@5 100.000 (99.969)   [2019-11-22 02:02:43]
  Epoch: [113][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0470 (0.0887)   Prec@1 97.656 (96.778)   Prec@5 100.000 (99.969)   [2019-11-22 02:02:48]
  Epoch: [113][300/391]   Time 0.072 (0.052)   Data 0.000 (0.001)   Loss 0.0872 (0.0894)   Prec@1 96.875 (96.776)   Prec@5 100.000 (99.977)   [2019-11-22 02:02:53]
  **Train** Prec@1 96.666 Prec@5 99.982 Error@1 3.334
  **Test** Prec@1 90.400 Prec@5 99.690 Error@1 9.600

==>>[2019-11-22 02:03:00] [Epoch=114/200] [Need: 00:31:36] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [114][000/391]   Time 0.233 (0.233)   Data 0.149 (0.149)   Loss 0.0938 (0.0938)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 02:03:00]
  Epoch: [114][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.1153 (0.0961)   Prec@1 93.750 (96.550)   Prec@5 100.000 (99.985)   [2019-11-22 02:03:05]
  Epoch: [114][200/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.0745 (0.0922)   Prec@1 96.875 (96.657)   Prec@5 100.000 (99.984)   [2019-11-22 02:03:10]
  Epoch: [114][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0970 (0.0915)   Prec@1 96.875 (96.699)   Prec@5 99.219 (99.971)   [2019-11-22 02:03:15]
  **Train** Prec@1 96.722 Prec@5 99.978 Error@1 3.278
  **Test** Prec@1 89.900 Prec@5 99.700 Error@1 10.100

==>>[2019-11-22 02:03:21] [Epoch=115/200] [Need: 00:31:14] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [115][000/391]   Time 0.242 (0.242)   Data 0.182 (0.182)   Loss 0.0519 (0.0519)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:03:22]
  Epoch: [115][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0713 (0.0880)   Prec@1 98.438 (96.844)   Prec@5 100.000 (99.992)   [2019-11-22 02:03:27]
  Epoch: [115][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0623 (0.0906)   Prec@1 97.656 (96.747)   Prec@5 100.000 (99.977)   [2019-11-22 02:03:32]
  Epoch: [115][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0728 (0.0897)   Prec@1 97.656 (96.769)   Prec@5 100.000 (99.982)   [2019-11-22 02:03:37]
  **Train** Prec@1 96.794 Prec@5 99.982 Error@1 3.206
  **Test** Prec@1 90.350 Prec@5 99.720 Error@1 9.650

==>>[2019-11-22 02:03:44] [Epoch=116/200] [Need: 00:30:52] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [116][000/391]   Time 0.219 (0.219)   Data 0.162 (0.162)   Loss 0.1581 (0.1581)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 02:03:44]
  Epoch: [116][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.1427 (0.0911)   Prec@1 94.531 (96.821)   Prec@5 100.000 (99.992)   [2019-11-22 02:03:49]
  Epoch: [116][200/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0469 (0.0917)   Prec@1 98.438 (96.665)   Prec@5 100.000 (99.988)   [2019-11-22 02:03:54]
  Epoch: [116][300/391]   Time 0.073 (0.052)   Data 0.000 (0.001)   Loss 0.0975 (0.0910)   Prec@1 96.875 (96.652)   Prec@5 100.000 (99.987)   [2019-11-22 02:03:59]
  **Train** Prec@1 96.682 Prec@5 99.976 Error@1 3.318
  **Test** Prec@1 90.290 Prec@5 99.740 Error@1 9.710

==>>[2019-11-22 02:04:06] [Epoch=117/200] [Need: 00:30:30] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [117][000/391]   Time 0.225 (0.225)   Data 0.159 (0.159)   Loss 0.1046 (0.1046)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 02:04:06]
  Epoch: [117][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0588 (0.0831)   Prec@1 98.438 (97.153)   Prec@5 100.000 (99.985)   [2019-11-22 02:04:11]
  Epoch: [117][200/391]   Time 0.070 (0.049)   Data 0.000 (0.001)   Loss 0.1615 (0.0882)   Prec@1 93.750 (96.875)   Prec@5 100.000 (99.992)   [2019-11-22 02:04:16]
  Epoch: [117][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0771 (0.0900)   Prec@1 96.875 (96.823)   Prec@5 100.000 (99.984)   [2019-11-22 02:04:21]
  **Train** Prec@1 96.866 Prec@5 99.980 Error@1 3.134
  **Test** Prec@1 90.370 Prec@5 99.690 Error@1 9.630

==>>[2019-11-22 02:04:27] [Epoch=118/200] [Need: 00:30:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [118][000/391]   Time 0.232 (0.232)   Data 0.165 (0.165)   Loss 0.1256 (0.1256)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 02:04:28]
  Epoch: [118][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.0618 (0.0808)   Prec@1 98.438 (97.030)   Prec@5 100.000 (99.992)   [2019-11-22 02:04:33]
  Epoch: [118][200/391]   Time 0.065 (0.054)   Data 0.000 (0.001)   Loss 0.0529 (0.0843)   Prec@1 99.219 (97.023)   Prec@5 100.000 (99.981)   [2019-11-22 02:04:38]
  Epoch: [118][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0962 (0.0854)   Prec@1 95.312 (97.002)   Prec@5 100.000 (99.987)   [2019-11-22 02:04:44]
  **Train** Prec@1 96.946 Prec@5 99.988 Error@1 3.054
  **Test** Prec@1 90.000 Prec@5 99.710 Error@1 10.000

==>>[2019-11-22 02:04:50] [Epoch=119/200] [Need: 00:29:46] [LR=0.0010][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [119][000/391]   Time 0.222 (0.222)   Data 0.162 (0.162)   Loss 0.0305 (0.0305)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:04:50]
  Epoch: [119][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.1048 (0.0829)   Prec@1 96.094 (97.107)   Prec@5 100.000 (99.985)   [2019-11-22 02:04:55]
  Epoch: [119][200/391]   Time 0.047 (0.049)   Data 0.000 (0.001)   Loss 0.0799 (0.0857)   Prec@1 98.438 (97.007)   Prec@5 100.000 (99.984)   [2019-11-22 02:05:00]
  Epoch: [119][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.0456 (0.0855)   Prec@1 98.438 (96.979)   Prec@5 100.000 (99.987)   [2019-11-22 02:05:05]
  **Train** Prec@1 96.960 Prec@5 99.978 Error@1 3.040
  **Test** Prec@1 90.250 Prec@5 99.730 Error@1 9.750

==>>[2019-11-22 02:05:11] [Epoch=120/200] [Need: 00:29:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [120][000/391]   Time 0.229 (0.229)   Data 0.171 (0.171)   Loss 0.1075 (0.1075)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:05:11]
  Epoch: [120][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0716 (0.0831)   Prec@1 97.656 (96.937)   Prec@5 100.000 (99.985)   [2019-11-22 02:05:16]
  Epoch: [120][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0732 (0.0799)   Prec@1 97.656 (97.190)   Prec@5 100.000 (99.988)   [2019-11-22 02:05:22]
  Epoch: [120][300/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.0841 (0.0794)   Prec@1 96.875 (97.238)   Prec@5 100.000 (99.990)   [2019-11-22 02:05:27]
  **Train** Prec@1 97.326 Prec@5 99.990 Error@1 2.674
  **Test** Prec@1 90.440 Prec@5 99.750 Error@1 9.560

==>>[2019-11-22 02:05:33] [Epoch=121/200] [Need: 00:29:01] [LR=0.0001][M=0.90] [Best : Accuracy=90.52, Error=9.48]
  Epoch: [121][000/391]   Time 0.228 (0.228)   Data 0.169 (0.169)   Loss 0.1013 (0.1013)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 02:05:33]
  Epoch: [121][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0763 (0.0694)   Prec@1 98.438 (97.540)   Prec@5 100.000 (99.992)   [2019-11-22 02:05:38]
  Epoch: [121][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.1111 (0.0695)   Prec@1 95.312 (97.485)   Prec@5 100.000 (99.996)   [2019-11-22 02:05:44]
  Epoch: [121][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0894 (0.0690)   Prec@1 97.656 (97.547)   Prec@5 100.000 (99.992)   [2019-11-22 02:05:49]
  **Train** Prec@1 97.534 Prec@5 99.988 Error@1 2.466
  **Test** Prec@1 90.570 Prec@5 99.800 Error@1 9.430
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:05:55] [Epoch=122/200] [Need: 00:28:39] [LR=0.0001][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [122][000/391]   Time 0.232 (0.232)   Data 0.171 (0.171)   Loss 0.0694 (0.0694)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:05:56]
  Epoch: [122][100/391]   Time 0.049 (0.052)   Data 0.000 (0.002)   Loss 0.1454 (0.0648)   Prec@1 95.312 (97.819)   Prec@5 100.000 (99.985)   [2019-11-22 02:06:01]
  Epoch: [122][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0902 (0.0685)   Prec@1 96.875 (97.664)   Prec@5 100.000 (99.988)   [2019-11-22 02:06:06]
  Epoch: [122][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0219 (0.0671)   Prec@1 99.219 (97.706)   Prec@5 100.000 (99.984)   [2019-11-22 02:06:11]
  **Train** Prec@1 97.702 Prec@5 99.986 Error@1 2.298
  **Test** Prec@1 90.630 Prec@5 99.740 Error@1 9.370
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:06:17] [Epoch=123/200] [Need: 00:28:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [123][000/391]   Time 0.229 (0.229)   Data 0.172 (0.172)   Loss 0.0773 (0.0773)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:06:18]
  Epoch: [123][100/391]   Time 0.075 (0.052)   Data 0.000 (0.002)   Loss 0.0447 (0.0688)   Prec@1 97.656 (97.664)   Prec@5 100.000 (99.977)   [2019-11-22 02:06:23]
  Epoch: [123][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0835 (0.0687)   Prec@1 96.875 (97.602)   Prec@5 100.000 (99.981)   [2019-11-22 02:06:27]
  Epoch: [123][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0605 (0.0666)   Prec@1 98.438 (97.729)   Prec@5 100.000 (99.984)   [2019-11-22 02:06:32]
  **Train** Prec@1 97.730 Prec@5 99.988 Error@1 2.270
  **Test** Prec@1 90.510 Prec@5 99.750 Error@1 9.490

==>>[2019-11-22 02:06:39] [Epoch=124/200] [Need: 00:27:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [124][000/391]   Time 0.224 (0.224)   Data 0.153 (0.153)   Loss 0.0393 (0.0393)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:06:39]
  Epoch: [124][100/391]   Time 0.031 (0.053)   Data 0.000 (0.002)   Loss 0.0501 (0.0618)   Prec@1 97.656 (97.981)   Prec@5 100.000 (99.992)   [2019-11-22 02:06:44]
  Epoch: [124][200/391]   Time 0.063 (0.053)   Data 0.000 (0.001)   Loss 0.0584 (0.0640)   Prec@1 98.438 (97.785)   Prec@5 100.000 (99.988)   [2019-11-22 02:06:49]
  Epoch: [124][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0269 (0.0660)   Prec@1 99.219 (97.703)   Prec@5 100.000 (99.987)   [2019-11-22 02:06:54]
  **Train** Prec@1 97.750 Prec@5 99.986 Error@1 2.250
  **Test** Prec@1 90.690 Prec@5 99.700 Error@1 9.310
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:07:01] [Epoch=125/200] [Need: 00:27:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.69, Error=9.31]
  Epoch: [125][000/391]   Time 0.241 (0.241)   Data 0.163 (0.163)   Loss 0.0571 (0.0571)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:01]
  Epoch: [125][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0446 (0.0604)   Prec@1 97.656 (97.958)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:06]
  Epoch: [125][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.1004 (0.0594)   Prec@1 96.875 (98.010)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:12]
  Epoch: [125][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0765 (0.0617)   Prec@1 97.656 (97.872)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:17]
  **Train** Prec@1 97.862 Prec@5 99.996 Error@1 2.138
  **Test** Prec@1 90.720 Prec@5 99.700 Error@1 9.280
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:07:24] [Epoch=126/200] [Need: 00:27:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [126][000/391]   Time 0.221 (0.221)   Data 0.150 (0.150)   Loss 0.0571 (0.0571)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:24]
  Epoch: [126][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.0240 (0.0664)   Prec@1 100.000 (97.672)   Prec@5 100.000 (99.985)   [2019-11-22 02:07:29]
  Epoch: [126][200/391]   Time 0.078 (0.053)   Data 0.000 (0.001)   Loss 0.0545 (0.0646)   Prec@1 99.219 (97.785)   Prec@5 100.000 (99.984)   [2019-11-22 02:07:34]
  Epoch: [126][300/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0382 (0.0656)   Prec@1 98.438 (97.747)   Prec@5 100.000 (99.982)   [2019-11-22 02:07:40]
  **Train** Prec@1 97.786 Prec@5 99.986 Error@1 2.214
  **Test** Prec@1 90.640 Prec@5 99.730 Error@1 9.360

==>>[2019-11-22 02:07:46] [Epoch=127/200] [Need: 00:26:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [127][000/391]   Time 0.235 (0.235)   Data 0.177 (0.177)   Loss 0.0945 (0.0945)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:07:47]
  Epoch: [127][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.0490 (0.0611)   Prec@1 98.438 (97.981)   Prec@5 100.000 (99.985)   [2019-11-22 02:07:51]
  Epoch: [127][200/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.0347 (0.0634)   Prec@1 99.219 (97.847)   Prec@5 100.000 (99.981)   [2019-11-22 02:07:56]
  Epoch: [127][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1067 (0.0619)   Prec@1 96.094 (97.926)   Prec@5 100.000 (99.984)   [2019-11-22 02:08:01]
  **Train** Prec@1 97.874 Prec@5 99.988 Error@1 2.126
  **Test** Prec@1 90.640 Prec@5 99.760 Error@1 9.360

==>>[2019-11-22 02:08:09] [Epoch=128/200] [Need: 00:26:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [128][000/391]   Time 0.209 (0.209)   Data 0.152 (0.152)   Loss 0.1143 (0.1143)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 02:08:09]
  Epoch: [128][100/391]   Time 0.071 (0.052)   Data 0.000 (0.002)   Loss 0.0679 (0.0664)   Prec@1 97.656 (97.811)   Prec@5 100.000 (99.985)   [2019-11-22 02:08:14]
  Epoch: [128][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0733 (0.0652)   Prec@1 96.875 (97.730)   Prec@5 100.000 (99.988)   [2019-11-22 02:08:19]
  Epoch: [128][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0315 (0.0652)   Prec@1 99.219 (97.739)   Prec@5 100.000 (99.992)   [2019-11-22 02:08:24]
  **Train** Prec@1 97.724 Prec@5 99.994 Error@1 2.276
  **Test** Prec@1 90.710 Prec@5 99.730 Error@1 9.290

==>>[2019-11-22 02:08:31] [Epoch=129/200] [Need: 00:26:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [129][000/391]   Time 0.226 (0.226)   Data 0.172 (0.172)   Loss 0.0539 (0.0539)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:08:31]
  Epoch: [129][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.0613 (0.0604)   Prec@1 97.656 (97.942)   Prec@5 100.000 (99.985)   [2019-11-22 02:08:36]
  Epoch: [129][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0210 (0.0619)   Prec@1 100.000 (97.928)   Prec@5 100.000 (99.992)   [2019-11-22 02:08:41]
  Epoch: [129][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0348 (0.0629)   Prec@1 98.438 (97.864)   Prec@5 100.000 (99.995)   [2019-11-22 02:08:46]
  **Train** Prec@1 97.858 Prec@5 99.996 Error@1 2.142
  **Test** Prec@1 90.660 Prec@5 99.740 Error@1 9.340

==>>[2019-11-22 02:08:53] [Epoch=130/200] [Need: 00:25:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [130][000/391]   Time 0.233 (0.233)   Data 0.177 (0.177)   Loss 0.0660 (0.0660)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:08:53]
  Epoch: [130][100/391]   Time 0.083 (0.056)   Data 0.000 (0.002)   Loss 0.0499 (0.0615)   Prec@1 98.438 (97.973)   Prec@5 100.000 (99.992)   [2019-11-22 02:08:58]
  Epoch: [130][200/391]   Time 0.055 (0.054)   Data 0.000 (0.001)   Loss 0.0555 (0.0611)   Prec@1 96.875 (97.878)   Prec@5 100.000 (99.988)   [2019-11-22 02:09:03]
  Epoch: [130][300/391]   Time 0.079 (0.053)   Data 0.000 (0.001)   Loss 0.0306 (0.0616)   Prec@1 100.000 (97.892)   Prec@5 100.000 (99.990)   [2019-11-22 02:09:09]
  **Train** Prec@1 97.948 Prec@5 99.988 Error@1 2.052
  **Test** Prec@1 90.680 Prec@5 99.740 Error@1 9.320

==>>[2019-11-22 02:09:15] [Epoch=131/200] [Need: 00:25:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.72, Error=9.28]
  Epoch: [131][000/391]   Time 0.233 (0.233)   Data 0.149 (0.149)   Loss 0.0932 (0.0932)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:09:15]
  Epoch: [131][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.1104 (0.0654)   Prec@1 96.094 (97.649)   Prec@5 100.000 (99.992)   [2019-11-22 02:09:20]
  Epoch: [131][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0296 (0.0636)   Prec@1 99.219 (97.757)   Prec@5 100.000 (99.988)   [2019-11-22 02:09:25]
  Epoch: [131][300/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.0599 (0.0618)   Prec@1 98.438 (97.898)   Prec@5 100.000 (99.992)   [2019-11-22 02:09:30]
  **Train** Prec@1 97.890 Prec@5 99.994 Error@1 2.110
  **Test** Prec@1 90.810 Prec@5 99.750 Error@1 9.190
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:09:36] [Epoch=132/200] [Need: 00:24:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [132][000/391]   Time 0.229 (0.229)   Data 0.165 (0.165)   Loss 0.0212 (0.0212)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:09:36]
  Epoch: [132][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.0326 (0.0638)   Prec@1 98.438 (97.857)   Prec@5 100.000 (99.992)   [2019-11-22 02:09:41]
  Epoch: [132][200/391]   Time 0.060 (0.050)   Data 0.000 (0.001)   Loss 0.1233 (0.0642)   Prec@1 94.531 (97.827)   Prec@5 100.000 (99.988)   [2019-11-22 02:09:46]
  Epoch: [132][300/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.0290 (0.0604)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.987)   [2019-11-22 02:09:52]
  **Train** Prec@1 97.946 Prec@5 99.988 Error@1 2.054
  **Test** Prec@1 90.590 Prec@5 99.750 Error@1 9.410

==>>[2019-11-22 02:09:58] [Epoch=133/200] [Need: 00:24:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [133][000/391]   Time 0.207 (0.207)   Data 0.150 (0.150)   Loss 0.0351 (0.0351)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:09:58]
  Epoch: [133][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.0903 (0.0564)   Prec@1 98.438 (98.190)   Prec@5 99.219 (99.977)   [2019-11-22 02:10:03]
  Epoch: [133][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0189 (0.0613)   Prec@1 100.000 (98.025)   Prec@5 100.000 (99.988)   [2019-11-22 02:10:08]
  Epoch: [133][300/391]   Time 0.084 (0.052)   Data 0.000 (0.001)   Loss 0.0395 (0.0602)   Prec@1 99.219 (98.030)   Prec@5 100.000 (99.992)   [2019-11-22 02:10:13]
  **Train** Prec@1 97.990 Prec@5 99.994 Error@1 2.010
  **Test** Prec@1 90.800 Prec@5 99.720 Error@1 9.200

==>>[2019-11-22 02:10:20] [Epoch=134/200] [Need: 00:24:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [134][000/391]   Time 0.237 (0.237)   Data 0.180 (0.180)   Loss 0.0767 (0.0767)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:10:21]
  Epoch: [134][100/391]   Time 0.060 (0.051)   Data 0.000 (0.002)   Loss 0.0475 (0.0613)   Prec@1 98.438 (97.888)   Prec@5 100.000 (99.985)   [2019-11-22 02:10:26]
  Epoch: [134][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0576 (0.0593)   Prec@1 97.656 (97.936)   Prec@5 100.000 (99.992)   [2019-11-22 02:10:31]
  Epoch: [134][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0467 (0.0591)   Prec@1 98.438 (97.965)   Prec@5 100.000 (99.995)   [2019-11-22 02:10:36]
  **Train** Prec@1 97.932 Prec@5 99.994 Error@1 2.068
  **Test** Prec@1 90.790 Prec@5 99.760 Error@1 9.210

==>>[2019-11-22 02:10:42] [Epoch=135/200] [Need: 00:23:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [135][000/391]   Time 0.221 (0.221)   Data 0.149 (0.149)   Loss 0.0440 (0.0440)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:10:42]
  Epoch: [135][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0714 (0.0587)   Prec@1 97.656 (97.826)   Prec@5 100.000 (99.992)   [2019-11-22 02:10:47]
  Epoch: [135][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0774 (0.0571)   Prec@1 96.875 (98.092)   Prec@5 100.000 (99.992)   [2019-11-22 02:10:53]
  Epoch: [135][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0435 (0.0586)   Prec@1 97.656 (98.001)   Prec@5 100.000 (99.990)   [2019-11-22 02:10:58]
  **Train** Prec@1 98.046 Prec@5 99.992 Error@1 1.954
  **Test** Prec@1 90.700 Prec@5 99.690 Error@1 9.300

==>>[2019-11-22 02:11:04] [Epoch=136/200] [Need: 00:23:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [136][000/391]   Time 0.243 (0.243)   Data 0.187 (0.187)   Loss 0.1022 (0.1022)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:04]
  Epoch: [136][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0451 (0.0576)   Prec@1 98.438 (97.973)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:09]
  Epoch: [136][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0462 (0.0593)   Prec@1 98.438 (97.967)   Prec@5 100.000 (99.996)   [2019-11-22 02:11:14]
  Epoch: [136][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0470 (0.0602)   Prec@1 98.438 (97.968)   Prec@5 100.000 (99.990)   [2019-11-22 02:11:19]
  **Train** Prec@1 97.968 Prec@5 99.990 Error@1 2.032
  **Test** Prec@1 90.670 Prec@5 99.660 Error@1 9.330

==>>[2019-11-22 02:11:26] [Epoch=137/200] [Need: 00:23:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [137][000/391]   Time 0.231 (0.231)   Data 0.175 (0.175)   Loss 0.0817 (0.0817)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:26]
  Epoch: [137][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0477 (0.0619)   Prec@1 98.438 (97.850)   Prec@5 100.000 (99.985)   [2019-11-22 02:11:31]
  Epoch: [137][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0543 (0.0615)   Prec@1 97.656 (97.886)   Prec@5 100.000 (99.984)   [2019-11-22 02:11:36]
  Epoch: [137][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0231 (0.0625)   Prec@1 99.219 (97.812)   Prec@5 100.000 (99.977)   [2019-11-22 02:11:42]
  **Train** Prec@1 97.848 Prec@5 99.980 Error@1 2.152
  **Test** Prec@1 90.530 Prec@5 99.710 Error@1 9.470

==>>[2019-11-22 02:11:48] [Epoch=138/200] [Need: 00:22:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [138][000/391]   Time 0.225 (0.225)   Data 0.152 (0.152)   Loss 0.0567 (0.0567)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:49]
  Epoch: [138][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0769 (0.0626)   Prec@1 99.219 (97.850)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:54]
  Epoch: [138][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0642 (0.0619)   Prec@1 96.875 (97.792)   Prec@5 100.000 (100.000)   [2019-11-22 02:11:59]
  Epoch: [138][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1415 (0.0607)   Prec@1 96.094 (97.879)   Prec@5 100.000 (99.997)   [2019-11-22 02:12:04]
  **Train** Prec@1 97.956 Prec@5 99.998 Error@1 2.044
  **Test** Prec@1 90.570 Prec@5 99.740 Error@1 9.430

==>>[2019-11-22 02:12:10] [Epoch=139/200] [Need: 00:22:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [139][000/391]   Time 0.221 (0.221)   Data 0.169 (0.169)   Loss 0.0369 (0.0369)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:12:10]
  Epoch: [139][100/391]   Time 0.075 (0.052)   Data 0.000 (0.002)   Loss 0.0176 (0.0557)   Prec@1 100.000 (98.004)   Prec@5 100.000 (100.000)   [2019-11-22 02:12:15]
  Epoch: [139][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0634 (0.0579)   Prec@1 98.438 (97.971)   Prec@5 100.000 (99.988)   [2019-11-22 02:12:21]
  Epoch: [139][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0430 (0.0581)   Prec@1 98.438 (97.970)   Prec@5 100.000 (99.987)   [2019-11-22 02:12:25]
  **Train** Prec@1 97.964 Prec@5 99.988 Error@1 2.036
  **Test** Prec@1 90.560 Prec@5 99.710 Error@1 9.440

==>>[2019-11-22 02:12:32] [Epoch=140/200] [Need: 00:22:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [140][000/391]   Time 0.228 (0.228)   Data 0.171 (0.171)   Loss 0.0670 (0.0670)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:12:32]
  Epoch: [140][100/391]   Time 0.073 (0.054)   Data 0.000 (0.002)   Loss 0.0452 (0.0614)   Prec@1 97.656 (97.904)   Prec@5 100.000 (100.000)   [2019-11-22 02:12:37]
  Epoch: [140][200/391]   Time 0.058 (0.053)   Data 0.000 (0.001)   Loss 0.0547 (0.0581)   Prec@1 98.438 (98.029)   Prec@5 100.000 (99.996)   [2019-11-22 02:12:43]
  Epoch: [140][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0334 (0.0571)   Prec@1 98.438 (98.007)   Prec@5 100.000 (99.997)   [2019-11-22 02:12:48]
  **Train** Prec@1 98.008 Prec@5 99.996 Error@1 1.992
  **Test** Prec@1 90.790 Prec@5 99.710 Error@1 9.210

==>>[2019-11-22 02:12:54] [Epoch=141/200] [Need: 00:21:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [141][000/391]   Time 0.228 (0.228)   Data 0.149 (0.149)   Loss 0.0794 (0.0794)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:12:55]
  Epoch: [141][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.0520 (0.0598)   Prec@1 99.219 (97.919)   Prec@5 100.000 (100.000)   [2019-11-22 02:13:00]
  Epoch: [141][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0923 (0.0598)   Prec@1 97.656 (97.893)   Prec@5 100.000 (99.996)   [2019-11-22 02:13:05]
  Epoch: [141][300/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.0601 (0.0611)   Prec@1 98.438 (97.856)   Prec@5 100.000 (99.995)   [2019-11-22 02:13:10]
  **Train** Prec@1 97.868 Prec@5 99.996 Error@1 2.132
  **Test** Prec@1 90.700 Prec@5 99.710 Error@1 9.300

==>>[2019-11-22 02:13:16] [Epoch=142/200] [Need: 00:21:18] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [142][000/391]   Time 0.217 (0.217)   Data 0.148 (0.148)   Loss 0.1061 (0.1061)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:13:16]
  Epoch: [142][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.0722 (0.0602)   Prec@1 97.656 (98.066)   Prec@5 100.000 (99.985)   [2019-11-22 02:13:21]
  Epoch: [142][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0533 (0.0578)   Prec@1 98.438 (98.080)   Prec@5 100.000 (99.988)   [2019-11-22 02:13:26]
  Epoch: [142][300/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.0961 (0.0595)   Prec@1 96.094 (97.986)   Prec@5 100.000 (99.990)   [2019-11-22 02:13:31]
  **Train** Prec@1 98.000 Prec@5 99.986 Error@1 2.000
  **Test** Prec@1 90.710 Prec@5 99.710 Error@1 9.290

==>>[2019-11-22 02:13:37] [Epoch=143/200] [Need: 00:20:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [143][000/391]   Time 0.225 (0.225)   Data 0.168 (0.168)   Loss 0.0371 (0.0371)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:13:38]
  Epoch: [143][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.0733 (0.0584)   Prec@1 97.656 (98.028)   Prec@5 100.000 (99.992)   [2019-11-22 02:13:43]
  Epoch: [143][200/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0924 (0.0580)   Prec@1 96.094 (98.006)   Prec@5 100.000 (99.988)   [2019-11-22 02:13:48]
  Epoch: [143][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0762 (0.0576)   Prec@1 97.656 (98.035)   Prec@5 100.000 (99.987)   [2019-11-22 02:13:53]
  **Train** Prec@1 98.038 Prec@5 99.990 Error@1 1.962
  **Test** Prec@1 90.680 Prec@5 99.730 Error@1 9.320

==>>[2019-11-22 02:14:00] [Epoch=144/200] [Need: 00:20:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [144][000/391]   Time 0.227 (0.227)   Data 0.167 (0.167)   Loss 0.0540 (0.0540)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:14:00]
  Epoch: [144][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0403 (0.0561)   Prec@1 98.438 (98.035)   Prec@5 100.000 (99.992)   [2019-11-22 02:14:05]
  Epoch: [144][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0574 (0.0577)   Prec@1 97.656 (97.975)   Prec@5 100.000 (99.988)   [2019-11-22 02:14:10]
  Epoch: [144][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0593 (0.0573)   Prec@1 98.438 (98.004)   Prec@5 100.000 (99.992)   [2019-11-22 02:14:15]
  **Train** Prec@1 98.016 Prec@5 99.992 Error@1 1.984
  **Test** Prec@1 90.780 Prec@5 99.710 Error@1 9.220

==>>[2019-11-22 02:14:21] [Epoch=145/200] [Need: 00:20:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [145][000/391]   Time 0.227 (0.227)   Data 0.164 (0.164)   Loss 0.0722 (0.0722)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 02:14:22]
  Epoch: [145][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.0954 (0.0545)   Prec@1 95.312 (98.182)   Prec@5 100.000 (100.000)   [2019-11-22 02:14:27]
  Epoch: [145][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0514 (0.0568)   Prec@1 98.438 (98.084)   Prec@5 100.000 (100.000)   [2019-11-22 02:14:32]
  Epoch: [145][300/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.0459 (0.0573)   Prec@1 97.656 (98.064)   Prec@5 100.000 (99.995)   [2019-11-22 02:14:37]
  **Train** Prec@1 98.004 Prec@5 99.996 Error@1 1.996
  **Test** Prec@1 90.670 Prec@5 99.690 Error@1 9.330

==>>[2019-11-22 02:14:43] [Epoch=146/200] [Need: 00:19:50] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [146][000/391]   Time 0.226 (0.226)   Data 0.159 (0.159)   Loss 0.0235 (0.0235)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:14:44]
  Epoch: [146][100/391]   Time 0.082 (0.053)   Data 0.000 (0.002)   Loss 0.0700 (0.0579)   Prec@1 97.656 (98.004)   Prec@5 100.000 (99.992)   [2019-11-22 02:14:49]
  Epoch: [146][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1003 (0.0588)   Prec@1 96.875 (97.971)   Prec@5 100.000 (99.984)   [2019-11-22 02:14:54]
  Epoch: [146][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0533 (0.0586)   Prec@1 98.438 (97.983)   Prec@5 100.000 (99.990)   [2019-11-22 02:14:59]
  **Train** Prec@1 97.998 Prec@5 99.990 Error@1 2.002
  **Test** Prec@1 90.660 Prec@5 99.770 Error@1 9.340

==>>[2019-11-22 02:15:05] [Epoch=147/200] [Need: 00:19:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [147][000/391]   Time 0.222 (0.222)   Data 0.166 (0.166)   Loss 0.0395 (0.0395)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:15:06]
  Epoch: [147][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.0734 (0.0570)   Prec@1 96.875 (98.159)   Prec@5 100.000 (99.985)   [2019-11-22 02:15:10]
  Epoch: [147][200/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0367 (0.0565)   Prec@1 98.438 (98.103)   Prec@5 100.000 (99.988)   [2019-11-22 02:15:15]
  Epoch: [147][300/391]   Time 0.083 (0.050)   Data 0.000 (0.001)   Loss 0.0416 (0.0552)   Prec@1 97.656 (98.131)   Prec@5 100.000 (99.990)   [2019-11-22 02:15:20]
  **Train** Prec@1 98.072 Prec@5 99.992 Error@1 1.928
  **Test** Prec@1 90.530 Prec@5 99.690 Error@1 9.470

==>>[2019-11-22 02:15:27] [Epoch=148/200] [Need: 00:19:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [148][000/391]   Time 0.224 (0.224)   Data 0.166 (0.166)   Loss 0.0503 (0.0503)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:15:27]
  Epoch: [148][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0575 (0.0533)   Prec@1 98.438 (98.089)   Prec@5 100.000 (100.000)   [2019-11-22 02:15:32]
  Epoch: [148][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0432 (0.0557)   Prec@1 98.438 (98.072)   Prec@5 100.000 (99.996)   [2019-11-22 02:15:37]
  Epoch: [148][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0936 (0.0553)   Prec@1 96.094 (98.108)   Prec@5 100.000 (99.995)   [2019-11-22 02:15:42]
  **Train** Prec@1 98.110 Prec@5 99.992 Error@1 1.890
  **Test** Prec@1 90.610 Prec@5 99.730 Error@1 9.390

==>>[2019-11-22 02:15:49] [Epoch=149/200] [Need: 00:18:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [149][000/391]   Time 0.247 (0.247)   Data 0.183 (0.183)   Loss 0.0972 (0.0972)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:15:49]
  Epoch: [149][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.1656 (0.0572)   Prec@1 93.750 (98.097)   Prec@5 100.000 (99.985)   [2019-11-22 02:15:54]
  Epoch: [149][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0478 (0.0559)   Prec@1 97.656 (98.088)   Prec@5 100.000 (99.981)   [2019-11-22 02:15:59]
  Epoch: [149][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0788 (0.0557)   Prec@1 96.875 (98.105)   Prec@5 100.000 (99.984)   [2019-11-22 02:16:04]
  **Train** Prec@1 98.046 Prec@5 99.988 Error@1 1.954
  **Test** Prec@1 90.800 Prec@5 99.750 Error@1 9.200

==>>[2019-11-22 02:16:11] [Epoch=150/200] [Need: 00:18:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [150][000/391]   Time 0.238 (0.238)   Data 0.159 (0.159)   Loss 0.0361 (0.0361)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:16:11]
  Epoch: [150][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.0416 (0.0512)   Prec@1 99.219 (98.128)   Prec@5 100.000 (100.000)   [2019-11-22 02:16:16]
  Epoch: [150][200/391]   Time 0.048 (0.054)   Data 0.000 (0.001)   Loss 0.0532 (0.0556)   Prec@1 98.438 (98.068)   Prec@5 100.000 (99.996)   [2019-11-22 02:16:21]
  Epoch: [150][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.1121 (0.0574)   Prec@1 96.094 (98.012)   Prec@5 100.000 (99.995)   [2019-11-22 02:16:27]
  **Train** Prec@1 98.004 Prec@5 99.994 Error@1 1.996
  **Test** Prec@1 90.580 Prec@5 99.700 Error@1 9.420

==>>[2019-11-22 02:16:33] [Epoch=151/200] [Need: 00:17:59] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [151][000/391]   Time 0.215 (0.215)   Data 0.150 (0.150)   Loss 0.0618 (0.0618)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:16:33]
  Epoch: [151][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.0443 (0.0538)   Prec@1 97.656 (98.136)   Prec@5 100.000 (100.000)   [2019-11-22 02:16:38]
  Epoch: [151][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0387 (0.0539)   Prec@1 99.219 (98.142)   Prec@5 100.000 (99.992)   [2019-11-22 02:16:44]
  Epoch: [151][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0377 (0.0556)   Prec@1 99.219 (98.077)   Prec@5 100.000 (99.995)   [2019-11-22 02:16:48]
  **Train** Prec@1 98.060 Prec@5 99.994 Error@1 1.940
  **Test** Prec@1 90.480 Prec@5 99.720 Error@1 9.520

==>>[2019-11-22 02:16:55] [Epoch=152/200] [Need: 00:17:37] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [152][000/391]   Time 0.233 (0.233)   Data 0.161 (0.161)   Loss 0.0227 (0.0227)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:16:55]
  Epoch: [152][100/391]   Time 0.052 (0.056)   Data 0.000 (0.002)   Loss 0.0413 (0.0564)   Prec@1 98.438 (98.043)   Prec@5 100.000 (99.977)   [2019-11-22 02:17:01]
  Epoch: [152][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.0409 (0.0556)   Prec@1 98.438 (98.099)   Prec@5 100.000 (99.988)   [2019-11-22 02:17:06]
  Epoch: [152][300/391]   Time 0.079 (0.053)   Data 0.000 (0.001)   Loss 0.0645 (0.0569)   Prec@1 97.656 (97.994)   Prec@5 100.000 (99.990)   [2019-11-22 02:17:11]
  **Train** Prec@1 98.008 Prec@5 99.992 Error@1 1.992
  **Test** Prec@1 90.350 Prec@5 99.700 Error@1 9.650

==>>[2019-11-22 02:17:18] [Epoch=153/200] [Need: 00:17:15] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [153][000/391]   Time 0.250 (0.250)   Data 0.172 (0.172)   Loss 0.0369 (0.0369)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:17:18]
  Epoch: [153][100/391]   Time 0.053 (0.054)   Data 0.000 (0.002)   Loss 0.0555 (0.0541)   Prec@1 97.656 (98.113)   Prec@5 100.000 (100.000)   [2019-11-22 02:17:23]
  Epoch: [153][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0950 (0.0545)   Prec@1 96.094 (98.095)   Prec@5 100.000 (100.000)   [2019-11-22 02:17:28]
  Epoch: [153][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0513 (0.0550)   Prec@1 98.438 (98.040)   Prec@5 100.000 (100.000)   [2019-11-22 02:17:33]
  **Train** Prec@1 98.084 Prec@5 99.998 Error@1 1.916
  **Test** Prec@1 90.420 Prec@5 99.740 Error@1 9.580

==>>[2019-11-22 02:17:40] [Epoch=154/200] [Need: 00:16:53] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [154][000/391]   Time 0.221 (0.221)   Data 0.150 (0.150)   Loss 0.0266 (0.0266)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:17:40]
  Epoch: [154][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0746 (0.0543)   Prec@1 96.094 (98.151)   Prec@5 100.000 (99.992)   [2019-11-22 02:17:45]
  Epoch: [154][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0661 (0.0562)   Prec@1 96.094 (98.068)   Prec@5 100.000 (99.992)   [2019-11-22 02:17:50]
  Epoch: [154][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0494 (0.0558)   Prec@1 97.656 (98.046)   Prec@5 100.000 (99.995)   [2019-11-22 02:17:55]
  **Train** Prec@1 98.074 Prec@5 99.994 Error@1 1.926
  **Test** Prec@1 90.500 Prec@5 99.740 Error@1 9.500

==>>[2019-11-22 02:18:01] [Epoch=155/200] [Need: 00:16:31] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [155][000/391]   Time 0.234 (0.234)   Data 0.167 (0.167)   Loss 0.0477 (0.0477)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:18:02]
  Epoch: [155][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0831 (0.0509)   Prec@1 96.094 (98.291)   Prec@5 100.000 (99.992)   [2019-11-22 02:18:07]
  Epoch: [155][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0585 (0.0531)   Prec@1 98.438 (98.247)   Prec@5 100.000 (99.988)   [2019-11-22 02:18:12]
  Epoch: [155][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0454 (0.0542)   Prec@1 97.656 (98.183)   Prec@5 100.000 (99.990)   [2019-11-22 02:18:17]
  **Train** Prec@1 98.192 Prec@5 99.992 Error@1 1.808
  **Test** Prec@1 90.370 Prec@5 99.730 Error@1 9.630

==>>[2019-11-22 02:18:23] [Epoch=156/200] [Need: 00:16:09] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [156][000/391]   Time 0.222 (0.222)   Data 0.157 (0.157)   Loss 0.0499 (0.0499)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:18:23]
  Epoch: [156][100/391]   Time 0.053 (0.057)   Data 0.000 (0.002)   Loss 0.1019 (0.0476)   Prec@1 94.531 (98.453)   Prec@5 100.000 (100.000)   [2019-11-22 02:18:29]
  Epoch: [156][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.0475 (0.0503)   Prec@1 98.438 (98.336)   Prec@5 100.000 (99.996)   [2019-11-22 02:18:34]
  Epoch: [156][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0511 (0.0516)   Prec@1 98.438 (98.253)   Prec@5 100.000 (99.995)   [2019-11-22 02:18:39]
  **Train** Prec@1 98.194 Prec@5 99.992 Error@1 1.806
  **Test** Prec@1 90.590 Prec@5 99.720 Error@1 9.410

==>>[2019-11-22 02:18:45] [Epoch=157/200] [Need: 00:15:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [157][000/391]   Time 0.226 (0.226)   Data 0.170 (0.170)   Loss 0.0786 (0.0786)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:18:46]
  Epoch: [157][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0359 (0.0542)   Prec@1 99.219 (98.020)   Prec@5 100.000 (99.992)   [2019-11-22 02:18:51]
  Epoch: [157][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.0591 (0.0567)   Prec@1 97.656 (97.901)   Prec@5 100.000 (99.992)   [2019-11-22 02:18:56]
  Epoch: [157][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0755 (0.0552)   Prec@1 97.656 (98.048)   Prec@5 100.000 (99.995)   [2019-11-22 02:19:01]
  **Train** Prec@1 98.024 Prec@5 99.996 Error@1 1.976
  **Test** Prec@1 90.560 Prec@5 99.690 Error@1 9.440

==>>[2019-11-22 02:19:08] [Epoch=158/200] [Need: 00:15:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [158][000/391]   Time 0.237 (0.237)   Data 0.155 (0.155)   Loss 0.1159 (0.1159)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2019-11-22 02:19:08]
  Epoch: [158][100/391]   Time 0.047 (0.053)   Data 0.000 (0.002)   Loss 0.0778 (0.0541)   Prec@1 96.875 (98.244)   Prec@5 100.000 (99.985)   [2019-11-22 02:19:13]
  Epoch: [158][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.0825 (0.0534)   Prec@1 96.094 (98.208)   Prec@5 100.000 (99.992)   [2019-11-22 02:19:18]
  Epoch: [158][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0807 (0.0542)   Prec@1 97.656 (98.178)   Prec@5 100.000 (99.990)   [2019-11-22 02:19:23]
  **Train** Prec@1 98.182 Prec@5 99.992 Error@1 1.818
  **Test** Prec@1 90.650 Prec@5 99.760 Error@1 9.350

==>>[2019-11-22 02:19:30] [Epoch=159/200] [Need: 00:15:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [159][000/391]   Time 0.231 (0.231)   Data 0.167 (0.167)   Loss 0.0170 (0.0170)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:19:30]
  Epoch: [159][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0641 (0.0516)   Prec@1 96.094 (98.167)   Prec@5 100.000 (99.992)   [2019-11-22 02:19:35]
  Epoch: [159][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0497 (0.0548)   Prec@1 97.656 (98.123)   Prec@5 100.000 (99.984)   [2019-11-22 02:19:40]
  Epoch: [159][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0327 (0.0544)   Prec@1 99.219 (98.147)   Prec@5 100.000 (99.987)   [2019-11-22 02:19:45]
  **Train** Prec@1 98.172 Prec@5 99.986 Error@1 1.828
  **Test** Prec@1 90.440 Prec@5 99.710 Error@1 9.560

==>>[2019-11-22 02:19:52] [Epoch=160/200] [Need: 00:14:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [160][000/391]   Time 0.238 (0.238)   Data 0.149 (0.149)   Loss 0.0675 (0.0675)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:19:52]
  Epoch: [160][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0334 (0.0507)   Prec@1 98.438 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 02:19:57]
  Epoch: [160][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0751 (0.0522)   Prec@1 96.875 (98.290)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:02]
  Epoch: [160][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0546 (0.0519)   Prec@1 97.656 (98.277)   Prec@5 100.000 (99.995)   [2019-11-22 02:20:07]
  **Train** Prec@1 98.260 Prec@5 99.994 Error@1 1.740
  **Test** Prec@1 90.930 Prec@5 99.700 Error@1 9.070
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 02:20:14] [Epoch=161/200] [Need: 00:14:19] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [161][000/391]   Time 0.229 (0.229)   Data 0.162 (0.162)   Loss 0.0478 (0.0478)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:14]
  Epoch: [161][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0324 (0.0574)   Prec@1 99.219 (97.981)   Prec@5 100.000 (99.985)   [2019-11-22 02:20:19]
  Epoch: [161][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0393 (0.0549)   Prec@1 98.438 (98.076)   Prec@5 100.000 (99.992)   [2019-11-22 02:20:24]
  Epoch: [161][300/391]   Time 0.061 (0.051)   Data 0.000 (0.001)   Loss 0.0943 (0.0530)   Prec@1 96.875 (98.162)   Prec@5 99.219 (99.990)   [2019-11-22 02:20:29]
  **Train** Prec@1 98.168 Prec@5 99.990 Error@1 1.832
  **Test** Prec@1 90.710 Prec@5 99.710 Error@1 9.290

==>>[2019-11-22 02:20:35] [Epoch=162/200] [Need: 00:13:57] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [162][000/391]   Time 0.236 (0.236)   Data 0.175 (0.175)   Loss 0.0392 (0.0392)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:36]
  Epoch: [162][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0291 (0.0523)   Prec@1 100.000 (98.190)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:41]
  Epoch: [162][200/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.0300 (0.0532)   Prec@1 99.219 (98.111)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:46]
  Epoch: [162][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0590 (0.0522)   Prec@1 97.656 (98.214)   Prec@5 100.000 (99.995)   [2019-11-22 02:20:51]
  **Train** Prec@1 98.180 Prec@5 99.996 Error@1 1.820
  **Test** Prec@1 90.680 Prec@5 99.720 Error@1 9.320

==>>[2019-11-22 02:20:57] [Epoch=163/200] [Need: 00:13:35] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [163][000/391]   Time 0.269 (0.269)   Data 0.180 (0.180)   Loss 0.0840 (0.0840)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:20:57]
  Epoch: [163][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0639 (0.0500)   Prec@1 96.875 (98.291)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:03]
  Epoch: [163][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0774 (0.0518)   Prec@1 96.875 (98.266)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:07]
  Epoch: [163][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0582 (0.0507)   Prec@1 98.438 (98.308)   Prec@5 100.000 (99.995)   [2019-11-22 02:21:13]
  **Train** Prec@1 98.302 Prec@5 99.992 Error@1 1.698
  **Test** Prec@1 90.580 Prec@5 99.730 Error@1 9.420

==>>[2019-11-22 02:21:19] [Epoch=164/200] [Need: 00:13:13] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [164][000/391]   Time 0.225 (0.225)   Data 0.157 (0.157)   Loss 0.0634 (0.0634)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:20]
  Epoch: [164][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.0523 (0.0565)   Prec@1 99.219 (98.066)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:25]
  Epoch: [164][200/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.0740 (0.0523)   Prec@1 96.875 (98.212)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:30]
  Epoch: [164][300/391]   Time 0.075 (0.052)   Data 0.000 (0.001)   Loss 0.0707 (0.0515)   Prec@1 98.438 (98.201)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:35]
  **Train** Prec@1 98.206 Prec@5 99.998 Error@1 1.794
  **Test** Prec@1 90.530 Prec@5 99.740 Error@1 9.470

==>>[2019-11-22 02:21:41] [Epoch=165/200] [Need: 00:12:51] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [165][000/391]   Time 0.232 (0.232)   Data 0.150 (0.150)   Loss 0.0747 (0.0747)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:42]
  Epoch: [165][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0434 (0.0510)   Prec@1 98.438 (98.244)   Prec@5 100.000 (100.000)   [2019-11-22 02:21:47]
  Epoch: [165][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0297 (0.0518)   Prec@1 100.000 (98.235)   Prec@5 100.000 (99.996)   [2019-11-22 02:21:52]
  Epoch: [165][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0722 (0.0515)   Prec@1 97.656 (98.248)   Prec@5 100.000 (99.995)   [2019-11-22 02:21:57]
  **Train** Prec@1 98.242 Prec@5 99.996 Error@1 1.758
  **Test** Prec@1 90.500 Prec@5 99.720 Error@1 9.500

==>>[2019-11-22 02:22:03] [Epoch=166/200] [Need: 00:12:29] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [166][000/391]   Time 0.211 (0.211)   Data 0.155 (0.155)   Loss 0.0448 (0.0448)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:04]
  Epoch: [166][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0269 (0.0492)   Prec@1 100.000 (98.329)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:09]
  Epoch: [166][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0275 (0.0504)   Prec@1 99.219 (98.239)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:14]
  Epoch: [166][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0353 (0.0507)   Prec@1 99.219 (98.274)   Prec@5 100.000 (99.990)   [2019-11-22 02:22:19]
  **Train** Prec@1 98.248 Prec@5 99.992 Error@1 1.752
  **Test** Prec@1 90.520 Prec@5 99.730 Error@1 9.480

==>>[2019-11-22 02:22:25] [Epoch=167/200] [Need: 00:12:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [167][000/391]   Time 0.225 (0.225)   Data 0.152 (0.152)   Loss 0.0199 (0.0199)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:25]
  Epoch: [167][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0353 (0.0491)   Prec@1 99.219 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:30]
  Epoch: [167][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.0842 (0.0496)   Prec@1 96.875 (98.383)   Prec@5 100.000 (99.996)   [2019-11-22 02:22:36]
  Epoch: [167][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0337 (0.0512)   Prec@1 98.438 (98.326)   Prec@5 100.000 (99.992)   [2019-11-22 02:22:41]
  **Train** Prec@1 98.250 Prec@5 99.990 Error@1 1.750
  **Test** Prec@1 90.520 Prec@5 99.680 Error@1 9.480

==>>[2019-11-22 02:22:47] [Epoch=168/200] [Need: 00:11:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [168][000/391]   Time 0.228 (0.228)   Data 0.163 (0.163)   Loss 0.0452 (0.0452)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:22:47]
  Epoch: [168][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.0566 (0.0513)   Prec@1 96.875 (98.236)   Prec@5 100.000 (99.992)   [2019-11-22 02:22:52]
  Epoch: [168][200/391]   Time 0.064 (0.051)   Data 0.000 (0.001)   Loss 0.0396 (0.0495)   Prec@1 99.219 (98.340)   Prec@5 100.000 (99.996)   [2019-11-22 02:22:57]
  Epoch: [168][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0564 (0.0509)   Prec@1 96.875 (98.292)   Prec@5 100.000 (99.995)   [2019-11-22 02:23:02]
  **Train** Prec@1 98.288 Prec@5 99.996 Error@1 1.712
  **Test** Prec@1 90.740 Prec@5 99.730 Error@1 9.260

==>>[2019-11-22 02:23:08] [Epoch=169/200] [Need: 00:11:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [169][000/391]   Time 0.226 (0.226)   Data 0.164 (0.164)   Loss 0.0639 (0.0639)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:23:09]
  Epoch: [169][100/391]   Time 0.059 (0.053)   Data 0.000 (0.002)   Loss 0.0175 (0.0501)   Prec@1 100.000 (98.236)   Prec@5 100.000 (99.985)   [2019-11-22 02:23:14]
  Epoch: [169][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0971 (0.0512)   Prec@1 96.875 (98.197)   Prec@5 100.000 (99.992)   [2019-11-22 02:23:19]
  Epoch: [169][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0512 (0.0533)   Prec@1 96.875 (98.134)   Prec@5 100.000 (99.995)   [2019-11-22 02:23:24]
  **Train** Prec@1 98.174 Prec@5 99.996 Error@1 1.826
  **Test** Prec@1 90.790 Prec@5 99.750 Error@1 9.210

==>>[2019-11-22 02:23:30] [Epoch=170/200] [Need: 00:11:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [170][000/391]   Time 0.225 (0.225)   Data 0.152 (0.152)   Loss 0.0368 (0.0368)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:23:30]
  Epoch: [170][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.0576 (0.0482)   Prec@1 98.438 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 02:23:35]
  Epoch: [170][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0750 (0.0498)   Prec@1 97.656 (98.313)   Prec@5 100.000 (99.996)   [2019-11-22 02:23:41]
  Epoch: [170][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0313 (0.0503)   Prec@1 99.219 (98.313)   Prec@5 100.000 (99.990)   [2019-11-22 02:23:46]
  **Train** Prec@1 98.320 Prec@5 99.990 Error@1 1.680
  **Test** Prec@1 90.550 Prec@5 99.670 Error@1 9.450

==>>[2019-11-22 02:23:52] [Epoch=171/200] [Need: 00:10:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [171][000/391]   Time 0.235 (0.235)   Data 0.164 (0.164)   Loss 0.0299 (0.0299)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:23:52]
  Epoch: [171][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0979 (0.0530)   Prec@1 96.094 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 02:23:57]
  Epoch: [171][200/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0599 (0.0517)   Prec@1 98.438 (98.317)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:02]
  Epoch: [171][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0209 (0.0515)   Prec@1 100.000 (98.269)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:07]
  **Train** Prec@1 98.248 Prec@5 100.000 Error@1 1.752
  **Test** Prec@1 90.620 Prec@5 99.740 Error@1 9.380

==>>[2019-11-22 02:24:13] [Epoch=172/200] [Need: 00:10:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [172][000/391]   Time 0.207 (0.207)   Data 0.148 (0.148)   Loss 0.0325 (0.0325)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:14]
  Epoch: [172][100/391]   Time 0.065 (0.050)   Data 0.000 (0.002)   Loss 0.0295 (0.0513)   Prec@1 100.000 (98.221)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:18]
  Epoch: [172][200/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.0465 (0.0512)   Prec@1 99.219 (98.189)   Prec@5 100.000 (99.992)   [2019-11-22 02:24:23]
  Epoch: [172][300/391]   Time 0.065 (0.051)   Data 0.000 (0.001)   Loss 0.0547 (0.0519)   Prec@1 97.656 (98.204)   Prec@5 100.000 (99.992)   [2019-11-22 02:24:29]
  **Train** Prec@1 98.184 Prec@5 99.988 Error@1 1.816
  **Test** Prec@1 90.570 Prec@5 99.700 Error@1 9.430

==>>[2019-11-22 02:24:35] [Epoch=173/200] [Need: 00:09:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [173][000/391]   Time 0.227 (0.227)   Data 0.170 (0.170)   Loss 0.0727 (0.0727)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:35]
  Epoch: [173][100/391]   Time 0.061 (0.054)   Data 0.000 (0.002)   Loss 0.0437 (0.0500)   Prec@1 98.438 (98.298)   Prec@5 100.000 (99.992)   [2019-11-22 02:24:41]
  Epoch: [173][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0544 (0.0511)   Prec@1 99.219 (98.259)   Prec@5 100.000 (99.988)   [2019-11-22 02:24:46]
  Epoch: [173][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0703 (0.0511)   Prec@1 98.438 (98.303)   Prec@5 100.000 (99.990)   [2019-11-22 02:24:51]
  **Train** Prec@1 98.318 Prec@5 99.992 Error@1 1.682
  **Test** Prec@1 90.580 Prec@5 99.640 Error@1 9.420

==>>[2019-11-22 02:24:57] [Epoch=174/200] [Need: 00:09:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [174][000/391]   Time 0.226 (0.226)   Data 0.164 (0.164)   Loss 0.0386 (0.0386)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:24:58]
  Epoch: [174][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0450 (0.0514)   Prec@1 97.656 (98.167)   Prec@5 100.000 (100.000)   [2019-11-22 02:25:03]
  Epoch: [174][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0391 (0.0517)   Prec@1 98.438 (98.255)   Prec@5 100.000 (99.988)   [2019-11-22 02:25:08]
  Epoch: [174][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0190 (0.0510)   Prec@1 100.000 (98.308)   Prec@5 100.000 (99.990)   [2019-11-22 02:25:13]
  **Train** Prec@1 98.266 Prec@5 99.990 Error@1 1.734
  **Test** Prec@1 90.610 Prec@5 99.690 Error@1 9.390

==>>[2019-11-22 02:25:19] [Epoch=175/200] [Need: 00:09:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [175][000/391]   Time 0.215 (0.215)   Data 0.152 (0.152)   Loss 0.0585 (0.0585)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:25:20]
  Epoch: [175][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0344 (0.0523)   Prec@1 98.438 (98.167)   Prec@5 100.000 (99.992)   [2019-11-22 02:25:24]
  Epoch: [175][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0893 (0.0523)   Prec@1 95.312 (98.173)   Prec@5 100.000 (99.996)   [2019-11-22 02:25:29]
  Epoch: [175][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0428 (0.0522)   Prec@1 99.219 (98.165)   Prec@5 100.000 (99.995)   [2019-11-22 02:25:35]
  **Train** Prec@1 98.228 Prec@5 99.994 Error@1 1.772
  **Test** Prec@1 90.490 Prec@5 99.700 Error@1 9.510

==>>[2019-11-22 02:25:41] [Epoch=176/200] [Need: 00:08:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [176][000/391]   Time 0.243 (0.243)   Data 0.173 (0.173)   Loss 0.0886 (0.0886)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 02:25:41]
  Epoch: [176][100/391]   Time 0.083 (0.056)   Data 0.000 (0.002)   Loss 0.0632 (0.0483)   Prec@1 96.094 (98.507)   Prec@5 100.000 (99.992)   [2019-11-22 02:25:47]
  Epoch: [176][200/391]   Time 0.046 (0.054)   Data 0.000 (0.001)   Loss 0.0366 (0.0493)   Prec@1 99.219 (98.403)   Prec@5 100.000 (99.992)   [2019-11-22 02:25:52]
  Epoch: [176][300/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0469 (0.0498)   Prec@1 98.438 (98.373)   Prec@5 100.000 (99.995)   [2019-11-22 02:25:57]
  **Train** Prec@1 98.306 Prec@5 99.996 Error@1 1.694
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-22 02:26:04] [Epoch=177/200] [Need: 00:08:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [177][000/391]   Time 0.220 (0.220)   Data 0.156 (0.156)   Loss 0.0151 (0.0151)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:04]
  Epoch: [177][100/391]   Time 0.047 (0.055)   Data 0.000 (0.002)   Loss 0.0613 (0.0509)   Prec@1 98.438 (98.275)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:09]
  Epoch: [177][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0400 (0.0511)   Prec@1 98.438 (98.278)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:14]
  Epoch: [177][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0282 (0.0503)   Prec@1 98.438 (98.277)   Prec@5 100.000 (99.997)   [2019-11-22 02:26:19]
  **Train** Prec@1 98.246 Prec@5 99.996 Error@1 1.754
  **Test** Prec@1 90.590 Prec@5 99.690 Error@1 9.410

==>>[2019-11-22 02:26:26] [Epoch=178/200] [Need: 00:08:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [178][000/391]   Time 0.221 (0.221)   Data 0.149 (0.149)   Loss 0.0470 (0.0470)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:27]
  Epoch: [178][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0483 (0.0503)   Prec@1 98.438 (98.345)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:32]
  Epoch: [178][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.0362 (0.0508)   Prec@1 99.219 (98.352)   Prec@5 100.000 (99.996)   [2019-11-22 02:26:37]
  Epoch: [178][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0434 (0.0497)   Prec@1 98.438 (98.341)   Prec@5 100.000 (99.997)   [2019-11-22 02:26:42]
  **Train** Prec@1 98.324 Prec@5 99.992 Error@1 1.676
  **Test** Prec@1 90.510 Prec@5 99.710 Error@1 9.490

==>>[2019-11-22 02:26:48] [Epoch=179/200] [Need: 00:07:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [179][000/391]   Time 0.226 (0.226)   Data 0.165 (0.165)   Loss 0.0521 (0.0521)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:48]
  Epoch: [179][100/391]   Time 0.055 (0.051)   Data 0.000 (0.002)   Loss 0.0284 (0.0519)   Prec@1 99.219 (98.066)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:53]
  Epoch: [179][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0520 (0.0496)   Prec@1 98.438 (98.208)   Prec@5 100.000 (100.000)   [2019-11-22 02:26:59]
  Epoch: [179][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0797 (0.0506)   Prec@1 96.875 (98.232)   Prec@5 100.000 (99.995)   [2019-11-22 02:27:04]
  **Train** Prec@1 98.268 Prec@5 99.994 Error@1 1.732
  **Test** Prec@1 90.750 Prec@5 99.690 Error@1 9.250

==>>[2019-11-22 02:27:10] [Epoch=180/200] [Need: 00:07:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [180][000/391]   Time 0.229 (0.229)   Data 0.148 (0.148)   Loss 0.0167 (0.0167)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:10]
  Epoch: [180][100/391]   Time 0.046 (0.049)   Data 0.000 (0.002)   Loss 0.0200 (0.0461)   Prec@1 99.219 (98.530)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:15]
  Epoch: [180][200/391]   Time 0.078 (0.050)   Data 0.000 (0.001)   Loss 0.0294 (0.0485)   Prec@1 98.438 (98.344)   Prec@5 100.000 (99.996)   [2019-11-22 02:27:20]
  Epoch: [180][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0297 (0.0486)   Prec@1 99.219 (98.318)   Prec@5 100.000 (99.997)   [2019-11-22 02:27:25]
  **Train** Prec@1 98.352 Prec@5 99.998 Error@1 1.648
  **Test** Prec@1 90.430 Prec@5 99.680 Error@1 9.570

==>>[2019-11-22 02:27:32] [Epoch=181/200] [Need: 00:06:58] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [181][000/391]   Time 0.224 (0.224)   Data 0.151 (0.151)   Loss 0.0456 (0.0456)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:32]
  Epoch: [181][100/391]   Time 0.055 (0.054)   Data 0.000 (0.002)   Loss 0.0216 (0.0478)   Prec@1 100.000 (98.407)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:37]
  Epoch: [181][200/391]   Time 0.062 (0.053)   Data 0.000 (0.001)   Loss 0.0614 (0.0485)   Prec@1 97.656 (98.348)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:42]
  Epoch: [181][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0724 (0.0480)   Prec@1 97.656 (98.386)   Prec@5 100.000 (99.997)   [2019-11-22 02:27:47]
  **Train** Prec@1 98.346 Prec@5 99.994 Error@1 1.654
  **Test** Prec@1 90.610 Prec@5 99.670 Error@1 9.390

==>>[2019-11-22 02:27:54] [Epoch=182/200] [Need: 00:06:36] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [182][000/391]   Time 0.244 (0.244)   Data 0.177 (0.177)   Loss 0.0599 (0.0599)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:54]
  Epoch: [182][100/391]   Time 0.052 (0.050)   Data 0.000 (0.002)   Loss 0.0430 (0.0498)   Prec@1 97.656 (98.244)   Prec@5 100.000 (100.000)   [2019-11-22 02:27:59]
  Epoch: [182][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0409 (0.0516)   Prec@1 98.438 (98.266)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:04]
  Epoch: [182][300/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.0492 (0.0513)   Prec@1 98.438 (98.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:09]
  **Train** Prec@1 98.232 Prec@5 99.998 Error@1 1.768
  **Test** Prec@1 90.630 Prec@5 99.730 Error@1 9.370

==>>[2019-11-22 02:28:15] [Epoch=183/200] [Need: 00:06:14] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [183][000/391]   Time 0.224 (0.224)   Data 0.147 (0.147)   Loss 0.0352 (0.0352)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:15]
  Epoch: [183][100/391]   Time 0.050 (0.052)   Data 0.000 (0.002)   Loss 0.0346 (0.0473)   Prec@1 99.219 (98.422)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:20]
  Epoch: [183][200/391]   Time 0.069 (0.052)   Data 0.000 (0.001)   Loss 0.0133 (0.0493)   Prec@1 100.000 (98.333)   Prec@5 100.000 (99.996)   [2019-11-22 02:28:26]
  Epoch: [183][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0641 (0.0496)   Prec@1 97.656 (98.310)   Prec@5 100.000 (99.992)   [2019-11-22 02:28:31]
  **Train** Prec@1 98.334 Prec@5 99.992 Error@1 1.666
  **Test** Prec@1 90.510 Prec@5 99.720 Error@1 9.490

==>>[2019-11-22 02:28:37] [Epoch=184/200] [Need: 00:05:52] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [184][000/391]   Time 0.225 (0.225)   Data 0.159 (0.159)   Loss 0.0504 (0.0504)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:37]
  Epoch: [184][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0960 (0.0523)   Prec@1 97.656 (98.244)   Prec@5 100.000 (99.992)   [2019-11-22 02:28:42]
  Epoch: [184][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0568 (0.0499)   Prec@1 97.656 (98.274)   Prec@5 100.000 (99.996)   [2019-11-22 02:28:47]
  Epoch: [184][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0343 (0.0499)   Prec@1 99.219 (98.316)   Prec@5 100.000 (99.997)   [2019-11-22 02:28:52]
  **Train** Prec@1 98.254 Prec@5 99.998 Error@1 1.746
  **Test** Prec@1 90.580 Prec@5 99.740 Error@1 9.420

==>>[2019-11-22 02:28:59] [Epoch=185/200] [Need: 00:05:30] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [185][000/391]   Time 0.222 (0.222)   Data 0.163 (0.163)   Loss 0.0385 (0.0385)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:28:59]
  Epoch: [185][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0543 (0.0486)   Prec@1 98.438 (98.314)   Prec@5 100.000 (100.000)   [2019-11-22 02:29:04]
  Epoch: [185][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0524 (0.0504)   Prec@1 97.656 (98.274)   Prec@5 100.000 (99.988)   [2019-11-22 02:29:09]
  Epoch: [185][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0313 (0.0495)   Prec@1 98.438 (98.321)   Prec@5 100.000 (99.987)   [2019-11-22 02:29:14]
  **Train** Prec@1 98.284 Prec@5 99.988 Error@1 1.716
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-22 02:29:21] [Epoch=186/200] [Need: 00:05:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [186][000/391]   Time 0.219 (0.219)   Data 0.148 (0.148)   Loss 0.0488 (0.0488)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:29:21]
  Epoch: [186][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.0316 (0.0499)   Prec@1 98.438 (98.260)   Prec@5 100.000 (99.992)   [2019-11-22 02:29:26]
  Epoch: [186][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0155 (0.0514)   Prec@1 100.000 (98.231)   Prec@5 100.000 (99.988)   [2019-11-22 02:29:31]
  Epoch: [186][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0505 (0.0513)   Prec@1 98.438 (98.238)   Prec@5 100.000 (99.992)   [2019-11-22 02:29:36]
  **Train** Prec@1 98.234 Prec@5 99.992 Error@1 1.766
  **Test** Prec@1 90.590 Prec@5 99.700 Error@1 9.410

==>>[2019-11-22 02:29:43] [Epoch=187/200] [Need: 00:04:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [187][000/391]   Time 0.216 (0.216)   Data 0.153 (0.153)   Loss 0.0719 (0.0719)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 02:29:43]
  Epoch: [187][100/391]   Time 0.051 (0.054)   Data 0.000 (0.002)   Loss 0.0575 (0.0486)   Prec@1 98.438 (98.337)   Prec@5 100.000 (99.985)   [2019-11-22 02:29:48]
  Epoch: [187][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0389 (0.0510)   Prec@1 98.438 (98.243)   Prec@5 100.000 (99.984)   [2019-11-22 02:29:53]
  Epoch: [187][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0290 (0.0508)   Prec@1 99.219 (98.238)   Prec@5 100.000 (99.990)   [2019-11-22 02:29:58]
  **Train** Prec@1 98.256 Prec@5 99.992 Error@1 1.744
  **Test** Prec@1 90.590 Prec@5 99.720 Error@1 9.410

==>>[2019-11-22 02:30:06] [Epoch=188/200] [Need: 00:04:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [188][000/391]   Time 0.230 (0.230)   Data 0.149 (0.149)   Loss 0.0282 (0.0282)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:30:06]
  Epoch: [188][100/391]   Time 0.040 (0.054)   Data 0.000 (0.002)   Loss 0.0301 (0.0450)   Prec@1 99.219 (98.445)   Prec@5 100.000 (99.992)   [2019-11-22 02:30:11]
  Epoch: [188][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0399 (0.0487)   Prec@1 97.656 (98.364)   Prec@5 100.000 (99.992)   [2019-11-22 02:30:16]
  Epoch: [188][300/391]   Time 0.084 (0.052)   Data 0.000 (0.001)   Loss 0.0298 (0.0485)   Prec@1 98.438 (98.365)   Prec@5 100.000 (99.995)   [2019-11-22 02:30:21]
  **Train** Prec@1 98.286 Prec@5 99.994 Error@1 1.714
  **Test** Prec@1 90.500 Prec@5 99.740 Error@1 9.500

==>>[2019-11-22 02:30:28] [Epoch=189/200] [Need: 00:04:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [189][000/391]   Time 0.225 (0.225)   Data 0.158 (0.158)   Loss 0.0422 (0.0422)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:30:28]
  Epoch: [189][100/391]   Time 0.048 (0.054)   Data 0.000 (0.002)   Loss 0.0669 (0.0482)   Prec@1 96.875 (98.391)   Prec@5 100.000 (100.000)   [2019-11-22 02:30:33]
  Epoch: [189][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0942 (0.0488)   Prec@1 95.312 (98.329)   Prec@5 100.000 (99.996)   [2019-11-22 02:30:39]
  Epoch: [189][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0543 (0.0486)   Prec@1 96.875 (98.326)   Prec@5 100.000 (99.992)   [2019-11-22 02:30:43]
  **Train** Prec@1 98.350 Prec@5 99.992 Error@1 1.650
  **Test** Prec@1 90.470 Prec@5 99.730 Error@1 9.530

==>>[2019-11-22 02:30:50] [Epoch=190/200] [Need: 00:03:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [190][000/391]   Time 0.229 (0.229)   Data 0.166 (0.166)   Loss 0.0328 (0.0328)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:30:50]
  Epoch: [190][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0391 (0.0539)   Prec@1 99.219 (98.074)   Prec@5 100.000 (99.992)   [2019-11-22 02:30:55]
  Epoch: [190][200/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0962 (0.0509)   Prec@1 96.875 (98.247)   Prec@5 100.000 (99.992)   [2019-11-22 02:31:00]
  Epoch: [190][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0890 (0.0502)   Prec@1 96.094 (98.297)   Prec@5 99.219 (99.992)   [2019-11-22 02:31:05]
  **Train** Prec@1 98.290 Prec@5 99.994 Error@1 1.710
  **Test** Prec@1 90.500 Prec@5 99.720 Error@1 9.500

==>>[2019-11-22 02:31:12] [Epoch=191/200] [Need: 00:03:18] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [191][000/391]   Time 0.233 (0.233)   Data 0.174 (0.174)   Loss 0.0491 (0.0491)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:31:12]
  Epoch: [191][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.0363 (0.0431)   Prec@1 98.438 (98.569)   Prec@5 100.000 (99.992)   [2019-11-22 02:31:17]
  Epoch: [191][200/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.0221 (0.0444)   Prec@1 100.000 (98.511)   Prec@5 100.000 (99.988)   [2019-11-22 02:31:22]
  Epoch: [191][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0321 (0.0464)   Prec@1 99.219 (98.453)   Prec@5 100.000 (99.992)   [2019-11-22 02:31:27]
  **Train** Prec@1 98.454 Prec@5 99.994 Error@1 1.546
  **Test** Prec@1 90.620 Prec@5 99.710 Error@1 9.380

==>>[2019-11-22 02:31:34] [Epoch=192/200] [Need: 00:02:56] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [192][000/391]   Time 0.233 (0.233)   Data 0.170 (0.170)   Loss 0.0224 (0.0224)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 02:31:34]
  Epoch: [192][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0373 (0.0456)   Prec@1 99.219 (98.546)   Prec@5 100.000 (100.000)   [2019-11-22 02:31:39]
  Epoch: [192][200/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.0420 (0.0470)   Prec@1 98.438 (98.488)   Prec@5 100.000 (99.996)   [2019-11-22 02:31:44]
  Epoch: [192][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0393 (0.0489)   Prec@1 99.219 (98.388)   Prec@5 100.000 (99.995)   [2019-11-22 02:31:49]
  **Train** Prec@1 98.380 Prec@5 99.992 Error@1 1.620
  **Test** Prec@1 90.500 Prec@5 99.710 Error@1 9.500

==>>[2019-11-22 02:31:55] [Epoch=193/200] [Need: 00:02:34] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [193][000/391]   Time 0.228 (0.228)   Data 0.165 (0.165)   Loss 0.0430 (0.0430)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:31:56]
  Epoch: [193][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0599 (0.0458)   Prec@1 97.656 (98.453)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:01]
  Epoch: [193][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0471 (0.0460)   Prec@1 99.219 (98.496)   Prec@5 100.000 (99.996)   [2019-11-22 02:32:06]
  Epoch: [193][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0426 (0.0478)   Prec@1 98.438 (98.412)   Prec@5 100.000 (99.997)   [2019-11-22 02:32:11]
  **Train** Prec@1 98.370 Prec@5 99.998 Error@1 1.630
  **Test** Prec@1 90.520 Prec@5 99.740 Error@1 9.480

==>>[2019-11-22 02:32:18] [Epoch=194/200] [Need: 00:02:12] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [194][000/391]   Time 0.235 (0.235)   Data 0.147 (0.147)   Loss 0.0312 (0.0312)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:18]
  Epoch: [194][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0344 (0.0491)   Prec@1 98.438 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:23]
  Epoch: [194][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0564 (0.0505)   Prec@1 96.875 (98.231)   Prec@5 100.000 (99.988)   [2019-11-22 02:32:28]
  Epoch: [194][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0304 (0.0510)   Prec@1 98.438 (98.212)   Prec@5 100.000 (99.990)   [2019-11-22 02:32:33]
  **Train** Prec@1 98.228 Prec@5 99.988 Error@1 1.772
  **Test** Prec@1 90.430 Prec@5 99.750 Error@1 9.570

==>>[2019-11-22 02:32:40] [Epoch=195/200] [Need: 00:01:50] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [195][000/391]   Time 0.234 (0.234)   Data 0.176 (0.176)   Loss 0.0474 (0.0474)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:40]
  Epoch: [195][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.1065 (0.0450)   Prec@1 95.312 (98.492)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:45]
  Epoch: [195][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0577 (0.0481)   Prec@1 96.875 (98.375)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:50]
  Epoch: [195][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0807 (0.0488)   Prec@1 97.656 (98.386)   Prec@5 100.000 (100.000)   [2019-11-22 02:32:55]
  **Train** Prec@1 98.364 Prec@5 100.000 Error@1 1.636
  **Test** Prec@1 90.690 Prec@5 99.700 Error@1 9.310

==>>[2019-11-22 02:33:02] [Epoch=196/200] [Need: 00:01:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [196][000/391]   Time 0.229 (0.229)   Data 0.165 (0.165)   Loss 0.0557 (0.0557)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:33:02]
  Epoch: [196][100/391]   Time 0.057 (0.055)   Data 0.000 (0.002)   Loss 0.0363 (0.0471)   Prec@1 98.438 (98.376)   Prec@5 100.000 (100.000)   [2019-11-22 02:33:08]
  Epoch: [196][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0602 (0.0459)   Prec@1 97.656 (98.457)   Prec@5 100.000 (99.996)   [2019-11-22 02:33:13]
  Epoch: [196][300/391]   Time 0.082 (0.051)   Data 0.000 (0.001)   Loss 0.0621 (0.0476)   Prec@1 97.656 (98.352)   Prec@5 100.000 (99.997)   [2019-11-22 02:33:17]
  **Train** Prec@1 98.326 Prec@5 99.998 Error@1 1.674
  **Test** Prec@1 90.630 Prec@5 99.740 Error@1 9.370

==>>[2019-11-22 02:33:24] [Epoch=197/200] [Need: 00:01:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [197][000/391]   Time 0.229 (0.229)   Data 0.165 (0.165)   Loss 0.0469 (0.0469)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:33:24]
  Epoch: [197][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.0295 (0.0516)   Prec@1 99.219 (98.159)   Prec@5 100.000 (99.992)   [2019-11-22 02:33:29]
  Epoch: [197][200/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0385 (0.0485)   Prec@1 99.219 (98.391)   Prec@5 100.000 (99.992)   [2019-11-22 02:33:34]
  Epoch: [197][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0156 (0.0482)   Prec@1 100.000 (98.399)   Prec@5 100.000 (99.990)   [2019-11-22 02:33:39]
  **Train** Prec@1 98.362 Prec@5 99.992 Error@1 1.638
  **Test** Prec@1 90.540 Prec@5 99.720 Error@1 9.460

==>>[2019-11-22 02:33:46] [Epoch=198/200] [Need: 00:00:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [198][000/391]   Time 0.226 (0.226)   Data 0.153 (0.153)   Loss 0.0590 (0.0590)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 02:33:46]
  Epoch: [198][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.0730 (0.0465)   Prec@1 97.656 (98.515)   Prec@5 100.000 (100.000)   [2019-11-22 02:33:51]
  Epoch: [198][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0256 (0.0482)   Prec@1 100.000 (98.406)   Prec@5 100.000 (99.996)   [2019-11-22 02:33:56]
  Epoch: [198][300/391]   Time 0.061 (0.051)   Data 0.000 (0.001)   Loss 0.0654 (0.0491)   Prec@1 96.094 (98.360)   Prec@5 100.000 (99.992)   [2019-11-22 02:34:01]
  **Train** Prec@1 98.336 Prec@5 99.990 Error@1 1.664
  **Test** Prec@1 90.670 Prec@5 99.690 Error@1 9.330

==>>[2019-11-22 02:34:08] [Epoch=199/200] [Need: 00:00:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.93, Error=9.07]
  Epoch: [199][000/391]   Time 0.217 (0.217)   Data 0.158 (0.158)   Loss 0.0364 (0.0364)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 02:34:08]
  Epoch: [199][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0161 (0.0481)   Prec@1 100.000 (98.391)   Prec@5 100.000 (99.985)   [2019-11-22 02:34:13]
  Epoch: [199][200/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.0273 (0.0494)   Prec@1 99.219 (98.298)   Prec@5 100.000 (99.988)   [2019-11-22 02:34:19]
  Epoch: [199][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0816 (0.0497)   Prec@1 95.312 (98.240)   Prec@5 100.000 (99.992)   [2019-11-22 02:34:23]
  **Train** Prec@1 98.240 Prec@5 99.994 Error@1 1.760
  **Test** Prec@1 90.650 Prec@5 99.690 Error@1 9.350
