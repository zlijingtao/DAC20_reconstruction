Evaluate saved Model : /home/jingtao1/TNN/save/2019-11-20/cifar10_quan_resnet20_200_i4r4o4_adam0.8_1bit/model_best.pth.tar
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'enable_bfa': True, 'enable_oneshot': False, 'enable_rfa': False, 'evaluate': False, 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 4], 'input_num_bits': 1, 'k_top': 10, 'manualSeed': 5000, 'n_iter': 20, 'ngpu': 1, 'output_M2D': 0.8, 'output_grain_size': [1, 4], 'output_num_bits': 1, 'res_M2D': 0.8, 'res_grain_size': [1, 4], 'res_num_bits': 1, 'reset_weight': True, 'resume': '/home/jingtao1/TNN/save/2019-11-20/cifar10_quan_resnet20_200_i4r4o4_adam0.8_1bit/model_best.pth.tar', 'update_mask_flag': False, 'use_cuda': True, 'workers': 4}
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> loading checkpoint '/home/jingtao1/TNN/save/2019-11-20/cifar10_quan_resnet20_200_i4r4o4_adam0.8_1bit/model_best.pth.tar'
=> loaded checkpoint '/home/jingtao1/TNN/save/2019-11-20/cifar10_quan_resnet20_200_i4r4o4_adam0.8_1bit/model_best.pth.tar'
  **Test** Prec@1 81.000 Prec@5 98.900 Error@1 19.000
k_top is set to 10
Attack sample size is 128
**********************************
Iteration: [001/020]   Attack Time 0.262 (0.262)  [2019-11-20 16:53:27]
loss before attack: 0.2893
loss after attack: 0.3555
bit flips: 1
hamming_dist: 0
  **Test** Prec@1 77.090 Prec@5 98.900 Error@1 22.910
actual loss: 0.6402
iteration Time 1.993 (1.993)
**********************************
Iteration: [002/020]   Attack Time 0.214 (0.238)  [2019-11-20 16:53:29]
loss before attack: 0.3555
loss after attack: 0.4126
bit flips: 2
hamming_dist: 0
  **Test** Prec@1 75.250 Prec@5 98.750 Error@1 24.750
actual loss: 0.6892
iteration Time 2.043 (2.018)
**********************************
Iteration: [003/020]   Attack Time 0.204 (0.227)  [2019-11-20 16:53:31]
loss before attack: 0.4126
loss after attack: 0.4436
bit flips: 3
hamming_dist: 0
  **Test** Prec@1 74.320 Prec@5 98.680 Error@1 25.680
actual loss: 0.7100
iteration Time 2.207 (2.081)
**********************************
Iteration: [004/020]   Attack Time 0.202 (0.220)  [2019-11-20 16:53:33]
loss before attack: 0.4436
loss after attack: 0.4799
bit flips: 4
hamming_dist: 0
  **Test** Prec@1 73.240 Prec@5 98.640 Error@1 26.760
actual loss: 0.7343
iteration Time 1.862 (2.026)
**********************************
Iteration: [005/020]   Attack Time 0.208 (0.218)  [2019-11-20 16:53:35]
loss before attack: 0.4799
loss after attack: 0.5199
bit flips: 5
hamming_dist: 0
  **Test** Prec@1 72.610 Prec@5 98.610 Error@1 27.390
actual loss: 0.7576
iteration Time 1.973 (2.016)
**********************************
Iteration: [006/020]   Attack Time 0.215 (0.217)  [2019-11-20 16:53:38]
loss before attack: 0.5199
loss after attack: 0.5652
bit flips: 6
hamming_dist: 0
  **Test** Prec@1 70.750 Prec@5 98.560 Error@1 29.250
actual loss: 0.8088
iteration Time 1.869 (1.991)
**********************************
Iteration: [007/020]   Attack Time 0.196 (0.214)  [2019-11-20 16:53:40]
loss before attack: 0.5652
loss after attack: 0.6577
bit flips: 7
hamming_dist: 0
  **Test** Prec@1 67.410 Prec@5 98.300 Error@1 32.590
actual loss: 0.9200
iteration Time 1.860 (1.973)
**********************************
Iteration: [008/020]   Attack Time 0.200 (0.213)  [2019-11-20 16:53:42]
loss before attack: 0.6577
loss after attack: 0.7584
bit flips: 8
hamming_dist: 0
  **Test** Prec@1 63.380 Prec@5 97.920 Error@1 36.620
actual loss: 1.0531
iteration Time 1.989 (1.975)
**********************************
Iteration: [009/020]   Attack Time 0.194 (0.210)  [2019-11-20 16:53:44]
loss before attack: 0.7584
loss after attack: 0.8409
bit flips: 9
hamming_dist: 0
  **Test** Prec@1 61.550 Prec@5 97.580 Error@1 38.450
actual loss: 1.1283
iteration Time 2.048 (1.983)
**********************************
Iteration: [010/020]   Attack Time 0.200 (0.209)  [2019-11-20 16:53:46]
loss before attack: 0.8409
loss after attack: 0.8903
bit flips: 10
hamming_dist: 0
  **Test** Prec@1 60.480 Prec@5 97.240 Error@1 39.520
actual loss: 1.1830
iteration Time 2.062 (1.991)
**********************************
Iteration: [011/020]   Attack Time 0.200 (0.209)  [2019-11-20 16:53:48]
loss before attack: 0.8903
loss after attack: 0.9485
bit flips: 11
hamming_dist: 0
  **Test** Prec@1 58.810 Prec@5 97.010 Error@1 41.190
actual loss: 1.2585
iteration Time 2.098 (2.000)
**********************************
Iteration: [012/020]   Attack Time 0.195 (0.207)  [2019-11-20 16:53:51]
loss before attack: 0.9485
loss after attack: 0.9996
bit flips: 12
hamming_dist: 0
  **Test** Prec@1 57.070 Prec@5 96.760 Error@1 42.930
actual loss: 1.3485
iteration Time 2.359 (2.030)
**********************************
Iteration: [013/020]   Attack Time 0.204 (0.207)  [2019-11-20 16:53:53]
loss before attack: 0.9996
loss after attack: 1.0447
bit flips: 13
hamming_dist: 0
  **Test** Prec@1 55.980 Prec@5 96.450 Error@1 44.020
actual loss: 1.4028
iteration Time 1.827 (2.015)
**********************************
Iteration: [014/020]   Attack Time 0.199 (0.207)  [2019-11-20 16:53:55]
loss before attack: 1.0447
loss after attack: 1.1121
bit flips: 14
hamming_dist: 0
  **Test** Prec@1 54.190 Prec@5 96.140 Error@1 45.810
actual loss: 1.4932
iteration Time 1.870 (2.004)
**********************************
Iteration: [015/020]   Attack Time 0.198 (0.206)  [2019-11-20 16:53:57]
loss before attack: 1.1121
loss after attack: 1.1617
bit flips: 15
hamming_dist: 0
  **Test** Prec@1 52.800 Prec@5 96.030 Error@1 47.200
actual loss: 1.5632
iteration Time 2.263 (2.022)
**********************************
Iteration: [016/020]   Attack Time 0.199 (0.206)  [2019-11-20 16:54:00]
loss before attack: 1.1617
loss after attack: 1.1998
bit flips: 16
hamming_dist: 0
  **Test** Prec@1 52.170 Prec@5 95.690 Error@1 47.830
actual loss: 1.6037
iteration Time 2.184 (2.032)
**********************************
Iteration: [017/020]   Attack Time 0.209 (0.206)  [2019-11-20 16:54:02]
loss before attack: 1.1998
loss after attack: 1.2357
bit flips: 17
hamming_dist: 0
  **Test** Prec@1 51.430 Prec@5 95.450 Error@1 48.570
actual loss: 1.6398
iteration Time 2.168 (2.040)
**********************************
Iteration: [018/020]   Attack Time 0.210 (0.206)  [2019-11-20 16:54:05]
loss before attack: 1.2357
loss after attack: 1.3392
bit flips: 18
hamming_dist: 0
  **Test** Prec@1 49.010 Prec@5 94.790 Error@1 50.990
actual loss: 1.8022
iteration Time 2.312 (2.055)
**********************************
Iteration: [019/020]   Attack Time 0.204 (0.206)  [2019-11-20 16:54:07]
loss before attack: 1.3392
loss after attack: 1.4238
bit flips: 19
hamming_dist: 0
  **Test** Prec@1 47.460 Prec@5 94.740 Error@1 52.540
actual loss: 1.9092
iteration Time 1.751 (2.039)
**********************************
Iteration: [020/020]   Attack Time 0.200 (0.206)  [2019-11-20 16:54:09]
loss before attack: 1.4238
loss after attack: 1.5486
bit flips: 20
hamming_dist: 0
  **Test** Prec@1 45.760 Prec@5 94.590 Error@1 54.240
actual loss: 2.0660
iteration Time 1.971 (2.035)
