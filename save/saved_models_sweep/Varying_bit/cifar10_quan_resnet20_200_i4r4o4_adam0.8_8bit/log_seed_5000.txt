save path : ./save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_8bit_reg0.0
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 4], 'input_num_bits': 8, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.8, 'output_grain_size': [1, 4], 'output_num_bits': 8, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.8, 'res_grain_size': [1, 4], 'res_num_bits': 8, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_8bit_reg0.0', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-22 03:48:05] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.620 (1.620)   Data 0.131 (0.131)   Loss 3.6706 (3.6706)   Prec@1 10.156 (10.156)   Prec@5 49.219 (49.219)   [2019-11-22 03:48:07]
  Epoch: [000][100/391]   Time 0.060 (0.068)   Data 0.000 (0.001)   Loss 1.8171 (1.9772)   Prec@1 32.812 (27.344)   Prec@5 87.500 (80.167)   [2019-11-22 03:48:12]
  Epoch: [000][200/391]   Time 0.042 (0.058)   Data 0.000 (0.001)   Loss 1.5967 (1.7885)   Prec@1 39.844 (33.535)   Prec@5 90.625 (85.331)   [2019-11-22 03:48:17]
  Epoch: [000][300/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 1.2410 (1.6440)   Prec@1 57.031 (39.081)   Prec@5 94.531 (88.115)   [2019-11-22 03:48:21]
  **Train** Prec@1 42.770 Prec@5 89.634 Error@1 57.230
  **Test** Prec@1 55.810 Prec@5 94.840 Error@1 44.190
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:48:27] [Epoch=001/200] [Need: 01:12:46] [LR=0.0100][M=0.90] [Best : Accuracy=55.81, Error=44.19]
  Epoch: [001][000/391]   Time 0.237 (0.237)   Data 0.148 (0.148)   Loss 1.2369 (1.2369)   Prec@1 55.469 (55.469)   Prec@5 92.969 (92.969)   [2019-11-22 03:48:28]
  Epoch: [001][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 1.0988 (1.1333)   Prec@1 62.500 (58.625)   Prec@5 97.656 (95.962)   [2019-11-22 03:48:33]
  Epoch: [001][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 1.0808 (1.0889)   Prec@1 57.031 (60.592)   Prec@5 99.219 (96.238)   [2019-11-22 03:48:38]
  Epoch: [001][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.9497 (1.0635)   Prec@1 62.500 (61.758)   Prec@5 96.094 (96.371)   [2019-11-22 03:48:42]
  **Train** Prec@1 62.884 Prec@5 96.520 Error@1 37.116
  **Test** Prec@1 56.820 Prec@5 96.180 Error@1 43.180
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:48:49] [Epoch=002/200] [Need: 01:11:57] [LR=0.0100][M=0.90] [Best : Accuracy=56.82, Error=43.18]
  Epoch: [002][000/391]   Time 0.231 (0.231)   Data 0.160 (0.160)   Loss 0.9133 (0.9133)   Prec@1 68.750 (68.750)   Prec@5 96.094 (96.094)   [2019-11-22 03:48:49]
  Epoch: [002][100/391]   Time 0.074 (0.053)   Data 0.000 (0.002)   Loss 0.9675 (0.8931)   Prec@1 62.500 (68.224)   Prec@5 98.438 (97.633)   [2019-11-22 03:48:54]
  Epoch: [002][200/391]   Time 0.078 (0.052)   Data 0.000 (0.001)   Loss 0.9685 (0.8595)   Prec@1 65.625 (69.286)   Prec@5 97.656 (97.777)   [2019-11-22 03:48:59]
  Epoch: [002][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.7783 (0.8467)   Prec@1 72.656 (69.949)   Prec@5 96.875 (97.786)   [2019-11-22 03:49:04]
  **Train** Prec@1 70.422 Prec@5 97.854 Error@1 29.578
  **Test** Prec@1 68.320 Prec@5 97.870 Error@1 31.680
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:49:11] [Epoch=003/200] [Need: 01:11:33] [LR=0.0100][M=0.90] [Best : Accuracy=68.32, Error=31.68]
  Epoch: [003][000/391]   Time 0.236 (0.236)   Data 0.148 (0.148)   Loss 0.9231 (0.9231)   Prec@1 68.750 (68.750)   Prec@5 94.531 (94.531)   [2019-11-22 03:49:11]
  Epoch: [003][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.6939 (0.7377)   Prec@1 71.094 (74.675)   Prec@5 100.000 (98.314)   [2019-11-22 03:49:16]
  Epoch: [003][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.7164 (0.7429)   Prec@1 75.000 (74.448)   Prec@5 97.656 (98.340)   [2019-11-22 03:49:21]
  Epoch: [003][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.5571 (0.7355)   Prec@1 83.594 (74.683)   Prec@5 99.219 (98.287)   [2019-11-22 03:49:26]
  **Train** Prec@1 74.960 Prec@5 98.318 Error@1 25.040
  **Test** Prec@1 71.420 Prec@5 97.760 Error@1 28.580
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:49:33] [Epoch=004/200] [Need: 01:11:15] [LR=0.0100][M=0.90] [Best : Accuracy=71.42, Error=28.58]
  Epoch: [004][000/391]   Time 0.222 (0.222)   Data 0.162 (0.162)   Loss 0.6792 (0.6792)   Prec@1 81.250 (81.250)   Prec@5 98.438 (98.438)   [2019-11-22 03:49:33]
  Epoch: [004][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.6136 (0.6811)   Prec@1 79.688 (76.245)   Prec@5 98.438 (98.298)   [2019-11-22 03:49:38]
  Epoch: [004][200/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.5693 (0.6746)   Prec@1 77.344 (76.356)   Prec@5 100.000 (98.465)   [2019-11-22 03:49:43]
  Epoch: [004][300/391]   Time 0.073 (0.053)   Data 0.000 (0.001)   Loss 0.6098 (0.6668)   Prec@1 77.344 (76.666)   Prec@5 99.219 (98.528)   [2019-11-22 03:49:49]
  **Train** Prec@1 76.962 Prec@5 98.556 Error@1 23.038
  **Test** Prec@1 73.830 Prec@5 98.340 Error@1 26.170
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:49:55] [Epoch=005/200] [Need: 01:11:23] [LR=0.0100][M=0.90] [Best : Accuracy=73.83, Error=26.17]
  Epoch: [005][000/391]   Time 0.230 (0.230)   Data 0.167 (0.167)   Loss 0.5883 (0.5883)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2019-11-22 03:49:55]
  Epoch: [005][100/391]   Time 0.063 (0.055)   Data 0.000 (0.002)   Loss 0.5506 (0.6152)   Prec@1 82.812 (78.512)   Prec@5 98.438 (98.871)   [2019-11-22 03:50:01]
  Epoch: [005][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.5959 (0.6217)   Prec@1 80.469 (78.514)   Prec@5 100.000 (98.756)   [2019-11-22 03:50:06]
  Epoch: [005][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.7158 (0.6194)   Prec@1 78.906 (78.571)   Prec@5 96.875 (98.707)   [2019-11-22 03:50:11]
  **Train** Prec@1 78.860 Prec@5 98.734 Error@1 21.140
  **Test** Prec@1 77.000 Prec@5 98.160 Error@1 23.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:50:17] [Epoch=006/200] [Need: 01:11:08] [LR=0.0100][M=0.90] [Best : Accuracy=77.00, Error=23.00]
  Epoch: [006][000/391]   Time 0.220 (0.220)   Data 0.157 (0.157)   Loss 0.4880 (0.4880)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 03:50:18]
  Epoch: [006][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.6251 (0.5831)   Prec@1 78.125 (79.927)   Prec@5 98.438 (98.747)   [2019-11-22 03:50:23]
  Epoch: [006][200/391]   Time 0.060 (0.050)   Data 0.000 (0.001)   Loss 0.6261 (0.5827)   Prec@1 75.000 (79.960)   Prec@5 100.000 (98.900)   [2019-11-22 03:50:28]
  Epoch: [006][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.6404 (0.5839)   Prec@1 80.469 (79.838)   Prec@5 99.219 (98.881)   [2019-11-22 03:50:32]
  **Train** Prec@1 80.016 Prec@5 98.860 Error@1 19.984
  **Test** Prec@1 78.050 Prec@5 98.740 Error@1 21.950
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:50:39] [Epoch=007/200] [Need: 01:10:28] [LR=0.0100][M=0.90] [Best : Accuracy=78.05, Error=21.95]
  Epoch: [007][000/391]   Time 0.229 (0.229)   Data 0.164 (0.164)   Loss 0.6132 (0.6132)   Prec@1 78.125 (78.125)   Prec@5 95.312 (95.312)   [2019-11-22 03:50:39]
  Epoch: [007][100/391]   Time 0.042 (0.056)   Data 0.000 (0.002)   Loss 0.6582 (0.5565)   Prec@1 73.438 (81.018)   Prec@5 97.656 (98.793)   [2019-11-22 03:50:44]
  Epoch: [007][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.6063 (0.5483)   Prec@1 78.906 (81.254)   Prec@5 99.219 (98.939)   [2019-11-22 03:50:50]
  Epoch: [007][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.6074 (0.5522)   Prec@1 78.125 (81.055)   Prec@5 97.656 (98.920)   [2019-11-22 03:50:54]
  **Train** Prec@1 80.962 Prec@5 98.934 Error@1 19.038
  **Test** Prec@1 80.120 Prec@5 98.350 Error@1 19.880
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:51:01] [Epoch=008/200] [Need: 01:10:11] [LR=0.0100][M=0.90] [Best : Accuracy=80.12, Error=19.88]
  Epoch: [008][000/391]   Time 0.234 (0.234)   Data 0.166 (0.166)   Loss 0.6017 (0.6017)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-22 03:51:01]
  Epoch: [008][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.5096 (0.5484)   Prec@1 82.812 (81.606)   Prec@5 97.656 (99.049)   [2019-11-22 03:51:06]
  Epoch: [008][200/391]   Time 0.054 (0.049)   Data 0.000 (0.001)   Loss 0.5844 (0.5430)   Prec@1 78.906 (81.697)   Prec@5 98.438 (99.040)   [2019-11-22 03:51:11]
  Epoch: [008][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.7217 (0.5374)   Prec@1 72.656 (81.774)   Prec@5 98.438 (99.112)   [2019-11-22 03:51:16]
  **Train** Prec@1 81.798 Prec@5 99.108 Error@1 18.202
  **Test** Prec@1 75.530 Prec@5 98.890 Error@1 24.470

==>>[2019-11-22 03:51:22] [Epoch=009/200] [Need: 01:09:24] [LR=0.0100][M=0.90] [Best : Accuracy=80.12, Error=19.88]
  Epoch: [009][000/391]   Time 0.214 (0.214)   Data 0.150 (0.150)   Loss 0.6281 (0.6281)   Prec@1 75.781 (75.781)   Prec@5 98.438 (98.438)   [2019-11-22 03:51:22]
  Epoch: [009][100/391]   Time 0.049 (0.055)   Data 0.000 (0.002)   Loss 0.4417 (0.5082)   Prec@1 82.812 (82.457)   Prec@5 100.000 (99.103)   [2019-11-22 03:51:27]
  Epoch: [009][200/391]   Time 0.054 (0.054)   Data 0.000 (0.001)   Loss 0.5492 (0.5079)   Prec@1 88.281 (82.610)   Prec@5 99.219 (99.133)   [2019-11-22 03:51:32]
  Epoch: [009][300/391]   Time 0.057 (0.052)   Data 0.000 (0.001)   Loss 0.5359 (0.5097)   Prec@1 78.906 (82.506)   Prec@5 97.656 (99.154)   [2019-11-22 03:51:37]
  **Train** Prec@1 82.308 Prec@5 99.124 Error@1 17.692
  **Test** Prec@1 80.320 Prec@5 99.100 Error@1 19.680
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:51:44] [Epoch=010/200] [Need: 01:09:12] [LR=0.0100][M=0.90] [Best : Accuracy=80.32, Error=19.68]
  Epoch: [010][000/391]   Time 0.238 (0.238)   Data 0.181 (0.181)   Loss 0.5224 (0.5224)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-22 03:51:44]
  Epoch: [010][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3381 (0.4864)   Prec@1 89.062 (83.192)   Prec@5 99.219 (99.226)   [2019-11-22 03:51:49]
  Epoch: [010][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.3930 (0.4970)   Prec@1 87.500 (82.914)   Prec@5 99.219 (99.122)   [2019-11-22 03:51:54]
  Epoch: [010][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2870 (0.5011)   Prec@1 92.969 (82.716)   Prec@5 99.219 (99.156)   [2019-11-22 03:51:59]
  **Train** Prec@1 82.688 Prec@5 99.188 Error@1 17.312
  **Test** Prec@1 79.360 Prec@5 98.580 Error@1 20.640

==>>[2019-11-22 03:52:06] [Epoch=011/200] [Need: 01:08:50] [LR=0.0100][M=0.90] [Best : Accuracy=80.32, Error=19.68]
  Epoch: [011][000/391]   Time 0.228 (0.228)   Data 0.169 (0.169)   Loss 0.4006 (0.4006)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 03:52:06]
  Epoch: [011][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5486 (0.4725)   Prec@1 80.469 (83.841)   Prec@5 100.000 (99.265)   [2019-11-22 03:52:11]
  Epoch: [011][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.5486 (0.4796)   Prec@1 79.688 (83.539)   Prec@5 100.000 (99.211)   [2019-11-22 03:52:16]
  Epoch: [011][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4386 (0.4801)   Prec@1 88.281 (83.570)   Prec@5 96.875 (99.206)   [2019-11-22 03:52:21]
  **Train** Prec@1 83.488 Prec@5 99.200 Error@1 16.512
  **Test** Prec@1 80.740 Prec@5 99.050 Error@1 19.260
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:52:28] [Epoch=012/200] [Need: 01:08:32] [LR=0.0100][M=0.90] [Best : Accuracy=80.74, Error=19.26]
  Epoch: [012][000/391]   Time 0.231 (0.231)   Data 0.163 (0.163)   Loss 0.3393 (0.3393)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 03:52:28]
  Epoch: [012][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.4928 (0.4539)   Prec@1 84.375 (84.367)   Prec@5 99.219 (99.234)   [2019-11-22 03:52:33]
  Epoch: [012][200/391]   Time 0.079 (0.053)   Data 0.000 (0.001)   Loss 0.4347 (0.4572)   Prec@1 85.156 (84.033)   Prec@5 99.219 (99.300)   [2019-11-22 03:52:38]
  Epoch: [012][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3778 (0.4656)   Prec@1 84.375 (83.672)   Prec@5 100.000 (99.291)   [2019-11-22 03:52:44]
  **Train** Prec@1 83.704 Prec@5 99.284 Error@1 16.296
  **Test** Prec@1 76.490 Prec@5 98.080 Error@1 23.510

==>>[2019-11-22 03:52:50] [Epoch=013/200] [Need: 01:08:12] [LR=0.0100][M=0.90] [Best : Accuracy=80.74, Error=19.26]
  Epoch: [013][000/391]   Time 0.223 (0.223)   Data 0.161 (0.161)   Loss 0.4965 (0.4965)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 03:52:50]
  Epoch: [013][100/391]   Time 0.064 (0.050)   Data 0.000 (0.002)   Loss 0.4810 (0.4528)   Prec@1 84.375 (84.329)   Prec@5 100.000 (99.242)   [2019-11-22 03:52:55]
  Epoch: [013][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.4385 (0.4539)   Prec@1 85.156 (84.394)   Prec@5 100.000 (99.316)   [2019-11-22 03:53:00]
  Epoch: [013][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.4736 (0.4585)   Prec@1 82.031 (84.266)   Prec@5 99.219 (99.271)   [2019-11-22 03:53:05]
  **Train** Prec@1 84.346 Prec@5 99.252 Error@1 15.654
  **Test** Prec@1 78.830 Prec@5 98.770 Error@1 21.170

==>>[2019-11-22 03:53:11] [Epoch=014/200] [Need: 01:07:43] [LR=0.0100][M=0.90] [Best : Accuracy=80.74, Error=19.26]
  Epoch: [014][000/391]   Time 0.217 (0.217)   Data 0.164 (0.164)   Loss 0.4583 (0.4583)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 03:53:11]
  Epoch: [014][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.4919 (0.4412)   Prec@1 84.375 (84.398)   Prec@5 100.000 (99.412)   [2019-11-22 03:53:17]
  Epoch: [014][200/391]   Time 0.038 (0.052)   Data 0.000 (0.001)   Loss 0.5663 (0.4519)   Prec@1 82.812 (84.227)   Prec@5 97.656 (99.366)   [2019-11-22 03:53:22]
  Epoch: [014][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.5403 (0.4549)   Prec@1 79.688 (84.222)   Prec@5 98.438 (99.367)   [2019-11-22 03:53:27]
  **Train** Prec@1 84.248 Prec@5 99.346 Error@1 15.752
  **Test** Prec@1 79.710 Prec@5 98.580 Error@1 20.290

==>>[2019-11-22 03:53:34] [Epoch=015/200] [Need: 01:07:29] [LR=0.0100][M=0.90] [Best : Accuracy=80.74, Error=19.26]
  Epoch: [015][000/391]   Time 0.242 (0.242)   Data 0.188 (0.188)   Loss 0.5269 (0.5269)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-22 03:53:34]
  Epoch: [015][100/391]   Time 0.052 (0.056)   Data 0.000 (0.002)   Loss 0.3641 (0.4317)   Prec@1 86.719 (84.924)   Prec@5 98.438 (99.420)   [2019-11-22 03:53:39]
  Epoch: [015][200/391]   Time 0.065 (0.055)   Data 0.000 (0.001)   Loss 0.4959 (0.4385)   Prec@1 84.375 (84.799)   Prec@5 99.219 (99.374)   [2019-11-22 03:53:45]
  Epoch: [015][300/391]   Time 0.059 (0.053)   Data 0.000 (0.001)   Loss 0.4552 (0.4410)   Prec@1 86.719 (84.808)   Prec@5 100.000 (99.393)   [2019-11-22 03:53:50]
  **Train** Prec@1 84.666 Prec@5 99.354 Error@1 15.334
  **Test** Prec@1 80.100 Prec@5 98.980 Error@1 19.900

==>>[2019-11-22 03:53:56] [Epoch=016/200] [Need: 01:07:11] [LR=0.0100][M=0.90] [Best : Accuracy=80.74, Error=19.26]
  Epoch: [016][000/391]   Time 0.242 (0.242)   Data 0.181 (0.181)   Loss 0.4459 (0.4459)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-22 03:53:56]
  Epoch: [016][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3816 (0.4276)   Prec@1 85.938 (85.218)   Prec@5 99.219 (99.397)   [2019-11-22 03:54:01]
  Epoch: [016][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.5957 (0.4386)   Prec@1 78.906 (84.803)   Prec@5 100.000 (99.390)   [2019-11-22 03:54:06]
  Epoch: [016][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3438 (0.4408)   Prec@1 87.500 (84.749)   Prec@5 99.219 (99.346)   [2019-11-22 03:54:11]
  **Train** Prec@1 84.860 Prec@5 99.358 Error@1 15.140
  **Test** Prec@1 82.000 Prec@5 98.950 Error@1 18.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:54:17] [Epoch=017/200] [Need: 01:06:45] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [017][000/391]   Time 0.225 (0.225)   Data 0.149 (0.149)   Loss 0.2723 (0.2723)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 03:54:18]
  Epoch: [017][100/391]   Time 0.077 (0.057)   Data 0.000 (0.002)   Loss 0.4669 (0.4096)   Prec@1 80.469 (85.667)   Prec@5 100.000 (99.459)   [2019-11-22 03:54:23]
  Epoch: [017][200/391]   Time 0.049 (0.054)   Data 0.000 (0.001)   Loss 0.5182 (0.4250)   Prec@1 80.469 (85.168)   Prec@5 100.000 (99.374)   [2019-11-22 03:54:28]
  Epoch: [017][300/391]   Time 0.080 (0.053)   Data 0.000 (0.001)   Loss 0.5076 (0.4293)   Prec@1 82.031 (85.125)   Prec@5 99.219 (99.374)   [2019-11-22 03:54:33]
  **Train** Prec@1 85.062 Prec@5 99.342 Error@1 14.938
  **Test** Prec@1 81.160 Prec@5 99.220 Error@1 18.840

==>>[2019-11-22 03:54:40] [Epoch=018/200] [Need: 01:06:27] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [018][000/391]   Time 0.223 (0.223)   Data 0.154 (0.154)   Loss 0.3831 (0.3831)   Prec@1 89.844 (89.844)   Prec@5 98.438 (98.438)   [2019-11-22 03:54:40]
  Epoch: [018][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.4196 (0.4088)   Prec@1 90.625 (86.162)   Prec@5 96.875 (99.288)   [2019-11-22 03:54:45]
  Epoch: [018][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.3994 (0.4149)   Prec@1 86.719 (85.926)   Prec@5 98.438 (99.366)   [2019-11-22 03:54:50]
  Epoch: [018][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.5012 (0.4163)   Prec@1 83.594 (85.782)   Prec@5 100.000 (99.403)   [2019-11-22 03:54:56]
  **Train** Prec@1 85.494 Prec@5 99.386 Error@1 14.506
  **Test** Prec@1 81.600 Prec@5 99.110 Error@1 18.400

==>>[2019-11-22 03:55:02] [Epoch=019/200] [Need: 01:06:13] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [019][000/391]   Time 0.234 (0.234)   Data 0.175 (0.175)   Loss 0.4470 (0.4470)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2019-11-22 03:55:03]
  Epoch: [019][100/391]   Time 0.046 (0.052)   Data 0.002 (0.002)   Loss 0.3505 (0.4222)   Prec@1 88.281 (85.497)   Prec@5 99.219 (99.335)   [2019-11-22 03:55:08]
  Epoch: [019][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4539 (0.4172)   Prec@1 86.719 (85.514)   Prec@5 100.000 (99.456)   [2019-11-22 03:55:13]
  Epoch: [019][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.4690 (0.4170)   Prec@1 85.156 (85.525)   Prec@5 100.000 (99.450)   [2019-11-22 03:55:17]
  **Train** Prec@1 85.396 Prec@5 99.438 Error@1 14.604
  **Test** Prec@1 83.160 Prec@5 99.150 Error@1 16.840
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:55:24] [Epoch=020/200] [Need: 01:05:45] [LR=0.0100][M=0.90] [Best : Accuracy=83.16, Error=16.84]
  Epoch: [020][000/391]   Time 0.211 (0.211)   Data 0.151 (0.151)   Loss 0.4416 (0.4416)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 03:55:24]
  Epoch: [020][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.3791 (0.4076)   Prec@1 84.375 (85.899)   Prec@5 99.219 (99.489)   [2019-11-22 03:55:29]
  Epoch: [020][200/391]   Time 0.063 (0.052)   Data 0.000 (0.001)   Loss 0.3878 (0.4062)   Prec@1 86.719 (86.147)   Prec@5 99.219 (99.495)   [2019-11-22 03:55:34]
  Epoch: [020][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.4393 (0.4083)   Prec@1 87.500 (86.021)   Prec@5 97.656 (99.439)   [2019-11-22 03:55:39]
  **Train** Prec@1 85.892 Prec@5 99.460 Error@1 14.108
  **Test** Prec@1 81.910 Prec@5 99.080 Error@1 18.090

==>>[2019-11-22 03:55:46] [Epoch=021/200] [Need: 01:05:22] [LR=0.0100][M=0.90] [Best : Accuracy=83.16, Error=16.84]
  Epoch: [021][000/391]   Time 0.231 (0.231)   Data 0.153 (0.153)   Loss 0.3878 (0.3878)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 03:55:46]
  Epoch: [021][100/391]   Time 0.047 (0.055)   Data 0.000 (0.002)   Loss 0.5209 (0.4057)   Prec@1 81.250 (85.922)   Prec@5 99.219 (99.373)   [2019-11-22 03:55:51]
  Epoch: [021][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.4665 (0.4044)   Prec@1 83.594 (85.969)   Prec@5 99.219 (99.390)   [2019-11-22 03:55:56]
  Epoch: [021][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4909 (0.4067)   Prec@1 83.594 (85.966)   Prec@5 100.000 (99.372)   [2019-11-22 03:56:02]
  **Train** Prec@1 85.958 Prec@5 99.382 Error@1 14.042
  **Test** Prec@1 83.680 Prec@5 99.370 Error@1 16.320
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:56:08] [Epoch=022/200] [Need: 01:05:06] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [022][000/391]   Time 0.234 (0.234)   Data 0.177 (0.177)   Loss 0.3352 (0.3352)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 03:56:08]
  Epoch: [022][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.5207 (0.3990)   Prec@1 78.906 (85.837)   Prec@5 100.000 (99.466)   [2019-11-22 03:56:14]
  Epoch: [022][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.4581 (0.3968)   Prec@1 85.156 (85.965)   Prec@5 99.219 (99.534)   [2019-11-22 03:56:19]
  Epoch: [022][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3128 (0.3981)   Prec@1 89.844 (85.945)   Prec@5 100.000 (99.509)   [2019-11-22 03:56:24]
  **Train** Prec@1 85.938 Prec@5 99.500 Error@1 14.062
  **Test** Prec@1 82.340 Prec@5 99.200 Error@1 17.660

==>>[2019-11-22 03:56:30] [Epoch=023/200] [Need: 01:04:45] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [023][000/391]   Time 0.235 (0.235)   Data 0.175 (0.175)   Loss 0.3806 (0.3806)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 03:56:30]
  Epoch: [023][100/391]   Time 0.074 (0.055)   Data 0.000 (0.002)   Loss 0.4073 (0.3839)   Prec@1 85.938 (86.726)   Prec@5 100.000 (99.381)   [2019-11-22 03:56:36]
  Epoch: [023][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3607 (0.3894)   Prec@1 86.719 (86.590)   Prec@5 100.000 (99.444)   [2019-11-22 03:56:41]
  Epoch: [023][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.4283 (0.3944)   Prec@1 88.281 (86.418)   Prec@5 98.438 (99.463)   [2019-11-22 03:56:46]
  **Train** Prec@1 86.388 Prec@5 99.462 Error@1 13.612
  **Test** Prec@1 80.680 Prec@5 98.980 Error@1 19.320

==>>[2019-11-22 03:56:53] [Epoch=024/200] [Need: 01:04:25] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [024][000/391]   Time 0.226 (0.226)   Data 0.163 (0.163)   Loss 0.3628 (0.3628)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 03:56:53]
  Epoch: [024][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.4485 (0.3867)   Prec@1 85.938 (86.904)   Prec@5 100.000 (99.459)   [2019-11-22 03:56:58]
  Epoch: [024][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4400 (0.3882)   Prec@1 86.719 (86.820)   Prec@5 100.000 (99.491)   [2019-11-22 03:57:03]
  Epoch: [024][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.5167 (0.3921)   Prec@1 82.031 (86.706)   Prec@5 100.000 (99.525)   [2019-11-22 03:57:08]
  **Train** Prec@1 86.594 Prec@5 99.530 Error@1 13.406
  **Test** Prec@1 79.160 Prec@5 99.210 Error@1 20.840

==>>[2019-11-22 03:57:14] [Epoch=025/200] [Need: 01:03:58] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [025][000/391]   Time 0.228 (0.228)   Data 0.170 (0.170)   Loss 0.3481 (0.3481)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 03:57:14]
  Epoch: [025][100/391]   Time 0.058 (0.055)   Data 0.000 (0.002)   Loss 0.3813 (0.3742)   Prec@1 89.844 (87.361)   Prec@5 99.219 (99.582)   [2019-11-22 03:57:19]
  Epoch: [025][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3650 (0.3845)   Prec@1 85.156 (86.754)   Prec@5 100.000 (99.537)   [2019-11-22 03:57:24]
  Epoch: [025][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3158 (0.3866)   Prec@1 89.062 (86.662)   Prec@5 100.000 (99.525)   [2019-11-22 03:57:29]
  **Train** Prec@1 86.582 Prec@5 99.492 Error@1 13.418
  **Test** Prec@1 82.610 Prec@5 99.150 Error@1 17.390

==>>[2019-11-22 03:57:36] [Epoch=026/200] [Need: 01:03:37] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [026][000/391]   Time 0.232 (0.232)   Data 0.159 (0.159)   Loss 0.2406 (0.2406)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 03:57:36]
  Epoch: [026][100/391]   Time 0.080 (0.052)   Data 0.000 (0.002)   Loss 0.3070 (0.3689)   Prec@1 90.625 (87.423)   Prec@5 98.438 (99.489)   [2019-11-22 03:57:41]
  Epoch: [026][200/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.3225 (0.3838)   Prec@1 90.625 (86.808)   Prec@5 100.000 (99.479)   [2019-11-22 03:57:46]
  Epoch: [026][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3503 (0.3864)   Prec@1 85.938 (86.649)   Prec@5 100.000 (99.452)   [2019-11-22 03:57:51]
  **Train** Prec@1 86.658 Prec@5 99.468 Error@1 13.342
  **Test** Prec@1 83.220 Prec@5 99.290 Error@1 16.780

==>>[2019-11-22 03:57:57] [Epoch=027/200] [Need: 01:03:10] [LR=0.0100][M=0.90] [Best : Accuracy=83.68, Error=16.32]
  Epoch: [027][000/391]   Time 0.229 (0.229)   Data 0.171 (0.171)   Loss 0.3828 (0.3828)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 03:57:57]
  Epoch: [027][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3551 (0.3660)   Prec@1 89.062 (87.090)   Prec@5 100.000 (99.636)   [2019-11-22 03:58:02]
  Epoch: [027][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4976 (0.3797)   Prec@1 80.469 (86.610)   Prec@5 100.000 (99.592)   [2019-11-22 03:58:08]
  Epoch: [027][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.2552 (0.3850)   Prec@1 91.406 (86.524)   Prec@5 99.219 (99.520)   [2019-11-22 03:58:12]
  **Train** Prec@1 86.442 Prec@5 99.516 Error@1 13.558
  **Test** Prec@1 85.500 Prec@5 99.600 Error@1 14.500
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 03:58:18] [Epoch=028/200] [Need: 01:02:46] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [028][000/391]   Time 0.220 (0.220)   Data 0.146 (0.146)   Loss 0.4392 (0.4392)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 03:58:19]
  Epoch: [028][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.3156 (0.3682)   Prec@1 89.062 (87.415)   Prec@5 100.000 (99.683)   [2019-11-22 03:58:24]
  Epoch: [028][200/391]   Time 0.040 (0.054)   Data 0.000 (0.001)   Loss 0.4312 (0.3728)   Prec@1 84.375 (87.022)   Prec@5 99.219 (99.600)   [2019-11-22 03:58:29]
  Epoch: [028][300/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.3791 (0.3783)   Prec@1 82.812 (86.849)   Prec@5 100.000 (99.554)   [2019-11-22 03:58:34]
  **Train** Prec@1 86.860 Prec@5 99.556 Error@1 13.140
  **Test** Prec@1 83.390 Prec@5 99.410 Error@1 16.610

==>>[2019-11-22 03:58:41] [Epoch=029/200] [Need: 01:02:27] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [029][000/391]   Time 0.235 (0.235)   Data 0.160 (0.160)   Loss 0.4792 (0.4792)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 03:58:41]
  Epoch: [029][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4006 (0.3715)   Prec@1 82.812 (87.283)   Prec@5 100.000 (99.528)   [2019-11-22 03:58:46]
  Epoch: [029][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4295 (0.3783)   Prec@1 82.031 (87.053)   Prec@5 100.000 (99.526)   [2019-11-22 03:58:51]
  Epoch: [029][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.4082 (0.3793)   Prec@1 86.719 (86.989)   Prec@5 99.219 (99.548)   [2019-11-22 03:58:56]
  **Train** Prec@1 87.032 Prec@5 99.554 Error@1 12.968
  **Test** Prec@1 84.120 Prec@5 99.230 Error@1 15.880

==>>[2019-11-22 03:59:02] [Epoch=030/200] [Need: 01:02:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [030][000/391]   Time 0.238 (0.238)   Data 0.178 (0.178)   Loss 0.3397 (0.3397)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 03:59:03]
  Epoch: [030][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.3566 (0.3622)   Prec@1 87.500 (87.508)   Prec@5 98.438 (99.528)   [2019-11-22 03:59:08]
  Epoch: [030][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3370 (0.3743)   Prec@1 89.844 (87.166)   Prec@5 99.219 (99.491)   [2019-11-22 03:59:13]
  Epoch: [030][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4409 (0.3745)   Prec@1 78.906 (87.022)   Prec@5 100.000 (99.530)   [2019-11-22 03:59:18]
  **Train** Prec@1 86.798 Prec@5 99.508 Error@1 13.202
  **Test** Prec@1 82.870 Prec@5 99.260 Error@1 17.130

==>>[2019-11-22 03:59:25] [Epoch=031/200] [Need: 01:01:43] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [031][000/391]   Time 0.227 (0.227)   Data 0.172 (0.172)   Loss 0.4165 (0.4165)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-22 03:59:25]
  Epoch: [031][100/391]   Time 0.081 (0.052)   Data 0.000 (0.002)   Loss 0.3296 (0.3567)   Prec@1 89.062 (87.562)   Prec@5 99.219 (99.575)   [2019-11-22 03:59:30]
  Epoch: [031][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3502 (0.3687)   Prec@1 88.281 (87.313)   Prec@5 99.219 (99.553)   [2019-11-22 03:59:35]
  Epoch: [031][300/391]   Time 0.082 (0.052)   Data 0.000 (0.001)   Loss 0.4228 (0.3699)   Prec@1 85.938 (87.251)   Prec@5 98.438 (99.556)   [2019-11-22 03:59:40]
  **Train** Prec@1 87.182 Prec@5 99.554 Error@1 12.818
  **Test** Prec@1 83.730 Prec@5 99.270 Error@1 16.270

==>>[2019-11-22 03:59:46] [Epoch=032/200] [Need: 01:01:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [032][000/391]   Time 0.233 (0.233)   Data 0.151 (0.151)   Loss 0.3639 (0.3639)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 03:59:47]
  Epoch: [032][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.3999 (0.3496)   Prec@1 87.500 (87.809)   Prec@5 99.219 (99.636)   [2019-11-22 03:59:52]
  Epoch: [032][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.3777 (0.3519)   Prec@1 85.938 (87.784)   Prec@5 100.000 (99.596)   [2019-11-22 03:59:57]
  Epoch: [032][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.4605 (0.3613)   Prec@1 82.031 (87.469)   Prec@5 100.000 (99.551)   [2019-11-22 04:00:02]
  **Train** Prec@1 87.236 Prec@5 99.564 Error@1 12.764
  **Test** Prec@1 82.970 Prec@5 98.980 Error@1 17.030

==>>[2019-11-22 04:00:08] [Epoch=033/200] [Need: 01:00:59] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [033][000/391]   Time 0.225 (0.225)   Data 0.155 (0.155)   Loss 0.4072 (0.4072)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 04:00:09]
  Epoch: [033][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.2671 (0.3426)   Prec@1 91.406 (88.351)   Prec@5 100.000 (99.544)   [2019-11-22 04:00:14]
  Epoch: [033][200/391]   Time 0.077 (0.053)   Data 0.000 (0.001)   Loss 0.4799 (0.3513)   Prec@1 82.812 (87.966)   Prec@5 98.438 (99.607)   [2019-11-22 04:00:19]
  Epoch: [033][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3225 (0.3531)   Prec@1 89.844 (87.793)   Prec@5 98.438 (99.603)   [2019-11-22 04:00:25]
  **Train** Prec@1 87.614 Prec@5 99.584 Error@1 12.386
  **Test** Prec@1 83.800 Prec@5 99.310 Error@1 16.200

==>>[2019-11-22 04:00:31] [Epoch=034/200] [Need: 01:00:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [034][000/391]   Time 0.244 (0.244)   Data 0.188 (0.188)   Loss 0.2888 (0.2888)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 04:00:32]
  Epoch: [034][100/391]   Time 0.059 (0.058)   Data 0.000 (0.002)   Loss 0.4612 (0.3508)   Prec@1 82.812 (87.709)   Prec@5 99.219 (99.636)   [2019-11-22 04:00:37]
  Epoch: [034][200/391]   Time 0.054 (0.055)   Data 0.000 (0.001)   Loss 0.3607 (0.3550)   Prec@1 86.719 (87.652)   Prec@5 99.219 (99.646)   [2019-11-22 04:00:42]
  Epoch: [034][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4107 (0.3596)   Prec@1 84.375 (87.555)   Prec@5 99.219 (99.618)   [2019-11-22 04:00:47]
  **Train** Prec@1 87.444 Prec@5 99.608 Error@1 12.556
  **Test** Prec@1 81.060 Prec@5 99.230 Error@1 18.940

==>>[2019-11-22 04:00:54] [Epoch=035/200] [Need: 01:00:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [035][000/391]   Time 0.213 (0.213)   Data 0.157 (0.157)   Loss 0.3198 (0.3198)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 04:00:54]
  Epoch: [035][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.3299 (0.3436)   Prec@1 89.844 (87.956)   Prec@5 99.219 (99.675)   [2019-11-22 04:00:59]
  Epoch: [035][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3387 (0.3557)   Prec@1 89.062 (87.586)   Prec@5 100.000 (99.642)   [2019-11-22 04:01:05]
  Epoch: [035][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.4094 (0.3567)   Prec@1 83.594 (87.653)   Prec@5 100.000 (99.637)   [2019-11-22 04:01:10]
  **Train** Prec@1 87.416 Prec@5 99.616 Error@1 12.584
  **Test** Prec@1 81.350 Prec@5 98.350 Error@1 18.650

==>>[2019-11-22 04:01:16] [Epoch=036/200] [Need: 01:00:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [036][000/391]   Time 0.236 (0.236)   Data 0.164 (0.164)   Loss 0.3289 (0.3289)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 04:01:17]
  Epoch: [036][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3917 (0.3517)   Prec@1 85.156 (87.732)   Prec@5 98.438 (99.613)   [2019-11-22 04:01:21]
  Epoch: [036][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.2521 (0.3445)   Prec@1 89.844 (87.959)   Prec@5 100.000 (99.639)   [2019-11-22 04:01:27]
  Epoch: [036][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.3075 (0.3541)   Prec@1 89.844 (87.692)   Prec@5 100.000 (99.590)   [2019-11-22 04:01:32]
  **Train** Prec@1 87.582 Prec@5 99.562 Error@1 12.418
  **Test** Prec@1 83.660 Prec@5 99.250 Error@1 16.340

==>>[2019-11-22 04:01:39] [Epoch=037/200] [Need: 00:59:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [037][000/391]   Time 0.239 (0.239)   Data 0.162 (0.162)   Loss 0.2972 (0.2972)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 04:01:39]
  Epoch: [037][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.2139 (0.3404)   Prec@1 95.312 (88.343)   Prec@5 100.000 (99.590)   [2019-11-22 04:01:45]
  Epoch: [037][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.2926 (0.3481)   Prec@1 89.844 (88.118)   Prec@5 100.000 (99.604)   [2019-11-22 04:01:50]
  Epoch: [037][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.3098 (0.3524)   Prec@1 88.281 (87.840)   Prec@5 99.219 (99.559)   [2019-11-22 04:01:55]
  **Train** Prec@1 87.764 Prec@5 99.556 Error@1 12.236
  **Test** Prec@1 83.290 Prec@5 98.930 Error@1 16.710

==>>[2019-11-22 04:02:01] [Epoch=038/200] [Need: 00:59:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [038][000/391]   Time 0.232 (0.232)   Data 0.157 (0.157)   Loss 0.2670 (0.2670)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 04:02:01]
  Epoch: [038][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.3103 (0.3353)   Prec@1 89.844 (88.405)   Prec@5 100.000 (99.667)   [2019-11-22 04:02:06]
  Epoch: [038][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3404 (0.3503)   Prec@1 89.062 (87.877)   Prec@5 98.438 (99.561)   [2019-11-22 04:02:12]
  Epoch: [038][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3903 (0.3536)   Prec@1 89.062 (87.749)   Prec@5 100.000 (99.543)   [2019-11-22 04:02:17]
  **Train** Prec@1 87.646 Prec@5 99.552 Error@1 12.354
  **Test** Prec@1 81.410 Prec@5 99.020 Error@1 18.590

==>>[2019-11-22 04:02:23] [Epoch=039/200] [Need: 00:59:01] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [039][000/391]   Time 0.225 (0.225)   Data 0.163 (0.163)   Loss 0.3399 (0.3399)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 04:02:23]
  Epoch: [039][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.3373 (0.3393)   Prec@1 89.062 (88.173)   Prec@5 100.000 (99.629)   [2019-11-22 04:02:28]
  Epoch: [039][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.3152 (0.3533)   Prec@1 90.625 (87.807)   Prec@5 100.000 (99.642)   [2019-11-22 04:02:34]
  Epoch: [039][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.2997 (0.3491)   Prec@1 89.844 (87.907)   Prec@5 100.000 (99.657)   [2019-11-22 04:02:39]
  **Train** Prec@1 87.806 Prec@5 99.644 Error@1 12.194
  **Test** Prec@1 84.140 Prec@5 99.300 Error@1 15.860

==>>[2019-11-22 04:02:45] [Epoch=040/200] [Need: 00:58:37] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [040][000/391]   Time 0.229 (0.229)   Data 0.170 (0.170)   Loss 0.3360 (0.3360)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 04:02:45]
  Epoch: [040][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.2460 (0.3400)   Prec@1 92.969 (88.266)   Prec@5 100.000 (99.582)   [2019-11-22 04:02:50]
  Epoch: [040][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.4179 (0.3514)   Prec@1 82.812 (87.741)   Prec@5 99.219 (99.569)   [2019-11-22 04:02:55]
  Epoch: [040][300/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.4676 (0.3504)   Prec@1 82.812 (87.806)   Prec@5 98.438 (99.577)   [2019-11-22 04:03:00]
  **Train** Prec@1 87.948 Prec@5 99.574 Error@1 12.052
  **Test** Prec@1 82.950 Prec@5 99.200 Error@1 17.050

==>>[2019-11-22 04:03:07] [Epoch=041/200] [Need: 00:58:15] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [041][000/391]   Time 0.235 (0.235)   Data 0.151 (0.151)   Loss 0.2995 (0.2995)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:03:07]
  Epoch: [041][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.3557 (0.3399)   Prec@1 87.500 (88.351)   Prec@5 100.000 (99.660)   [2019-11-22 04:03:12]
  Epoch: [041][200/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.3516 (0.3408)   Prec@1 86.719 (88.312)   Prec@5 100.000 (99.674)   [2019-11-22 04:03:17]
  Epoch: [041][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3343 (0.3448)   Prec@1 87.500 (88.164)   Prec@5 100.000 (99.678)   [2019-11-22 04:03:22]
  **Train** Prec@1 88.124 Prec@5 99.642 Error@1 11.876
  **Test** Prec@1 83.330 Prec@5 99.300 Error@1 16.670

==>>[2019-11-22 04:03:29] [Epoch=042/200] [Need: 00:57:53] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [042][000/391]   Time 0.227 (0.227)   Data 0.152 (0.152)   Loss 0.3004 (0.3004)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 04:03:29]
  Epoch: [042][100/391]   Time 0.066 (0.055)   Data 0.000 (0.002)   Loss 0.4364 (0.3278)   Prec@1 87.500 (88.776)   Prec@5 99.219 (99.621)   [2019-11-22 04:03:34]
  Epoch: [042][200/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.2775 (0.3288)   Prec@1 91.406 (88.705)   Prec@5 100.000 (99.639)   [2019-11-22 04:03:39]
  Epoch: [042][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2929 (0.3372)   Prec@1 87.500 (88.380)   Prec@5 100.000 (99.626)   [2019-11-22 04:03:44]
  **Train** Prec@1 88.150 Prec@5 99.634 Error@1 11.850
  **Test** Prec@1 83.700 Prec@5 99.250 Error@1 16.300

==>>[2019-11-22 04:03:50] [Epoch=043/200] [Need: 00:57:30] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [043][000/391]   Time 0.225 (0.225)   Data 0.163 (0.163)   Loss 0.3449 (0.3449)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 04:03:51]
  Epoch: [043][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.1732 (0.3104)   Prec@1 93.750 (88.939)   Prec@5 100.000 (99.745)   [2019-11-22 04:03:56]
  Epoch: [043][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3604 (0.3217)   Prec@1 89.062 (88.748)   Prec@5 100.000 (99.654)   [2019-11-22 04:04:01]
  Epoch: [043][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3497 (0.3289)   Prec@1 89.062 (88.554)   Prec@5 100.000 (99.626)   [2019-11-22 04:04:06]
  **Train** Prec@1 88.274 Prec@5 99.598 Error@1 11.726
  **Test** Prec@1 83.350 Prec@5 99.350 Error@1 16.650

==>>[2019-11-22 04:04:12] [Epoch=044/200] [Need: 00:57:08] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [044][000/391]   Time 0.240 (0.240)   Data 0.163 (0.163)   Loss 0.3370 (0.3370)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-22 04:04:13]
  Epoch: [044][100/391]   Time 0.082 (0.056)   Data 0.000 (0.002)   Loss 0.3737 (0.3433)   Prec@1 86.719 (88.351)   Prec@5 100.000 (99.652)   [2019-11-22 04:04:18]
  Epoch: [044][200/391]   Time 0.047 (0.054)   Data 0.000 (0.001)   Loss 0.2766 (0.3416)   Prec@1 90.625 (88.359)   Prec@5 100.000 (99.623)   [2019-11-22 04:04:23]
  Epoch: [044][300/391]   Time 0.082 (0.054)   Data 0.000 (0.001)   Loss 0.4483 (0.3411)   Prec@1 85.938 (88.305)   Prec@5 100.000 (99.616)   [2019-11-22 04:04:29]
  **Train** Prec@1 88.240 Prec@5 99.580 Error@1 11.760
  **Test** Prec@1 84.240 Prec@5 99.270 Error@1 15.760

==>>[2019-11-22 04:04:35] [Epoch=045/200] [Need: 00:56:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [045][000/391]   Time 0.244 (0.244)   Data 0.155 (0.155)   Loss 0.3022 (0.3022)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 04:04:35]
  Epoch: [045][100/391]   Time 0.063 (0.057)   Data 0.000 (0.002)   Loss 0.4371 (0.3307)   Prec@1 86.719 (88.343)   Prec@5 98.438 (99.590)   [2019-11-22 04:04:41]
  Epoch: [045][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.2620 (0.3341)   Prec@1 87.500 (88.382)   Prec@5 99.219 (99.639)   [2019-11-22 04:04:46]
  Epoch: [045][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.4313 (0.3384)   Prec@1 85.156 (88.188)   Prec@5 100.000 (99.652)   [2019-11-22 04:04:50]
  **Train** Prec@1 88.256 Prec@5 99.648 Error@1 11.744
  **Test** Prec@1 81.100 Prec@5 99.170 Error@1 18.900

==>>[2019-11-22 04:04:57] [Epoch=046/200] [Need: 00:56:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [046][000/391]   Time 0.237 (0.237)   Data 0.179 (0.179)   Loss 0.3916 (0.3916)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 04:04:57]
  Epoch: [046][100/391]   Time 0.054 (0.059)   Data 0.000 (0.002)   Loss 0.2323 (0.3376)   Prec@1 90.625 (88.320)   Prec@5 100.000 (99.636)   [2019-11-22 04:05:03]
  Epoch: [046][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3360 (0.3467)   Prec@1 88.281 (88.110)   Prec@5 97.656 (99.588)   [2019-11-22 04:05:08]
  Epoch: [046][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3890 (0.3373)   Prec@1 85.938 (88.354)   Prec@5 99.219 (99.629)   [2019-11-22 04:05:13]
  **Train** Prec@1 88.288 Prec@5 99.628 Error@1 11.712
  **Test** Prec@1 84.790 Prec@5 99.210 Error@1 15.210

==>>[2019-11-22 04:05:19] [Epoch=047/200] [Need: 00:56:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [047][000/391]   Time 0.237 (0.237)   Data 0.171 (0.171)   Loss 0.1457 (0.1457)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:05:19]
  Epoch: [047][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.2649 (0.3239)   Prec@1 91.406 (88.885)   Prec@5 100.000 (99.636)   [2019-11-22 04:05:24]
  Epoch: [047][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.3027 (0.3360)   Prec@1 87.500 (88.293)   Prec@5 100.000 (99.639)   [2019-11-22 04:05:29]
  Epoch: [047][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3301 (0.3352)   Prec@1 85.938 (88.281)   Prec@5 100.000 (99.652)   [2019-11-22 04:05:34]
  **Train** Prec@1 88.190 Prec@5 99.652 Error@1 11.810
  **Test** Prec@1 82.150 Prec@5 99.160 Error@1 17.850

==>>[2019-11-22 04:05:41] [Epoch=048/200] [Need: 00:55:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [048][000/391]   Time 0.228 (0.228)   Data 0.167 (0.167)   Loss 0.2372 (0.2372)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 04:05:41]
  Epoch: [048][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.3079 (0.3216)   Prec@1 89.062 (88.869)   Prec@5 99.219 (99.598)   [2019-11-22 04:05:46]
  Epoch: [048][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2716 (0.3289)   Prec@1 90.625 (88.647)   Prec@5 100.000 (99.615)   [2019-11-22 04:05:51]
  Epoch: [048][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4440 (0.3347)   Prec@1 85.938 (88.538)   Prec@5 99.219 (99.603)   [2019-11-22 04:05:56]
  **Train** Prec@1 88.550 Prec@5 99.612 Error@1 11.450
  **Test** Prec@1 84.030 Prec@5 99.260 Error@1 15.970

==>>[2019-11-22 04:06:02] [Epoch=049/200] [Need: 00:55:19] [LR=0.0100][M=0.90] [Best : Accuracy=85.50, Error=14.50]
  Epoch: [049][000/391]   Time 0.239 (0.239)   Data 0.182 (0.182)   Loss 0.2888 (0.2888)   Prec@1 92.969 (92.969)   Prec@5 98.438 (98.438)   [2019-11-22 04:06:03]
  Epoch: [049][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.2753 (0.3331)   Prec@1 89.844 (88.173)   Prec@5 100.000 (99.621)   [2019-11-22 04:06:08]
  Epoch: [049][200/391]   Time 0.035 (0.052)   Data 0.000 (0.001)   Loss 0.4598 (0.3333)   Prec@1 86.719 (88.266)   Prec@5 100.000 (99.619)   [2019-11-22 04:06:13]
  Epoch: [049][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.3210 (0.3351)   Prec@1 88.281 (88.333)   Prec@5 100.000 (99.618)   [2019-11-22 04:06:18]
  **Train** Prec@1 88.356 Prec@5 99.622 Error@1 11.644
  **Test** Prec@1 86.250 Prec@5 99.500 Error@1 13.750
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:06:24] [Epoch=050/200] [Need: 00:54:57] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [050][000/391]   Time 0.231 (0.231)   Data 0.152 (0.152)   Loss 0.3126 (0.3126)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 04:06:25]
  Epoch: [050][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.2907 (0.3248)   Prec@1 91.406 (88.861)   Prec@5 99.219 (99.613)   [2019-11-22 04:06:30]
  Epoch: [050][200/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.2363 (0.3263)   Prec@1 90.625 (88.701)   Prec@5 100.000 (99.627)   [2019-11-22 04:06:34]
  Epoch: [050][300/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.4100 (0.3279)   Prec@1 83.594 (88.595)   Prec@5 100.000 (99.652)   [2019-11-22 04:06:39]
  **Train** Prec@1 88.462 Prec@5 99.642 Error@1 11.538
  **Test** Prec@1 84.510 Prec@5 99.290 Error@1 15.490

==>>[2019-11-22 04:06:46] [Epoch=051/200] [Need: 00:54:33] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [051][000/391]   Time 0.237 (0.237)   Data 0.177 (0.177)   Loss 0.3219 (0.3219)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 04:06:46]
  Epoch: [051][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3342 (0.3189)   Prec@1 89.062 (88.753)   Prec@5 99.219 (99.606)   [2019-11-22 04:06:51]
  Epoch: [051][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3015 (0.3256)   Prec@1 90.625 (88.565)   Prec@5 100.000 (99.627)   [2019-11-22 04:06:56]
  Epoch: [051][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2674 (0.3266)   Prec@1 89.844 (88.582)   Prec@5 100.000 (99.631)   [2019-11-22 04:07:01]
  **Train** Prec@1 88.522 Prec@5 99.632 Error@1 11.478
  **Test** Prec@1 84.100 Prec@5 99.350 Error@1 15.900

==>>[2019-11-22 04:07:08] [Epoch=052/200] [Need: 00:54:13] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [052][000/391]   Time 0.240 (0.240)   Data 0.184 (0.184)   Loss 0.2919 (0.2919)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:07:09]
  Epoch: [052][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.3108 (0.3210)   Prec@1 87.500 (88.591)   Prec@5 100.000 (99.613)   [2019-11-22 04:07:14]
  Epoch: [052][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4464 (0.3300)   Prec@1 84.375 (88.359)   Prec@5 99.219 (99.677)   [2019-11-22 04:07:19]
  Epoch: [052][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3075 (0.3276)   Prec@1 89.062 (88.528)   Prec@5 99.219 (99.657)   [2019-11-22 04:07:24]
  **Train** Prec@1 88.494 Prec@5 99.650 Error@1 11.506
  **Test** Prec@1 85.730 Prec@5 99.410 Error@1 14.270

==>>[2019-11-22 04:07:31] [Epoch=053/200] [Need: 00:53:52] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [053][000/391]   Time 0.232 (0.232)   Data 0.170 (0.170)   Loss 0.2589 (0.2589)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:07:31]
  Epoch: [053][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.2148 (0.3150)   Prec@1 94.531 (89.016)   Prec@5 100.000 (99.575)   [2019-11-22 04:07:36]
  Epoch: [053][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1896 (0.3236)   Prec@1 96.875 (88.759)   Prec@5 100.000 (99.619)   [2019-11-22 04:07:41]
  Epoch: [053][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.4567 (0.3264)   Prec@1 84.375 (88.569)   Prec@5 100.000 (99.611)   [2019-11-22 04:07:46]
  **Train** Prec@1 88.578 Prec@5 99.620 Error@1 11.422
  **Test** Prec@1 81.330 Prec@5 98.850 Error@1 18.670

==>>[2019-11-22 04:07:53] [Epoch=054/200] [Need: 00:53:29] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [054][000/391]   Time 0.248 (0.248)   Data 0.179 (0.179)   Loss 0.1831 (0.1831)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 04:07:53]
  Epoch: [054][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.3470 (0.3182)   Prec@1 89.062 (89.101)   Prec@5 98.438 (99.644)   [2019-11-22 04:07:58]
  Epoch: [054][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4028 (0.3208)   Prec@1 83.594 (88.907)   Prec@5 100.000 (99.658)   [2019-11-22 04:08:03]
  Epoch: [054][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.4282 (0.3260)   Prec@1 84.375 (88.673)   Prec@5 99.219 (99.647)   [2019-11-22 04:08:08]
  **Train** Prec@1 88.588 Prec@5 99.614 Error@1 11.412
  **Test** Prec@1 84.210 Prec@5 99.180 Error@1 15.790

==>>[2019-11-22 04:08:15] [Epoch=055/200] [Need: 00:53:09] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [055][000/391]   Time 0.234 (0.234)   Data 0.155 (0.155)   Loss 0.3148 (0.3148)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 04:08:15]
  Epoch: [055][100/391]   Time 0.074 (0.056)   Data 0.000 (0.002)   Loss 0.4066 (0.3163)   Prec@1 82.812 (88.807)   Prec@5 100.000 (99.706)   [2019-11-22 04:08:21]
  Epoch: [055][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.2455 (0.3189)   Prec@1 91.406 (88.911)   Prec@5 100.000 (99.693)   [2019-11-22 04:08:26]
  Epoch: [055][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.3207 (0.3196)   Prec@1 90.625 (88.873)   Prec@5 99.219 (99.686)   [2019-11-22 04:08:31]
  **Train** Prec@1 88.804 Prec@5 99.674 Error@1 11.196
  **Test** Prec@1 83.140 Prec@5 98.970 Error@1 16.860

==>>[2019-11-22 04:08:37] [Epoch=056/200] [Need: 00:52:47] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [056][000/391]   Time 0.236 (0.236)   Data 0.154 (0.154)   Loss 0.2976 (0.2976)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 04:08:37]
  Epoch: [056][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3332 (0.3098)   Prec@1 90.625 (89.248)   Prec@5 100.000 (99.691)   [2019-11-22 04:08:43]
  Epoch: [056][200/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.2652 (0.3224)   Prec@1 88.281 (88.930)   Prec@5 100.000 (99.654)   [2019-11-22 04:08:48]
  Epoch: [056][300/391]   Time 0.063 (0.051)   Data 0.000 (0.001)   Loss 0.2967 (0.3253)   Prec@1 91.406 (88.819)   Prec@5 99.219 (99.660)   [2019-11-22 04:08:52]
  **Train** Prec@1 88.768 Prec@5 99.648 Error@1 11.232
  **Test** Prec@1 85.430 Prec@5 99.320 Error@1 14.570

==>>[2019-11-22 04:08:59] [Epoch=057/200] [Need: 00:52:24] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [057][000/391]   Time 0.225 (0.225)   Data 0.166 (0.166)   Loss 0.2765 (0.2765)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 04:08:59]
  Epoch: [057][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.3137 (0.3147)   Prec@1 92.188 (89.039)   Prec@5 98.438 (99.683)   [2019-11-22 04:09:04]
  Epoch: [057][200/391]   Time 0.051 (0.054)   Data 0.000 (0.001)   Loss 0.3135 (0.3183)   Prec@1 86.719 (88.915)   Prec@5 100.000 (99.642)   [2019-11-22 04:09:09]
  Epoch: [057][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.4274 (0.3248)   Prec@1 85.938 (88.681)   Prec@5 99.219 (99.642)   [2019-11-22 04:09:15]
  **Train** Prec@1 88.664 Prec@5 99.626 Error@1 11.336
  **Test** Prec@1 85.100 Prec@5 99.440 Error@1 14.900

==>>[2019-11-22 04:09:21] [Epoch=058/200] [Need: 00:52:03] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [058][000/391]   Time 0.227 (0.227)   Data 0.155 (0.155)   Loss 0.3194 (0.3194)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:09:22]
  Epoch: [058][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.2777 (0.2865)   Prec@1 91.406 (90.045)   Prec@5 99.219 (99.714)   [2019-11-22 04:09:27]
  Epoch: [058][200/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.3390 (0.3001)   Prec@1 88.281 (89.572)   Prec@5 99.219 (99.720)   [2019-11-22 04:09:31]
  Epoch: [058][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2659 (0.3106)   Prec@1 91.406 (89.252)   Prec@5 100.000 (99.676)   [2019-11-22 04:09:36]
  **Train** Prec@1 89.050 Prec@5 99.656 Error@1 10.950
  **Test** Prec@1 83.250 Prec@5 99.290 Error@1 16.750

==>>[2019-11-22 04:09:43] [Epoch=059/200] [Need: 00:51:40] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [059][000/391]   Time 0.224 (0.224)   Data 0.169 (0.169)   Loss 0.3604 (0.3604)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 04:09:43]
  Epoch: [059][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.2659 (0.3168)   Prec@1 92.188 (89.194)   Prec@5 99.219 (99.691)   [2019-11-22 04:09:48]
  Epoch: [059][200/391]   Time 0.069 (0.052)   Data 0.000 (0.001)   Loss 0.3656 (0.3098)   Prec@1 85.938 (89.502)   Prec@5 100.000 (99.666)   [2019-11-22 04:09:53]
  Epoch: [059][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3987 (0.3221)   Prec@1 85.156 (89.057)   Prec@5 100.000 (99.650)   [2019-11-22 04:09:58]
  **Train** Prec@1 89.010 Prec@5 99.646 Error@1 10.990
  **Test** Prec@1 83.350 Prec@5 99.260 Error@1 16.650

==>>[2019-11-22 04:10:05] [Epoch=060/200] [Need: 00:51:18] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [060][000/391]   Time 0.251 (0.251)   Data 0.178 (0.178)   Loss 0.3516 (0.3516)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 04:10:05]
  Epoch: [060][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.3830 (0.3071)   Prec@1 85.938 (89.341)   Prec@5 100.000 (99.636)   [2019-11-22 04:10:10]
  Epoch: [060][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.3802 (0.3098)   Prec@1 86.719 (89.214)   Prec@5 100.000 (99.604)   [2019-11-22 04:10:15]
  Epoch: [060][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3101 (0.3144)   Prec@1 86.719 (89.083)   Prec@5 100.000 (99.631)   [2019-11-22 04:10:20]
  **Train** Prec@1 89.046 Prec@5 99.650 Error@1 10.954
  **Test** Prec@1 83.670 Prec@5 99.270 Error@1 16.330

==>>[2019-11-22 04:10:26] [Epoch=061/200] [Need: 00:50:55] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [061][000/391]   Time 0.227 (0.227)   Data 0.154 (0.154)   Loss 0.3144 (0.3144)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 04:10:27]
  Epoch: [061][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.2661 (0.3051)   Prec@1 89.844 (89.550)   Prec@5 100.000 (99.737)   [2019-11-22 04:10:32]
  Epoch: [061][200/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.4677 (0.3100)   Prec@1 82.812 (89.241)   Prec@5 99.219 (99.681)   [2019-11-22 04:10:37]
  Epoch: [061][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3663 (0.3138)   Prec@1 85.156 (89.081)   Prec@5 100.000 (99.683)   [2019-11-22 04:10:42]
  **Train** Prec@1 89.002 Prec@5 99.680 Error@1 10.998
  **Test** Prec@1 86.060 Prec@5 99.390 Error@1 13.940

==>>[2019-11-22 04:10:48] [Epoch=062/200] [Need: 00:50:32] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [062][000/391]   Time 0.213 (0.213)   Data 0.146 (0.146)   Loss 0.3979 (0.3979)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 04:10:48]
  Epoch: [062][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.4122 (0.3004)   Prec@1 83.594 (89.565)   Prec@5 100.000 (99.776)   [2019-11-22 04:10:53]
  Epoch: [062][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.2865 (0.3083)   Prec@1 89.844 (89.156)   Prec@5 100.000 (99.743)   [2019-11-22 04:10:58]
  Epoch: [062][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2388 (0.3148)   Prec@1 91.406 (89.024)   Prec@5 100.000 (99.717)   [2019-11-22 04:11:03]
  **Train** Prec@1 88.950 Prec@5 99.710 Error@1 11.050
  **Test** Prec@1 84.540 Prec@5 99.400 Error@1 15.460

==>>[2019-11-22 04:11:10] [Epoch=063/200] [Need: 00:50:10] [LR=0.0100][M=0.90] [Best : Accuracy=86.25, Error=13.75]
  Epoch: [063][000/391]   Time 0.226 (0.226)   Data 0.152 (0.152)   Loss 0.2735 (0.2735)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-22 04:11:10]
  Epoch: [063][100/391]   Time 0.075 (0.054)   Data 0.000 (0.002)   Loss 0.3336 (0.2909)   Prec@1 85.156 (89.859)   Prec@5 99.219 (99.683)   [2019-11-22 04:11:15]
  Epoch: [063][200/391]   Time 0.038 (0.053)   Data 0.000 (0.001)   Loss 0.4791 (0.3014)   Prec@1 80.469 (89.424)   Prec@5 99.219 (99.732)   [2019-11-22 04:11:20]
  Epoch: [063][300/391]   Time 0.077 (0.053)   Data 0.000 (0.001)   Loss 0.2811 (0.3077)   Prec@1 91.406 (89.229)   Prec@5 99.219 (99.730)   [2019-11-22 04:11:26]
  **Train** Prec@1 89.024 Prec@5 99.706 Error@1 10.976
  **Test** Prec@1 86.560 Prec@5 99.400 Error@1 13.440
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:11:33] [Epoch=064/200] [Need: 00:49:50] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [064][000/391]   Time 0.239 (0.239)   Data 0.183 (0.183)   Loss 0.2558 (0.2558)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 04:11:33]
  Epoch: [064][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.3983 (0.3026)   Prec@1 87.500 (89.503)   Prec@5 99.219 (99.691)   [2019-11-22 04:11:38]
  Epoch: [064][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.2488 (0.3109)   Prec@1 90.625 (89.199)   Prec@5 100.000 (99.681)   [2019-11-22 04:11:43]
  Epoch: [064][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.3761 (0.3155)   Prec@1 85.156 (89.060)   Prec@5 100.000 (99.707)   [2019-11-22 04:11:49]
  **Train** Prec@1 89.098 Prec@5 99.704 Error@1 10.902
  **Test** Prec@1 83.640 Prec@5 99.220 Error@1 16.360

==>>[2019-11-22 04:11:55] [Epoch=065/200] [Need: 00:49:29] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [065][000/391]   Time 0.232 (0.232)   Data 0.166 (0.166)   Loss 0.2662 (0.2662)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 04:11:56]
  Epoch: [065][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.2507 (0.3073)   Prec@1 90.625 (89.403)   Prec@5 100.000 (99.752)   [2019-11-22 04:12:01]
  Epoch: [065][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3053 (0.3074)   Prec@1 88.281 (89.447)   Prec@5 100.000 (99.732)   [2019-11-22 04:12:06]
  Epoch: [065][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3607 (0.3158)   Prec@1 88.281 (89.146)   Prec@5 100.000 (99.681)   [2019-11-22 04:12:11]
  **Train** Prec@1 89.148 Prec@5 99.680 Error@1 10.852
  **Test** Prec@1 85.790 Prec@5 99.420 Error@1 14.210

==>>[2019-11-22 04:12:17] [Epoch=066/200] [Need: 00:49:08] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [066][000/391]   Time 0.230 (0.230)   Data 0.171 (0.171)   Loss 0.3277 (0.3277)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 04:12:18]
  Epoch: [066][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3704 (0.3082)   Prec@1 85.938 (89.287)   Prec@5 99.219 (99.675)   [2019-11-22 04:12:23]
  Epoch: [066][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.3716 (0.3148)   Prec@1 85.938 (89.043)   Prec@5 100.000 (99.639)   [2019-11-22 04:12:28]
  Epoch: [066][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.3232 (0.3145)   Prec@1 90.625 (89.073)   Prec@5 100.000 (99.663)   [2019-11-22 04:12:33]
  **Train** Prec@1 89.144 Prec@5 99.664 Error@1 10.856
  **Test** Prec@1 84.380 Prec@5 99.280 Error@1 15.620

==>>[2019-11-22 04:12:40] [Epoch=067/200] [Need: 00:48:47] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [067][000/391]   Time 0.230 (0.230)   Data 0.153 (0.153)   Loss 0.3503 (0.3503)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-22 04:12:40]
  Epoch: [067][100/391]   Time 0.060 (0.057)   Data 0.000 (0.002)   Loss 0.2853 (0.3027)   Prec@1 92.188 (89.511)   Prec@5 100.000 (99.652)   [2019-11-22 04:12:46]
  Epoch: [067][200/391]   Time 0.046 (0.055)   Data 0.000 (0.001)   Loss 0.2349 (0.3080)   Prec@1 91.406 (89.389)   Prec@5 100.000 (99.674)   [2019-11-22 04:12:51]
  Epoch: [067][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.3403 (0.3090)   Prec@1 90.625 (89.366)   Prec@5 99.219 (99.681)   [2019-11-22 04:12:56]
  **Train** Prec@1 89.298 Prec@5 99.680 Error@1 10.702
  **Test** Prec@1 85.180 Prec@5 99.400 Error@1 14.820

==>>[2019-11-22 04:13:03] [Epoch=068/200] [Need: 00:48:26] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [068][000/391]   Time 0.232 (0.232)   Data 0.161 (0.161)   Loss 0.2602 (0.2602)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 04:13:03]
  Epoch: [068][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.3255 (0.3104)   Prec@1 86.719 (89.155)   Prec@5 100.000 (99.737)   [2019-11-22 04:13:08]
  Epoch: [068][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3637 (0.3104)   Prec@1 87.500 (89.405)   Prec@5 100.000 (99.705)   [2019-11-22 04:13:13]
  Epoch: [068][300/391]   Time 0.078 (0.052)   Data 0.000 (0.001)   Loss 0.2552 (0.3099)   Prec@1 89.844 (89.390)   Prec@5 99.219 (99.678)   [2019-11-22 04:13:18]
  **Train** Prec@1 89.258 Prec@5 99.676 Error@1 10.742
  **Test** Prec@1 84.970 Prec@5 99.530 Error@1 15.030

==>>[2019-11-22 04:13:25] [Epoch=069/200] [Need: 00:48:04] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [069][000/391]   Time 0.227 (0.227)   Data 0.155 (0.155)   Loss 0.1187 (0.1187)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:13:25]
  Epoch: [069][100/391]   Time 0.057 (0.051)   Data 0.000 (0.002)   Loss 0.2484 (0.3031)   Prec@1 91.406 (89.155)   Prec@5 99.219 (99.729)   [2019-11-22 04:13:30]
  Epoch: [069][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.2933 (0.3076)   Prec@1 90.625 (89.039)   Prec@5 99.219 (99.724)   [2019-11-22 04:13:35]
  Epoch: [069][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.2608 (0.3086)   Prec@1 92.188 (89.065)   Prec@5 99.219 (99.696)   [2019-11-22 04:13:40]
  **Train** Prec@1 88.976 Prec@5 99.664 Error@1 11.024
  **Test** Prec@1 85.210 Prec@5 99.210 Error@1 14.790

==>>[2019-11-22 04:13:46] [Epoch=070/200] [Need: 00:47:41] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [070][000/391]   Time 0.228 (0.228)   Data 0.167 (0.167)   Loss 0.2844 (0.2844)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:13:47]
  Epoch: [070][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.2125 (0.3035)   Prec@1 92.188 (89.588)   Prec@5 100.000 (99.791)   [2019-11-22 04:13:52]
  Epoch: [070][200/391]   Time 0.063 (0.052)   Data 0.000 (0.001)   Loss 0.3217 (0.3127)   Prec@1 86.719 (89.167)   Prec@5 100.000 (99.732)   [2019-11-22 04:13:57]
  Epoch: [070][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.3116 (0.3155)   Prec@1 89.844 (89.029)   Prec@5 100.000 (99.717)   [2019-11-22 04:14:02]
  **Train** Prec@1 89.086 Prec@5 99.708 Error@1 10.914
  **Test** Prec@1 83.300 Prec@5 99.170 Error@1 16.700

==>>[2019-11-22 04:14:08] [Epoch=071/200] [Need: 00:47:19] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [071][000/391]   Time 0.228 (0.228)   Data 0.170 (0.170)   Loss 0.2721 (0.2721)   Prec@1 91.406 (91.406)   Prec@5 97.656 (97.656)   [2019-11-22 04:14:08]
  Epoch: [071][100/391]   Time 0.077 (0.057)   Data 0.000 (0.002)   Loss 0.3246 (0.2963)   Prec@1 86.719 (89.782)   Prec@5 99.219 (99.752)   [2019-11-22 04:14:14]
  Epoch: [071][200/391]   Time 0.055 (0.055)   Data 0.000 (0.001)   Loss 0.2781 (0.2958)   Prec@1 86.719 (89.801)   Prec@5 99.219 (99.743)   [2019-11-22 04:14:19]
  Epoch: [071][300/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.3088 (0.3066)   Prec@1 89.844 (89.452)   Prec@5 99.219 (99.720)   [2019-11-22 04:14:25]
  **Train** Prec@1 89.364 Prec@5 99.710 Error@1 10.636
  **Test** Prec@1 83.830 Prec@5 99.240 Error@1 16.170

==>>[2019-11-22 04:14:31] [Epoch=072/200] [Need: 00:46:59] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [072][000/391]   Time 0.225 (0.225)   Data 0.164 (0.164)   Loss 0.2044 (0.2044)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 04:14:31]
  Epoch: [072][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.3313 (0.2850)   Prec@1 86.719 (90.192)   Prec@5 100.000 (99.776)   [2019-11-22 04:14:36]
  Epoch: [072][200/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.2786 (0.2942)   Prec@1 91.406 (89.750)   Prec@5 98.438 (99.759)   [2019-11-22 04:14:41]
  Epoch: [072][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3179 (0.3046)   Prec@1 87.500 (89.366)   Prec@5 100.000 (99.699)   [2019-11-22 04:14:47]
  **Train** Prec@1 89.256 Prec@5 99.690 Error@1 10.744
  **Test** Prec@1 85.970 Prec@5 99.270 Error@1 14.030

==>>[2019-11-22 04:14:53] [Epoch=073/200] [Need: 00:46:37] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [073][000/391]   Time 0.234 (0.234)   Data 0.153 (0.153)   Loss 0.2649 (0.2649)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 04:14:54]
  Epoch: [073][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.2831 (0.2984)   Prec@1 89.062 (89.442)   Prec@5 100.000 (99.729)   [2019-11-22 04:14:59]
  Epoch: [073][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.2846 (0.3057)   Prec@1 89.062 (89.323)   Prec@5 99.219 (99.670)   [2019-11-22 04:15:04]
  Epoch: [073][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.2888 (0.3041)   Prec@1 90.625 (89.260)   Prec@5 100.000 (99.694)   [2019-11-22 04:15:09]
  **Train** Prec@1 89.290 Prec@5 99.676 Error@1 10.710
  **Test** Prec@1 85.500 Prec@5 99.440 Error@1 14.500

==>>[2019-11-22 04:15:15] [Epoch=074/200] [Need: 00:46:14] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [074][000/391]   Time 0.222 (0.222)   Data 0.166 (0.166)   Loss 0.3348 (0.3348)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 04:15:15]
  Epoch: [074][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3928 (0.2915)   Prec@1 88.281 (89.813)   Prec@5 100.000 (99.675)   [2019-11-22 04:15:20]
  Epoch: [074][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3799 (0.3045)   Prec@1 85.938 (89.408)   Prec@5 99.219 (99.701)   [2019-11-22 04:15:25]
  Epoch: [074][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.4121 (0.3118)   Prec@1 87.500 (89.221)   Prec@5 99.219 (99.699)   [2019-11-22 04:15:30]
  **Train** Prec@1 89.274 Prec@5 99.686 Error@1 10.726
  **Test** Prec@1 82.820 Prec@5 99.120 Error@1 17.180

==>>[2019-11-22 04:15:37] [Epoch=075/200] [Need: 00:45:52] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [075][000/391]   Time 0.230 (0.230)   Data 0.153 (0.153)   Loss 0.2666 (0.2666)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 04:15:37]
  Epoch: [075][100/391]   Time 0.053 (0.056)   Data 0.000 (0.002)   Loss 0.3414 (0.2985)   Prec@1 90.625 (89.666)   Prec@5 100.000 (99.691)   [2019-11-22 04:15:43]
  Epoch: [075][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2729 (0.3037)   Prec@1 91.406 (89.506)   Prec@5 100.000 (99.670)   [2019-11-22 04:15:48]
  Epoch: [075][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.3073 (0.3085)   Prec@1 88.281 (89.262)   Prec@5 100.000 (99.650)   [2019-11-22 04:15:52]
  **Train** Prec@1 89.280 Prec@5 99.660 Error@1 10.720
  **Test** Prec@1 85.380 Prec@5 99.430 Error@1 14.620

==>>[2019-11-22 04:15:59] [Epoch=076/200] [Need: 00:45:30] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [076][000/391]   Time 0.240 (0.240)   Data 0.176 (0.176)   Loss 0.3131 (0.3131)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 04:15:59]
  Epoch: [076][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.2556 (0.3058)   Prec@1 92.969 (89.488)   Prec@5 100.000 (99.729)   [2019-11-22 04:16:04]
  Epoch: [076][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.2435 (0.3125)   Prec@1 91.406 (88.981)   Prec@5 99.219 (99.728)   [2019-11-22 04:16:09]
  Epoch: [076][300/391]   Time 0.061 (0.052)   Data 0.000 (0.001)   Loss 0.3433 (0.3102)   Prec@1 87.500 (89.055)   Prec@5 99.219 (99.702)   [2019-11-22 04:16:15]
  **Train** Prec@1 89.014 Prec@5 99.722 Error@1 10.986
  **Test** Prec@1 85.150 Prec@5 99.340 Error@1 14.850

==>>[2019-11-22 04:16:21] [Epoch=077/200] [Need: 00:45:07] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [077][000/391]   Time 0.233 (0.233)   Data 0.163 (0.163)   Loss 0.2170 (0.2170)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 04:16:21]
  Epoch: [077][100/391]   Time 0.054 (0.052)   Data 0.000 (0.002)   Loss 0.3409 (0.2908)   Prec@1 86.719 (89.511)   Prec@5 100.000 (99.845)   [2019-11-22 04:16:26]
  Epoch: [077][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.2435 (0.2967)   Prec@1 92.188 (89.587)   Prec@5 100.000 (99.790)   [2019-11-22 04:16:31]
  Epoch: [077][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3042 (0.3007)   Prec@1 90.625 (89.379)   Prec@5 100.000 (99.790)   [2019-11-22 04:16:36]
  **Train** Prec@1 89.230 Prec@5 99.746 Error@1 10.770
  **Test** Prec@1 85.940 Prec@5 99.390 Error@1 14.060

==>>[2019-11-22 04:16:43] [Epoch=078/200] [Need: 00:44:45] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [078][000/391]   Time 0.222 (0.222)   Data 0.158 (0.158)   Loss 0.2754 (0.2754)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 04:16:43]
  Epoch: [078][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.4280 (0.2905)   Prec@1 84.375 (89.821)   Prec@5 100.000 (99.838)   [2019-11-22 04:16:48]
  Epoch: [078][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.3441 (0.2984)   Prec@1 89.062 (89.607)   Prec@5 99.219 (99.759)   [2019-11-22 04:16:53]
  Epoch: [078][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2525 (0.2994)   Prec@1 91.406 (89.626)   Prec@5 100.000 (99.740)   [2019-11-22 04:16:58]
  **Train** Prec@1 89.522 Prec@5 99.736 Error@1 10.478
  **Test** Prec@1 84.980 Prec@5 99.220 Error@1 15.020

==>>[2019-11-22 04:17:04] [Epoch=079/200] [Need: 00:44:23] [LR=0.0100][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [079][000/391]   Time 0.223 (0.223)   Data 0.165 (0.165)   Loss 0.2867 (0.2867)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 04:17:05]
  Epoch: [079][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.3405 (0.2984)   Prec@1 92.188 (89.619)   Prec@5 100.000 (99.752)   [2019-11-22 04:17:10]
  Epoch: [079][200/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.3394 (0.2968)   Prec@1 87.500 (89.684)   Prec@5 100.000 (99.732)   [2019-11-22 04:17:14]
  Epoch: [079][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.2904 (0.3059)   Prec@1 89.844 (89.426)   Prec@5 99.219 (99.683)   [2019-11-22 04:17:20]
  **Train** Prec@1 89.170 Prec@5 99.666 Error@1 10.830
  **Test** Prec@1 85.280 Prec@5 99.370 Error@1 14.720

==>>[2019-11-22 04:17:26] [Epoch=080/200] [Need: 00:44:00] [LR=0.0010][M=0.90] [Best : Accuracy=86.56, Error=13.44]
  Epoch: [080][000/391]   Time 0.218 (0.218)   Data 0.172 (0.172)   Loss 0.5311 (0.5311)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-22 04:17:26]
  Epoch: [080][100/391]   Time 0.056 (0.053)   Data 0.000 (0.002)   Loss 0.2719 (0.2584)   Prec@1 89.062 (90.865)   Prec@5 100.000 (99.807)   [2019-11-22 04:17:31]
  Epoch: [080][200/391]   Time 0.045 (0.051)   Data 0.004 (0.001)   Loss 0.2503 (0.2399)   Prec@1 92.969 (91.636)   Prec@5 100.000 (99.817)   [2019-11-22 04:17:36]
  Epoch: [080][300/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.2593 (0.2303)   Prec@1 91.406 (92.024)   Prec@5 100.000 (99.842)   [2019-11-22 04:17:41]
  **Train** Prec@1 92.262 Prec@5 99.832 Error@1 7.738
  **Test** Prec@1 89.540 Prec@5 99.660 Error@1 10.460
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:17:48] [Epoch=081/200] [Need: 00:43:38] [LR=0.0010][M=0.90] [Best : Accuracy=89.54, Error=10.46]
  Epoch: [081][000/391]   Time 0.225 (0.225)   Data 0.167 (0.167)   Loss 0.1905 (0.1905)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 04:17:48]
  Epoch: [081][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.2403 (0.1924)   Prec@1 88.281 (93.301)   Prec@5 100.000 (99.884)   [2019-11-22 04:17:53]
  Epoch: [081][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.3172 (0.1903)   Prec@1 90.625 (93.462)   Prec@5 99.219 (99.891)   [2019-11-22 04:17:58]
  Epoch: [081][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1834 (0.1869)   Prec@1 92.969 (93.566)   Prec@5 100.000 (99.909)   [2019-11-22 04:18:03]
  **Train** Prec@1 93.506 Prec@5 99.896 Error@1 6.494
  **Test** Prec@1 90.210 Prec@5 99.730 Error@1 9.790
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:18:10] [Epoch=082/200] [Need: 00:43:16] [LR=0.0010][M=0.90] [Best : Accuracy=90.21, Error=9.79]
  Epoch: [082][000/391]   Time 0.236 (0.236)   Data 0.178 (0.178)   Loss 0.1468 (0.1468)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 04:18:10]
  Epoch: [082][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.3336 (0.1665)   Prec@1 89.844 (94.237)   Prec@5 99.219 (99.876)   [2019-11-22 04:18:15]
  Epoch: [082][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.1666 (0.1711)   Prec@1 94.531 (94.127)   Prec@5 100.000 (99.899)   [2019-11-22 04:18:20]
  Epoch: [082][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.1109 (0.1737)   Prec@1 95.312 (94.043)   Prec@5 100.000 (99.894)   [2019-11-22 04:18:25]
  **Train** Prec@1 94.088 Prec@5 99.896 Error@1 5.912
  **Test** Prec@1 90.060 Prec@5 99.750 Error@1 9.940

==>>[2019-11-22 04:18:31] [Epoch=083/200] [Need: 00:42:53] [LR=0.0010][M=0.90] [Best : Accuracy=90.21, Error=9.79]
  Epoch: [083][000/391]   Time 0.231 (0.231)   Data 0.154 (0.154)   Loss 0.1556 (0.1556)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 04:18:32]
  Epoch: [083][100/391]   Time 0.065 (0.057)   Data 0.000 (0.002)   Loss 0.1030 (0.1648)   Prec@1 95.312 (94.237)   Prec@5 100.000 (99.814)   [2019-11-22 04:18:37]
  Epoch: [083][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1805 (0.1633)   Prec@1 93.750 (94.356)   Prec@5 100.000 (99.852)   [2019-11-22 04:18:42]
  Epoch: [083][300/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.1585 (0.1626)   Prec@1 94.531 (94.391)   Prec@5 99.219 (99.883)   [2019-11-22 04:18:47]
  **Train** Prec@1 94.354 Prec@5 99.872 Error@1 5.646
  **Test** Prec@1 90.330 Prec@5 99.730 Error@1 9.670
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:18:53] [Epoch=084/200] [Need: 00:42:31] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [084][000/391]   Time 0.237 (0.237)   Data 0.148 (0.148)   Loss 0.1323 (0.1323)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:18:54]
  Epoch: [084][100/391]   Time 0.055 (0.051)   Data 0.000 (0.002)   Loss 0.1190 (0.1538)   Prec@1 96.094 (94.732)   Prec@5 99.219 (99.915)   [2019-11-22 04:18:58]
  Epoch: [084][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1433 (0.1572)   Prec@1 95.312 (94.578)   Prec@5 100.000 (99.911)   [2019-11-22 04:19:04]
  Epoch: [084][300/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.2187 (0.1579)   Prec@1 92.969 (94.513)   Prec@5 100.000 (99.914)   [2019-11-22 04:19:08]
  **Train** Prec@1 94.460 Prec@5 99.920 Error@1 5.540
  **Test** Prec@1 90.160 Prec@5 99.680 Error@1 9.840

==>>[2019-11-22 04:19:15] [Epoch=085/200] [Need: 00:42:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [085][000/391]   Time 0.225 (0.225)   Data 0.161 (0.161)   Loss 0.1400 (0.1400)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 04:19:15]
  Epoch: [085][100/391]   Time 0.056 (0.053)   Data 0.000 (0.002)   Loss 0.1405 (0.1491)   Prec@1 93.750 (94.933)   Prec@5 100.000 (99.892)   [2019-11-22 04:19:20]
  Epoch: [085][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1016 (0.1496)   Prec@1 97.656 (94.928)   Prec@5 100.000 (99.907)   [2019-11-22 04:19:25]
  Epoch: [085][300/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.1056 (0.1514)   Prec@1 96.094 (94.809)   Prec@5 100.000 (99.907)   [2019-11-22 04:19:30]
  **Train** Prec@1 94.760 Prec@5 99.916 Error@1 5.240
  **Test** Prec@1 90.420 Prec@5 99.620 Error@1 9.580
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:19:37] [Epoch=086/200] [Need: 00:41:47] [LR=0.0010][M=0.90] [Best : Accuracy=90.42, Error=9.58]
  Epoch: [086][000/391]   Time 0.233 (0.233)   Data 0.165 (0.165)   Loss 0.1306 (0.1306)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:19:37]
  Epoch: [086][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.1386 (0.1386)   Prec@1 96.094 (95.204)   Prec@5 100.000 (99.938)   [2019-11-22 04:19:42]
  Epoch: [086][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2373 (0.1446)   Prec@1 92.188 (94.982)   Prec@5 100.000 (99.942)   [2019-11-22 04:19:47]
  Epoch: [086][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.1823 (0.1478)   Prec@1 92.969 (94.838)   Prec@5 100.000 (99.927)   [2019-11-22 04:19:52]
  **Train** Prec@1 94.820 Prec@5 99.918 Error@1 5.180
  **Test** Prec@1 90.240 Prec@5 99.720 Error@1 9.760

==>>[2019-11-22 04:19:59] [Epoch=087/200] [Need: 00:41:25] [LR=0.0010][M=0.90] [Best : Accuracy=90.42, Error=9.58]
  Epoch: [087][000/391]   Time 0.231 (0.231)   Data 0.172 (0.172)   Loss 0.0801 (0.0801)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:19:59]
  Epoch: [087][100/391]   Time 0.037 (0.054)   Data 0.000 (0.002)   Loss 0.1273 (0.1395)   Prec@1 96.094 (95.127)   Prec@5 100.000 (99.884)   [2019-11-22 04:20:04]
  Epoch: [087][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0859 (0.1430)   Prec@1 96.094 (95.029)   Prec@5 100.000 (99.887)   [2019-11-22 04:20:09]
  Epoch: [087][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0725 (0.1416)   Prec@1 97.656 (95.087)   Prec@5 100.000 (99.901)   [2019-11-22 04:20:14]
  **Train** Prec@1 95.030 Prec@5 99.916 Error@1 4.970
  **Test** Prec@1 90.630 Prec@5 99.710 Error@1 9.370
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:20:21] [Epoch=088/200] [Need: 00:41:02] [LR=0.0010][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [088][000/391]   Time 0.236 (0.236)   Data 0.178 (0.178)   Loss 0.1094 (0.1094)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:20:21]
  Epoch: [088][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1994 (0.1358)   Prec@1 93.750 (95.382)   Prec@5 100.000 (99.923)   [2019-11-22 04:20:26]
  Epoch: [088][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0973 (0.1364)   Prec@1 96.875 (95.165)   Prec@5 100.000 (99.934)   [2019-11-22 04:20:31]
  Epoch: [088][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1028 (0.1366)   Prec@1 96.094 (95.170)   Prec@5 100.000 (99.917)   [2019-11-22 04:20:36]
  **Train** Prec@1 95.166 Prec@5 99.926 Error@1 4.834
  **Test** Prec@1 90.430 Prec@5 99.690 Error@1 9.570

==>>[2019-11-22 04:20:43] [Epoch=089/200] [Need: 00:40:40] [LR=0.0010][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [089][000/391]   Time 0.244 (0.244)   Data 0.164 (0.164)   Loss 0.0886 (0.0886)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:20:43]
  Epoch: [089][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.1182 (0.1350)   Prec@1 96.094 (95.220)   Prec@5 100.000 (99.907)   [2019-11-22 04:20:48]
  Epoch: [089][200/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.1477 (0.1365)   Prec@1 93.750 (95.254)   Prec@5 99.219 (99.922)   [2019-11-22 04:20:53]
  Epoch: [089][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1601 (0.1327)   Prec@1 93.750 (95.377)   Prec@5 100.000 (99.933)   [2019-11-22 04:20:58]
  **Train** Prec@1 95.344 Prec@5 99.938 Error@1 4.656
  **Test** Prec@1 90.570 Prec@5 99.680 Error@1 9.430

==>>[2019-11-22 04:21:04] [Epoch=090/200] [Need: 00:40:18] [LR=0.0010][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [090][000/391]   Time 0.234 (0.234)   Data 0.173 (0.173)   Loss 0.1899 (0.1899)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 04:21:05]
  Epoch: [090][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0909 (0.1278)   Prec@1 96.094 (95.622)   Prec@5 100.000 (99.930)   [2019-11-22 04:21:10]
  Epoch: [090][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1836 (0.1251)   Prec@1 90.625 (95.581)   Prec@5 100.000 (99.953)   [2019-11-22 04:21:15]
  Epoch: [090][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.2029 (0.1280)   Prec@1 95.312 (95.551)   Prec@5 100.000 (99.945)   [2019-11-22 04:21:20]
  **Train** Prec@1 95.510 Prec@5 99.946 Error@1 4.490
  **Test** Prec@1 90.580 Prec@5 99.720 Error@1 9.420

==>>[2019-11-22 04:21:26] [Epoch=091/200] [Need: 00:39:56] [LR=0.0010][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [091][000/391]   Time 0.228 (0.228)   Data 0.154 (0.154)   Loss 0.1067 (0.1067)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:21:26]
  Epoch: [091][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.1587 (0.1290)   Prec@1 94.531 (95.444)   Prec@5 100.000 (99.946)   [2019-11-22 04:21:32]
  Epoch: [091][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.1126 (0.1280)   Prec@1 95.312 (95.464)   Prec@5 100.000 (99.938)   [2019-11-22 04:21:36]
  Epoch: [091][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1675 (0.1270)   Prec@1 92.969 (95.525)   Prec@5 100.000 (99.945)   [2019-11-22 04:21:41]
  **Train** Prec@1 95.578 Prec@5 99.948 Error@1 4.422
  **Test** Prec@1 90.580 Prec@5 99.710 Error@1 9.420

==>>[2019-11-22 04:21:48] [Epoch=092/200] [Need: 00:39:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [092][000/391]   Time 0.238 (0.238)   Data 0.178 (0.178)   Loss 0.1143 (0.1143)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:21:48]
  Epoch: [092][100/391]   Time 0.059 (0.051)   Data 0.000 (0.002)   Loss 0.1215 (0.1247)   Prec@1 94.531 (95.560)   Prec@5 100.000 (99.954)   [2019-11-22 04:21:53]
  Epoch: [092][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1312 (0.1262)   Prec@1 95.312 (95.553)   Prec@5 100.000 (99.953)   [2019-11-22 04:21:58]
  Epoch: [092][300/391]   Time 0.075 (0.051)   Data 0.000 (0.001)   Loss 0.1156 (0.1272)   Prec@1 96.875 (95.505)   Prec@5 100.000 (99.943)   [2019-11-22 04:22:03]
  **Train** Prec@1 95.490 Prec@5 99.942 Error@1 4.510
  **Test** Prec@1 90.790 Prec@5 99.640 Error@1 9.210
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:22:10] [Epoch=093/200] [Need: 00:39:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [093][000/391]   Time 0.221 (0.221)   Data 0.165 (0.165)   Loss 0.0762 (0.0762)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:22:10]
  Epoch: [093][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.1429 (0.1173)   Prec@1 95.312 (95.970)   Prec@5 100.000 (99.938)   [2019-11-22 04:22:15]
  Epoch: [093][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.1524 (0.1210)   Prec@1 95.312 (95.802)   Prec@5 100.000 (99.949)   [2019-11-22 04:22:20]
  Epoch: [093][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.1301 (0.1229)   Prec@1 94.531 (95.686)   Prec@5 100.000 (99.938)   [2019-11-22 04:22:24]
  **Train** Prec@1 95.656 Prec@5 99.942 Error@1 4.344
  **Test** Prec@1 90.400 Prec@5 99.710 Error@1 9.600

==>>[2019-11-22 04:22:31] [Epoch=094/200] [Need: 00:38:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [094][000/391]   Time 0.229 (0.229)   Data 0.163 (0.163)   Loss 0.1242 (0.1242)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:22:31]
  Epoch: [094][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.0779 (0.1175)   Prec@1 97.656 (95.831)   Prec@5 100.000 (99.954)   [2019-11-22 04:22:36]
  Epoch: [094][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0960 (0.1163)   Prec@1 96.094 (95.880)   Prec@5 100.000 (99.965)   [2019-11-22 04:22:41]
  Epoch: [094][300/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.0927 (0.1175)   Prec@1 96.875 (95.845)   Prec@5 100.000 (99.951)   [2019-11-22 04:22:46]
  **Train** Prec@1 95.836 Prec@5 99.948 Error@1 4.164
  **Test** Prec@1 90.660 Prec@5 99.690 Error@1 9.340

==>>[2019-11-22 04:22:52] [Epoch=095/200] [Need: 00:38:26] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [095][000/391]   Time 0.238 (0.238)   Data 0.162 (0.162)   Loss 0.0944 (0.0944)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:22:52]
  Epoch: [095][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1013 (0.1028)   Prec@1 96.094 (96.357)   Prec@5 100.000 (99.977)   [2019-11-22 04:22:58]
  Epoch: [095][200/391]   Time 0.080 (0.051)   Data 0.000 (0.001)   Loss 0.0968 (0.1085)   Prec@1 96.875 (96.171)   Prec@5 100.000 (99.965)   [2019-11-22 04:23:02]
  Epoch: [095][300/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.1601 (0.1130)   Prec@1 95.312 (96.003)   Prec@5 100.000 (99.964)   [2019-11-22 04:23:07]
  **Train** Prec@1 95.954 Prec@5 99.950 Error@1 4.046
  **Test** Prec@1 90.580 Prec@5 99.730 Error@1 9.420

==>>[2019-11-22 04:23:14] [Epoch=096/200] [Need: 00:38:03] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [096][000/391]   Time 0.241 (0.241)   Data 0.175 (0.175)   Loss 0.0825 (0.0825)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:23:14]
  Epoch: [096][100/391]   Time 0.080 (0.056)   Data 0.000 (0.002)   Loss 0.0402 (0.1136)   Prec@1 97.656 (96.009)   Prec@5 100.000 (99.977)   [2019-11-22 04:23:19]
  Epoch: [096][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0922 (0.1147)   Prec@1 98.438 (95.907)   Prec@5 100.000 (99.965)   [2019-11-22 04:23:24]
  Epoch: [096][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.1441 (0.1142)   Prec@1 96.094 (95.904)   Prec@5 99.219 (99.974)   [2019-11-22 04:23:29]
  **Train** Prec@1 95.972 Prec@5 99.974 Error@1 4.028
  **Test** Prec@1 90.630 Prec@5 99.680 Error@1 9.370

==>>[2019-11-22 04:23:36] [Epoch=097/200] [Need: 00:37:41] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [097][000/391]   Time 0.235 (0.235)   Data 0.177 (0.177)   Loss 0.1037 (0.1037)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:23:36]
  Epoch: [097][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.1369 (0.1077)   Prec@1 96.094 (96.334)   Prec@5 100.000 (99.985)   [2019-11-22 04:23:41]
  Epoch: [097][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0927 (0.1089)   Prec@1 96.875 (96.214)   Prec@5 100.000 (99.965)   [2019-11-22 04:23:46]
  Epoch: [097][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0636 (0.1122)   Prec@1 98.438 (96.135)   Prec@5 100.000 (99.958)   [2019-11-22 04:23:51]
  **Train** Prec@1 96.142 Prec@5 99.962 Error@1 3.858
  **Test** Prec@1 90.410 Prec@5 99.700 Error@1 9.590

==>>[2019-11-22 04:23:57] [Epoch=098/200] [Need: 00:37:19] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [098][000/391]   Time 0.222 (0.222)   Data 0.155 (0.155)   Loss 0.1249 (0.1249)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:23:58]
  Epoch: [098][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.1489 (0.1069)   Prec@1 94.531 (96.264)   Prec@5 100.000 (99.961)   [2019-11-22 04:24:03]
  Epoch: [098][200/391]   Time 0.057 (0.052)   Data 0.005 (0.001)   Loss 0.1385 (0.1076)   Prec@1 96.094 (96.164)   Prec@5 100.000 (99.969)   [2019-11-22 04:24:08]
  Epoch: [098][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0968 (0.1110)   Prec@1 94.531 (96.021)   Prec@5 100.000 (99.969)   [2019-11-22 04:24:13]
  **Train** Prec@1 96.090 Prec@5 99.966 Error@1 3.910
  **Test** Prec@1 90.490 Prec@5 99.700 Error@1 9.510

==>>[2019-11-22 04:24:19] [Epoch=099/200] [Need: 00:36:57] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [099][000/391]   Time 0.223 (0.223)   Data 0.155 (0.155)   Loss 0.1284 (0.1284)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 04:24:19]
  Epoch: [099][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.1276 (0.0997)   Prec@1 96.094 (96.558)   Prec@5 100.000 (99.985)   [2019-11-22 04:24:24]
  Epoch: [099][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.1011 (0.1020)   Prec@1 96.875 (96.381)   Prec@5 100.000 (99.988)   [2019-11-22 04:24:29]
  Epoch: [099][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0708 (0.1050)   Prec@1 96.875 (96.255)   Prec@5 100.000 (99.982)   [2019-11-22 04:24:34]
  **Train** Prec@1 96.172 Prec@5 99.974 Error@1 3.828
  **Test** Prec@1 90.520 Prec@5 99.750 Error@1 9.480

==>>[2019-11-22 04:24:41] [Epoch=100/200] [Need: 00:36:35] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [100][000/391]   Time 0.228 (0.228)   Data 0.168 (0.168)   Loss 0.1637 (0.1637)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:24:41]
  Epoch: [100][100/391]   Time 0.058 (0.050)   Data 0.000 (0.002)   Loss 0.1313 (0.1041)   Prec@1 93.750 (96.318)   Prec@5 100.000 (99.946)   [2019-11-22 04:24:46]
  Epoch: [100][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0734 (0.1042)   Prec@1 97.656 (96.292)   Prec@5 100.000 (99.957)   [2019-11-22 04:24:51]
  Epoch: [100][300/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.0773 (0.1052)   Prec@1 96.094 (96.260)   Prec@5 100.000 (99.951)   [2019-11-22 04:24:56]
  **Train** Prec@1 96.222 Prec@5 99.956 Error@1 3.778
  **Test** Prec@1 90.650 Prec@5 99.760 Error@1 9.350

==>>[2019-11-22 04:25:03] [Epoch=101/200] [Need: 00:36:13] [LR=0.0010][M=0.90] [Best : Accuracy=90.79, Error=9.21]
  Epoch: [101][000/391]   Time 0.223 (0.223)   Data 0.161 (0.161)   Loss 0.0941 (0.0941)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:25:03]
  Epoch: [101][100/391]   Time 0.061 (0.049)   Data 0.000 (0.002)   Loss 0.0323 (0.0975)   Prec@1 99.219 (96.612)   Prec@5 100.000 (99.969)   [2019-11-22 04:25:08]
  Epoch: [101][200/391]   Time 0.046 (0.048)   Data 0.000 (0.001)   Loss 0.1207 (0.0997)   Prec@1 96.094 (96.514)   Prec@5 100.000 (99.961)   [2019-11-22 04:25:12]
  Epoch: [101][300/391]   Time 0.044 (0.048)   Data 0.000 (0.001)   Loss 0.1385 (0.1001)   Prec@1 95.312 (96.506)   Prec@5 100.000 (99.964)   [2019-11-22 04:25:17]
  **Train** Prec@1 96.440 Prec@5 99.966 Error@1 3.560
  **Test** Prec@1 90.800 Prec@5 99.680 Error@1 9.200
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:25:23] [Epoch=102/200] [Need: 00:35:50] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [102][000/391]   Time 0.218 (0.218)   Data 0.161 (0.161)   Loss 0.1015 (0.1015)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:25:24]
  Epoch: [102][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0656 (0.0928)   Prec@1 96.875 (96.705)   Prec@5 100.000 (99.985)   [2019-11-22 04:25:29]
  Epoch: [102][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0800 (0.0943)   Prec@1 96.094 (96.560)   Prec@5 100.000 (99.977)   [2019-11-22 04:25:34]
  Epoch: [102][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1700 (0.0969)   Prec@1 92.969 (96.517)   Prec@5 100.000 (99.969)   [2019-11-22 04:25:39]
  **Train** Prec@1 96.450 Prec@5 99.966 Error@1 3.550
  **Test** Prec@1 90.470 Prec@5 99.660 Error@1 9.530

==>>[2019-11-22 04:25:46] [Epoch=103/200] [Need: 00:35:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [103][000/391]   Time 0.227 (0.227)   Data 0.170 (0.170)   Loss 0.0534 (0.0534)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:25:46]
  Epoch: [103][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.1028 (0.0987)   Prec@1 96.094 (96.620)   Prec@5 100.000 (99.977)   [2019-11-22 04:25:51]
  Epoch: [103][200/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.1276 (0.1000)   Prec@1 94.531 (96.583)   Prec@5 100.000 (99.973)   [2019-11-22 04:25:56]
  Epoch: [103][300/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.0874 (0.0981)   Prec@1 96.875 (96.577)   Prec@5 100.000 (99.969)   [2019-11-22 04:26:02]
  **Train** Prec@1 96.518 Prec@5 99.970 Error@1 3.482
  **Test** Prec@1 90.630 Prec@5 99.720 Error@1 9.370

==>>[2019-11-22 04:26:08] [Epoch=104/200] [Need: 00:35:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [104][000/391]   Time 0.230 (0.230)   Data 0.164 (0.164)   Loss 0.0392 (0.0392)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:26:09]
  Epoch: [104][100/391]   Time 0.062 (0.050)   Data 0.000 (0.002)   Loss 0.0867 (0.0858)   Prec@1 96.094 (97.014)   Prec@5 100.000 (99.977)   [2019-11-22 04:26:13]
  Epoch: [104][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0709 (0.0894)   Prec@1 96.875 (96.859)   Prec@5 100.000 (99.981)   [2019-11-22 04:26:18]
  Epoch: [104][300/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.1129 (0.0933)   Prec@1 96.875 (96.717)   Prec@5 100.000 (99.984)   [2019-11-22 04:26:23]
  **Train** Prec@1 96.632 Prec@5 99.988 Error@1 3.368
  **Test** Prec@1 90.590 Prec@5 99.740 Error@1 9.410

==>>[2019-11-22 04:26:30] [Epoch=105/200] [Need: 00:34:44] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [105][000/391]   Time 0.234 (0.234)   Data 0.153 (0.153)   Loss 0.1890 (0.1890)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:26:30]
  Epoch: [105][100/391]   Time 0.054 (0.052)   Data 0.000 (0.002)   Loss 0.0687 (0.0955)   Prec@1 96.875 (96.867)   Prec@5 100.000 (99.985)   [2019-11-22 04:26:35]
  Epoch: [105][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1115 (0.0936)   Prec@1 96.094 (96.793)   Prec@5 100.000 (99.988)   [2019-11-22 04:26:40]
  Epoch: [105][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0779 (0.0921)   Prec@1 96.875 (96.753)   Prec@5 100.000 (99.990)   [2019-11-22 04:26:45]
  **Train** Prec@1 96.682 Prec@5 99.984 Error@1 3.318
  **Test** Prec@1 90.500 Prec@5 99.760 Error@1 9.500

==>>[2019-11-22 04:26:52] [Epoch=106/200] [Need: 00:34:23] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [106][000/391]   Time 0.246 (0.246)   Data 0.161 (0.161)   Loss 0.0819 (0.0819)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:26:52]
  Epoch: [106][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0921 (0.0893)   Prec@1 96.875 (96.751)   Prec@5 100.000 (99.954)   [2019-11-22 04:26:57]
  Epoch: [106][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0707 (0.0928)   Prec@1 96.875 (96.650)   Prec@5 100.000 (99.965)   [2019-11-22 04:27:02]
  Epoch: [106][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0966 (0.0958)   Prec@1 94.531 (96.571)   Prec@5 100.000 (99.964)   [2019-11-22 04:27:08]
  **Train** Prec@1 96.620 Prec@5 99.970 Error@1 3.380
  **Test** Prec@1 90.790 Prec@5 99.700 Error@1 9.210

==>>[2019-11-22 04:27:14] [Epoch=107/200] [Need: 00:34:01] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [107][000/391]   Time 0.244 (0.244)   Data 0.157 (0.157)   Loss 0.1392 (0.1392)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 04:27:15]
  Epoch: [107][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0357 (0.0893)   Prec@1 99.219 (96.906)   Prec@5 100.000 (99.977)   [2019-11-22 04:27:20]
  Epoch: [107][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1507 (0.0890)   Prec@1 95.312 (96.918)   Prec@5 100.000 (99.981)   [2019-11-22 04:27:25]
  Epoch: [107][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1145 (0.0922)   Prec@1 95.312 (96.753)   Prec@5 100.000 (99.969)   [2019-11-22 04:27:30]
  **Train** Prec@1 96.768 Prec@5 99.964 Error@1 3.232
  **Test** Prec@1 90.500 Prec@5 99.660 Error@1 9.500

==>>[2019-11-22 04:27:37] [Epoch=108/200] [Need: 00:33:39] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [108][000/391]   Time 0.229 (0.229)   Data 0.167 (0.167)   Loss 0.0819 (0.0819)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:27:37]
  Epoch: [108][100/391]   Time 0.068 (0.052)   Data 0.000 (0.002)   Loss 0.0925 (0.0879)   Prec@1 96.094 (96.945)   Prec@5 100.000 (99.969)   [2019-11-22 04:27:42]
  Epoch: [108][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0703 (0.0887)   Prec@1 97.656 (96.964)   Prec@5 100.000 (99.953)   [2019-11-22 04:27:47]
  Epoch: [108][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1034 (0.0875)   Prec@1 96.094 (96.937)   Prec@5 100.000 (99.961)   [2019-11-22 04:27:52]
  **Train** Prec@1 96.920 Prec@5 99.964 Error@1 3.080
  **Test** Prec@1 90.590 Prec@5 99.690 Error@1 9.410

==>>[2019-11-22 04:27:58] [Epoch=109/200] [Need: 00:33:17] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [109][000/391]   Time 0.237 (0.237)   Data 0.171 (0.171)   Loss 0.0627 (0.0627)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:27:59]
  Epoch: [109][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0554 (0.0858)   Prec@1 98.438 (96.890)   Prec@5 100.000 (99.977)   [2019-11-22 04:28:04]
  Epoch: [109][200/391]   Time 0.057 (0.054)   Data 0.000 (0.001)   Loss 0.0642 (0.0875)   Prec@1 99.219 (96.945)   Prec@5 100.000 (99.973)   [2019-11-22 04:28:09]
  Epoch: [109][300/391]   Time 0.075 (0.053)   Data 0.000 (0.001)   Loss 0.0433 (0.0873)   Prec@1 98.438 (96.911)   Prec@5 100.000 (99.974)   [2019-11-22 04:28:14]
  **Train** Prec@1 96.854 Prec@5 99.976 Error@1 3.146
  **Test** Prec@1 90.480 Prec@5 99.730 Error@1 9.520

==>>[2019-11-22 04:28:20] [Epoch=110/200] [Need: 00:32:55] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [110][000/391]   Time 0.230 (0.230)   Data 0.155 (0.155)   Loss 0.0801 (0.0801)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:28:21]
  Epoch: [110][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0785 (0.0820)   Prec@1 98.438 (97.061)   Prec@5 100.000 (99.985)   [2019-11-22 04:28:26]
  Epoch: [110][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0703 (0.0858)   Prec@1 98.438 (96.918)   Prec@5 100.000 (99.984)   [2019-11-22 04:28:31]
  Epoch: [110][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0570 (0.0852)   Prec@1 99.219 (96.953)   Prec@5 100.000 (99.990)   [2019-11-22 04:28:36]
  **Train** Prec@1 96.904 Prec@5 99.980 Error@1 3.096
  **Test** Prec@1 90.590 Prec@5 99.650 Error@1 9.410

==>>[2019-11-22 04:28:42] [Epoch=111/200] [Need: 00:32:33] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [111][000/391]   Time 0.227 (0.227)   Data 0.153 (0.153)   Loss 0.0933 (0.0933)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:28:42]
  Epoch: [111][100/391]   Time 0.047 (0.049)   Data 0.000 (0.002)   Loss 0.1057 (0.0832)   Prec@1 96.094 (97.022)   Prec@5 100.000 (99.969)   [2019-11-22 04:28:47]
  Epoch: [111][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0920 (0.0857)   Prec@1 96.875 (96.879)   Prec@5 100.000 (99.965)   [2019-11-22 04:28:52]
  Epoch: [111][300/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.1047 (0.0875)   Prec@1 93.750 (96.823)   Prec@5 100.000 (99.966)   [2019-11-22 04:28:57]
  **Train** Prec@1 96.840 Prec@5 99.968 Error@1 3.160
  **Test** Prec@1 90.480 Prec@5 99.770 Error@1 9.520

==>>[2019-11-22 04:29:04] [Epoch=112/200] [Need: 00:32:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [112][000/391]   Time 0.224 (0.224)   Data 0.151 (0.151)   Loss 0.0681 (0.0681)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:29:04]
  Epoch: [112][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.0900 (0.0816)   Prec@1 96.094 (97.045)   Prec@5 100.000 (99.977)   [2019-11-22 04:29:09]
  Epoch: [112][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0566 (0.0813)   Prec@1 98.438 (97.128)   Prec@5 100.000 (99.984)   [2019-11-22 04:29:15]
  Epoch: [112][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0381 (0.0827)   Prec@1 100.000 (97.093)   Prec@5 100.000 (99.977)   [2019-11-22 04:29:19]
  **Train** Prec@1 97.024 Prec@5 99.978 Error@1 2.976
  **Test** Prec@1 90.500 Prec@5 99.760 Error@1 9.500

==>>[2019-11-22 04:29:26] [Epoch=113/200] [Need: 00:31:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [113][000/391]   Time 0.225 (0.225)   Data 0.153 (0.153)   Loss 0.1115 (0.1115)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:29:26]
  Epoch: [113][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0620 (0.0791)   Prec@1 97.656 (97.208)   Prec@5 100.000 (100.000)   [2019-11-22 04:29:31]
  Epoch: [113][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0428 (0.0806)   Prec@1 97.656 (97.190)   Prec@5 100.000 (99.988)   [2019-11-22 04:29:36]
  Epoch: [113][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0821 (0.0820)   Prec@1 96.094 (97.145)   Prec@5 100.000 (99.977)   [2019-11-22 04:29:41]
  **Train** Prec@1 97.004 Prec@5 99.974 Error@1 2.996
  **Test** Prec@1 90.500 Prec@5 99.760 Error@1 9.500

==>>[2019-11-22 04:29:48] [Epoch=114/200] [Need: 00:31:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [114][000/391]   Time 0.229 (0.229)   Data 0.152 (0.152)   Loss 0.1310 (0.1310)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:29:48]
  Epoch: [114][100/391]   Time 0.037 (0.053)   Data 0.000 (0.002)   Loss 0.0638 (0.0798)   Prec@1 96.094 (97.215)   Prec@5 100.000 (99.977)   [2019-11-22 04:29:53]
  Epoch: [114][200/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0817 (0.0797)   Prec@1 97.656 (97.256)   Prec@5 100.000 (99.984)   [2019-11-22 04:29:58]
  Epoch: [114][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0812 (0.0801)   Prec@1 96.875 (97.259)   Prec@5 100.000 (99.977)   [2019-11-22 04:30:03]
  **Train** Prec@1 97.188 Prec@5 99.982 Error@1 2.812
  **Test** Prec@1 90.280 Prec@5 99.790 Error@1 9.720

==>>[2019-11-22 04:30:11] [Epoch=115/200] [Need: 00:31:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [115][000/391]   Time 0.245 (0.245)   Data 0.177 (0.177)   Loss 0.0681 (0.0681)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:30:11]
  Epoch: [115][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0794 (0.0849)   Prec@1 97.656 (97.014)   Prec@5 100.000 (99.977)   [2019-11-22 04:30:16]
  Epoch: [115][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0755 (0.0855)   Prec@1 97.656 (97.034)   Prec@5 100.000 (99.977)   [2019-11-22 04:30:21]
  Epoch: [115][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0798 (0.0853)   Prec@1 94.531 (97.015)   Prec@5 100.000 (99.982)   [2019-11-22 04:30:26]
  **Train** Prec@1 97.052 Prec@5 99.984 Error@1 2.948
  **Test** Prec@1 90.520 Prec@5 99.690 Error@1 9.480

==>>[2019-11-22 04:30:32] [Epoch=116/200] [Need: 00:30:44] [LR=0.0010][M=0.90] [Best : Accuracy=90.80, Error=9.20]
  Epoch: [116][000/391]   Time 0.232 (0.232)   Data 0.173 (0.173)   Loss 0.1444 (0.1444)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2019-11-22 04:30:32]
  Epoch: [116][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0651 (0.0740)   Prec@1 98.438 (97.447)   Prec@5 100.000 (99.969)   [2019-11-22 04:30:37]
  Epoch: [116][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0704 (0.0764)   Prec@1 95.312 (97.260)   Prec@5 100.000 (99.973)   [2019-11-22 04:30:43]
  Epoch: [116][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0377 (0.0773)   Prec@1 99.219 (97.267)   Prec@5 100.000 (99.977)   [2019-11-22 04:30:47]
  **Train** Prec@1 97.224 Prec@5 99.982 Error@1 2.776
  **Test** Prec@1 90.860 Prec@5 99.700 Error@1 9.140
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:30:54] [Epoch=117/200] [Need: 00:30:22] [LR=0.0010][M=0.90] [Best : Accuracy=90.86, Error=9.14]
  Epoch: [117][000/391]   Time 0.209 (0.209)   Data 0.155 (0.155)   Loss 0.0675 (0.0675)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:30:54]
  Epoch: [117][100/391]   Time 0.040 (0.051)   Data 0.000 (0.002)   Loss 0.0647 (0.0756)   Prec@1 98.438 (97.355)   Prec@5 100.000 (99.977)   [2019-11-22 04:30:59]
  Epoch: [117][200/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.0962 (0.0771)   Prec@1 97.656 (97.345)   Prec@5 100.000 (99.981)   [2019-11-22 04:31:04]
  Epoch: [117][300/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.1552 (0.0801)   Prec@1 94.531 (97.205)   Prec@5 100.000 (99.982)   [2019-11-22 04:31:10]
  **Train** Prec@1 97.230 Prec@5 99.976 Error@1 2.770
  **Test** Prec@1 90.630 Prec@5 99.730 Error@1 9.370

==>>[2019-11-22 04:31:16] [Epoch=118/200] [Need: 00:30:00] [LR=0.0010][M=0.90] [Best : Accuracy=90.86, Error=9.14]
  Epoch: [118][000/391]   Time 0.247 (0.247)   Data 0.166 (0.166)   Loss 0.0676 (0.0676)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:31:16]
  Epoch: [118][100/391]   Time 0.053 (0.057)   Data 0.000 (0.002)   Loss 0.0422 (0.0727)   Prec@1 98.438 (97.571)   Prec@5 100.000 (99.985)   [2019-11-22 04:31:22]
  Epoch: [118][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.0847 (0.0775)   Prec@1 96.094 (97.326)   Prec@5 100.000 (99.981)   [2019-11-22 04:31:27]
  Epoch: [118][300/391]   Time 0.042 (0.054)   Data 0.000 (0.001)   Loss 0.0762 (0.0768)   Prec@1 96.875 (97.308)   Prec@5 100.000 (99.982)   [2019-11-22 04:31:33]
  **Train** Prec@1 97.254 Prec@5 99.984 Error@1 2.746
  **Test** Prec@1 90.430 Prec@5 99.660 Error@1 9.570

==>>[2019-11-22 04:31:39] [Epoch=119/200] [Need: 00:29:38] [LR=0.0010][M=0.90] [Best : Accuracy=90.86, Error=9.14]
  Epoch: [119][000/391]   Time 0.213 (0.213)   Data 0.155 (0.155)   Loss 0.0374 (0.0374)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:31:39]
  Epoch: [119][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.1430 (0.0734)   Prec@1 95.312 (97.440)   Prec@5 100.000 (99.985)   [2019-11-22 04:31:44]
  Epoch: [119][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0389 (0.0760)   Prec@1 99.219 (97.264)   Prec@5 100.000 (99.988)   [2019-11-22 04:31:49]
  Epoch: [119][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0482 (0.0777)   Prec@1 97.656 (97.192)   Prec@5 100.000 (99.982)   [2019-11-22 04:31:55]
  **Train** Prec@1 97.250 Prec@5 99.984 Error@1 2.750
  **Test** Prec@1 90.470 Prec@5 99.710 Error@1 9.530

==>>[2019-11-22 04:32:01] [Epoch=120/200] [Need: 00:29:17] [LR=0.0001][M=0.90] [Best : Accuracy=90.86, Error=9.14]
  Epoch: [120][000/391]   Time 0.222 (0.222)   Data 0.164 (0.164)   Loss 0.0629 (0.0629)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:01]
  Epoch: [120][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0666 (0.0691)   Prec@1 97.656 (97.703)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:07]
  Epoch: [120][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.0339 (0.0676)   Prec@1 99.219 (97.718)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:12]
  Epoch: [120][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0181 (0.0676)   Prec@1 100.000 (97.648)   Prec@5 100.000 (99.997)   [2019-11-22 04:32:17]
  **Train** Prec@1 97.682 Prec@5 99.998 Error@1 2.318
  **Test** Prec@1 90.790 Prec@5 99.690 Error@1 9.210

==>>[2019-11-22 04:32:23] [Epoch=121/200] [Need: 00:28:55] [LR=0.0001][M=0.90] [Best : Accuracy=90.86, Error=9.14]
  Epoch: [121][000/391]   Time 0.232 (0.232)   Data 0.163 (0.163)   Loss 0.0592 (0.0592)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:24]
  Epoch: [121][100/391]   Time 0.059 (0.052)   Data 0.000 (0.002)   Loss 0.0741 (0.0670)   Prec@1 98.438 (97.679)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:29]
  Epoch: [121][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0796 (0.0634)   Prec@1 97.656 (97.808)   Prec@5 100.000 (99.996)   [2019-11-22 04:32:34]
  Epoch: [121][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.0944 (0.0623)   Prec@1 96.875 (97.900)   Prec@5 100.000 (99.990)   [2019-11-22 04:32:39]
  **Train** Prec@1 97.864 Prec@5 99.990 Error@1 2.136
  **Test** Prec@1 90.870 Prec@5 99.710 Error@1 9.130
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:32:45] [Epoch=122/200] [Need: 00:28:33] [LR=0.0001][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [122][000/391]   Time 0.226 (0.226)   Data 0.161 (0.161)   Loss 0.0778 (0.0778)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:32:45]
  Epoch: [122][100/391]   Time 0.046 (0.055)   Data 0.000 (0.002)   Loss 0.0633 (0.0659)   Prec@1 98.438 (97.741)   Prec@5 100.000 (99.992)   [2019-11-22 04:32:51]
  Epoch: [122][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0811 (0.0631)   Prec@1 95.312 (97.839)   Prec@5 100.000 (99.988)   [2019-11-22 04:32:56]
  Epoch: [122][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0441 (0.0605)   Prec@1 98.438 (97.952)   Prec@5 100.000 (99.992)   [2019-11-22 04:33:01]
  **Train** Prec@1 97.934 Prec@5 99.994 Error@1 2.066
  **Test** Prec@1 90.780 Prec@5 99.720 Error@1 9.220

==>>[2019-11-22 04:33:07] [Epoch=123/200] [Need: 00:28:11] [LR=0.0001][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [123][000/391]   Time 0.224 (0.224)   Data 0.154 (0.154)   Loss 0.0401 (0.0401)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:33:08]
  Epoch: [123][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0284 (0.0614)   Prec@1 98.438 (97.819)   Prec@5 100.000 (99.992)   [2019-11-22 04:33:13]
  Epoch: [123][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0427 (0.0617)   Prec@1 98.438 (97.847)   Prec@5 100.000 (99.988)   [2019-11-22 04:33:18]
  Epoch: [123][300/391]   Time 0.063 (0.050)   Data 0.000 (0.001)   Loss 0.0756 (0.0607)   Prec@1 96.875 (97.921)   Prec@5 100.000 (99.990)   [2019-11-22 04:33:23]
  **Train** Prec@1 97.922 Prec@5 99.990 Error@1 2.078
  **Test** Prec@1 90.890 Prec@5 99.740 Error@1 9.110
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:33:29] [Epoch=124/200] [Need: 00:27:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.89, Error=9.11]
  Epoch: [124][000/391]   Time 0.238 (0.238)   Data 0.171 (0.171)   Loss 0.0861 (0.0861)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:33:29]
  Epoch: [124][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.0272 (0.0579)   Prec@1 100.000 (97.896)   Prec@5 100.000 (100.000)   [2019-11-22 04:33:34]
  Epoch: [124][200/391]   Time 0.083 (0.052)   Data 0.000 (0.001)   Loss 0.0558 (0.0573)   Prec@1 97.656 (97.975)   Prec@5 100.000 (99.996)   [2019-11-22 04:33:39]
  Epoch: [124][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0770 (0.0589)   Prec@1 96.875 (97.939)   Prec@5 100.000 (99.992)   [2019-11-22 04:33:44]
  **Train** Prec@1 97.990 Prec@5 99.992 Error@1 2.010
  **Test** Prec@1 90.790 Prec@5 99.730 Error@1 9.210

==>>[2019-11-22 04:33:51] [Epoch=125/200] [Need: 00:27:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.89, Error=9.11]
  Epoch: [125][000/391]   Time 0.228 (0.228)   Data 0.171 (0.171)   Loss 0.0253 (0.0253)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:33:51]
  Epoch: [125][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0592 (0.0593)   Prec@1 96.875 (97.935)   Prec@5 100.000 (100.000)   [2019-11-22 04:33:56]
  Epoch: [125][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0326 (0.0575)   Prec@1 98.438 (98.022)   Prec@5 100.000 (100.000)   [2019-11-22 04:34:01]
  Epoch: [125][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0791 (0.0587)   Prec@1 97.656 (97.973)   Prec@5 100.000 (99.997)   [2019-11-22 04:34:06]
  **Train** Prec@1 97.974 Prec@5 99.996 Error@1 2.026
  **Test** Prec@1 90.890 Prec@5 99.710 Error@1 9.110
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:34:13] [Epoch=126/200] [Need: 00:27:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.89, Error=9.11]
  Epoch: [126][000/391]   Time 0.231 (0.231)   Data 0.163 (0.163)   Loss 0.0809 (0.0809)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:34:13]
  Epoch: [126][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.0754 (0.0599)   Prec@1 96.875 (98.004)   Prec@5 100.000 (99.992)   [2019-11-22 04:34:18]
  Epoch: [126][200/391]   Time 0.052 (0.055)   Data 0.000 (0.001)   Loss 0.0680 (0.0593)   Prec@1 96.094 (97.952)   Prec@5 100.000 (99.996)   [2019-11-22 04:34:24]
  Epoch: [126][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0237 (0.0594)   Prec@1 99.219 (97.973)   Prec@5 100.000 (99.992)   [2019-11-22 04:34:29]
  **Train** Prec@1 98.006 Prec@5 99.992 Error@1 1.994
  **Test** Prec@1 90.890 Prec@5 99.750 Error@1 9.110
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:34:35] [Epoch=127/200] [Need: 00:26:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.89, Error=9.11]
  Epoch: [127][000/391]   Time 0.242 (0.242)   Data 0.154 (0.154)   Loss 0.0843 (0.0843)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:34:36]
  Epoch: [127][100/391]   Time 0.078 (0.057)   Data 0.000 (0.002)   Loss 0.0431 (0.0576)   Prec@1 98.438 (97.981)   Prec@5 100.000 (100.000)   [2019-11-22 04:34:41]
  Epoch: [127][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0344 (0.0577)   Prec@1 99.219 (98.029)   Prec@5 100.000 (99.996)   [2019-11-22 04:34:46]
  Epoch: [127][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.1067 (0.0564)   Prec@1 93.750 (98.066)   Prec@5 100.000 (99.995)   [2019-11-22 04:34:51]
  **Train** Prec@1 98.084 Prec@5 99.988 Error@1 1.916
  **Test** Prec@1 90.960 Prec@5 99.730 Error@1 9.040
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:34:58] [Epoch=128/200] [Need: 00:26:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.96, Error=9.04]
  Epoch: [128][000/391]   Time 0.215 (0.215)   Data 0.153 (0.153)   Loss 0.1427 (0.1427)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:34:58]
  Epoch: [128][100/391]   Time 0.052 (0.057)   Data 0.000 (0.002)   Loss 0.1280 (0.0560)   Prec@1 96.094 (97.997)   Prec@5 100.000 (100.000)   [2019-11-22 04:35:04]
  Epoch: [128][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.0922 (0.0570)   Prec@1 96.094 (97.967)   Prec@5 100.000 (100.000)   [2019-11-22 04:35:09]
  Epoch: [128][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0426 (0.0566)   Prec@1 99.219 (98.027)   Prec@5 100.000 (100.000)   [2019-11-22 04:35:14]
  **Train** Prec@1 97.992 Prec@5 100.000 Error@1 2.008
  **Test** Prec@1 90.980 Prec@5 99.720 Error@1 9.020
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:35:20] [Epoch=129/200] [Need: 00:26:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [129][000/391]   Time 0.222 (0.222)   Data 0.144 (0.144)   Loss 0.0545 (0.0545)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:35:21]
  Epoch: [129][100/391]   Time 0.075 (0.050)   Data 0.000 (0.002)   Loss 0.0579 (0.0535)   Prec@1 98.438 (98.113)   Prec@5 100.000 (99.985)   [2019-11-22 04:35:25]
  Epoch: [129][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0210 (0.0555)   Prec@1 100.000 (98.053)   Prec@5 100.000 (99.992)   [2019-11-22 04:35:31]
  Epoch: [129][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0360 (0.0565)   Prec@1 99.219 (98.051)   Prec@5 100.000 (99.992)   [2019-11-22 04:35:36]
  **Train** Prec@1 98.006 Prec@5 99.990 Error@1 1.994
  **Test** Prec@1 90.800 Prec@5 99.730 Error@1 9.200

==>>[2019-11-22 04:35:42] [Epoch=130/200] [Need: 00:25:38] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [130][000/391]   Time 0.245 (0.245)   Data 0.165 (0.165)   Loss 0.0693 (0.0693)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:35:43]
  Epoch: [130][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0420 (0.0530)   Prec@1 97.656 (98.105)   Prec@5 100.000 (99.977)   [2019-11-22 04:35:48]
  Epoch: [130][200/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0291 (0.0540)   Prec@1 100.000 (98.146)   Prec@5 100.000 (99.984)   [2019-11-22 04:35:53]
  Epoch: [130][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0347 (0.0548)   Prec@1 99.219 (98.142)   Prec@5 100.000 (99.984)   [2019-11-22 04:35:58]
  **Train** Prec@1 98.084 Prec@5 99.988 Error@1 1.916
  **Test** Prec@1 90.880 Prec@5 99.710 Error@1 9.120

==>>[2019-11-22 04:36:04] [Epoch=131/200] [Need: 00:25:16] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [131][000/391]   Time 0.227 (0.227)   Data 0.153 (0.153)   Loss 0.0619 (0.0619)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:36:05]
  Epoch: [131][100/391]   Time 0.071 (0.051)   Data 0.000 (0.002)   Loss 0.0353 (0.0562)   Prec@1 99.219 (98.097)   Prec@5 100.000 (99.985)   [2019-11-22 04:36:10]
  Epoch: [131][200/391]   Time 0.053 (0.051)   Data 0.004 (0.001)   Loss 0.0296 (0.0575)   Prec@1 99.219 (98.092)   Prec@5 100.000 (99.988)   [2019-11-22 04:36:15]
  Epoch: [131][300/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.1313 (0.0558)   Prec@1 95.312 (98.131)   Prec@5 100.000 (99.987)   [2019-11-22 04:36:20]
  **Train** Prec@1 98.150 Prec@5 99.990 Error@1 1.850
  **Test** Prec@1 90.760 Prec@5 99.750 Error@1 9.240

==>>[2019-11-22 04:36:26] [Epoch=132/200] [Need: 00:24:54] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [132][000/391]   Time 0.238 (0.238)   Data 0.180 (0.180)   Loss 0.0306 (0.0306)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:36:26]
  Epoch: [132][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0397 (0.0523)   Prec@1 98.438 (98.221)   Prec@5 100.000 (99.992)   [2019-11-22 04:36:32]
  Epoch: [132][200/391]   Time 0.048 (0.052)   Data 0.000 (0.001)   Loss 0.0921 (0.0529)   Prec@1 95.312 (98.220)   Prec@5 100.000 (99.996)   [2019-11-22 04:36:37]
  Epoch: [132][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0523 (0.0536)   Prec@1 99.219 (98.149)   Prec@5 100.000 (99.997)   [2019-11-22 04:36:42]
  **Train** Prec@1 98.134 Prec@5 99.996 Error@1 1.866
  **Test** Prec@1 90.880 Prec@5 99.740 Error@1 9.120

==>>[2019-11-22 04:36:48] [Epoch=133/200] [Need: 00:24:32] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [133][000/391]   Time 0.227 (0.227)   Data 0.161 (0.161)   Loss 0.0358 (0.0358)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:36:48]
  Epoch: [133][100/391]   Time 0.056 (0.055)   Data 0.000 (0.002)   Loss 0.0287 (0.0530)   Prec@1 99.219 (98.205)   Prec@5 100.000 (99.992)   [2019-11-22 04:36:54]
  Epoch: [133][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0295 (0.0547)   Prec@1 99.219 (98.154)   Prec@5 100.000 (99.992)   [2019-11-22 04:36:59]
  Epoch: [133][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0276 (0.0539)   Prec@1 99.219 (98.168)   Prec@5 100.000 (99.992)   [2019-11-22 04:37:04]
  **Train** Prec@1 98.146 Prec@5 99.990 Error@1 1.854
  **Test** Prec@1 90.830 Prec@5 99.720 Error@1 9.170

==>>[2019-11-22 04:37:10] [Epoch=134/200] [Need: 00:24:10] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [134][000/391]   Time 0.236 (0.236)   Data 0.170 (0.170)   Loss 0.0318 (0.0318)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:11]
  Epoch: [134][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0512 (0.0560)   Prec@1 98.438 (98.089)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:16]
  Epoch: [134][200/391]   Time 0.031 (0.051)   Data 0.000 (0.001)   Loss 0.0464 (0.0548)   Prec@1 97.656 (98.142)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:21]
  Epoch: [134][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0617 (0.0546)   Prec@1 97.656 (98.147)   Prec@5 100.000 (99.997)   [2019-11-22 04:37:26]
  **Train** Prec@1 98.168 Prec@5 99.998 Error@1 1.832
  **Test** Prec@1 90.900 Prec@5 99.730 Error@1 9.100

==>>[2019-11-22 04:37:32] [Epoch=135/200] [Need: 00:23:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [135][000/391]   Time 0.221 (0.221)   Data 0.152 (0.152)   Loss 0.0476 (0.0476)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:33]
  Epoch: [135][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.0482 (0.0513)   Prec@1 98.438 (98.275)   Prec@5 100.000 (99.992)   [2019-11-22 04:37:37]
  Epoch: [135][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.0512 (0.0509)   Prec@1 98.438 (98.313)   Prec@5 100.000 (99.992)   [2019-11-22 04:37:43]
  Epoch: [135][300/391]   Time 0.060 (0.050)   Data 0.000 (0.001)   Loss 0.0292 (0.0528)   Prec@1 99.219 (98.230)   Prec@5 100.000 (99.990)   [2019-11-22 04:37:47]
  **Train** Prec@1 98.238 Prec@5 99.990 Error@1 1.762
  **Test** Prec@1 90.820 Prec@5 99.680 Error@1 9.180

==>>[2019-11-22 04:37:54] [Epoch=136/200] [Need: 00:23:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [136][000/391]   Time 0.230 (0.230)   Data 0.163 (0.163)   Loss 0.1039 (0.1039)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:54]
  Epoch: [136][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0534 (0.0544)   Prec@1 97.656 (98.113)   Prec@5 100.000 (100.000)   [2019-11-22 04:37:59]
  Epoch: [136][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0190 (0.0526)   Prec@1 100.000 (98.193)   Prec@5 100.000 (99.996)   [2019-11-22 04:38:04]
  Epoch: [136][300/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.0238 (0.0522)   Prec@1 100.000 (98.245)   Prec@5 100.000 (99.997)   [2019-11-22 04:38:09]
  **Train** Prec@1 98.200 Prec@5 99.998 Error@1 1.800
  **Test** Prec@1 90.840 Prec@5 99.710 Error@1 9.160

==>>[2019-11-22 04:38:15] [Epoch=137/200] [Need: 00:23:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [137][000/391]   Time 0.249 (0.249)   Data 0.191 (0.191)   Loss 0.0647 (0.0647)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:38:16]
  Epoch: [137][100/391]   Time 0.047 (0.057)   Data 0.000 (0.002)   Loss 0.0493 (0.0538)   Prec@1 99.219 (98.236)   Prec@5 100.000 (99.992)   [2019-11-22 04:38:21]
  Epoch: [137][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0635 (0.0522)   Prec@1 98.438 (98.255)   Prec@5 100.000 (99.988)   [2019-11-22 04:38:26]
  Epoch: [137][300/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0218 (0.0542)   Prec@1 99.219 (98.183)   Prec@5 100.000 (99.992)   [2019-11-22 04:38:31]
  **Train** Prec@1 98.168 Prec@5 99.990 Error@1 1.832
  **Test** Prec@1 90.920 Prec@5 99.760 Error@1 9.080

==>>[2019-11-22 04:38:38] [Epoch=138/200] [Need: 00:22:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [138][000/391]   Time 0.223 (0.223)   Data 0.156 (0.156)   Loss 0.0914 (0.0914)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:38:38]
  Epoch: [138][100/391]   Time 0.053 (0.053)   Data 0.000 (0.002)   Loss 0.0427 (0.0540)   Prec@1 99.219 (98.190)   Prec@5 100.000 (99.992)   [2019-11-22 04:38:43]
  Epoch: [138][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0653 (0.0532)   Prec@1 96.875 (98.208)   Prec@5 100.000 (99.996)   [2019-11-22 04:38:48]
  Epoch: [138][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0862 (0.0528)   Prec@1 96.875 (98.178)   Prec@5 100.000 (99.997)   [2019-11-22 04:38:53]
  **Train** Prec@1 98.192 Prec@5 99.996 Error@1 1.808
  **Test** Prec@1 90.960 Prec@5 99.770 Error@1 9.040

==>>[2019-11-22 04:39:00] [Epoch=139/200] [Need: 00:22:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.98, Error=9.02]
  Epoch: [139][000/391]   Time 0.229 (0.229)   Data 0.173 (0.173)   Loss 0.0367 (0.0367)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:39:00]
  Epoch: [139][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0364 (0.0498)   Prec@1 99.219 (98.252)   Prec@5 100.000 (99.992)   [2019-11-22 04:39:05]
  Epoch: [139][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0600 (0.0530)   Prec@1 97.656 (98.076)   Prec@5 100.000 (99.992)   [2019-11-22 04:39:10]
  Epoch: [139][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0352 (0.0520)   Prec@1 99.219 (98.139)   Prec@5 100.000 (99.995)   [2019-11-22 04:39:15]
  **Train** Prec@1 98.158 Prec@5 99.996 Error@1 1.842
  **Test** Prec@1 91.000 Prec@5 99.730 Error@1 9.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:39:22] [Epoch=140/200] [Need: 00:21:58] [LR=0.0001][M=0.90] [Best : Accuracy=91.00, Error=9.00]
  Epoch: [140][000/391]   Time 0.228 (0.228)   Data 0.158 (0.158)   Loss 0.0544 (0.0544)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:39:22]
  Epoch: [140][100/391]   Time 0.052 (0.049)   Data 0.000 (0.002)   Loss 0.0126 (0.0516)   Prec@1 100.000 (98.329)   Prec@5 100.000 (99.977)   [2019-11-22 04:39:27]
  Epoch: [140][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0320 (0.0509)   Prec@1 100.000 (98.294)   Prec@5 100.000 (99.977)   [2019-11-22 04:39:32]
  Epoch: [140][300/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.0259 (0.0512)   Prec@1 98.438 (98.269)   Prec@5 100.000 (99.977)   [2019-11-22 04:39:37]
  **Train** Prec@1 98.270 Prec@5 99.980 Error@1 1.730
  **Test** Prec@1 90.880 Prec@5 99.730 Error@1 9.120

==>>[2019-11-22 04:39:43] [Epoch=141/200] [Need: 00:21:36] [LR=0.0001][M=0.90] [Best : Accuracy=91.00, Error=9.00]
  Epoch: [141][000/391]   Time 0.250 (0.250)   Data 0.153 (0.153)   Loss 0.1133 (0.1133)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:39:44]
  Epoch: [141][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0513 (0.0509)   Prec@1 97.656 (98.205)   Prec@5 100.000 (99.992)   [2019-11-22 04:39:49]
  Epoch: [141][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0919 (0.0527)   Prec@1 98.438 (98.154)   Prec@5 100.000 (99.992)   [2019-11-22 04:39:54]
  Epoch: [141][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0382 (0.0529)   Prec@1 98.438 (98.126)   Prec@5 100.000 (99.992)   [2019-11-22 04:39:59]
  **Train** Prec@1 98.144 Prec@5 99.990 Error@1 1.856
  **Test** Prec@1 91.020 Prec@5 99.760 Error@1 8.980
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:40:05] [Epoch=142/200] [Need: 00:21:14] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [142][000/391]   Time 0.234 (0.234)   Data 0.179 (0.179)   Loss 0.0634 (0.0634)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 04:40:06]
  Epoch: [142][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0831 (0.0543)   Prec@1 97.656 (98.175)   Prec@5 100.000 (99.985)   [2019-11-22 04:40:11]
  Epoch: [142][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0446 (0.0513)   Prec@1 98.438 (98.239)   Prec@5 100.000 (99.988)   [2019-11-22 04:40:16]
  Epoch: [142][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0323 (0.0521)   Prec@1 99.219 (98.160)   Prec@5 100.000 (99.992)   [2019-11-22 04:40:21]
  **Train** Prec@1 98.166 Prec@5 99.994 Error@1 1.834
  **Test** Prec@1 90.880 Prec@5 99.710 Error@1 9.120

==>>[2019-11-22 04:40:27] [Epoch=143/200] [Need: 00:20:52] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [143][000/391]   Time 0.242 (0.242)   Data 0.165 (0.165)   Loss 0.0546 (0.0546)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:40:27]
  Epoch: [143][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0338 (0.0516)   Prec@1 98.438 (98.213)   Prec@5 100.000 (99.992)   [2019-11-22 04:40:32]
  Epoch: [143][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0804 (0.0504)   Prec@1 97.656 (98.243)   Prec@5 100.000 (99.992)   [2019-11-22 04:40:37]
  Epoch: [143][300/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.0419 (0.0500)   Prec@1 99.219 (98.316)   Prec@5 100.000 (99.995)   [2019-11-22 04:40:43]
  **Train** Prec@1 98.300 Prec@5 99.996 Error@1 1.700
  **Test** Prec@1 90.880 Prec@5 99.720 Error@1 9.120

==>>[2019-11-22 04:40:49] [Epoch=144/200] [Need: 00:20:30] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [144][000/391]   Time 0.232 (0.232)   Data 0.158 (0.158)   Loss 0.0216 (0.0216)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:40:50]
  Epoch: [144][100/391]   Time 0.057 (0.055)   Data 0.000 (0.002)   Loss 0.0771 (0.0528)   Prec@1 97.656 (98.329)   Prec@5 100.000 (100.000)   [2019-11-22 04:40:55]
  Epoch: [144][200/391]   Time 0.061 (0.053)   Data 0.000 (0.001)   Loss 0.0180 (0.0518)   Prec@1 99.219 (98.348)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:00]
  Epoch: [144][300/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0441 (0.0514)   Prec@1 98.438 (98.328)   Prec@5 100.000 (99.995)   [2019-11-22 04:41:05]
  **Train** Prec@1 98.308 Prec@5 99.996 Error@1 1.692
  **Test** Prec@1 90.920 Prec@5 99.740 Error@1 9.080

==>>[2019-11-22 04:41:12] [Epoch=145/200] [Need: 00:20:08] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [145][000/391]   Time 0.242 (0.242)   Data 0.181 (0.181)   Loss 0.0673 (0.0673)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:12]
  Epoch: [145][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0616 (0.0497)   Prec@1 98.438 (98.345)   Prec@5 100.000 (99.992)   [2019-11-22 04:41:17]
  Epoch: [145][200/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.0425 (0.0484)   Prec@1 98.438 (98.379)   Prec@5 100.000 (99.996)   [2019-11-22 04:41:22]
  Epoch: [145][300/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.0384 (0.0495)   Prec@1 97.656 (98.321)   Prec@5 100.000 (99.992)   [2019-11-22 04:41:27]
  **Train** Prec@1 98.258 Prec@5 99.994 Error@1 1.742
  **Test** Prec@1 90.770 Prec@5 99.700 Error@1 9.230

==>>[2019-11-22 04:41:34] [Epoch=146/200] [Need: 00:19:46] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [146][000/391]   Time 0.233 (0.233)   Data 0.167 (0.167)   Loss 0.0278 (0.0278)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:34]
  Epoch: [146][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.0279 (0.0484)   Prec@1 99.219 (98.345)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:40]
  Epoch: [146][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0576 (0.0495)   Prec@1 98.438 (98.333)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:44]
  Epoch: [146][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0834 (0.0494)   Prec@1 96.875 (98.339)   Prec@5 100.000 (99.997)   [2019-11-22 04:41:49]
  **Train** Prec@1 98.370 Prec@5 99.994 Error@1 1.630
  **Test** Prec@1 90.800 Prec@5 99.730 Error@1 9.200

==>>[2019-11-22 04:41:56] [Epoch=147/200] [Need: 00:19:24] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [147][000/391]   Time 0.239 (0.239)   Data 0.152 (0.152)   Loss 0.0273 (0.0273)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:41:56]
  Epoch: [147][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.0530 (0.0478)   Prec@1 97.656 (98.306)   Prec@5 100.000 (100.000)   [2019-11-22 04:42:01]
  Epoch: [147][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.0555 (0.0502)   Prec@1 98.438 (98.247)   Prec@5 100.000 (99.988)   [2019-11-22 04:42:07]
  Epoch: [147][300/391]   Time 0.070 (0.052)   Data 0.000 (0.001)   Loss 0.0891 (0.0492)   Prec@1 97.656 (98.287)   Prec@5 100.000 (99.990)   [2019-11-22 04:42:11]
  **Train** Prec@1 98.268 Prec@5 99.990 Error@1 1.732
  **Test** Prec@1 90.860 Prec@5 99.730 Error@1 9.140

==>>[2019-11-22 04:42:18] [Epoch=148/200] [Need: 00:19:02] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [148][000/391]   Time 0.225 (0.225)   Data 0.161 (0.161)   Loss 0.0207 (0.0207)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:42:18]
  Epoch: [148][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.0489 (0.0468)   Prec@1 99.219 (98.445)   Prec@5 100.000 (99.985)   [2019-11-22 04:42:24]
  Epoch: [148][200/391]   Time 0.042 (0.055)   Data 0.000 (0.001)   Loss 0.0367 (0.0477)   Prec@1 99.219 (98.371)   Prec@5 100.000 (99.992)   [2019-11-22 04:42:29]
  Epoch: [148][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0770 (0.0480)   Prec@1 96.875 (98.352)   Prec@5 100.000 (99.995)   [2019-11-22 04:42:34]
  **Train** Prec@1 98.316 Prec@5 99.992 Error@1 1.684
  **Test** Prec@1 90.820 Prec@5 99.730 Error@1 9.180

==>>[2019-11-22 04:42:41] [Epoch=149/200] [Need: 00:18:41] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [149][000/391]   Time 0.234 (0.234)   Data 0.178 (0.178)   Loss 0.0707 (0.0707)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:42:41]
  Epoch: [149][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0617 (0.0494)   Prec@1 96.875 (98.407)   Prec@5 100.000 (99.985)   [2019-11-22 04:42:46]
  Epoch: [149][200/391]   Time 0.052 (0.052)   Data 0.000 (0.001)   Loss 0.0272 (0.0502)   Prec@1 99.219 (98.301)   Prec@5 100.000 (99.992)   [2019-11-22 04:42:51]
  Epoch: [149][300/391]   Time 0.064 (0.052)   Data 0.000 (0.001)   Loss 0.0729 (0.0494)   Prec@1 97.656 (98.357)   Prec@5 100.000 (99.995)   [2019-11-22 04:42:56]
  **Train** Prec@1 98.366 Prec@5 99.994 Error@1 1.634
  **Test** Prec@1 90.790 Prec@5 99.730 Error@1 9.210

==>>[2019-11-22 04:43:03] [Epoch=150/200] [Need: 00:18:19] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [150][000/391]   Time 0.229 (0.229)   Data 0.167 (0.167)   Loss 0.0418 (0.0418)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:43:04]
  Epoch: [150][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0420 (0.0492)   Prec@1 98.438 (98.283)   Prec@5 100.000 (100.000)   [2019-11-22 04:43:09]
  Epoch: [150][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0414 (0.0502)   Prec@1 99.219 (98.235)   Prec@5 100.000 (99.996)   [2019-11-22 04:43:14]
  Epoch: [150][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0845 (0.0503)   Prec@1 96.875 (98.214)   Prec@5 100.000 (99.995)   [2019-11-22 04:43:19]
  **Train** Prec@1 98.182 Prec@5 99.994 Error@1 1.818
  **Test** Prec@1 90.900 Prec@5 99.720 Error@1 9.100

==>>[2019-11-22 04:43:26] [Epoch=151/200] [Need: 00:17:57] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [151][000/391]   Time 0.233 (0.233)   Data 0.174 (0.174)   Loss 0.0698 (0.0698)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 04:43:26]
  Epoch: [151][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0598 (0.0488)   Prec@1 97.656 (98.275)   Prec@5 100.000 (100.000)   [2019-11-22 04:43:31]
  Epoch: [151][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0273 (0.0480)   Prec@1 100.000 (98.364)   Prec@5 100.000 (99.996)   [2019-11-22 04:43:36]
  Epoch: [151][300/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.0104 (0.0486)   Prec@1 100.000 (98.341)   Prec@5 100.000 (99.997)   [2019-11-22 04:43:42]
  **Train** Prec@1 98.356 Prec@5 99.998 Error@1 1.644
  **Test** Prec@1 90.980 Prec@5 99.690 Error@1 9.020

==>>[2019-11-22 04:43:48] [Epoch=152/200] [Need: 00:17:35] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [152][000/391]   Time 0.226 (0.226)   Data 0.171 (0.171)   Loss 0.0596 (0.0596)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:43:48]
  Epoch: [152][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.0538 (0.0476)   Prec@1 97.656 (98.507)   Prec@5 100.000 (99.992)   [2019-11-22 04:43:53]
  Epoch: [152][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0556 (0.0490)   Prec@1 98.438 (98.371)   Prec@5 100.000 (99.996)   [2019-11-22 04:43:58]
  Epoch: [152][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0677 (0.0487)   Prec@1 97.656 (98.354)   Prec@5 100.000 (99.995)   [2019-11-22 04:44:03]
  **Train** Prec@1 98.368 Prec@5 99.996 Error@1 1.632
  **Test** Prec@1 90.850 Prec@5 99.720 Error@1 9.150

==>>[2019-11-22 04:44:10] [Epoch=153/200] [Need: 00:17:13] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [153][000/391]   Time 0.229 (0.229)   Data 0.155 (0.155)   Loss 0.0536 (0.0536)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:44:10]
  Epoch: [153][100/391]   Time 0.083 (0.053)   Data 0.000 (0.002)   Loss 0.0299 (0.0463)   Prec@1 99.219 (98.391)   Prec@5 100.000 (99.992)   [2019-11-22 04:44:15]
  Epoch: [153][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0226 (0.0465)   Prec@1 99.219 (98.438)   Prec@5 100.000 (99.992)   [2019-11-22 04:44:21]
  Epoch: [153][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0347 (0.0462)   Prec@1 98.438 (98.453)   Prec@5 100.000 (99.995)   [2019-11-22 04:44:26]
  **Train** Prec@1 98.472 Prec@5 99.996 Error@1 1.528
  **Test** Prec@1 90.980 Prec@5 99.690 Error@1 9.020

==>>[2019-11-22 04:44:32] [Epoch=154/200] [Need: 00:16:51] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [154][000/391]   Time 0.236 (0.236)   Data 0.157 (0.157)   Loss 0.0155 (0.0155)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:44:32]
  Epoch: [154][100/391]   Time 0.049 (0.054)   Data 0.000 (0.002)   Loss 0.0360 (0.0476)   Prec@1 99.219 (98.445)   Prec@5 100.000 (100.000)   [2019-11-22 04:44:37]
  Epoch: [154][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0840 (0.0485)   Prec@1 96.094 (98.360)   Prec@5 100.000 (99.992)   [2019-11-22 04:44:42]
  Epoch: [154][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0949 (0.0492)   Prec@1 96.875 (98.347)   Prec@5 100.000 (99.995)   [2019-11-22 04:44:47]
  **Train** Prec@1 98.366 Prec@5 99.992 Error@1 1.634
  **Test** Prec@1 90.800 Prec@5 99.700 Error@1 9.200

==>>[2019-11-22 04:44:54] [Epoch=155/200] [Need: 00:16:29] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [155][000/391]   Time 0.247 (0.247)   Data 0.190 (0.190)   Loss 0.0467 (0.0467)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:44:54]
  Epoch: [155][100/391]   Time 0.055 (0.054)   Data 0.000 (0.002)   Loss 0.0819 (0.0460)   Prec@1 97.656 (98.484)   Prec@5 100.000 (100.000)   [2019-11-22 04:44:59]
  Epoch: [155][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.0430 (0.0471)   Prec@1 98.438 (98.449)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:04]
  Epoch: [155][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0618 (0.0471)   Prec@1 96.875 (98.445)   Prec@5 100.000 (99.997)   [2019-11-22 04:45:09]
  **Train** Prec@1 98.386 Prec@5 99.996 Error@1 1.614
  **Test** Prec@1 90.980 Prec@5 99.700 Error@1 9.020

==>>[2019-11-22 04:45:16] [Epoch=156/200] [Need: 00:16:07] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [156][000/391]   Time 0.228 (0.228)   Data 0.149 (0.149)   Loss 0.0421 (0.0421)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:16]
  Epoch: [156][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0890 (0.0451)   Prec@1 96.094 (98.461)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:21]
  Epoch: [156][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0286 (0.0456)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:26]
  Epoch: [156][300/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0186 (0.0455)   Prec@1 99.219 (98.458)   Prec@5 100.000 (99.997)   [2019-11-22 04:45:31]
  **Train** Prec@1 98.448 Prec@5 99.994 Error@1 1.552
  **Test** Prec@1 90.830 Prec@5 99.730 Error@1 9.170

==>>[2019-11-22 04:45:37] [Epoch=157/200] [Need: 00:15:45] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [157][000/391]   Time 0.223 (0.223)   Data 0.143 (0.143)   Loss 0.0351 (0.0351)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:38]
  Epoch: [157][100/391]   Time 0.071 (0.054)   Data 0.000 (0.002)   Loss 0.0266 (0.0488)   Prec@1 99.219 (98.414)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:43]
  Epoch: [157][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0507 (0.0491)   Prec@1 99.219 (98.344)   Prec@5 100.000 (99.996)   [2019-11-22 04:45:47]
  Epoch: [157][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0508 (0.0468)   Prec@1 96.875 (98.458)   Prec@5 100.000 (99.997)   [2019-11-22 04:45:52]
  **Train** Prec@1 98.404 Prec@5 99.998 Error@1 1.596
  **Test** Prec@1 90.930 Prec@5 99.680 Error@1 9.070

==>>[2019-11-22 04:45:59] [Epoch=158/200] [Need: 00:15:23] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [158][000/391]   Time 0.253 (0.253)   Data 0.181 (0.181)   Loss 0.0455 (0.0455)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:45:59]
  Epoch: [158][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.1450 (0.0501)   Prec@1 95.312 (98.221)   Prec@5 100.000 (100.000)   [2019-11-22 04:46:04]
  Epoch: [158][200/391]   Time 0.083 (0.053)   Data 0.000 (0.001)   Loss 0.0373 (0.0489)   Prec@1 98.438 (98.333)   Prec@5 100.000 (99.996)   [2019-11-22 04:46:09]
  Epoch: [158][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.1302 (0.0485)   Prec@1 93.750 (98.316)   Prec@5 100.000 (99.997)   [2019-11-22 04:46:14]
  **Train** Prec@1 98.334 Prec@5 99.998 Error@1 1.666
  **Test** Prec@1 90.880 Prec@5 99.750 Error@1 9.120

==>>[2019-11-22 04:46:21] [Epoch=159/200] [Need: 00:15:01] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [159][000/391]   Time 0.236 (0.236)   Data 0.175 (0.175)   Loss 0.0595 (0.0595)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:46:21]
  Epoch: [159][100/391]   Time 0.040 (0.053)   Data 0.000 (0.002)   Loss 0.0492 (0.0475)   Prec@1 99.219 (98.407)   Prec@5 100.000 (100.000)   [2019-11-22 04:46:26]
  Epoch: [159][200/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.0643 (0.0469)   Prec@1 97.656 (98.461)   Prec@5 100.000 (99.988)   [2019-11-22 04:46:31]
  Epoch: [159][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.0225 (0.0470)   Prec@1 99.219 (98.456)   Prec@5 100.000 (99.992)   [2019-11-22 04:46:37]
  **Train** Prec@1 98.428 Prec@5 99.990 Error@1 1.572
  **Test** Prec@1 90.860 Prec@5 99.740 Error@1 9.140

==>>[2019-11-22 04:46:43] [Epoch=160/200] [Need: 00:14:39] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [160][000/391]   Time 0.219 (0.219)   Data 0.158 (0.158)   Loss 0.0239 (0.0239)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:46:43]
  Epoch: [160][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0223 (0.0463)   Prec@1 99.219 (98.530)   Prec@5 100.000 (100.000)   [2019-11-22 04:46:48]
  Epoch: [160][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0484 (0.0465)   Prec@1 96.875 (98.476)   Prec@5 100.000 (99.988)   [2019-11-22 04:46:53]
  Epoch: [160][300/391]   Time 0.053 (0.049)   Data 0.000 (0.001)   Loss 0.0270 (0.0449)   Prec@1 100.000 (98.523)   Prec@5 100.000 (99.990)   [2019-11-22 04:46:58]
  **Train** Prec@1 98.474 Prec@5 99.992 Error@1 1.526
  **Test** Prec@1 90.840 Prec@5 99.680 Error@1 9.160

==>>[2019-11-22 04:47:05] [Epoch=161/200] [Need: 00:14:17] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [161][000/391]   Time 0.223 (0.223)   Data 0.164 (0.164)   Loss 0.0408 (0.0408)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:05]
  Epoch: [161][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0716 (0.0480)   Prec@1 97.656 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:10]
  Epoch: [161][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0288 (0.0468)   Prec@1 99.219 (98.465)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:15]
  Epoch: [161][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0757 (0.0474)   Prec@1 97.656 (98.404)   Prec@5 100.000 (99.997)   [2019-11-22 04:47:20]
  **Train** Prec@1 98.346 Prec@5 99.994 Error@1 1.654
  **Test** Prec@1 91.010 Prec@5 99.740 Error@1 8.990

==>>[2019-11-22 04:47:27] [Epoch=162/200] [Need: 00:13:55] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [162][000/391]   Time 0.233 (0.233)   Data 0.165 (0.165)   Loss 0.0377 (0.0377)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:27]
  Epoch: [162][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.0389 (0.0465)   Prec@1 98.438 (98.407)   Prec@5 100.000 (99.992)   [2019-11-22 04:47:32]
  Epoch: [162][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0466 (0.0464)   Prec@1 98.438 (98.430)   Prec@5 100.000 (99.996)   [2019-11-22 04:47:36]
  Epoch: [162][300/391]   Time 0.045 (0.048)   Data 0.000 (0.001)   Loss 0.0644 (0.0458)   Prec@1 97.656 (98.427)   Prec@5 100.000 (99.997)   [2019-11-22 04:47:41]
  **Train** Prec@1 98.440 Prec@5 99.994 Error@1 1.560
  **Test** Prec@1 90.930 Prec@5 99.720 Error@1 9.070

==>>[2019-11-22 04:47:48] [Epoch=163/200] [Need: 00:13:33] [LR=0.0001][M=0.90] [Best : Accuracy=91.02, Error=8.98]
  Epoch: [163][000/391]   Time 0.238 (0.238)   Data 0.165 (0.165)   Loss 0.0605 (0.0605)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:48]
  Epoch: [163][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.0443 (0.0450)   Prec@1 97.656 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:53]
  Epoch: [163][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0964 (0.0470)   Prec@1 96.094 (98.325)   Prec@5 100.000 (100.000)   [2019-11-22 04:47:58]
  Epoch: [163][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0271 (0.0464)   Prec@1 99.219 (98.370)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:03]
  **Train** Prec@1 98.376 Prec@5 100.000 Error@1 1.624
  **Test** Prec@1 91.050 Prec@5 99.710 Error@1 8.950
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:48:09] [Epoch=164/200] [Need: 00:13:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [164][000/391]   Time 0.225 (0.225)   Data 0.165 (0.165)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:10]
  Epoch: [164][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0247 (0.0513)   Prec@1 99.219 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:15]
  Epoch: [164][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.0504 (0.0484)   Prec@1 96.875 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:20]
  Epoch: [164][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0568 (0.0471)   Prec@1 98.438 (98.401)   Prec@5 100.000 (99.995)   [2019-11-22 04:48:25]
  **Train** Prec@1 98.382 Prec@5 99.996 Error@1 1.618
  **Test** Prec@1 90.850 Prec@5 99.760 Error@1 9.150

==>>[2019-11-22 04:48:32] [Epoch=165/200] [Need: 00:12:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [165][000/391]   Time 0.221 (0.221)   Data 0.151 (0.151)   Loss 0.0545 (0.0545)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:32]
  Epoch: [165][100/391]   Time 0.053 (0.055)   Data 0.000 (0.002)   Loss 0.0284 (0.0479)   Prec@1 99.219 (98.321)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:37]
  Epoch: [165][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0343 (0.0484)   Prec@1 99.219 (98.368)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:42]
  Epoch: [165][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0306 (0.0465)   Prec@1 99.219 (98.406)   Prec@5 100.000 (99.997)   [2019-11-22 04:48:47]
  **Train** Prec@1 98.408 Prec@5 99.994 Error@1 1.592
  **Test** Prec@1 90.870 Prec@5 99.700 Error@1 9.130

==>>[2019-11-22 04:48:54] [Epoch=166/200] [Need: 00:12:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [166][000/391]   Time 0.237 (0.237)   Data 0.178 (0.178)   Loss 0.0397 (0.0397)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:54]
  Epoch: [166][100/391]   Time 0.050 (0.054)   Data 0.000 (0.002)   Loss 0.0460 (0.0443)   Prec@1 97.656 (98.561)   Prec@5 100.000 (100.000)   [2019-11-22 04:48:59]
  Epoch: [166][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0104 (0.0451)   Prec@1 100.000 (98.476)   Prec@5 100.000 (100.000)   [2019-11-22 04:49:04]
  Epoch: [166][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0161 (0.0473)   Prec@1 99.219 (98.409)   Prec@5 100.000 (99.995)   [2019-11-22 04:49:09]
  **Train** Prec@1 98.456 Prec@5 99.996 Error@1 1.544
  **Test** Prec@1 90.900 Prec@5 99.710 Error@1 9.100

==>>[2019-11-22 04:49:16] [Epoch=167/200] [Need: 00:12:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [167][000/391]   Time 0.226 (0.226)   Data 0.150 (0.150)   Loss 0.0500 (0.0500)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:49:16]
  Epoch: [167][100/391]   Time 0.059 (0.054)   Data 0.000 (0.002)   Loss 0.0202 (0.0461)   Prec@1 100.000 (98.453)   Prec@5 100.000 (100.000)   [2019-11-22 04:49:21]
  Epoch: [167][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.0374 (0.0455)   Prec@1 100.000 (98.527)   Prec@5 100.000 (99.992)   [2019-11-22 04:49:26]
  Epoch: [167][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0189 (0.0465)   Prec@1 100.000 (98.476)   Prec@5 100.000 (99.990)   [2019-11-22 04:49:31]
  **Train** Prec@1 98.448 Prec@5 99.992 Error@1 1.552
  **Test** Prec@1 90.850 Prec@5 99.710 Error@1 9.150

==>>[2019-11-22 04:49:38] [Epoch=168/200] [Need: 00:11:43] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [168][000/391]   Time 0.236 (0.236)   Data 0.176 (0.176)   Loss 0.0548 (0.0548)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:49:38]
  Epoch: [168][100/391]   Time 0.079 (0.057)   Data 0.000 (0.002)   Loss 0.0385 (0.0445)   Prec@1 99.219 (98.453)   Prec@5 100.000 (100.000)   [2019-11-22 04:49:44]
  Epoch: [168][200/391]   Time 0.045 (0.055)   Data 0.000 (0.001)   Loss 0.0131 (0.0445)   Prec@1 100.000 (98.469)   Prec@5 100.000 (99.996)   [2019-11-22 04:49:49]
  Epoch: [168][300/391]   Time 0.071 (0.053)   Data 0.000 (0.001)   Loss 0.0234 (0.0442)   Prec@1 99.219 (98.552)   Prec@5 100.000 (99.997)   [2019-11-22 04:49:54]
  **Train** Prec@1 98.532 Prec@5 99.998 Error@1 1.468
  **Test** Prec@1 90.960 Prec@5 99.710 Error@1 9.040

==>>[2019-11-22 04:50:01] [Epoch=169/200] [Need: 00:11:21] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [169][000/391]   Time 0.232 (0.232)   Data 0.165 (0.165)   Loss 0.0790 (0.0790)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:01]
  Epoch: [169][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0111 (0.0405)   Prec@1 100.000 (98.716)   Prec@5 100.000 (99.977)   [2019-11-22 04:50:06]
  Epoch: [169][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0619 (0.0446)   Prec@1 98.438 (98.480)   Prec@5 100.000 (99.988)   [2019-11-22 04:50:11]
  Epoch: [169][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0307 (0.0472)   Prec@1 98.438 (98.373)   Prec@5 100.000 (99.990)   [2019-11-22 04:50:16]
  **Train** Prec@1 98.428 Prec@5 99.990 Error@1 1.572
  **Test** Prec@1 90.910 Prec@5 99.710 Error@1 9.090

==>>[2019-11-22 04:50:22] [Epoch=170/200] [Need: 00:10:59] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [170][000/391]   Time 0.231 (0.231)   Data 0.174 (0.174)   Loss 0.0368 (0.0368)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:22]
  Epoch: [170][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.0139 (0.0437)   Prec@1 100.000 (98.569)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:27]
  Epoch: [170][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.0568 (0.0436)   Prec@1 98.438 (98.570)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:32]
  Epoch: [170][300/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0131 (0.0440)   Prec@1 100.000 (98.526)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:37]
  **Train** Prec@1 98.474 Prec@5 99.996 Error@1 1.526
  **Test** Prec@1 90.930 Prec@5 99.710 Error@1 9.070

==>>[2019-11-22 04:50:44] [Epoch=171/200] [Need: 00:10:37] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [171][000/391]   Time 0.224 (0.224)   Data 0.164 (0.164)   Loss 0.0647 (0.0647)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:44]
  Epoch: [171][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0371 (0.0489)   Prec@1 99.219 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:49]
  Epoch: [171][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0497 (0.0475)   Prec@1 98.438 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:54]
  Epoch: [171][300/391]   Time 0.055 (0.051)   Data 0.000 (0.001)   Loss 0.0201 (0.0461)   Prec@1 100.000 (98.445)   Prec@5 100.000 (100.000)   [2019-11-22 04:50:59]
  **Train** Prec@1 98.432 Prec@5 100.000 Error@1 1.568
  **Test** Prec@1 90.960 Prec@5 99.720 Error@1 9.040

==>>[2019-11-22 04:51:06] [Epoch=172/200] [Need: 00:10:15] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [172][000/391]   Time 0.228 (0.228)   Data 0.166 (0.166)   Loss 0.0278 (0.0278)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:51:06]
  Epoch: [172][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0416 (0.0479)   Prec@1 98.438 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 04:51:11]
  Epoch: [172][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0481 (0.0452)   Prec@1 98.438 (98.488)   Prec@5 100.000 (99.996)   [2019-11-22 04:51:16]
  Epoch: [172][300/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0475 (0.0449)   Prec@1 97.656 (98.479)   Prec@5 100.000 (99.995)   [2019-11-22 04:51:21]
  **Train** Prec@1 98.470 Prec@5 99.996 Error@1 1.530
  **Test** Prec@1 90.900 Prec@5 99.720 Error@1 9.100

==>>[2019-11-22 04:51:28] [Epoch=173/200] [Need: 00:09:53] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [173][000/391]   Time 0.234 (0.234)   Data 0.151 (0.151)   Loss 0.0501 (0.0501)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:51:28]
  Epoch: [173][100/391]   Time 0.059 (0.053)   Data 0.000 (0.002)   Loss 0.0257 (0.0441)   Prec@1 99.219 (98.492)   Prec@5 100.000 (99.992)   [2019-11-22 04:51:33]
  Epoch: [173][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0439 (0.0452)   Prec@1 98.438 (98.465)   Prec@5 100.000 (99.996)   [2019-11-22 04:51:38]
  Epoch: [173][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0295 (0.0444)   Prec@1 100.000 (98.502)   Prec@5 100.000 (99.997)   [2019-11-22 04:51:43]
  **Train** Prec@1 98.500 Prec@5 99.998 Error@1 1.500
  **Test** Prec@1 90.980 Prec@5 99.700 Error@1 9.020

==>>[2019-11-22 04:51:49] [Epoch=174/200] [Need: 00:09:31] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [174][000/391]   Time 0.229 (0.229)   Data 0.173 (0.173)   Loss 0.0744 (0.0744)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:51:50]
  Epoch: [174][100/391]   Time 0.085 (0.052)   Data 0.000 (0.002)   Loss 0.0395 (0.0431)   Prec@1 98.438 (98.554)   Prec@5 100.000 (100.000)   [2019-11-22 04:51:55]
  Epoch: [174][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0185 (0.0433)   Prec@1 100.000 (98.585)   Prec@5 100.000 (99.996)   [2019-11-22 04:52:00]
  Epoch: [174][300/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0374 (0.0435)   Prec@1 98.438 (98.572)   Prec@5 100.000 (99.995)   [2019-11-22 04:52:05]
  **Train** Prec@1 98.546 Prec@5 99.992 Error@1 1.454
  **Test** Prec@1 90.950 Prec@5 99.710 Error@1 9.050

==>>[2019-11-22 04:52:11] [Epoch=175/200] [Need: 00:09:09] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [175][000/391]   Time 0.232 (0.232)   Data 0.177 (0.177)   Loss 0.0434 (0.0434)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:52:11]
  Epoch: [175][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0304 (0.0460)   Prec@1 99.219 (98.515)   Prec@5 100.000 (99.992)   [2019-11-22 04:52:16]
  Epoch: [175][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0412 (0.0467)   Prec@1 98.438 (98.430)   Prec@5 100.000 (99.992)   [2019-11-22 04:52:21]
  Epoch: [175][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0374 (0.0465)   Prec@1 98.438 (98.383)   Prec@5 100.000 (99.995)   [2019-11-22 04:52:26]
  **Train** Prec@1 98.410 Prec@5 99.996 Error@1 1.590
  **Test** Prec@1 90.990 Prec@5 99.730 Error@1 9.010

==>>[2019-11-22 04:52:33] [Epoch=176/200] [Need: 00:08:47] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [176][000/391]   Time 0.227 (0.227)   Data 0.158 (0.158)   Loss 0.0365 (0.0365)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 04:52:33]
  Epoch: [176][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.0881 (0.0443)   Prec@1 96.094 (98.523)   Prec@5 100.000 (99.992)   [2019-11-22 04:52:38]
  Epoch: [176][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0548 (0.0420)   Prec@1 97.656 (98.620)   Prec@5 100.000 (99.992)   [2019-11-22 04:52:43]
  Epoch: [176][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0445 (0.0432)   Prec@1 98.438 (98.572)   Prec@5 100.000 (99.995)   [2019-11-22 04:52:48]
  **Train** Prec@1 98.530 Prec@5 99.996 Error@1 1.470
  **Test** Prec@1 90.860 Prec@5 99.710 Error@1 9.140

==>>[2019-11-22 04:52:55] [Epoch=177/200] [Need: 00:08:25] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [177][000/391]   Time 0.231 (0.231)   Data 0.157 (0.157)   Loss 0.0168 (0.0168)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:52:55]
  Epoch: [177][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0411 (0.0441)   Prec@1 98.438 (98.484)   Prec@5 100.000 (99.985)   [2019-11-22 04:53:00]
  Epoch: [177][200/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.0592 (0.0460)   Prec@1 97.656 (98.403)   Prec@5 100.000 (99.988)   [2019-11-22 04:53:05]
  Epoch: [177][300/391]   Time 0.060 (0.051)   Data 0.000 (0.001)   Loss 0.0391 (0.0451)   Prec@1 98.438 (98.469)   Prec@5 100.000 (99.992)   [2019-11-22 04:53:10]
  **Train** Prec@1 98.498 Prec@5 99.990 Error@1 1.502
  **Test** Prec@1 90.840 Prec@5 99.700 Error@1 9.160

==>>[2019-11-22 04:53:16] [Epoch=178/200] [Need: 00:08:03] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [178][000/391]   Time 0.234 (0.234)   Data 0.152 (0.152)   Loss 0.0396 (0.0396)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:53:17]
  Epoch: [178][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0407 (0.0467)   Prec@1 99.219 (98.368)   Prec@5 100.000 (100.000)   [2019-11-22 04:53:22]
  Epoch: [178][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0220 (0.0442)   Prec@1 100.000 (98.430)   Prec@5 100.000 (100.000)   [2019-11-22 04:53:27]
  Epoch: [178][300/391]   Time 0.056 (0.054)   Data 0.000 (0.001)   Loss 0.0172 (0.0438)   Prec@1 99.219 (98.443)   Prec@5 100.000 (100.000)   [2019-11-22 04:53:33]
  **Train** Prec@1 98.430 Prec@5 99.996 Error@1 1.570
  **Test** Prec@1 90.820 Prec@5 99.690 Error@1 9.180

==>>[2019-11-22 04:53:39] [Epoch=179/200] [Need: 00:07:41] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [179][000/391]   Time 0.226 (0.226)   Data 0.170 (0.170)   Loss 0.0736 (0.0736)   Prec@1 98.438 (98.438)   Prec@5 99.219 (99.219)   [2019-11-22 04:53:39]
  Epoch: [179][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0139 (0.0439)   Prec@1 99.219 (98.546)   Prec@5 100.000 (99.992)   [2019-11-22 04:53:44]
  Epoch: [179][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.0743 (0.0446)   Prec@1 96.875 (98.527)   Prec@5 100.000 (99.988)   [2019-11-22 04:53:49]
  Epoch: [179][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.0653 (0.0442)   Prec@1 96.875 (98.549)   Prec@5 100.000 (99.990)   [2019-11-22 04:53:54]
  **Train** Prec@1 98.566 Prec@5 99.992 Error@1 1.434
  **Test** Prec@1 90.790 Prec@5 99.700 Error@1 9.210

==>>[2019-11-22 04:54:01] [Epoch=180/200] [Need: 00:07:19] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [180][000/391]   Time 0.237 (0.237)   Data 0.170 (0.170)   Loss 0.0266 (0.0266)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:54:01]
  Epoch: [180][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0479 (0.0434)   Prec@1 98.438 (98.484)   Prec@5 100.000 (100.000)   [2019-11-22 04:54:06]
  Epoch: [180][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0282 (0.0433)   Prec@1 99.219 (98.472)   Prec@5 100.000 (99.996)   [2019-11-22 04:54:11]
  Epoch: [180][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0341 (0.0435)   Prec@1 99.219 (98.510)   Prec@5 100.000 (99.997)   [2019-11-22 04:54:16]
  **Train** Prec@1 98.490 Prec@5 99.998 Error@1 1.510
  **Test** Prec@1 90.840 Prec@5 99.670 Error@1 9.160

==>>[2019-11-22 04:54:23] [Epoch=181/200] [Need: 00:06:57] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [181][000/391]   Time 0.231 (0.231)   Data 0.163 (0.163)   Loss 0.0266 (0.0266)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:54:23]
  Epoch: [181][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.0238 (0.0426)   Prec@1 99.219 (98.639)   Prec@5 100.000 (99.985)   [2019-11-22 04:54:28]
  Epoch: [181][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0191 (0.0422)   Prec@1 100.000 (98.632)   Prec@5 100.000 (99.992)   [2019-11-22 04:54:33]
  Epoch: [181][300/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.0284 (0.0433)   Prec@1 98.438 (98.565)   Prec@5 100.000 (99.992)   [2019-11-22 04:54:38]
  **Train** Prec@1 98.526 Prec@5 99.992 Error@1 1.474
  **Test** Prec@1 90.960 Prec@5 99.700 Error@1 9.040

==>>[2019-11-22 04:54:45] [Epoch=182/200] [Need: 00:06:35] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [182][000/391]   Time 0.227 (0.227)   Data 0.152 (0.152)   Loss 0.1061 (0.1061)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-22 04:54:45]
  Epoch: [182][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0691 (0.0430)   Prec@1 97.656 (98.561)   Prec@5 100.000 (99.992)   [2019-11-22 04:54:50]
  Epoch: [182][200/391]   Time 0.081 (0.051)   Data 0.005 (0.001)   Loss 0.0236 (0.0448)   Prec@1 100.000 (98.453)   Prec@5 100.000 (99.996)   [2019-11-22 04:54:55]
  Epoch: [182][300/391]   Time 0.073 (0.052)   Data 0.000 (0.001)   Loss 0.0398 (0.0456)   Prec@1 98.438 (98.440)   Prec@5 100.000 (99.995)   [2019-11-22 04:55:01]
  **Train** Prec@1 98.486 Prec@5 99.992 Error@1 1.514
  **Test** Prec@1 90.990 Prec@5 99.690 Error@1 9.010

==>>[2019-11-22 04:55:07] [Epoch=183/200] [Need: 00:06:13] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [183][000/391]   Time 0.244 (0.244)   Data 0.190 (0.190)   Loss 0.0371 (0.0371)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:08]
  Epoch: [183][100/391]   Time 0.055 (0.051)   Data 0.000 (0.002)   Loss 0.0195 (0.0406)   Prec@1 100.000 (98.569)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:13]
  Epoch: [183][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0389 (0.0443)   Prec@1 98.438 (98.449)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:18]
  Epoch: [183][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0391 (0.0437)   Prec@1 98.438 (98.497)   Prec@5 100.000 (99.995)   [2019-11-22 04:55:23]
  **Train** Prec@1 98.500 Prec@5 99.996 Error@1 1.500
  **Test** Prec@1 91.030 Prec@5 99.700 Error@1 8.970

==>>[2019-11-22 04:55:30] [Epoch=184/200] [Need: 00:05:51] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [184][000/391]   Time 0.235 (0.235)   Data 0.163 (0.163)   Loss 0.0315 (0.0315)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:30]
  Epoch: [184][100/391]   Time 0.047 (0.056)   Data 0.000 (0.002)   Loss 0.0358 (0.0422)   Prec@1 98.438 (98.554)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:35]
  Epoch: [184][200/391]   Time 0.052 (0.055)   Data 0.000 (0.001)   Loss 0.0239 (0.0409)   Prec@1 99.219 (98.651)   Prec@5 100.000 (99.992)   [2019-11-22 04:55:41]
  Epoch: [184][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.0907 (0.0431)   Prec@1 96.094 (98.596)   Prec@5 100.000 (99.992)   [2019-11-22 04:55:46]
  **Train** Prec@1 98.564 Prec@5 99.994 Error@1 1.436
  **Test** Prec@1 91.020 Prec@5 99.720 Error@1 8.980

==>>[2019-11-22 04:55:53] [Epoch=185/200] [Need: 00:05:29] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [185][000/391]   Time 0.214 (0.214)   Data 0.156 (0.156)   Loss 0.0408 (0.0408)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:53]
  Epoch: [185][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.0374 (0.0460)   Prec@1 97.656 (98.523)   Prec@5 100.000 (100.000)   [2019-11-22 04:55:58]
  Epoch: [185][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0310 (0.0468)   Prec@1 98.438 (98.403)   Prec@5 100.000 (99.996)   [2019-11-22 04:56:03]
  Epoch: [185][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0744 (0.0449)   Prec@1 96.094 (98.453)   Prec@5 100.000 (99.997)   [2019-11-22 04:56:08]
  **Train** Prec@1 98.454 Prec@5 99.994 Error@1 1.546
  **Test** Prec@1 90.840 Prec@5 99.670 Error@1 9.160

==>>[2019-11-22 04:56:15] [Epoch=186/200] [Need: 00:05:07] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [186][000/391]   Time 0.238 (0.238)   Data 0.178 (0.178)   Loss 0.0174 (0.0174)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:56:15]
  Epoch: [186][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0205 (0.0435)   Prec@1 100.000 (98.492)   Prec@5 100.000 (100.000)   [2019-11-22 04:56:20]
  Epoch: [186][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0649 (0.0461)   Prec@1 96.094 (98.375)   Prec@5 100.000 (100.000)   [2019-11-22 04:56:25]
  Epoch: [186][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0435 (0.0438)   Prec@1 98.438 (98.474)   Prec@5 100.000 (100.000)   [2019-11-22 04:56:31]
  **Train** Prec@1 98.528 Prec@5 99.998 Error@1 1.472
  **Test** Prec@1 91.020 Prec@5 99.740 Error@1 8.980

==>>[2019-11-22 04:56:37] [Epoch=187/200] [Need: 00:04:45] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [187][000/391]   Time 0.223 (0.223)   Data 0.155 (0.155)   Loss 0.0537 (0.0537)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:56:38]
  Epoch: [187][100/391]   Time 0.081 (0.052)   Data 0.000 (0.002)   Loss 0.0921 (0.0430)   Prec@1 96.094 (98.507)   Prec@5 100.000 (99.992)   [2019-11-22 04:56:43]
  Epoch: [187][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0434 (0.0449)   Prec@1 98.438 (98.461)   Prec@5 100.000 (99.996)   [2019-11-22 04:56:48]
  Epoch: [187][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0348 (0.0449)   Prec@1 99.219 (98.482)   Prec@5 100.000 (99.992)   [2019-11-22 04:56:53]
  **Train** Prec@1 98.480 Prec@5 99.994 Error@1 1.520
  **Test** Prec@1 90.890 Prec@5 99.700 Error@1 9.110

==>>[2019-11-22 04:56:59] [Epoch=188/200] [Need: 00:04:23] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [188][000/391]   Time 0.232 (0.232)   Data 0.170 (0.170)   Loss 0.0470 (0.0470)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:57:00]
  Epoch: [188][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0253 (0.0439)   Prec@1 99.219 (98.523)   Prec@5 100.000 (99.985)   [2019-11-22 04:57:05]
  Epoch: [188][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.0479 (0.0447)   Prec@1 97.656 (98.480)   Prec@5 100.000 (99.992)   [2019-11-22 04:57:10]
  Epoch: [188][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0158 (0.0438)   Prec@1 100.000 (98.508)   Prec@5 100.000 (99.992)   [2019-11-22 04:57:15]
  **Train** Prec@1 98.476 Prec@5 99.994 Error@1 1.524
  **Test** Prec@1 90.980 Prec@5 99.700 Error@1 9.020

==>>[2019-11-22 04:57:22] [Epoch=189/200] [Need: 00:04:01] [LR=0.0001][M=0.90] [Best : Accuracy=91.05, Error=8.95]
  Epoch: [189][000/391]   Time 0.228 (0.228)   Data 0.168 (0.168)   Loss 0.0569 (0.0569)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:57:22]
  Epoch: [189][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.0317 (0.0447)   Prec@1 99.219 (98.468)   Prec@5 100.000 (99.992)   [2019-11-22 04:57:27]
  Epoch: [189][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0295 (0.0441)   Prec@1 99.219 (98.488)   Prec@5 100.000 (99.996)   [2019-11-22 04:57:32]
  Epoch: [189][300/391]   Time 0.075 (0.050)   Data 0.000 (0.001)   Loss 0.0405 (0.0440)   Prec@1 98.438 (98.505)   Prec@5 100.000 (99.997)   [2019-11-22 04:57:37]
  **Train** Prec@1 98.490 Prec@5 99.998 Error@1 1.510
  **Test** Prec@1 91.070 Prec@5 99.710 Error@1 8.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 04:57:43] [Epoch=190/200] [Need: 00:03:39] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [190][000/391]   Time 0.233 (0.233)   Data 0.163 (0.163)   Loss 0.0277 (0.0277)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:57:43]
  Epoch: [190][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0561 (0.0461)   Prec@1 96.875 (98.445)   Prec@5 100.000 (99.992)   [2019-11-22 04:57:48]
  Epoch: [190][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0472 (0.0448)   Prec@1 98.438 (98.469)   Prec@5 100.000 (99.996)   [2019-11-22 04:57:54]
  Epoch: [190][300/391]   Time 0.078 (0.052)   Data 0.000 (0.001)   Loss 0.0557 (0.0438)   Prec@1 97.656 (98.482)   Prec@5 100.000 (99.997)   [2019-11-22 04:57:59]
  **Train** Prec@1 98.476 Prec@5 99.996 Error@1 1.524
  **Test** Prec@1 90.940 Prec@5 99.720 Error@1 9.060

==>>[2019-11-22 04:58:05] [Epoch=191/200] [Need: 00:03:17] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [191][000/391]   Time 0.254 (0.254)   Data 0.186 (0.186)   Loss 0.0406 (0.0406)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:58:05]
  Epoch: [191][100/391]   Time 0.043 (0.055)   Data 0.000 (0.002)   Loss 0.0629 (0.0424)   Prec@1 96.875 (98.554)   Prec@5 100.000 (100.000)   [2019-11-22 04:58:11]
  Epoch: [191][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0457 (0.0424)   Prec@1 99.219 (98.589)   Prec@5 100.000 (99.992)   [2019-11-22 04:58:16]
  Epoch: [191][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0337 (0.0437)   Prec@1 100.000 (98.528)   Prec@5 100.000 (99.995)   [2019-11-22 04:58:21]
  **Train** Prec@1 98.498 Prec@5 99.994 Error@1 1.502
  **Test** Prec@1 90.960 Prec@5 99.690 Error@1 9.040

==>>[2019-11-22 04:58:27] [Epoch=192/200] [Need: 00:02:55] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [192][000/391]   Time 0.225 (0.225)   Data 0.154 (0.154)   Loss 0.0177 (0.0177)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 04:58:28]
  Epoch: [192][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0287 (0.0412)   Prec@1 100.000 (98.693)   Prec@5 100.000 (99.992)   [2019-11-22 04:58:33]
  Epoch: [192][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.1030 (0.0418)   Prec@1 95.312 (98.624)   Prec@5 100.000 (99.996)   [2019-11-22 04:58:38]
  Epoch: [192][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0524 (0.0416)   Prec@1 98.438 (98.619)   Prec@5 100.000 (99.995)   [2019-11-22 04:58:43]
  **Train** Prec@1 98.628 Prec@5 99.996 Error@1 1.372
  **Test** Prec@1 91.020 Prec@5 99.710 Error@1 8.980

==>>[2019-11-22 04:58:49] [Epoch=193/200] [Need: 00:02:33] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [193][000/391]   Time 0.239 (0.239)   Data 0.180 (0.180)   Loss 0.0585 (0.0585)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:58:49]
  Epoch: [193][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0753 (0.0428)   Prec@1 96.875 (98.507)   Prec@5 100.000 (100.000)   [2019-11-22 04:58:54]
  Epoch: [193][200/391]   Time 0.074 (0.051)   Data 0.000 (0.001)   Loss 0.0317 (0.0415)   Prec@1 99.219 (98.601)   Prec@5 100.000 (99.992)   [2019-11-22 04:58:59]
  Epoch: [193][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0921 (0.0430)   Prec@1 96.875 (98.544)   Prec@5 100.000 (99.995)   [2019-11-22 04:59:05]
  **Train** Prec@1 98.550 Prec@5 99.996 Error@1 1.450
  **Test** Prec@1 90.840 Prec@5 99.740 Error@1 9.160

==>>[2019-11-22 04:59:11] [Epoch=194/200] [Need: 00:02:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [194][000/391]   Time 0.228 (0.228)   Data 0.152 (0.152)   Loss 0.0310 (0.0310)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 04:59:11]
  Epoch: [194][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0319 (0.0431)   Prec@1 99.219 (98.530)   Prec@5 100.000 (100.000)   [2019-11-22 04:59:16]
  Epoch: [194][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0257 (0.0421)   Prec@1 99.219 (98.612)   Prec@5 100.000 (99.996)   [2019-11-22 04:59:22]
  Epoch: [194][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0429 (0.0426)   Prec@1 98.438 (98.562)   Prec@5 100.000 (99.995)   [2019-11-22 04:59:26]
  **Train** Prec@1 98.570 Prec@5 99.994 Error@1 1.430
  **Test** Prec@1 90.950 Prec@5 99.690 Error@1 9.050

==>>[2019-11-22 04:59:33] [Epoch=195/200] [Need: 00:01:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [195][000/391]   Time 0.236 (0.236)   Data 0.164 (0.164)   Loss 0.0513 (0.0513)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:59:33]
  Epoch: [195][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0544 (0.0432)   Prec@1 97.656 (98.484)   Prec@5 100.000 (99.992)   [2019-11-22 04:59:38]
  Epoch: [195][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0197 (0.0441)   Prec@1 100.000 (98.438)   Prec@5 100.000 (99.996)   [2019-11-22 04:59:43]
  Epoch: [195][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0549 (0.0435)   Prec@1 97.656 (98.453)   Prec@5 100.000 (99.997)   [2019-11-22 04:59:48]
  **Train** Prec@1 98.478 Prec@5 99.998 Error@1 1.522
  **Test** Prec@1 90.880 Prec@5 99.690 Error@1 9.120

==>>[2019-11-22 04:59:55] [Epoch=196/200] [Need: 00:01:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [196][000/391]   Time 0.221 (0.221)   Data 0.165 (0.165)   Loss 0.0362 (0.0362)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 04:59:55]
  Epoch: [196][100/391]   Time 0.035 (0.052)   Data 0.000 (0.002)   Loss 0.0612 (0.0412)   Prec@1 97.656 (98.592)   Prec@5 100.000 (100.000)   [2019-11-22 05:00:00]
  Epoch: [196][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0706 (0.0409)   Prec@1 97.656 (98.624)   Prec@5 100.000 (99.996)   [2019-11-22 05:00:05]
  Epoch: [196][300/391]   Time 0.085 (0.051)   Data 0.000 (0.001)   Loss 0.0717 (0.0414)   Prec@1 97.656 (98.575)   Prec@5 100.000 (99.997)   [2019-11-22 05:00:10]
  **Train** Prec@1 98.534 Prec@5 99.996 Error@1 1.466
  **Test** Prec@1 91.010 Prec@5 99.710 Error@1 8.990

==>>[2019-11-22 05:00:16] [Epoch=197/200] [Need: 00:01:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [197][000/391]   Time 0.230 (0.230)   Data 0.153 (0.153)   Loss 0.0374 (0.0374)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 05:00:17]
  Epoch: [197][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0406 (0.0431)   Prec@1 97.656 (98.422)   Prec@5 100.000 (99.985)   [2019-11-22 05:00:22]
  Epoch: [197][200/391]   Time 0.062 (0.053)   Data 0.000 (0.001)   Loss 0.0526 (0.0439)   Prec@1 99.219 (98.465)   Prec@5 100.000 (99.984)   [2019-11-22 05:00:27]
  Epoch: [197][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0330 (0.0434)   Prec@1 99.219 (98.510)   Prec@5 100.000 (99.984)   [2019-11-22 05:00:32]
  **Train** Prec@1 98.534 Prec@5 99.986 Error@1 1.466
  **Test** Prec@1 90.950 Prec@5 99.700 Error@1 9.050

==>>[2019-11-22 05:00:38] [Epoch=198/200] [Need: 00:00:43] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [198][000/391]   Time 0.236 (0.236)   Data 0.165 (0.165)   Loss 0.0263 (0.0263)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 05:00:38]
  Epoch: [198][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0865 (0.0418)   Prec@1 96.875 (98.554)   Prec@5 100.000 (100.000)   [2019-11-22 05:00:43]
  Epoch: [198][200/391]   Time 0.038 (0.053)   Data 0.000 (0.001)   Loss 0.0309 (0.0430)   Prec@1 98.438 (98.500)   Prec@5 100.000 (99.992)   [2019-11-22 05:00:49]
  Epoch: [198][300/391]   Time 0.047 (0.053)   Data 0.000 (0.001)   Loss 0.0490 (0.0427)   Prec@1 98.438 (98.547)   Prec@5 100.000 (99.992)   [2019-11-22 05:00:54]
  **Train** Prec@1 98.502 Prec@5 99.992 Error@1 1.498
  **Test** Prec@1 90.920 Prec@5 99.680 Error@1 9.080

==>>[2019-11-22 05:01:00] [Epoch=199/200] [Need: 00:00:21] [LR=0.0001][M=0.90] [Best : Accuracy=91.07, Error=8.93]
  Epoch: [199][000/391]   Time 0.229 (0.229)   Data 0.170 (0.170)   Loss 0.0465 (0.0465)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 05:01:00]
  Epoch: [199][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.0192 (0.0430)   Prec@1 100.000 (98.561)   Prec@5 100.000 (99.992)   [2019-11-22 05:01:06]
  Epoch: [199][200/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0393 (0.0430)   Prec@1 98.438 (98.527)   Prec@5 100.000 (99.996)   [2019-11-22 05:01:10]
  Epoch: [199][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.0786 (0.0437)   Prec@1 96.094 (98.492)   Prec@5 100.000 (99.997)   [2019-11-22 05:01:15]
  **Train** Prec@1 98.496 Prec@5 99.998 Error@1 1.504
  **Test** Prec@1 90.890 Prec@5 99.680 Error@1 9.110
