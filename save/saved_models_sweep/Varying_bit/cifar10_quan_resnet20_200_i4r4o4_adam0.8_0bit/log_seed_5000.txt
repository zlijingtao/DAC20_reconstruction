save path : ./save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_0bit_reg0.0
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.8, 'input_grain_size': [1, 4], 'input_num_bits': 0, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.8, 'output_grain_size': [1, 4], 'output_num_bits': 0, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.8, 'res_grain_size': [1, 4], 'res_num_bits': 0, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-21/cifar10_quan_resnet20_200_i4r4o4_adam0.8_0bit_reg0.0', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-22 00:13:45] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.653 (1.653)   Data 0.136 (0.136)   Loss 3.0097 (3.0097)   Prec@1 8.594 (8.594)   Prec@5 49.219 (49.219)   [2019-11-22 00:13:47]
  Epoch: [000][100/391]   Time 0.039 (0.060)   Data 0.000 (0.001)   Loss 1.7481 (1.9254)   Prec@1 32.031 (28.728)   Prec@5 86.719 (80.910)   [2019-11-22 00:13:51]
  Epoch: [000][200/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 1.5663 (1.7622)   Prec@1 42.188 (34.235)   Prec@5 91.406 (85.704)   [2019-11-22 00:13:55]
  Epoch: [000][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 1.2199 (1.6367)   Prec@1 52.344 (39.120)   Prec@5 94.531 (88.237)   [2019-11-22 00:14:00]
  **Train** Prec@1 42.728 Prec@5 89.642 Error@1 57.272
  **Test** Prec@1 55.220 Prec@5 94.740 Error@1 44.780
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:14:05] [Epoch=001/200] [Need: 01:06:45] [LR=0.0100][M=0.90] [Best : Accuracy=55.22, Error=44.78]
  Epoch: [001][000/391]   Time 0.208 (0.208)   Data 0.142 (0.142)   Loss 1.2084 (1.2084)   Prec@1 57.812 (57.812)   Prec@5 93.750 (93.750)   [2019-11-22 00:14:06]
  Epoch: [001][100/391]   Time 0.047 (0.046)   Data 0.000 (0.002)   Loss 1.1141 (1.1611)   Prec@1 58.594 (57.743)   Prec@5 97.656 (95.552)   [2019-11-22 00:14:10]
  Epoch: [001][200/391]   Time 0.045 (0.046)   Data 0.000 (0.001)   Loss 1.0601 (1.1158)   Prec@1 58.594 (59.709)   Prec@5 96.875 (95.868)   [2019-11-22 00:14:15]
  Epoch: [001][300/391]   Time 0.060 (0.045)   Data 0.000 (0.001)   Loss 1.0201 (1.0955)   Prec@1 66.406 (60.743)   Prec@5 95.312 (95.954)   [2019-11-22 00:14:19]
  **Train** Prec@1 61.800 Prec@5 96.142 Error@1 38.200
  **Test** Prec@1 51.520 Prec@5 92.990 Error@1 48.480

==>>[2019-11-22 00:14:25] [Epoch=002/200] [Need: 01:05:18] [LR=0.0100][M=0.90] [Best : Accuracy=55.22, Error=44.78]
  Epoch: [002][000/391]   Time 0.220 (0.220)   Data 0.156 (0.156)   Loss 0.9679 (0.9679)   Prec@1 67.188 (67.188)   Prec@5 94.531 (94.531)   [2019-11-22 00:14:25]
  Epoch: [002][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.9924 (0.9354)   Prec@1 63.281 (66.538)   Prec@5 98.438 (97.269)   [2019-11-22 00:14:29]
  Epoch: [002][200/391]   Time 0.066 (0.044)   Data 0.000 (0.001)   Loss 0.9449 (0.9024)   Prec@1 65.625 (67.724)   Prec@5 98.438 (97.493)   [2019-11-22 00:14:34]
  Epoch: [002][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.8506 (0.8886)   Prec@1 72.656 (68.550)   Prec@5 96.094 (97.506)   [2019-11-22 00:14:38]
  **Train** Prec@1 69.058 Prec@5 97.560 Error@1 30.942
  **Test** Prec@1 68.460 Prec@5 97.740 Error@1 31.540
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:14:45] [Epoch=003/200] [Need: 01:05:04] [LR=0.0100][M=0.90] [Best : Accuracy=68.46, Error=31.54]
  Epoch: [003][000/391]   Time 0.218 (0.218)   Data 0.162 (0.162)   Loss 0.9121 (0.9121)   Prec@1 67.969 (67.969)   Prec@5 97.656 (97.656)   [2019-11-22 00:14:45]
  Epoch: [003][100/391]   Time 0.048 (0.046)   Data 0.000 (0.002)   Loss 0.7093 (0.7819)   Prec@1 74.219 (72.826)   Prec@5 99.219 (97.935)   [2019-11-22 00:14:49]
  Epoch: [003][200/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.7610 (0.7766)   Prec@1 71.875 (72.967)   Prec@5 98.438 (98.057)   [2019-11-22 00:14:54]
  Epoch: [003][300/391]   Time 0.050 (0.046)   Data 0.000 (0.001)   Loss 0.5536 (0.7664)   Prec@1 85.156 (73.479)   Prec@5 98.438 (98.043)   [2019-11-22 00:14:59]
  **Train** Prec@1 73.788 Prec@5 98.100 Error@1 26.212
  **Test** Prec@1 72.780 Prec@5 98.150 Error@1 27.220
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:15:05] [Epoch=004/200] [Need: 01:04:52] [LR=0.0100][M=0.90] [Best : Accuracy=72.78, Error=27.22]
  Epoch: [004][000/391]   Time 0.225 (0.225)   Data 0.168 (0.168)   Loss 0.6122 (0.6122)   Prec@1 78.125 (78.125)   Prec@5 99.219 (99.219)   [2019-11-22 00:15:05]
  Epoch: [004][100/391]   Time 0.039 (0.047)   Data 0.000 (0.002)   Loss 0.5665 (0.7022)   Prec@1 81.250 (75.673)   Prec@5 96.875 (98.182)   [2019-11-22 00:15:09]
  Epoch: [004][200/391]   Time 0.047 (0.048)   Data 0.000 (0.001)   Loss 0.6833 (0.6932)   Prec@1 72.656 (76.084)   Prec@5 100.000 (98.336)   [2019-11-22 00:15:14]
  Epoch: [004][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.6579 (0.6881)   Prec@1 78.125 (76.241)   Prec@5 97.656 (98.422)   [2019-11-22 00:15:19]
  **Train** Prec@1 76.504 Prec@5 98.508 Error@1 23.496
  **Test** Prec@1 73.270 Prec@5 98.610 Error@1 26.730
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:15:25] [Epoch=005/200] [Need: 01:04:53] [LR=0.0100][M=0.90] [Best : Accuracy=73.27, Error=26.73]
  Epoch: [005][000/391]   Time 0.229 (0.229)   Data 0.145 (0.145)   Loss 0.6327 (0.6327)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-22 00:15:25]
  Epoch: [005][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.4899 (0.6345)   Prec@1 85.938 (77.738)   Prec@5 98.438 (98.786)   [2019-11-22 00:15:30]
  Epoch: [005][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.6518 (0.6413)   Prec@1 76.562 (77.612)   Prec@5 98.438 (98.690)   [2019-11-22 00:15:35]
  Epoch: [005][300/391]   Time 0.057 (0.047)   Data 0.000 (0.001)   Loss 0.7173 (0.6379)   Prec@1 77.344 (77.891)   Prec@5 97.656 (98.702)   [2019-11-22 00:15:39]
  **Train** Prec@1 78.126 Prec@5 98.706 Error@1 21.874
  **Test** Prec@1 74.510 Prec@5 98.510 Error@1 25.490
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:15:45] [Epoch=006/200] [Need: 01:04:32] [LR=0.0100][M=0.90] [Best : Accuracy=74.51, Error=25.49]
  Epoch: [006][000/391]   Time 0.206 (0.206)   Data 0.144 (0.144)   Loss 0.5162 (0.5162)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2019-11-22 00:15:45]
  Epoch: [006][100/391]   Time 0.041 (0.046)   Data 0.000 (0.002)   Loss 0.5894 (0.6060)   Prec@1 81.250 (79.247)   Prec@5 99.219 (98.956)   [2019-11-22 00:15:50]
  Epoch: [006][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.6740 (0.6006)   Prec@1 75.000 (79.268)   Prec@5 100.000 (98.927)   [2019-11-22 00:15:55]
  Epoch: [006][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.6481 (0.6024)   Prec@1 76.562 (79.244)   Prec@5 99.219 (98.931)   [2019-11-22 00:15:59]
  **Train** Prec@1 79.460 Prec@5 98.908 Error@1 20.540
  **Test** Prec@1 76.370 Prec@5 98.580 Error@1 23.630
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:16:05] [Epoch=007/200] [Need: 01:04:18] [LR=0.0100][M=0.90] [Best : Accuracy=76.37, Error=23.63]
  Epoch: [007][000/391]   Time 0.216 (0.216)   Data 0.159 (0.159)   Loss 0.6577 (0.6577)   Prec@1 75.781 (75.781)   Prec@5 99.219 (99.219)   [2019-11-22 00:16:05]
  Epoch: [007][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.6451 (0.5651)   Prec@1 79.688 (80.492)   Prec@5 98.438 (99.056)   [2019-11-22 00:16:10]
  Epoch: [007][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.6186 (0.5601)   Prec@1 77.344 (80.414)   Prec@5 99.219 (99.083)   [2019-11-22 00:16:15]
  Epoch: [007][300/391]   Time 0.048 (0.047)   Data 0.000 (0.001)   Loss 0.6297 (0.5592)   Prec@1 78.906 (80.544)   Prec@5 97.656 (99.047)   [2019-11-22 00:16:19]
  **Train** Prec@1 80.574 Prec@5 99.050 Error@1 19.426
  **Test** Prec@1 75.710 Prec@5 98.450 Error@1 24.290

==>>[2019-11-22 00:16:25] [Epoch=008/200] [Need: 01:04:01] [LR=0.0100][M=0.90] [Best : Accuracy=76.37, Error=23.63]
  Epoch: [008][000/391]   Time 0.219 (0.219)   Data 0.163 (0.163)   Loss 0.5548 (0.5548)   Prec@1 78.125 (78.125)   Prec@5 99.219 (99.219)   [2019-11-22 00:16:25]
  Epoch: [008][100/391]   Time 0.040 (0.051)   Data 0.000 (0.002)   Loss 0.4875 (0.5410)   Prec@1 82.031 (81.451)   Prec@5 99.219 (99.157)   [2019-11-22 00:16:30]
  Epoch: [008][200/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.5221 (0.5425)   Prec@1 79.688 (81.301)   Prec@5 100.000 (99.075)   [2019-11-22 00:16:35]
  Epoch: [008][300/391]   Time 0.045 (0.048)   Data 0.000 (0.001)   Loss 0.5450 (0.5367)   Prec@1 81.250 (81.452)   Prec@5 100.000 (99.097)   [2019-11-22 00:16:40]
  **Train** Prec@1 81.560 Prec@5 99.100 Error@1 18.440
  **Test** Prec@1 77.480 Prec@5 98.830 Error@1 22.520
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:16:46] [Epoch=009/200] [Need: 01:03:54] [LR=0.0100][M=0.90] [Best : Accuracy=77.48, Error=22.52]
  Epoch: [009][000/391]   Time 0.217 (0.217)   Data 0.147 (0.147)   Loss 0.7116 (0.7116)   Prec@1 74.219 (74.219)   Prec@5 98.438 (98.438)   [2019-11-22 00:16:46]
  Epoch: [009][100/391]   Time 0.041 (0.044)   Data 0.000 (0.002)   Loss 0.4099 (0.4999)   Prec@1 87.500 (82.464)   Prec@5 98.438 (99.149)   [2019-11-22 00:16:50]
  Epoch: [009][200/391]   Time 0.037 (0.045)   Data 0.000 (0.001)   Loss 0.4917 (0.5094)   Prec@1 85.156 (82.455)   Prec@5 98.438 (99.098)   [2019-11-22 00:16:55]
  Epoch: [009][300/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.6001 (0.5100)   Prec@1 80.469 (82.462)   Prec@5 98.438 (99.112)   [2019-11-22 00:17:00]
  **Train** Prec@1 82.282 Prec@5 99.090 Error@1 17.718
  **Test** Prec@1 76.140 Prec@5 98.280 Error@1 23.860

==>>[2019-11-22 00:17:05] [Epoch=010/200] [Need: 01:03:15] [LR=0.0100][M=0.90] [Best : Accuracy=77.48, Error=22.52]
  Epoch: [010][000/391]   Time 0.250 (0.250)   Data 0.175 (0.175)   Loss 0.5609 (0.5609)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2019-11-22 00:17:05]
  Epoch: [010][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.4003 (0.4961)   Prec@1 82.031 (82.627)   Prec@5 100.000 (99.397)   [2019-11-22 00:17:10]
  Epoch: [010][200/391]   Time 0.048 (0.048)   Data 0.000 (0.001)   Loss 0.3798 (0.4993)   Prec@1 84.375 (82.622)   Prec@5 99.219 (99.223)   [2019-11-22 00:17:15]
  Epoch: [010][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3574 (0.4991)   Prec@1 87.500 (82.711)   Prec@5 99.219 (99.169)   [2019-11-22 00:17:19]
  **Train** Prec@1 82.728 Prec@5 99.204 Error@1 17.272
  **Test** Prec@1 79.610 Prec@5 98.690 Error@1 20.390
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:17:25] [Epoch=011/200] [Need: 01:02:51] [LR=0.0100][M=0.90] [Best : Accuracy=79.61, Error=20.39]
  Epoch: [011][000/391]   Time 0.211 (0.211)   Data 0.144 (0.144)   Loss 0.3910 (0.3910)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 00:17:25]
  Epoch: [011][100/391]   Time 0.040 (0.049)   Data 0.000 (0.002)   Loss 0.6269 (0.4822)   Prec@1 77.344 (83.671)   Prec@5 100.000 (99.219)   [2019-11-22 00:17:30]
  Epoch: [011][200/391]   Time 0.072 (0.048)   Data 0.000 (0.001)   Loss 0.6034 (0.4805)   Prec@1 78.125 (83.368)   Prec@5 99.219 (99.199)   [2019-11-22 00:17:34]
  Epoch: [011][300/391]   Time 0.065 (0.048)   Data 0.000 (0.001)   Loss 0.4363 (0.4837)   Prec@1 84.375 (83.277)   Prec@5 98.438 (99.167)   [2019-11-22 00:17:39]
  **Train** Prec@1 83.282 Prec@5 99.198 Error@1 16.718
  **Test** Prec@1 81.450 Prec@5 98.810 Error@1 18.550
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:17:45] [Epoch=012/200] [Need: 01:02:36] [LR=0.0100][M=0.90] [Best : Accuracy=81.45, Error=18.55]
  Epoch: [012][000/391]   Time 0.217 (0.217)   Data 0.162 (0.162)   Loss 0.3839 (0.3839)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 00:17:45]
  Epoch: [012][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.4920 (0.4520)   Prec@1 82.031 (84.452)   Prec@5 100.000 (99.319)   [2019-11-22 00:17:50]
  Epoch: [012][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.4950 (0.4588)   Prec@1 82.031 (84.056)   Prec@5 99.219 (99.246)   [2019-11-22 00:17:54]
  Epoch: [012][300/391]   Time 0.057 (0.045)   Data 0.000 (0.001)   Loss 0.3678 (0.4650)   Prec@1 85.156 (83.858)   Prec@5 100.000 (99.232)   [2019-11-22 00:17:59]
  **Train** Prec@1 83.742 Prec@5 99.246 Error@1 16.258
  **Test** Prec@1 78.410 Prec@5 98.960 Error@1 21.590

==>>[2019-11-22 00:18:04] [Epoch=013/200] [Need: 01:02:09] [LR=0.0100][M=0.90] [Best : Accuracy=81.45, Error=18.55]
  Epoch: [013][000/391]   Time 0.236 (0.236)   Data 0.184 (0.184)   Loss 0.5616 (0.5616)   Prec@1 79.688 (79.688)   Prec@5 98.438 (98.438)   [2019-11-22 00:18:05]
  Epoch: [013][100/391]   Time 0.040 (0.046)   Data 0.000 (0.002)   Loss 0.4409 (0.4514)   Prec@1 85.156 (84.414)   Prec@5 100.000 (99.288)   [2019-11-22 00:18:09]
  Epoch: [013][200/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.4900 (0.4471)   Prec@1 85.938 (84.523)   Prec@5 99.219 (99.335)   [2019-11-22 00:18:14]
  Epoch: [013][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.4914 (0.4565)   Prec@1 84.375 (84.201)   Prec@5 99.219 (99.320)   [2019-11-22 00:18:18]
  **Train** Prec@1 84.210 Prec@5 99.294 Error@1 15.790
  **Test** Prec@1 81.450 Prec@5 99.040 Error@1 18.550
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:18:24] [Epoch=014/200] [Need: 01:01:42] [LR=0.0100][M=0.90] [Best : Accuracy=81.45, Error=18.55]
  Epoch: [014][000/391]   Time 0.230 (0.230)   Data 0.174 (0.174)   Loss 0.5207 (0.5207)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2019-11-22 00:18:24]
  Epoch: [014][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.3923 (0.4413)   Prec@1 89.844 (84.754)   Prec@5 99.219 (99.389)   [2019-11-22 00:18:29]
  Epoch: [014][200/391]   Time 0.038 (0.048)   Data 0.000 (0.001)   Loss 0.4436 (0.4504)   Prec@1 86.719 (84.437)   Prec@5 98.438 (99.370)   [2019-11-22 00:18:34]
  Epoch: [014][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.5242 (0.4501)   Prec@1 84.375 (84.406)   Prec@5 99.219 (99.369)   [2019-11-22 00:18:38]
  **Train** Prec@1 84.424 Prec@5 99.340 Error@1 15.576
  **Test** Prec@1 81.210 Prec@5 99.090 Error@1 18.790

==>>[2019-11-22 00:18:44] [Epoch=015/200] [Need: 01:01:29] [LR=0.0100][M=0.90] [Best : Accuracy=81.45, Error=18.55]
  Epoch: [015][000/391]   Time 0.215 (0.215)   Data 0.158 (0.158)   Loss 0.4743 (0.4743)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 00:18:45]
  Epoch: [015][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.3642 (0.4254)   Prec@1 84.375 (85.404)   Prec@5 99.219 (99.428)   [2019-11-22 00:18:49]
  Epoch: [015][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.4890 (0.4374)   Prec@1 82.812 (84.900)   Prec@5 100.000 (99.401)   [2019-11-22 00:18:54]
  Epoch: [015][300/391]   Time 0.039 (0.048)   Data 0.000 (0.001)   Loss 0.4555 (0.4383)   Prec@1 86.719 (84.941)   Prec@5 98.438 (99.395)   [2019-11-22 00:18:59]
  **Train** Prec@1 84.868 Prec@5 99.374 Error@1 15.132
  **Test** Prec@1 82.000 Prec@5 99.060 Error@1 18.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:19:05] [Epoch=016/200] [Need: 01:01:12] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [016][000/391]   Time 0.224 (0.224)   Data 0.171 (0.171)   Loss 0.4321 (0.4321)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 00:19:05]
  Epoch: [016][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.3598 (0.4170)   Prec@1 89.062 (85.412)   Prec@5 99.219 (99.428)   [2019-11-22 00:19:10]
  Epoch: [016][200/391]   Time 0.038 (0.048)   Data 0.000 (0.001)   Loss 0.5152 (0.4274)   Prec@1 82.031 (85.312)   Prec@5 98.438 (99.421)   [2019-11-22 00:19:14]
  Epoch: [016][300/391]   Time 0.038 (0.048)   Data 0.000 (0.001)   Loss 0.3635 (0.4333)   Prec@1 85.156 (85.019)   Prec@5 99.219 (99.380)   [2019-11-22 00:19:19]
  **Train** Prec@1 85.174 Prec@5 99.374 Error@1 14.826
  **Test** Prec@1 80.710 Prec@5 98.950 Error@1 19.290

==>>[2019-11-22 00:19:24] [Epoch=017/200] [Need: 01:00:50] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [017][000/391]   Time 0.222 (0.222)   Data 0.149 (0.149)   Loss 0.3176 (0.3176)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 00:19:25]
  Epoch: [017][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.4641 (0.4182)   Prec@1 84.375 (85.752)   Prec@5 99.219 (99.428)   [2019-11-22 00:19:29]
  Epoch: [017][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.6073 (0.4231)   Prec@1 80.469 (85.475)   Prec@5 100.000 (99.436)   [2019-11-22 00:19:34]
  Epoch: [017][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.5046 (0.4238)   Prec@1 82.812 (85.372)   Prec@5 98.438 (99.452)   [2019-11-22 00:19:39]
  **Train** Prec@1 85.336 Prec@5 99.450 Error@1 14.664
  **Test** Prec@1 79.370 Prec@5 98.560 Error@1 20.630

==>>[2019-11-22 00:19:45] [Epoch=018/200] [Need: 01:00:34] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [018][000/391]   Time 0.223 (0.223)   Data 0.146 (0.146)   Loss 0.3036 (0.3036)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:19:45]
  Epoch: [018][100/391]   Time 0.052 (0.050)   Data 0.000 (0.002)   Loss 0.4818 (0.4060)   Prec@1 82.031 (85.791)   Prec@5 99.219 (99.412)   [2019-11-22 00:19:50]
  Epoch: [018][200/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.4109 (0.4163)   Prec@1 85.938 (85.421)   Prec@5 98.438 (99.440)   [2019-11-22 00:19:54]
  Epoch: [018][300/391]   Time 0.036 (0.048)   Data 0.000 (0.001)   Loss 0.5906 (0.4166)   Prec@1 78.125 (85.473)   Prec@5 98.438 (99.424)   [2019-11-22 00:19:59]
  **Train** Prec@1 85.354 Prec@5 99.402 Error@1 14.646
  **Test** Prec@1 81.540 Prec@5 98.960 Error@1 18.460

==>>[2019-11-22 00:20:05] [Epoch=019/200] [Need: 01:00:18] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [019][000/391]   Time 0.231 (0.231)   Data 0.176 (0.176)   Loss 0.4819 (0.4819)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2019-11-22 00:20:05]
  Epoch: [019][100/391]   Time 0.047 (0.048)   Data 0.000 (0.002)   Loss 0.3465 (0.4142)   Prec@1 89.844 (85.705)   Prec@5 100.000 (99.420)   [2019-11-22 00:20:10]
  Epoch: [019][200/391]   Time 0.058 (0.049)   Data 0.000 (0.001)   Loss 0.4865 (0.4088)   Prec@1 82.031 (85.704)   Prec@5 100.000 (99.468)   [2019-11-22 00:20:15]
  Epoch: [019][300/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.4564 (0.4104)   Prec@1 82.812 (85.704)   Prec@5 99.219 (99.447)   [2019-11-22 00:20:19]
  **Train** Prec@1 85.700 Prec@5 99.460 Error@1 14.300
  **Test** Prec@1 80.760 Prec@5 98.900 Error@1 19.240

==>>[2019-11-22 00:20:25] [Epoch=020/200] [Need: 00:59:58] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [020][000/391]   Time 0.214 (0.214)   Data 0.145 (0.145)   Loss 0.3542 (0.3542)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 00:20:25]
  Epoch: [020][100/391]   Time 0.039 (0.047)   Data 0.000 (0.002)   Loss 0.4066 (0.3955)   Prec@1 85.156 (86.494)   Prec@5 99.219 (99.497)   [2019-11-22 00:20:30]
  Epoch: [020][200/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.4046 (0.4001)   Prec@1 83.594 (86.315)   Prec@5 98.438 (99.444)   [2019-11-22 00:20:34]
  Epoch: [020][300/391]   Time 0.047 (0.044)   Data 0.000 (0.001)   Loss 0.4543 (0.4030)   Prec@1 85.938 (86.187)   Prec@5 97.656 (99.421)   [2019-11-22 00:20:38]
  **Train** Prec@1 86.160 Prec@5 99.424 Error@1 13.840
  **Test** Prec@1 80.930 Prec@5 99.170 Error@1 19.070

==>>[2019-11-22 00:20:44] [Epoch=021/200] [Need: 00:59:33] [LR=0.0100][M=0.90] [Best : Accuracy=82.00, Error=18.00]
  Epoch: [021][000/391]   Time 0.224 (0.224)   Data 0.145 (0.145)   Loss 0.3936 (0.3936)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-22 00:20:45]
  Epoch: [021][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.6186 (0.3958)   Prec@1 82.031 (86.247)   Prec@5 98.438 (99.474)   [2019-11-22 00:20:49]
  Epoch: [021][200/391]   Time 0.050 (0.046)   Data 0.000 (0.001)   Loss 0.4997 (0.3967)   Prec@1 82.812 (86.213)   Prec@5 99.219 (99.491)   [2019-11-22 00:20:54]
  Epoch: [021][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.4747 (0.3977)   Prec@1 83.594 (86.215)   Prec@5 100.000 (99.439)   [2019-11-22 00:20:58]
  **Train** Prec@1 86.110 Prec@5 99.446 Error@1 13.890
  **Test** Prec@1 83.950 Prec@5 99.340 Error@1 16.050
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:21:04] [Epoch=022/200] [Need: 00:59:14] [LR=0.0100][M=0.90] [Best : Accuracy=83.95, Error=16.05]
  Epoch: [022][000/391]   Time 0.214 (0.214)   Data 0.157 (0.157)   Loss 0.3717 (0.3717)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-22 00:21:05]
  Epoch: [022][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.3839 (0.3848)   Prec@1 84.375 (86.665)   Prec@5 100.000 (99.606)   [2019-11-22 00:21:09]
  Epoch: [022][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.4776 (0.3829)   Prec@1 85.938 (86.579)   Prec@5 100.000 (99.557)   [2019-11-22 00:21:14]
  Epoch: [022][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.3331 (0.3886)   Prec@1 87.500 (86.405)   Prec@5 100.000 (99.499)   [2019-11-22 00:21:18]
  **Train** Prec@1 86.242 Prec@5 99.460 Error@1 13.758
  **Test** Prec@1 80.760 Prec@5 98.910 Error@1 19.240

==>>[2019-11-22 00:21:24] [Epoch=023/200] [Need: 00:58:49] [LR=0.0100][M=0.90] [Best : Accuracy=83.95, Error=16.05]
  Epoch: [023][000/391]   Time 0.230 (0.230)   Data 0.173 (0.173)   Loss 0.2895 (0.2895)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:21:24]
  Epoch: [023][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.4309 (0.3531)   Prec@1 86.719 (87.686)   Prec@5 100.000 (99.497)   [2019-11-22 00:21:29]
  Epoch: [023][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2961 (0.3699)   Prec@1 90.625 (87.251)   Prec@5 100.000 (99.479)   [2019-11-22 00:21:34]
  Epoch: [023][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.4203 (0.3797)   Prec@1 86.719 (86.872)   Prec@5 99.219 (99.481)   [2019-11-22 00:21:39]
  **Train** Prec@1 86.570 Prec@5 99.504 Error@1 13.430
  **Test** Prec@1 82.710 Prec@5 99.260 Error@1 17.290

==>>[2019-11-22 00:21:45] [Epoch=024/200] [Need: 00:58:40] [LR=0.0100][M=0.90] [Best : Accuracy=83.95, Error=16.05]
  Epoch: [024][000/391]   Time 0.227 (0.227)   Data 0.147 (0.147)   Loss 0.3618 (0.3618)   Prec@1 88.281 (88.281)   Prec@5 97.656 (97.656)   [2019-11-22 00:21:46]
  Epoch: [024][100/391]   Time 0.052 (0.049)   Data 0.000 (0.002)   Loss 0.3881 (0.3799)   Prec@1 88.281 (86.757)   Prec@5 100.000 (99.544)   [2019-11-22 00:21:50]
  Epoch: [024][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.4663 (0.3797)   Prec@1 82.812 (86.878)   Prec@5 98.438 (99.541)   [2019-11-22 00:21:55]
  Epoch: [024][300/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.5733 (0.3842)   Prec@1 79.688 (86.672)   Prec@5 99.219 (99.541)   [2019-11-22 00:21:59]
  **Train** Prec@1 86.686 Prec@5 99.512 Error@1 13.314
  **Test** Prec@1 84.310 Prec@5 99.330 Error@1 15.690
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:22:05] [Epoch=025/200] [Need: 00:58:16] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [025][000/391]   Time 0.231 (0.231)   Data 0.171 (0.171)   Loss 0.3010 (0.3010)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:22:05]
  Epoch: [025][100/391]   Time 0.051 (0.049)   Data 0.000 (0.002)   Loss 0.3849 (0.3608)   Prec@1 88.281 (87.662)   Prec@5 99.219 (99.582)   [2019-11-22 00:22:10]
  Epoch: [025][200/391]   Time 0.049 (0.049)   Data 0.000 (0.001)   Loss 0.3298 (0.3742)   Prec@1 87.500 (87.158)   Prec@5 99.219 (99.506)   [2019-11-22 00:22:15]
  Epoch: [025][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.2058 (0.3788)   Prec@1 94.531 (86.856)   Prec@5 100.000 (99.551)   [2019-11-22 00:22:19]
  **Train** Prec@1 86.796 Prec@5 99.532 Error@1 13.204
  **Test** Prec@1 83.790 Prec@5 99.240 Error@1 16.210

==>>[2019-11-22 00:22:25] [Epoch=026/200] [Need: 00:57:58] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [026][000/391]   Time 0.214 (0.214)   Data 0.155 (0.155)   Loss 0.2912 (0.2912)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:22:25]
  Epoch: [026][100/391]   Time 0.080 (0.049)   Data 0.000 (0.002)   Loss 0.3202 (0.3661)   Prec@1 90.625 (87.252)   Prec@5 99.219 (99.698)   [2019-11-22 00:22:30]
  Epoch: [026][200/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.3267 (0.3742)   Prec@1 87.500 (86.987)   Prec@5 99.219 (99.635)   [2019-11-22 00:22:35]
  Epoch: [026][300/391]   Time 0.052 (0.047)   Data 0.000 (0.001)   Loss 0.3793 (0.3745)   Prec@1 86.719 (86.989)   Prec@5 99.219 (99.613)   [2019-11-22 00:22:39]
  **Train** Prec@1 86.938 Prec@5 99.574 Error@1 13.062
  **Test** Prec@1 81.470 Prec@5 98.900 Error@1 18.530

==>>[2019-11-22 00:22:45] [Epoch=027/200] [Need: 00:57:38] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [027][000/391]   Time 0.216 (0.216)   Data 0.145 (0.145)   Loss 0.4150 (0.4150)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 00:22:45]
  Epoch: [027][100/391]   Time 0.040 (0.052)   Data 0.000 (0.002)   Loss 0.2832 (0.3555)   Prec@1 91.406 (87.570)   Prec@5 100.000 (99.636)   [2019-11-22 00:22:50]
  Epoch: [027][200/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.3918 (0.3683)   Prec@1 85.156 (87.065)   Prec@5 99.219 (99.639)   [2019-11-22 00:22:55]
  Epoch: [027][300/391]   Time 0.074 (0.047)   Data 0.000 (0.001)   Loss 0.2959 (0.3702)   Prec@1 89.062 (87.043)   Prec@5 100.000 (99.618)   [2019-11-22 00:22:59]
  **Train** Prec@1 86.990 Prec@5 99.602 Error@1 13.010
  **Test** Prec@1 82.570 Prec@5 99.430 Error@1 17.430

==>>[2019-11-22 00:23:05] [Epoch=028/200] [Need: 00:57:17] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [028][000/391]   Time 0.221 (0.221)   Data 0.167 (0.167)   Loss 0.4907 (0.4907)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2019-11-22 00:23:05]
  Epoch: [028][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.2664 (0.3499)   Prec@1 89.062 (87.755)   Prec@5 100.000 (99.706)   [2019-11-22 00:23:10]
  Epoch: [028][200/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.4043 (0.3639)   Prec@1 86.719 (87.317)   Prec@5 99.219 (99.604)   [2019-11-22 00:23:14]
  Epoch: [028][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.2561 (0.3687)   Prec@1 92.188 (87.207)   Prec@5 100.000 (99.546)   [2019-11-22 00:23:19]
  **Train** Prec@1 87.236 Prec@5 99.528 Error@1 12.764
  **Test** Prec@1 83.170 Prec@5 98.810 Error@1 16.830

==>>[2019-11-22 00:23:25] [Epoch=029/200] [Need: 00:57:00] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [029][000/391]   Time 0.223 (0.223)   Data 0.165 (0.165)   Loss 0.3850 (0.3850)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 00:23:25]
  Epoch: [029][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.4541 (0.3565)   Prec@1 84.375 (87.338)   Prec@5 100.000 (99.551)   [2019-11-22 00:23:30]
  Epoch: [029][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.5132 (0.3623)   Prec@1 83.594 (87.271)   Prec@5 99.219 (99.530)   [2019-11-22 00:23:35]
  Epoch: [029][300/391]   Time 0.057 (0.046)   Data 0.000 (0.001)   Loss 0.4469 (0.3633)   Prec@1 85.156 (87.451)   Prec@5 100.000 (99.546)   [2019-11-22 00:23:39]
  **Train** Prec@1 87.446 Prec@5 99.536 Error@1 12.554
  **Test** Prec@1 82.980 Prec@5 99.260 Error@1 17.020

==>>[2019-11-22 00:23:45] [Epoch=030/200] [Need: 00:56:40] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [030][000/391]   Time 0.210 (0.210)   Data 0.144 (0.144)   Loss 0.4050 (0.4050)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 00:23:45]
  Epoch: [030][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.4084 (0.3541)   Prec@1 87.500 (87.539)   Prec@5 98.438 (99.644)   [2019-11-22 00:23:50]
  Epoch: [030][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.3519 (0.3612)   Prec@1 84.375 (87.337)   Prec@5 100.000 (99.572)   [2019-11-22 00:23:55]
  Epoch: [030][300/391]   Time 0.046 (0.047)   Data 0.000 (0.001)   Loss 0.4078 (0.3625)   Prec@1 84.375 (87.394)   Prec@5 100.000 (99.572)   [2019-11-22 00:23:59]
  **Train** Prec@1 87.292 Prec@5 99.574 Error@1 12.708
  **Test** Prec@1 82.570 Prec@5 99.450 Error@1 17.430

==>>[2019-11-22 00:24:05] [Epoch=031/200] [Need: 00:56:20] [LR=0.0100][M=0.90] [Best : Accuracy=84.31, Error=15.69]
  Epoch: [031][000/391]   Time 0.203 (0.203)   Data 0.148 (0.148)   Loss 0.4296 (0.4296)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-22 00:24:06]
  Epoch: [031][100/391]   Time 0.045 (0.047)   Data 0.000 (0.002)   Loss 0.3064 (0.3503)   Prec@1 91.406 (88.003)   Prec@5 99.219 (99.606)   [2019-11-22 00:24:10]
  Epoch: [031][200/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.2812 (0.3577)   Prec@1 91.406 (87.655)   Prec@5 99.219 (99.600)   [2019-11-22 00:24:15]
  Epoch: [031][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.4214 (0.3602)   Prec@1 85.156 (87.490)   Prec@5 100.000 (99.624)   [2019-11-22 00:24:20]
  **Train** Prec@1 87.458 Prec@5 99.618 Error@1 12.542
  **Test** Prec@1 84.900 Prec@5 99.350 Error@1 15.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:24:26] [Epoch=032/200] [Need: 00:56:02] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [032][000/391]   Time 0.215 (0.215)   Data 0.146 (0.146)   Loss 0.3916 (0.3916)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-22 00:24:26]
  Epoch: [032][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.3581 (0.3394)   Prec@1 87.500 (87.964)   Prec@5 100.000 (99.536)   [2019-11-22 00:24:30]
  Epoch: [032][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.3851 (0.3430)   Prec@1 87.500 (87.959)   Prec@5 97.656 (99.607)   [2019-11-22 00:24:35]
  Epoch: [032][300/391]   Time 0.049 (0.046)   Data 0.000 (0.001)   Loss 0.3660 (0.3518)   Prec@1 87.500 (87.721)   Prec@5 99.219 (99.543)   [2019-11-22 00:24:39]
  **Train** Prec@1 87.650 Prec@5 99.568 Error@1 12.350
  **Test** Prec@1 83.120 Prec@5 99.210 Error@1 16.880

==>>[2019-11-22 00:24:46] [Epoch=033/200] [Need: 00:55:43] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [033][000/391]   Time 0.214 (0.214)   Data 0.146 (0.146)   Loss 0.3389 (0.3389)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 00:24:46]
  Epoch: [033][100/391]   Time 0.041 (0.044)   Data 0.000 (0.002)   Loss 0.3469 (0.3433)   Prec@1 89.062 (87.848)   Prec@5 100.000 (99.590)   [2019-11-22 00:24:50]
  Epoch: [033][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.4449 (0.3487)   Prec@1 85.938 (87.799)   Prec@5 100.000 (99.639)   [2019-11-22 00:24:55]
  Epoch: [033][300/391]   Time 0.060 (0.046)   Data 0.000 (0.001)   Loss 0.2146 (0.3481)   Prec@1 93.750 (87.892)   Prec@5 100.000 (99.616)   [2019-11-22 00:25:00]
  **Train** Prec@1 87.660 Prec@5 99.596 Error@1 12.340
  **Test** Prec@1 81.740 Prec@5 98.810 Error@1 18.260

==>>[2019-11-22 00:25:06] [Epoch=034/200] [Need: 00:55:22] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [034][000/391]   Time 0.233 (0.233)   Data 0.178 (0.178)   Loss 0.3240 (0.3240)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 00:25:06]
  Epoch: [034][100/391]   Time 0.065 (0.047)   Data 0.000 (0.002)   Loss 0.4957 (0.3457)   Prec@1 86.719 (88.127)   Prec@5 99.219 (99.629)   [2019-11-22 00:25:10]
  Epoch: [034][200/391]   Time 0.072 (0.046)   Data 0.000 (0.001)   Loss 0.3199 (0.3457)   Prec@1 90.625 (88.048)   Prec@5 100.000 (99.607)   [2019-11-22 00:25:15]
  Epoch: [034][300/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.4064 (0.3475)   Prec@1 86.719 (87.954)   Prec@5 100.000 (99.608)   [2019-11-22 00:25:19]
  **Train** Prec@1 87.812 Prec@5 99.616 Error@1 12.188
  **Test** Prec@1 83.080 Prec@5 99.240 Error@1 16.920

==>>[2019-11-22 00:25:25] [Epoch=035/200] [Need: 00:55:00] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [035][000/391]   Time 0.216 (0.216)   Data 0.162 (0.162)   Loss 0.2794 (0.2794)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:25:26]
  Epoch: [035][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.3092 (0.3253)   Prec@1 89.062 (88.513)   Prec@5 100.000 (99.629)   [2019-11-22 00:25:30]
  Epoch: [035][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3054 (0.3429)   Prec@1 89.844 (87.966)   Prec@5 100.000 (99.642)   [2019-11-22 00:25:35]
  Epoch: [035][300/391]   Time 0.072 (0.047)   Data 0.000 (0.001)   Loss 0.3608 (0.3435)   Prec@1 87.500 (88.045)   Prec@5 98.438 (99.611)   [2019-11-22 00:25:39]
  **Train** Prec@1 87.852 Prec@5 99.582 Error@1 12.148
  **Test** Prec@1 84.040 Prec@5 99.230 Error@1 15.960

==>>[2019-11-22 00:25:45] [Epoch=036/200] [Need: 00:54:41] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [036][000/391]   Time 0.222 (0.222)   Data 0.154 (0.154)   Loss 0.2821 (0.2821)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:25:46]
  Epoch: [036][100/391]   Time 0.047 (0.048)   Data 0.000 (0.002)   Loss 0.4723 (0.3404)   Prec@1 85.938 (88.173)   Prec@5 98.438 (99.636)   [2019-11-22 00:25:50]
  Epoch: [036][200/391]   Time 0.049 (0.047)   Data 0.000 (0.001)   Loss 0.3142 (0.3315)   Prec@1 86.719 (88.538)   Prec@5 100.000 (99.642)   [2019-11-22 00:25:55]
  Epoch: [036][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.3155 (0.3399)   Prec@1 89.062 (88.336)   Prec@5 100.000 (99.574)   [2019-11-22 00:26:00]
  **Train** Prec@1 88.266 Prec@5 99.544 Error@1 11.734
  **Test** Prec@1 84.790 Prec@5 99.170 Error@1 15.210

==>>[2019-11-22 00:26:05] [Epoch=037/200] [Need: 00:54:20] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [037][000/391]   Time 0.216 (0.216)   Data 0.160 (0.160)   Loss 0.2954 (0.2954)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2019-11-22 00:26:06]
  Epoch: [037][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3113 (0.3333)   Prec@1 89.062 (88.560)   Prec@5 98.438 (99.551)   [2019-11-22 00:26:11]
  Epoch: [037][200/391]   Time 0.056 (0.048)   Data 0.000 (0.001)   Loss 0.3249 (0.3404)   Prec@1 89.844 (88.172)   Prec@5 100.000 (99.596)   [2019-11-22 00:26:15]
  Epoch: [037][300/391]   Time 0.054 (0.048)   Data 0.000 (0.001)   Loss 0.2717 (0.3454)   Prec@1 90.625 (88.131)   Prec@5 100.000 (99.587)   [2019-11-22 00:26:20]
  **Train** Prec@1 88.132 Prec@5 99.598 Error@1 11.868
  **Test** Prec@1 82.970 Prec@5 99.040 Error@1 17.030

==>>[2019-11-22 00:26:26] [Epoch=038/200] [Need: 00:54:03] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [038][000/391]   Time 0.205 (0.205)   Data 0.144 (0.144)   Loss 0.2218 (0.2218)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:26:26]
  Epoch: [038][100/391]   Time 0.048 (0.048)   Data 0.000 (0.002)   Loss 0.3115 (0.3235)   Prec@1 86.719 (89.039)   Prec@5 100.000 (99.629)   [2019-11-22 00:26:31]
  Epoch: [038][200/391]   Time 0.045 (0.047)   Data 0.000 (0.001)   Loss 0.2671 (0.3352)   Prec@1 92.188 (88.281)   Prec@5 100.000 (99.646)   [2019-11-22 00:26:35]
  Epoch: [038][300/391]   Time 0.043 (0.045)   Data 0.000 (0.001)   Loss 0.4801 (0.3404)   Prec@1 87.500 (88.162)   Prec@5 99.219 (99.637)   [2019-11-22 00:26:40]
  **Train** Prec@1 88.050 Prec@5 99.634 Error@1 11.950
  **Test** Prec@1 82.640 Prec@5 98.940 Error@1 17.360

==>>[2019-11-22 00:26:45] [Epoch=039/200] [Need: 00:53:40] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [039][000/391]   Time 0.217 (0.217)   Data 0.159 (0.159)   Loss 0.3458 (0.3458)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2019-11-22 00:26:46]
  Epoch: [039][100/391]   Time 0.069 (0.052)   Data 0.000 (0.002)   Loss 0.4833 (0.3325)   Prec@1 85.156 (88.359)   Prec@5 100.000 (99.567)   [2019-11-22 00:26:51]
  Epoch: [039][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.2570 (0.3369)   Prec@1 89.844 (88.161)   Prec@5 100.000 (99.611)   [2019-11-22 00:26:56]
  Epoch: [039][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.3607 (0.3385)   Prec@1 86.719 (88.128)   Prec@5 100.000 (99.644)   [2019-11-22 00:27:00]
  **Train** Prec@1 88.058 Prec@5 99.658 Error@1 11.942
  **Test** Prec@1 84.330 Prec@5 99.250 Error@1 15.670

==>>[2019-11-22 00:27:06] [Epoch=040/200] [Need: 00:53:22] [LR=0.0100][M=0.90] [Best : Accuracy=84.90, Error=15.10]
  Epoch: [040][000/391]   Time 0.229 (0.229)   Data 0.163 (0.163)   Loss 0.2188 (0.2188)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 00:27:06]
  Epoch: [040][100/391]   Time 0.040 (0.046)   Data 0.000 (0.002)   Loss 0.3304 (0.3240)   Prec@1 88.281 (88.622)   Prec@5 100.000 (99.629)   [2019-11-22 00:27:10]
  Epoch: [040][200/391]   Time 0.055 (0.046)   Data 0.000 (0.001)   Loss 0.3757 (0.3343)   Prec@1 85.938 (88.293)   Prec@5 100.000 (99.623)   [2019-11-22 00:27:15]
  Epoch: [040][300/391]   Time 0.073 (0.046)   Data 0.000 (0.001)   Loss 0.3280 (0.3342)   Prec@1 86.719 (88.349)   Prec@5 100.000 (99.631)   [2019-11-22 00:27:20]
  **Train** Prec@1 88.358 Prec@5 99.650 Error@1 11.642
  **Test** Prec@1 85.720 Prec@5 99.470 Error@1 14.280
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:27:26] [Epoch=041/200] [Need: 00:53:01] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [041][000/391]   Time 0.216 (0.216)   Data 0.157 (0.157)   Loss 0.4979 (0.4979)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2019-11-22 00:27:26]
  Epoch: [041][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.3367 (0.3259)   Prec@1 87.500 (88.776)   Prec@5 100.000 (99.683)   [2019-11-22 00:27:31]
  Epoch: [041][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3433 (0.3295)   Prec@1 85.156 (88.534)   Prec@5 100.000 (99.693)   [2019-11-22 00:27:35]
  Epoch: [041][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.3533 (0.3355)   Prec@1 86.719 (88.375)   Prec@5 100.000 (99.694)   [2019-11-22 00:27:39]
  **Train** Prec@1 88.334 Prec@5 99.692 Error@1 11.666
  **Test** Prec@1 78.680 Prec@5 98.940 Error@1 21.320

==>>[2019-11-22 00:27:45] [Epoch=042/200] [Need: 00:52:39] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [042][000/391]   Time 0.209 (0.209)   Data 0.158 (0.158)   Loss 0.2959 (0.2959)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:27:45]
  Epoch: [042][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.3723 (0.3182)   Prec@1 89.844 (89.062)   Prec@5 100.000 (99.644)   [2019-11-22 00:27:50]
  Epoch: [042][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.3334 (0.3211)   Prec@1 88.281 (88.868)   Prec@5 99.219 (99.611)   [2019-11-22 00:27:55]
  Epoch: [042][300/391]   Time 0.039 (0.048)   Data 0.000 (0.001)   Loss 0.2641 (0.3287)   Prec@1 91.406 (88.606)   Prec@5 100.000 (99.626)   [2019-11-22 00:27:59]
  **Train** Prec@1 88.482 Prec@5 99.638 Error@1 11.518
  **Test** Prec@1 81.720 Prec@5 98.750 Error@1 18.280

==>>[2019-11-22 00:28:06] [Epoch=043/200] [Need: 00:52:21] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [043][000/391]   Time 0.220 (0.220)   Data 0.159 (0.159)   Loss 0.2952 (0.2952)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:28:06]
  Epoch: [043][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.2552 (0.3101)   Prec@1 90.625 (88.869)   Prec@5 100.000 (99.714)   [2019-11-22 00:28:11]
  Epoch: [043][200/391]   Time 0.039 (0.050)   Data 0.000 (0.001)   Loss 0.3682 (0.3212)   Prec@1 86.719 (88.503)   Prec@5 99.219 (99.693)   [2019-11-22 00:28:16]
  Epoch: [043][300/391]   Time 0.072 (0.049)   Data 0.000 (0.001)   Loss 0.3128 (0.3248)   Prec@1 89.062 (88.515)   Prec@5 99.219 (99.668)   [2019-11-22 00:28:20]
  **Train** Prec@1 88.426 Prec@5 99.668 Error@1 11.574
  **Test** Prec@1 83.680 Prec@5 99.330 Error@1 16.320

==>>[2019-11-22 00:28:27] [Epoch=044/200] [Need: 00:52:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [044][000/391]   Time 0.212 (0.212)   Data 0.158 (0.158)   Loss 0.3377 (0.3377)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-22 00:28:27]
  Epoch: [044][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.3945 (0.3224)   Prec@1 87.500 (88.714)   Prec@5 100.000 (99.629)   [2019-11-22 00:28:31]
  Epoch: [044][200/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.2641 (0.3324)   Prec@1 89.844 (88.343)   Prec@5 100.000 (99.631)   [2019-11-22 00:28:37]
  Epoch: [044][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.4298 (0.3332)   Prec@1 85.938 (88.411)   Prec@5 100.000 (99.650)   [2019-11-22 00:28:41]
  **Train** Prec@1 88.456 Prec@5 99.636 Error@1 11.544
  **Test** Prec@1 81.880 Prec@5 99.220 Error@1 18.120

==>>[2019-11-22 00:28:47] [Epoch=045/200] [Need: 00:51:46] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [045][000/391]   Time 0.225 (0.225)   Data 0.168 (0.168)   Loss 0.2832 (0.2832)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 00:28:47]
  Epoch: [045][100/391]   Time 0.037 (0.046)   Data 0.000 (0.002)   Loss 0.4316 (0.3278)   Prec@1 85.938 (88.606)   Prec@5 99.219 (99.667)   [2019-11-22 00:28:52]
  Epoch: [045][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.3018 (0.3300)   Prec@1 91.406 (88.476)   Prec@5 100.000 (99.677)   [2019-11-22 00:28:56]
  Epoch: [045][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.3574 (0.3278)   Prec@1 85.938 (88.533)   Prec@5 99.219 (99.670)   [2019-11-22 00:29:01]
  **Train** Prec@1 88.520 Prec@5 99.646 Error@1 11.480
  **Test** Prec@1 83.140 Prec@5 99.060 Error@1 16.860

==>>[2019-11-22 00:29:06] [Epoch=046/200] [Need: 00:51:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [046][000/391]   Time 0.212 (0.212)   Data 0.138 (0.138)   Loss 0.3541 (0.3541)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 00:29:07]
  Epoch: [046][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.2266 (0.3260)   Prec@1 92.969 (88.537)   Prec@5 99.219 (99.698)   [2019-11-22 00:29:11]
  Epoch: [046][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.4070 (0.3299)   Prec@1 86.719 (88.522)   Prec@5 97.656 (99.658)   [2019-11-22 00:29:16]
  Epoch: [046][300/391]   Time 0.072 (0.047)   Data 0.000 (0.001)   Loss 0.4155 (0.3242)   Prec@1 83.594 (88.637)   Prec@5 99.219 (99.686)   [2019-11-22 00:29:20]
  **Train** Prec@1 88.608 Prec@5 99.678 Error@1 11.392
  **Test** Prec@1 84.550 Prec@5 99.330 Error@1 15.450

==>>[2019-11-22 00:29:26] [Epoch=047/200] [Need: 00:51:03] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [047][000/391]   Time 0.217 (0.217)   Data 0.161 (0.161)   Loss 0.1649 (0.1649)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:29:26]
  Epoch: [047][100/391]   Time 0.047 (0.046)   Data 0.000 (0.002)   Loss 0.2573 (0.3149)   Prec@1 88.281 (89.001)   Prec@5 100.000 (99.629)   [2019-11-22 00:29:31]
  Epoch: [047][200/391]   Time 0.071 (0.047)   Data 0.000 (0.001)   Loss 0.2793 (0.3250)   Prec@1 89.844 (88.666)   Prec@5 100.000 (99.677)   [2019-11-22 00:29:36]
  Epoch: [047][300/391]   Time 0.079 (0.046)   Data 0.000 (0.001)   Loss 0.2961 (0.3253)   Prec@1 89.062 (88.707)   Prec@5 100.000 (99.657)   [2019-11-22 00:29:40]
  **Train** Prec@1 88.616 Prec@5 99.686 Error@1 11.384
  **Test** Prec@1 83.750 Prec@5 99.310 Error@1 16.250

==>>[2019-11-22 00:29:46] [Epoch=048/200] [Need: 00:50:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [048][000/391]   Time 0.227 (0.227)   Data 0.170 (0.170)   Loss 0.2129 (0.2129)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:29:46]
  Epoch: [048][100/391]   Time 0.040 (0.053)   Data 0.000 (0.002)   Loss 0.3047 (0.3223)   Prec@1 89.062 (88.916)   Prec@5 100.000 (99.636)   [2019-11-22 00:29:51]
  Epoch: [048][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.2309 (0.3218)   Prec@1 90.625 (88.771)   Prec@5 99.219 (99.674)   [2019-11-22 00:29:56]
  Epoch: [048][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.3656 (0.3240)   Prec@1 86.719 (88.652)   Prec@5 99.219 (99.689)   [2019-11-22 00:30:01]
  **Train** Prec@1 88.580 Prec@5 99.654 Error@1 11.420
  **Test** Prec@1 84.390 Prec@5 99.320 Error@1 15.610

==>>[2019-11-22 00:30:07] [Epoch=049/200] [Need: 00:50:25] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [049][000/391]   Time 0.215 (0.215)   Data 0.153 (0.153)   Loss 0.2761 (0.2761)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-22 00:30:07]
  Epoch: [049][100/391]   Time 0.044 (0.049)   Data 0.000 (0.002)   Loss 0.2384 (0.3269)   Prec@1 90.625 (88.699)   Prec@5 100.000 (99.667)   [2019-11-22 00:30:12]
  Epoch: [049][200/391]   Time 0.057 (0.049)   Data 0.000 (0.001)   Loss 0.4989 (0.3244)   Prec@1 82.812 (88.697)   Prec@5 98.438 (99.677)   [2019-11-22 00:30:17]
  Epoch: [049][300/391]   Time 0.065 (0.047)   Data 0.000 (0.001)   Loss 0.2708 (0.3230)   Prec@1 89.844 (88.689)   Prec@5 100.000 (99.686)   [2019-11-22 00:30:21]
  **Train** Prec@1 88.614 Prec@5 99.694 Error@1 11.386
  **Test** Prec@1 85.030 Prec@5 99.440 Error@1 14.970

==>>[2019-11-22 00:30:27] [Epoch=050/200] [Need: 00:50:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [050][000/391]   Time 0.210 (0.210)   Data 0.150 (0.150)   Loss 0.2228 (0.2228)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:30:27]
  Epoch: [050][100/391]   Time 0.041 (0.047)   Data 0.000 (0.002)   Loss 0.2075 (0.3082)   Prec@1 92.969 (89.349)   Prec@5 100.000 (99.652)   [2019-11-22 00:30:32]
  Epoch: [050][200/391]   Time 0.044 (0.045)   Data 0.000 (0.001)   Loss 0.2437 (0.3169)   Prec@1 92.188 (89.140)   Prec@5 98.438 (99.639)   [2019-11-22 00:30:36]
  Epoch: [050][300/391]   Time 0.043 (0.045)   Data 0.000 (0.001)   Loss 0.4176 (0.3171)   Prec@1 84.375 (89.083)   Prec@5 100.000 (99.665)   [2019-11-22 00:30:41]
  **Train** Prec@1 88.922 Prec@5 99.664 Error@1 11.078
  **Test** Prec@1 84.870 Prec@5 99.240 Error@1 15.130

==>>[2019-11-22 00:30:46] [Epoch=051/200] [Need: 00:49:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [051][000/391]   Time 0.222 (0.222)   Data 0.160 (0.160)   Loss 0.2705 (0.2705)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-22 00:30:46]
  Epoch: [051][100/391]   Time 0.081 (0.049)   Data 0.000 (0.002)   Loss 0.3274 (0.3000)   Prec@1 85.156 (89.310)   Prec@5 100.000 (99.675)   [2019-11-22 00:30:51]
  Epoch: [051][200/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.2080 (0.3106)   Prec@1 92.188 (89.028)   Prec@5 100.000 (99.674)   [2019-11-22 00:30:56]
  Epoch: [051][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.2511 (0.3134)   Prec@1 90.625 (88.894)   Prec@5 100.000 (99.655)   [2019-11-22 00:31:00]
  **Train** Prec@1 88.856 Prec@5 99.638 Error@1 11.144
  **Test** Prec@1 84.390 Prec@5 99.190 Error@1 15.610

==>>[2019-11-22 00:31:06] [Epoch=052/200] [Need: 00:49:23] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [052][000/391]   Time 0.213 (0.213)   Data 0.143 (0.143)   Loss 0.2993 (0.2993)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:31:07]
  Epoch: [052][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.2953 (0.3120)   Prec@1 91.406 (89.132)   Prec@5 99.219 (99.714)   [2019-11-22 00:31:11]
  Epoch: [052][200/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.4124 (0.3202)   Prec@1 82.812 (88.790)   Prec@5 99.219 (99.689)   [2019-11-22 00:31:16]
  Epoch: [052][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.3220 (0.3195)   Prec@1 90.625 (88.948)   Prec@5 99.219 (99.652)   [2019-11-22 00:31:21]
  **Train** Prec@1 88.870 Prec@5 99.610 Error@1 11.130
  **Test** Prec@1 84.820 Prec@5 99.270 Error@1 15.180

==>>[2019-11-22 00:31:27] [Epoch=053/200] [Need: 00:49:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [053][000/391]   Time 0.231 (0.231)   Data 0.164 (0.164)   Loss 0.2234 (0.2234)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:31:27]
  Epoch: [053][100/391]   Time 0.065 (0.047)   Data 0.000 (0.002)   Loss 0.2032 (0.2993)   Prec@1 92.969 (89.588)   Prec@5 100.000 (99.714)   [2019-11-22 00:31:32]
  Epoch: [053][200/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.2085 (0.3042)   Prec@1 93.750 (89.552)   Prec@5 99.219 (99.685)   [2019-11-22 00:31:36]
  Epoch: [053][300/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.3761 (0.3107)   Prec@1 87.500 (89.301)   Prec@5 100.000 (99.668)   [2019-11-22 00:31:41]
  **Train** Prec@1 89.154 Prec@5 99.652 Error@1 10.846
  **Test** Prec@1 83.360 Prec@5 99.210 Error@1 16.640

==>>[2019-11-22 00:31:47] [Epoch=054/200] [Need: 00:48:45] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [054][000/391]   Time 0.233 (0.233)   Data 0.158 (0.158)   Loss 0.2198 (0.2198)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2019-11-22 00:31:47]
  Epoch: [054][100/391]   Time 0.078 (0.050)   Data 0.000 (0.002)   Loss 0.3410 (0.3024)   Prec@1 88.281 (89.766)   Prec@5 100.000 (99.722)   [2019-11-22 00:31:52]
  Epoch: [054][200/391]   Time 0.055 (0.049)   Data 0.000 (0.001)   Loss 0.2990 (0.3075)   Prec@1 89.062 (89.440)   Prec@5 100.000 (99.732)   [2019-11-22 00:31:57]
  Epoch: [054][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.4103 (0.3174)   Prec@1 83.594 (88.938)   Prec@5 100.000 (99.704)   [2019-11-22 00:32:02]
  **Train** Prec@1 88.940 Prec@5 99.698 Error@1 11.060
  **Test** Prec@1 82.670 Prec@5 99.160 Error@1 17.330

==>>[2019-11-22 00:32:08] [Epoch=055/200] [Need: 00:48:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [055][000/391]   Time 0.229 (0.229)   Data 0.173 (0.173)   Loss 0.3173 (0.3173)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 00:32:08]
  Epoch: [055][100/391]   Time 0.047 (0.055)   Data 0.000 (0.002)   Loss 0.3208 (0.3083)   Prec@1 86.719 (89.225)   Prec@5 100.000 (99.737)   [2019-11-22 00:32:13]
  Epoch: [055][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.3045 (0.3160)   Prec@1 90.625 (88.969)   Prec@5 100.000 (99.666)   [2019-11-22 00:32:18]
  Epoch: [055][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.2801 (0.3175)   Prec@1 91.406 (88.961)   Prec@5 100.000 (99.652)   [2019-11-22 00:32:23]
  **Train** Prec@1 89.042 Prec@5 99.652 Error@1 10.958
  **Test** Prec@1 85.010 Prec@5 99.270 Error@1 14.990

==>>[2019-11-22 00:32:29] [Epoch=056/200] [Need: 00:48:08] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [056][000/391]   Time 0.225 (0.225)   Data 0.162 (0.162)   Loss 0.2881 (0.2881)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 00:32:29]
  Epoch: [056][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.3352 (0.2989)   Prec@1 85.156 (89.442)   Prec@5 100.000 (99.752)   [2019-11-22 00:32:34]
  Epoch: [056][200/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.3070 (0.3112)   Prec@1 87.500 (89.152)   Prec@5 100.000 (99.705)   [2019-11-22 00:32:38]
  Epoch: [056][300/391]   Time 0.049 (0.049)   Data 0.001 (0.001)   Loss 0.2071 (0.3172)   Prec@1 92.188 (88.966)   Prec@5 100.000 (99.670)   [2019-11-22 00:32:43]
  **Train** Prec@1 88.928 Prec@5 99.672 Error@1 11.072
  **Test** Prec@1 85.170 Prec@5 99.310 Error@1 14.830

==>>[2019-11-22 00:32:49] [Epoch=057/200] [Need: 00:47:50] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [057][000/391]   Time 0.222 (0.222)   Data 0.162 (0.162)   Loss 0.3153 (0.3153)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:32:49]
  Epoch: [057][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.3683 (0.3011)   Prec@1 88.281 (89.503)   Prec@5 99.219 (99.660)   [2019-11-22 00:32:54]
  Epoch: [057][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.2940 (0.3048)   Prec@1 89.844 (89.502)   Prec@5 100.000 (99.670)   [2019-11-22 00:32:58]
  Epoch: [057][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.3258 (0.3111)   Prec@1 87.500 (89.218)   Prec@5 100.000 (99.655)   [2019-11-22 00:33:03]
  **Train** Prec@1 89.070 Prec@5 99.658 Error@1 10.930
  **Test** Prec@1 85.360 Prec@5 99.360 Error@1 14.640

==>>[2019-11-22 00:33:09] [Epoch=058/200] [Need: 00:47:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [058][000/391]   Time 0.221 (0.221)   Data 0.157 (0.157)   Loss 0.3151 (0.3151)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 00:33:09]
  Epoch: [058][100/391]   Time 0.043 (0.047)   Data 0.000 (0.002)   Loss 0.2698 (0.2918)   Prec@1 90.625 (89.975)   Prec@5 100.000 (99.768)   [2019-11-22 00:33:14]
  Epoch: [058][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3825 (0.2994)   Prec@1 85.938 (89.576)   Prec@5 99.219 (99.755)   [2019-11-22 00:33:18]
  Epoch: [058][300/391]   Time 0.045 (0.046)   Data 0.000 (0.001)   Loss 0.2404 (0.3061)   Prec@1 92.188 (89.377)   Prec@5 100.000 (99.704)   [2019-11-22 00:33:23]
  **Train** Prec@1 89.322 Prec@5 99.690 Error@1 10.678
  **Test** Prec@1 83.050 Prec@5 99.310 Error@1 16.950

==>>[2019-11-22 00:33:29] [Epoch=059/200] [Need: 00:47:08] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [059][000/391]   Time 0.225 (0.225)   Data 0.172 (0.172)   Loss 0.3090 (0.3090)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 00:33:29]
  Epoch: [059][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.2597 (0.3056)   Prec@1 90.625 (89.318)   Prec@5 100.000 (99.714)   [2019-11-22 00:33:34]
  Epoch: [059][200/391]   Time 0.049 (0.047)   Data 0.000 (0.001)   Loss 0.3804 (0.3021)   Prec@1 85.156 (89.556)   Prec@5 100.000 (99.685)   [2019-11-22 00:33:38]
  Epoch: [059][300/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.2940 (0.3133)   Prec@1 92.188 (89.288)   Prec@5 100.000 (99.639)   [2019-11-22 00:33:43]
  **Train** Prec@1 89.200 Prec@5 99.636 Error@1 10.800
  **Test** Prec@1 81.340 Prec@5 98.930 Error@1 18.660

==>>[2019-11-22 00:33:49] [Epoch=060/200] [Need: 00:46:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [060][000/391]   Time 0.231 (0.231)   Data 0.176 (0.176)   Loss 0.2485 (0.2485)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 00:33:49]
  Epoch: [060][100/391]   Time 0.047 (0.049)   Data 0.000 (0.002)   Loss 0.3553 (0.2969)   Prec@1 85.156 (89.318)   Prec@5 100.000 (99.722)   [2019-11-22 00:33:54]
  Epoch: [060][200/391]   Time 0.060 (0.049)   Data 0.000 (0.001)   Loss 0.3371 (0.3007)   Prec@1 85.156 (89.241)   Prec@5 99.219 (99.751)   [2019-11-22 00:33:59]
  Epoch: [060][300/391]   Time 0.046 (0.048)   Data 0.000 (0.001)   Loss 0.3716 (0.3064)   Prec@1 85.938 (89.166)   Prec@5 100.000 (99.714)   [2019-11-22 00:34:03]
  **Train** Prec@1 89.164 Prec@5 99.704 Error@1 10.836
  **Test** Prec@1 84.550 Prec@5 99.400 Error@1 15.450

==>>[2019-11-22 00:34:09] [Epoch=061/200] [Need: 00:46:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.72, Error=14.28]
  Epoch: [061][000/391]   Time 0.213 (0.213)   Data 0.146 (0.146)   Loss 0.3403 (0.3403)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-22 00:34:09]
  Epoch: [061][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.2952 (0.3083)   Prec@1 90.625 (89.372)   Prec@5 100.000 (99.698)   [2019-11-22 00:34:14]
  Epoch: [061][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.3083 (0.3035)   Prec@1 87.500 (89.579)   Prec@5 100.000 (99.697)   [2019-11-22 00:34:19]
  Epoch: [061][300/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.2653 (0.3074)   Prec@1 86.719 (89.377)   Prec@5 100.000 (99.699)   [2019-11-22 00:34:24]
  **Train** Prec@1 89.310 Prec@5 99.704 Error@1 10.690
  **Test** Prec@1 86.720 Prec@5 99.440 Error@1 13.280
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:34:30] [Epoch=062/200] [Need: 00:46:11] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [062][000/391]   Time 0.227 (0.227)   Data 0.174 (0.174)   Loss 0.3330 (0.3330)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:34:31]
  Epoch: [062][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.3992 (0.2924)   Prec@1 85.156 (89.650)   Prec@5 100.000 (99.822)   [2019-11-22 00:34:35]
  Epoch: [062][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.2909 (0.3040)   Prec@1 87.500 (89.284)   Prec@5 100.000 (99.786)   [2019-11-22 00:34:40]
  Epoch: [062][300/391]   Time 0.079 (0.048)   Data 0.000 (0.001)   Loss 0.2678 (0.3058)   Prec@1 90.625 (89.335)   Prec@5 100.000 (99.764)   [2019-11-22 00:34:45]
  **Train** Prec@1 89.258 Prec@5 99.744 Error@1 10.742
  **Test** Prec@1 86.240 Prec@5 99.420 Error@1 13.760

==>>[2019-11-22 00:34:51] [Epoch=063/200] [Need: 00:45:51] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [063][000/391]   Time 0.224 (0.224)   Data 0.162 (0.162)   Loss 0.2353 (0.2353)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 00:34:51]
  Epoch: [063][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.4564 (0.2834)   Prec@1 84.375 (89.844)   Prec@5 99.219 (99.760)   [2019-11-22 00:34:56]
  Epoch: [063][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.4953 (0.2954)   Prec@1 80.469 (89.498)   Prec@5 98.438 (99.740)   [2019-11-22 00:35:00]
  Epoch: [063][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.4225 (0.2996)   Prec@1 86.719 (89.358)   Prec@5 100.000 (99.735)   [2019-11-22 00:35:05]
  **Train** Prec@1 89.130 Prec@5 99.734 Error@1 10.870
  **Test** Prec@1 86.170 Prec@5 99.280 Error@1 13.830

==>>[2019-11-22 00:35:11] [Epoch=064/200] [Need: 00:45:32] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [064][000/391]   Time 0.222 (0.222)   Data 0.145 (0.145)   Loss 0.2719 (0.2719)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-22 00:35:11]
  Epoch: [064][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.3165 (0.2907)   Prec@1 89.844 (89.890)   Prec@5 100.000 (99.768)   [2019-11-22 00:35:16]
  Epoch: [064][200/391]   Time 0.059 (0.050)   Data 0.000 (0.001)   Loss 0.2075 (0.3009)   Prec@1 95.312 (89.459)   Prec@5 99.219 (99.728)   [2019-11-22 00:35:21]
  Epoch: [064][300/391]   Time 0.058 (0.049)   Data 0.000 (0.001)   Loss 0.3615 (0.3064)   Prec@1 86.719 (89.195)   Prec@5 100.000 (99.714)   [2019-11-22 00:35:26]
  **Train** Prec@1 89.196 Prec@5 99.702 Error@1 10.804
  **Test** Prec@1 85.090 Prec@5 99.450 Error@1 14.910

==>>[2019-11-22 00:35:31] [Epoch=065/200] [Need: 00:45:12] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [065][000/391]   Time 0.221 (0.221)   Data 0.168 (0.168)   Loss 0.2701 (0.2701)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-22 00:35:32]
  Epoch: [065][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.2947 (0.3023)   Prec@1 90.625 (89.743)   Prec@5 100.000 (99.698)   [2019-11-22 00:35:36]
  Epoch: [065][200/391]   Time 0.037 (0.048)   Data 0.000 (0.001)   Loss 0.2459 (0.2961)   Prec@1 93.750 (89.894)   Prec@5 99.219 (99.724)   [2019-11-22 00:35:41]
  Epoch: [065][300/391]   Time 0.038 (0.048)   Data 0.000 (0.001)   Loss 0.2670 (0.3039)   Prec@1 88.281 (89.646)   Prec@5 99.219 (99.683)   [2019-11-22 00:35:46]
  **Train** Prec@1 89.640 Prec@5 99.674 Error@1 10.360
  **Test** Prec@1 84.970 Prec@5 99.460 Error@1 15.030

==>>[2019-11-22 00:35:52] [Epoch=066/200] [Need: 00:44:52] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [066][000/391]   Time 0.212 (0.212)   Data 0.138 (0.138)   Loss 0.2574 (0.2574)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:35:52]
  Epoch: [066][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.3467 (0.2863)   Prec@1 85.156 (89.983)   Prec@5 100.000 (99.745)   [2019-11-22 00:35:56]
  Epoch: [066][200/391]   Time 0.039 (0.047)   Data 0.000 (0.001)   Loss 0.3259 (0.2982)   Prec@1 89.844 (89.475)   Prec@5 100.000 (99.708)   [2019-11-22 00:36:01]
  Epoch: [066][300/391]   Time 0.059 (0.047)   Data 0.000 (0.001)   Loss 0.2212 (0.3024)   Prec@1 92.188 (89.358)   Prec@5 100.000 (99.683)   [2019-11-22 00:36:06]
  **Train** Prec@1 89.372 Prec@5 99.706 Error@1 10.628
  **Test** Prec@1 85.840 Prec@5 99.500 Error@1 14.160

==>>[2019-11-22 00:36:12] [Epoch=067/200] [Need: 00:44:33] [LR=0.0100][M=0.90] [Best : Accuracy=86.72, Error=13.28]
  Epoch: [067][000/391]   Time 0.219 (0.219)   Data 0.148 (0.148)   Loss 0.3519 (0.3519)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-22 00:36:12]
  Epoch: [067][100/391]   Time 0.046 (0.048)   Data 0.000 (0.002)   Loss 0.3181 (0.2788)   Prec@1 90.625 (90.524)   Prec@5 100.000 (99.768)   [2019-11-22 00:36:17]
  Epoch: [067][200/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.2733 (0.2969)   Prec@1 90.625 (89.770)   Prec@5 100.000 (99.712)   [2019-11-22 00:36:21]
  Epoch: [067][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.3242 (0.2964)   Prec@1 90.625 (89.797)   Prec@5 100.000 (99.720)   [2019-11-22 00:36:26]
  **Train** Prec@1 89.586 Prec@5 99.708 Error@1 10.414
  **Test** Prec@1 86.750 Prec@5 99.490 Error@1 13.250
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:36:32] [Epoch=068/200] [Need: 00:44:13] [LR=0.0100][M=0.90] [Best : Accuracy=86.75, Error=13.25]
  Epoch: [068][000/391]   Time 0.218 (0.218)   Data 0.170 (0.170)   Loss 0.2918 (0.2918)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-22 00:36:32]
  Epoch: [068][100/391]   Time 0.052 (0.050)   Data 0.000 (0.002)   Loss 0.3402 (0.2847)   Prec@1 87.500 (89.952)   Prec@5 100.000 (99.783)   [2019-11-22 00:36:37]
  Epoch: [068][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.4223 (0.2976)   Prec@1 87.500 (89.774)   Prec@5 99.219 (99.716)   [2019-11-22 00:36:42]
  Epoch: [068][300/391]   Time 0.059 (0.048)   Data 0.000 (0.001)   Loss 0.1713 (0.3021)   Prec@1 93.750 (89.657)   Prec@5 100.000 (99.720)   [2019-11-22 00:36:47]
  **Train** Prec@1 89.546 Prec@5 99.734 Error@1 10.454
  **Test** Prec@1 84.960 Prec@5 99.390 Error@1 15.040

==>>[2019-11-22 00:36:52] [Epoch=069/200] [Need: 00:43:53] [LR=0.0100][M=0.90] [Best : Accuracy=86.75, Error=13.25]
  Epoch: [069][000/391]   Time 0.211 (0.211)   Data 0.156 (0.156)   Loss 0.1275 (0.1275)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:36:53]
  Epoch: [069][100/391]   Time 0.045 (0.048)   Data 0.000 (0.002)   Loss 0.2515 (0.2877)   Prec@1 90.625 (89.705)   Prec@5 100.000 (99.768)   [2019-11-22 00:36:57]
  Epoch: [069][200/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.2616 (0.2922)   Prec@1 89.844 (89.646)   Prec@5 100.000 (99.790)   [2019-11-22 00:37:02]
  Epoch: [069][300/391]   Time 0.059 (0.048)   Data 0.000 (0.001)   Loss 0.3330 (0.2951)   Prec@1 86.719 (89.636)   Prec@5 99.219 (99.759)   [2019-11-22 00:37:07]
  **Train** Prec@1 89.584 Prec@5 99.744 Error@1 10.416
  **Test** Prec@1 85.810 Prec@5 99.260 Error@1 14.190

==>>[2019-11-22 00:37:13] [Epoch=070/200] [Need: 00:43:34] [LR=0.0100][M=0.90] [Best : Accuracy=86.75, Error=13.25]
  Epoch: [070][000/391]   Time 0.228 (0.228)   Data 0.157 (0.157)   Loss 0.2503 (0.2503)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-22 00:37:13]
  Epoch: [070][100/391]   Time 0.041 (0.047)   Data 0.000 (0.002)   Loss 0.2271 (0.2795)   Prec@1 90.625 (90.091)   Prec@5 100.000 (99.783)   [2019-11-22 00:37:18]
  Epoch: [070][200/391]   Time 0.043 (0.047)   Data 0.000 (0.001)   Loss 0.3290 (0.2991)   Prec@1 87.500 (89.587)   Prec@5 100.000 (99.751)   [2019-11-22 00:37:22]
  Epoch: [070][300/391]   Time 0.065 (0.047)   Data 0.000 (0.001)   Loss 0.3729 (0.3025)   Prec@1 85.938 (89.447)   Prec@5 100.000 (99.743)   [2019-11-22 00:37:27]
  **Train** Prec@1 89.540 Prec@5 99.722 Error@1 10.460
  **Test** Prec@1 86.140 Prec@5 99.510 Error@1 13.860

==>>[2019-11-22 00:37:33] [Epoch=071/200] [Need: 00:43:14] [LR=0.0100][M=0.90] [Best : Accuracy=86.75, Error=13.25]
  Epoch: [071][000/391]   Time 0.224 (0.224)   Data 0.171 (0.171)   Loss 0.1782 (0.1782)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2019-11-22 00:37:33]
  Epoch: [071][100/391]   Time 0.061 (0.052)   Data 0.000 (0.002)   Loss 0.3667 (0.2960)   Prec@1 85.156 (89.712)   Prec@5 100.000 (99.714)   [2019-11-22 00:37:38]
  Epoch: [071][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.2372 (0.2892)   Prec@1 91.406 (89.933)   Prec@5 100.000 (99.720)   [2019-11-22 00:37:43]
  Epoch: [071][300/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.2513 (0.2967)   Prec@1 89.844 (89.667)   Prec@5 100.000 (99.704)   [2019-11-22 00:37:47]
  **Train** Prec@1 89.600 Prec@5 99.712 Error@1 10.400
  **Test** Prec@1 85.050 Prec@5 99.470 Error@1 14.950

==>>[2019-11-22 00:37:54] [Epoch=072/200] [Need: 00:42:54] [LR=0.0100][M=0.90] [Best : Accuracy=86.75, Error=13.25]
  Epoch: [072][000/391]   Time 0.226 (0.226)   Data 0.161 (0.161)   Loss 0.2770 (0.2770)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-22 00:37:54]
  Epoch: [072][100/391]   Time 0.042 (0.047)   Data 0.000 (0.002)   Loss 0.3680 (0.2772)   Prec@1 87.500 (90.192)   Prec@5 99.219 (99.768)   [2019-11-22 00:37:58]
  Epoch: [072][200/391]   Time 0.037 (0.047)   Data 0.000 (0.001)   Loss 0.1801 (0.2856)   Prec@1 93.750 (90.030)   Prec@5 99.219 (99.740)   [2019-11-22 00:38:03]
  Epoch: [072][300/391]   Time 0.039 (0.047)   Data 0.000 (0.001)   Loss 0.3696 (0.2915)   Prec@1 85.938 (89.877)   Prec@5 100.000 (99.717)   [2019-11-22 00:38:08]
  **Train** Prec@1 89.654 Prec@5 99.704 Error@1 10.346
  **Test** Prec@1 86.770 Prec@5 99.360 Error@1 13.230
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:38:14] [Epoch=073/200] [Need: 00:42:34] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [073][000/391]   Time 0.221 (0.221)   Data 0.162 (0.162)   Loss 0.2606 (0.2606)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:38:14]
  Epoch: [073][100/391]   Time 0.078 (0.050)   Data 0.000 (0.002)   Loss 0.3186 (0.2972)   Prec@1 88.281 (89.411)   Prec@5 99.219 (99.729)   [2019-11-22 00:38:19]
  Epoch: [073][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.2625 (0.2961)   Prec@1 90.625 (89.595)   Prec@5 100.000 (99.701)   [2019-11-22 00:38:23]
  Epoch: [073][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.1658 (0.2991)   Prec@1 95.312 (89.504)   Prec@5 100.000 (99.691)   [2019-11-22 00:38:28]
  **Train** Prec@1 89.514 Prec@5 99.682 Error@1 10.486
  **Test** Prec@1 85.870 Prec@5 99.470 Error@1 14.130

==>>[2019-11-22 00:38:34] [Epoch=074/200] [Need: 00:42:15] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [074][000/391]   Time 0.241 (0.241)   Data 0.168 (0.168)   Loss 0.2564 (0.2564)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:38:34]
  Epoch: [074][100/391]   Time 0.077 (0.048)   Data 0.000 (0.002)   Loss 0.3257 (0.2917)   Prec@1 88.281 (89.581)   Prec@5 100.000 (99.698)   [2019-11-22 00:38:39]
  Epoch: [074][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.3726 (0.2917)   Prec@1 88.281 (89.813)   Prec@5 98.438 (99.732)   [2019-11-22 00:38:44]
  Epoch: [074][300/391]   Time 0.048 (0.047)   Data 0.000 (0.001)   Loss 0.3276 (0.3026)   Prec@1 89.062 (89.532)   Prec@5 100.000 (99.709)   [2019-11-22 00:38:48]
  **Train** Prec@1 89.440 Prec@5 99.686 Error@1 10.560
  **Test** Prec@1 85.120 Prec@5 99.440 Error@1 14.880

==>>[2019-11-22 00:38:54] [Epoch=075/200] [Need: 00:41:54] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [075][000/391]   Time 0.230 (0.230)   Data 0.169 (0.169)   Loss 0.3061 (0.3061)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-22 00:38:54]
  Epoch: [075][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.2665 (0.2771)   Prec@1 89.062 (90.246)   Prec@5 99.219 (99.838)   [2019-11-22 00:38:59]
  Epoch: [075][200/391]   Time 0.079 (0.048)   Data 0.000 (0.001)   Loss 0.3229 (0.2889)   Prec@1 88.281 (89.902)   Prec@5 99.219 (99.778)   [2019-11-22 00:39:03]
  Epoch: [075][300/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.3341 (0.2971)   Prec@1 88.281 (89.678)   Prec@5 99.219 (99.714)   [2019-11-22 00:39:08]
  **Train** Prec@1 89.664 Prec@5 99.688 Error@1 10.336
  **Test** Prec@1 84.840 Prec@5 99.200 Error@1 15.160

==>>[2019-11-22 00:39:13] [Epoch=076/200] [Need: 00:41:33] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [076][000/391]   Time 0.223 (0.223)   Data 0.145 (0.145)   Loss 0.3580 (0.3580)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-22 00:39:14]
  Epoch: [076][100/391]   Time 0.040 (0.049)   Data 0.000 (0.002)   Loss 0.3343 (0.2945)   Prec@1 89.844 (89.944)   Prec@5 98.438 (99.737)   [2019-11-22 00:39:18]
  Epoch: [076][200/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.2166 (0.2998)   Prec@1 92.969 (89.692)   Prec@5 99.219 (99.728)   [2019-11-22 00:39:23]
  Epoch: [076][300/391]   Time 0.036 (0.048)   Data 0.000 (0.001)   Loss 0.3301 (0.2958)   Prec@1 88.281 (89.872)   Prec@5 99.219 (99.722)   [2019-11-22 00:39:28]
  **Train** Prec@1 89.804 Prec@5 99.726 Error@1 10.196
  **Test** Prec@1 82.780 Prec@5 99.300 Error@1 17.220

==>>[2019-11-22 00:39:34] [Epoch=077/200] [Need: 00:41:13] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [077][000/391]   Time 0.228 (0.228)   Data 0.175 (0.175)   Loss 0.2440 (0.2440)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 00:39:34]
  Epoch: [077][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.2767 (0.3006)   Prec@1 91.406 (89.349)   Prec@5 100.000 (99.783)   [2019-11-22 00:39:39]
  Epoch: [077][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3832 (0.2981)   Prec@1 86.719 (89.537)   Prec@5 99.219 (99.743)   [2019-11-22 00:39:44]
  Epoch: [077][300/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.1646 (0.2962)   Prec@1 95.312 (89.644)   Prec@5 100.000 (99.761)   [2019-11-22 00:39:48]
  **Train** Prec@1 89.654 Prec@5 99.754 Error@1 10.346
  **Test** Prec@1 81.630 Prec@5 98.550 Error@1 18.370

==>>[2019-11-22 00:39:54] [Epoch=078/200] [Need: 00:40:54] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [078][000/391]   Time 0.216 (0.216)   Data 0.152 (0.152)   Loss 0.2246 (0.2246)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 00:39:54]
  Epoch: [078][100/391]   Time 0.039 (0.046)   Data 0.000 (0.002)   Loss 0.3647 (0.2823)   Prec@1 87.500 (90.122)   Prec@5 100.000 (99.799)   [2019-11-22 00:39:59]
  Epoch: [078][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3334 (0.2890)   Prec@1 87.500 (89.805)   Prec@5 99.219 (99.759)   [2019-11-22 00:40:03]
  Epoch: [078][300/391]   Time 0.054 (0.045)   Data 0.000 (0.001)   Loss 0.3217 (0.2890)   Prec@1 89.062 (89.935)   Prec@5 100.000 (99.746)   [2019-11-22 00:40:08]
  **Train** Prec@1 89.870 Prec@5 99.726 Error@1 10.130
  **Test** Prec@1 86.430 Prec@5 99.370 Error@1 13.570

==>>[2019-11-22 00:40:14] [Epoch=079/200] [Need: 00:40:32] [LR=0.0100][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [079][000/391]   Time 0.216 (0.216)   Data 0.162 (0.162)   Loss 0.2887 (0.2887)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-22 00:40:14]
  Epoch: [079][100/391]   Time 0.039 (0.049)   Data 0.000 (0.002)   Loss 0.2996 (0.2847)   Prec@1 91.406 (90.022)   Prec@5 99.219 (99.768)   [2019-11-22 00:40:18]
  Epoch: [079][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.3675 (0.2817)   Prec@1 85.938 (90.166)   Prec@5 99.219 (99.782)   [2019-11-22 00:40:23]
  Epoch: [079][300/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.1985 (0.2910)   Prec@1 92.188 (89.932)   Prec@5 99.219 (99.777)   [2019-11-22 00:40:27]
  **Train** Prec@1 89.678 Prec@5 99.748 Error@1 10.322
  **Test** Prec@1 83.550 Prec@5 99.410 Error@1 16.450

==>>[2019-11-22 00:40:33] [Epoch=080/200] [Need: 00:40:11] [LR=0.0010][M=0.90] [Best : Accuracy=86.77, Error=13.23]
  Epoch: [080][000/391]   Time 0.217 (0.217)   Data 0.162 (0.162)   Loss 0.6175 (0.6175)   Prec@1 79.688 (79.688)   Prec@5 100.000 (100.000)   [2019-11-22 00:40:33]
  Epoch: [080][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.2900 (0.2457)   Prec@1 89.844 (91.576)   Prec@5 99.219 (99.752)   [2019-11-22 00:40:38]
  Epoch: [080][200/391]   Time 0.064 (0.048)   Data 0.000 (0.001)   Loss 0.2014 (0.2307)   Prec@1 91.406 (92.055)   Prec@5 100.000 (99.794)   [2019-11-22 00:40:43]
  Epoch: [080][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.1836 (0.2223)   Prec@1 93.750 (92.302)   Prec@5 100.000 (99.836)   [2019-11-22 00:40:48]
  **Train** Prec@1 92.516 Prec@5 99.828 Error@1 7.484
  **Test** Prec@1 89.530 Prec@5 99.640 Error@1 10.470
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:40:54] [Epoch=081/200] [Need: 00:39:52] [LR=0.0010][M=0.90] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [081][000/391]   Time 0.224 (0.224)   Data 0.162 (0.162)   Loss 0.2176 (0.2176)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:40:54]
  Epoch: [081][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.1207 (0.1809)   Prec@1 96.875 (93.998)   Prec@5 100.000 (99.869)   [2019-11-22 00:40:58]
  Epoch: [081][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.2394 (0.1810)   Prec@1 90.625 (93.925)   Prec@5 100.000 (99.852)   [2019-11-22 00:41:03]
  Epoch: [081][300/391]   Time 0.048 (0.045)   Data 0.000 (0.001)   Loss 0.1729 (0.1799)   Prec@1 93.750 (93.952)   Prec@5 100.000 (99.860)   [2019-11-22 00:41:07]
  **Train** Prec@1 93.896 Prec@5 99.864 Error@1 6.104
  **Test** Prec@1 90.070 Prec@5 99.690 Error@1 9.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:41:13] [Epoch=082/200] [Need: 00:39:31] [LR=0.0010][M=0.90] [Best : Accuracy=90.07, Error=9.93]
  Epoch: [082][000/391]   Time 0.217 (0.217)   Data 0.171 (0.171)   Loss 0.1774 (0.1774)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-22 00:41:13]
  Epoch: [082][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.2834 (0.1626)   Prec@1 92.188 (94.423)   Prec@5 100.000 (99.923)   [2019-11-22 00:41:18]
  Epoch: [082][200/391]   Time 0.044 (0.048)   Data 0.000 (0.001)   Loss 0.1952 (0.1676)   Prec@1 92.188 (94.255)   Prec@5 100.000 (99.899)   [2019-11-22 00:41:23]
  Epoch: [082][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.1594 (0.1690)   Prec@1 92.969 (94.173)   Prec@5 100.000 (99.896)   [2019-11-22 00:41:28]
  **Train** Prec@1 94.226 Prec@5 99.904 Error@1 5.774
  **Test** Prec@1 89.710 Prec@5 99.630 Error@1 10.290

==>>[2019-11-22 00:41:33] [Epoch=083/200] [Need: 00:39:11] [LR=0.0010][M=0.90] [Best : Accuracy=90.07, Error=9.93]
  Epoch: [083][000/391]   Time 0.216 (0.216)   Data 0.151 (0.151)   Loss 0.1359 (0.1359)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:41:33]
  Epoch: [083][100/391]   Time 0.045 (0.048)   Data 0.000 (0.002)   Loss 0.0999 (0.1595)   Prec@1 97.656 (94.493)   Prec@5 100.000 (99.899)   [2019-11-22 00:41:38]
  Epoch: [083][200/391]   Time 0.059 (0.048)   Data 0.000 (0.001)   Loss 0.1887 (0.1600)   Prec@1 92.188 (94.465)   Prec@5 100.000 (99.899)   [2019-11-22 00:41:43]
  Epoch: [083][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.2107 (0.1599)   Prec@1 92.969 (94.451)   Prec@5 100.000 (99.907)   [2019-11-22 00:41:47]
  **Train** Prec@1 94.350 Prec@5 99.906 Error@1 5.650
  **Test** Prec@1 89.970 Prec@5 99.640 Error@1 10.030

==>>[2019-11-22 00:41:53] [Epoch=084/200] [Need: 00:38:50] [LR=0.0010][M=0.90] [Best : Accuracy=90.07, Error=9.93]
  Epoch: [084][000/391]   Time 0.219 (0.219)   Data 0.157 (0.157)   Loss 0.1251 (0.1251)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:41:53]
  Epoch: [084][100/391]   Time 0.036 (0.048)   Data 0.000 (0.002)   Loss 0.1109 (0.1516)   Prec@1 96.875 (94.856)   Prec@5 99.219 (99.938)   [2019-11-22 00:41:58]
  Epoch: [084][200/391]   Time 0.040 (0.044)   Data 0.000 (0.001)   Loss 0.1410 (0.1526)   Prec@1 95.312 (94.768)   Prec@5 100.000 (99.926)   [2019-11-22 00:42:02]
  Epoch: [084][300/391]   Time 0.041 (0.043)   Data 0.000 (0.001)   Loss 0.2505 (0.1527)   Prec@1 93.750 (94.705)   Prec@5 100.000 (99.933)   [2019-11-22 00:42:06]
  **Train** Prec@1 94.642 Prec@5 99.918 Error@1 5.358
  **Test** Prec@1 90.080 Prec@5 99.560 Error@1 9.920
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:42:11] [Epoch=085/200] [Need: 00:38:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.08, Error=9.92]
  Epoch: [085][000/391]   Time 0.229 (0.229)   Data 0.145 (0.145)   Loss 0.1687 (0.1687)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:42:12]
  Epoch: [085][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.0816 (0.1541)   Prec@1 96.094 (94.794)   Prec@5 100.000 (99.915)   [2019-11-22 00:42:16]
  Epoch: [085][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.1136 (0.1483)   Prec@1 98.438 (94.939)   Prec@5 100.000 (99.922)   [2019-11-22 00:42:21]
  Epoch: [085][300/391]   Time 0.044 (0.046)   Data 0.000 (0.001)   Loss 0.1034 (0.1505)   Prec@1 96.875 (94.786)   Prec@5 100.000 (99.920)   [2019-11-22 00:42:25]
  **Train** Prec@1 94.730 Prec@5 99.914 Error@1 5.270
  **Test** Prec@1 90.330 Prec@5 99.630 Error@1 9.670
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:42:31] [Epoch=086/200] [Need: 00:38:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [086][000/391]   Time 0.243 (0.243)   Data 0.177 (0.177)   Loss 0.1347 (0.1347)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:42:31]
  Epoch: [086][100/391]   Time 0.038 (0.047)   Data 0.000 (0.002)   Loss 0.1473 (0.1380)   Prec@1 94.531 (95.135)   Prec@5 100.000 (99.946)   [2019-11-22 00:42:36]
  Epoch: [086][200/391]   Time 0.046 (0.046)   Data 0.000 (0.001)   Loss 0.1667 (0.1417)   Prec@1 94.531 (94.994)   Prec@5 99.219 (99.930)   [2019-11-22 00:42:40]
  Epoch: [086][300/391]   Time 0.076 (0.047)   Data 0.000 (0.001)   Loss 0.2050 (0.1447)   Prec@1 92.969 (94.936)   Prec@5 100.000 (99.922)   [2019-11-22 00:42:45]
  **Train** Prec@1 94.880 Prec@5 99.924 Error@1 5.120
  **Test** Prec@1 90.150 Prec@5 99.600 Error@1 9.850

==>>[2019-11-22 00:42:51] [Epoch=087/200] [Need: 00:37:47] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [087][000/391]   Time 0.228 (0.228)   Data 0.171 (0.171)   Loss 0.0850 (0.0850)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:42:51]
  Epoch: [087][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.1222 (0.1374)   Prec@1 97.656 (95.057)   Prec@5 100.000 (99.892)   [2019-11-22 00:42:56]
  Epoch: [087][200/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.1147 (0.1397)   Prec@1 96.875 (95.033)   Prec@5 100.000 (99.895)   [2019-11-22 00:43:00]
  Epoch: [087][300/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.0770 (0.1407)   Prec@1 97.656 (95.017)   Prec@5 100.000 (99.912)   [2019-11-22 00:43:05]
  **Train** Prec@1 95.048 Prec@5 99.906 Error@1 4.952
  **Test** Prec@1 90.240 Prec@5 99.670 Error@1 9.760

==>>[2019-11-22 00:43:11] [Epoch=088/200] [Need: 00:37:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [088][000/391]   Time 0.227 (0.227)   Data 0.146 (0.146)   Loss 0.1302 (0.1302)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:43:11]
  Epoch: [088][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.1589 (0.1396)   Prec@1 94.531 (95.034)   Prec@5 100.000 (99.946)   [2019-11-22 00:43:16]
  Epoch: [088][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0940 (0.1330)   Prec@1 96.094 (95.312)   Prec@5 100.000 (99.953)   [2019-11-22 00:43:20]
  Epoch: [088][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.1306 (0.1334)   Prec@1 96.875 (95.336)   Prec@5 100.000 (99.940)   [2019-11-22 00:43:25]
  **Train** Prec@1 95.272 Prec@5 99.938 Error@1 4.728
  **Test** Prec@1 90.230 Prec@5 99.630 Error@1 9.770

==>>[2019-11-22 00:43:31] [Epoch=089/200] [Need: 00:37:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.33, Error=9.67]
  Epoch: [089][000/391]   Time 0.238 (0.238)   Data 0.175 (0.175)   Loss 0.1116 (0.1116)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:43:31]
  Epoch: [089][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.1461 (0.1337)   Prec@1 93.750 (95.312)   Prec@5 100.000 (99.938)   [2019-11-22 00:43:36]
  Epoch: [089][200/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.1442 (0.1362)   Prec@1 96.094 (95.285)   Prec@5 100.000 (99.934)   [2019-11-22 00:43:41]
  Epoch: [089][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.1276 (0.1333)   Prec@1 94.531 (95.434)   Prec@5 100.000 (99.935)   [2019-11-22 00:43:45]
  **Train** Prec@1 95.378 Prec@5 99.946 Error@1 4.622
  **Test** Prec@1 90.360 Prec@5 99.650 Error@1 9.640
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:43:51] [Epoch=090/200] [Need: 00:36:47] [LR=0.0010][M=0.90] [Best : Accuracy=90.36, Error=9.64]
  Epoch: [090][000/391]   Time 0.232 (0.232)   Data 0.175 (0.175)   Loss 0.1879 (0.1879)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 00:43:51]
  Epoch: [090][100/391]   Time 0.036 (0.050)   Data 0.000 (0.002)   Loss 0.0721 (0.1321)   Prec@1 97.656 (95.367)   Prec@5 100.000 (99.961)   [2019-11-22 00:43:56]
  Epoch: [090][200/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.2125 (0.1322)   Prec@1 92.188 (95.425)   Prec@5 99.219 (99.949)   [2019-11-22 00:44:01]
  Epoch: [090][300/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.1645 (0.1330)   Prec@1 92.969 (95.388)   Prec@5 100.000 (99.951)   [2019-11-22 00:44:06]
  **Train** Prec@1 95.436 Prec@5 99.948 Error@1 4.564
  **Test** Prec@1 90.270 Prec@5 99.630 Error@1 9.730

==>>[2019-11-22 00:44:12] [Epoch=091/200] [Need: 00:36:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.36, Error=9.64]
  Epoch: [091][000/391]   Time 0.233 (0.233)   Data 0.146 (0.146)   Loss 0.1583 (0.1583)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 00:44:12]
  Epoch: [091][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.1044 (0.1239)   Prec@1 94.531 (95.784)   Prec@5 100.000 (99.969)   [2019-11-22 00:44:17]
  Epoch: [091][200/391]   Time 0.052 (0.048)   Data 0.000 (0.001)   Loss 0.1124 (0.1242)   Prec@1 96.875 (95.690)   Prec@5 100.000 (99.949)   [2019-11-22 00:44:22]
  Epoch: [091][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.1655 (0.1258)   Prec@1 94.531 (95.632)   Prec@5 100.000 (99.953)   [2019-11-22 00:44:26]
  **Train** Prec@1 95.554 Prec@5 99.940 Error@1 4.446
  **Test** Prec@1 90.570 Prec@5 99.630 Error@1 9.430
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:44:31] [Epoch=092/200] [Need: 00:36:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [092][000/391]   Time 0.218 (0.218)   Data 0.168 (0.168)   Loss 0.1145 (0.1145)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:44:32]
  Epoch: [092][100/391]   Time 0.069 (0.050)   Data 0.000 (0.002)   Loss 0.1581 (0.1255)   Prec@1 94.531 (95.699)   Prec@5 100.000 (99.969)   [2019-11-22 00:44:36]
  Epoch: [092][200/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0642 (0.1229)   Prec@1 98.438 (95.833)   Prec@5 100.000 (99.965)   [2019-11-22 00:44:41]
  Epoch: [092][300/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0827 (0.1214)   Prec@1 96.094 (95.871)   Prec@5 100.000 (99.961)   [2019-11-22 00:44:46]
  **Train** Prec@1 95.766 Prec@5 99.960 Error@1 4.234
  **Test** Prec@1 90.430 Prec@5 99.640 Error@1 9.570

==>>[2019-11-22 00:44:52] [Epoch=093/200] [Need: 00:35:47] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [093][000/391]   Time 0.223 (0.223)   Data 0.162 (0.162)   Loss 0.0805 (0.0805)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:44:52]
  Epoch: [093][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.0985 (0.1174)   Prec@1 97.656 (95.792)   Prec@5 100.000 (99.961)   [2019-11-22 00:44:57]
  Epoch: [093][200/391]   Time 0.056 (0.046)   Data 0.000 (0.001)   Loss 0.1549 (0.1208)   Prec@1 96.094 (95.697)   Prec@5 100.000 (99.942)   [2019-11-22 00:45:01]
  Epoch: [093][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.1364 (0.1234)   Prec@1 94.531 (95.614)   Prec@5 100.000 (99.951)   [2019-11-22 00:45:06]
  **Train** Prec@1 95.620 Prec@5 99.956 Error@1 4.380
  **Test** Prec@1 90.530 Prec@5 99.630 Error@1 9.470

==>>[2019-11-22 00:45:11] [Epoch=094/200] [Need: 00:35:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [094][000/391]   Time 0.222 (0.222)   Data 0.164 (0.164)   Loss 0.1017 (0.1017)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:45:12]
  Epoch: [094][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.0925 (0.1116)   Prec@1 98.438 (96.086)   Prec@5 100.000 (99.969)   [2019-11-22 00:45:16]
  Epoch: [094][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.1406 (0.1151)   Prec@1 93.750 (96.039)   Prec@5 100.000 (99.957)   [2019-11-22 00:45:21]
  Epoch: [094][300/391]   Time 0.039 (0.045)   Data 0.000 (0.001)   Loss 0.1214 (0.1152)   Prec@1 95.312 (95.993)   Prec@5 100.000 (99.956)   [2019-11-22 00:45:25]
  **Train** Prec@1 95.930 Prec@5 99.946 Error@1 4.070
  **Test** Prec@1 90.260 Prec@5 99.660 Error@1 9.740

==>>[2019-11-22 00:45:31] [Epoch=095/200] [Need: 00:35:06] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [095][000/391]   Time 0.223 (0.223)   Data 0.171 (0.171)   Loss 0.0567 (0.0567)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:45:32]
  Epoch: [095][100/391]   Time 0.046 (0.050)   Data 0.000 (0.002)   Loss 0.1048 (0.1073)   Prec@1 96.094 (96.148)   Prec@5 100.000 (99.954)   [2019-11-22 00:45:37]
  Epoch: [095][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0950 (0.1108)   Prec@1 95.312 (95.965)   Prec@5 100.000 (99.961)   [2019-11-22 00:45:41]
  Epoch: [095][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.1254 (0.1152)   Prec@1 95.312 (95.850)   Prec@5 100.000 (99.964)   [2019-11-22 00:45:46]
  **Train** Prec@1 95.858 Prec@5 99.962 Error@1 4.142
  **Test** Prec@1 90.250 Prec@5 99.630 Error@1 9.750

==>>[2019-11-22 00:45:52] [Epoch=096/200] [Need: 00:34:47] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [096][000/391]   Time 0.217 (0.217)   Data 0.149 (0.149)   Loss 0.0972 (0.0972)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:45:52]
  Epoch: [096][100/391]   Time 0.044 (0.050)   Data 0.000 (0.002)   Loss 0.0504 (0.1093)   Prec@1 98.438 (96.171)   Prec@5 100.000 (99.946)   [2019-11-22 00:45:57]
  Epoch: [096][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.1651 (0.1123)   Prec@1 92.969 (96.047)   Prec@5 100.000 (99.949)   [2019-11-22 00:46:02]
  Epoch: [096][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.1025 (0.1130)   Prec@1 96.875 (96.000)   Prec@5 100.000 (99.958)   [2019-11-22 00:46:07]
  **Train** Prec@1 95.984 Prec@5 99.960 Error@1 4.016
  **Test** Prec@1 90.120 Prec@5 99.670 Error@1 9.880

==>>[2019-11-22 00:46:13] [Epoch=097/200] [Need: 00:34:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [097][000/391]   Time 0.228 (0.228)   Data 0.174 (0.174)   Loss 0.0767 (0.0767)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:46:13]
  Epoch: [097][100/391]   Time 0.047 (0.051)   Data 0.000 (0.002)   Loss 0.1228 (0.1075)   Prec@1 95.312 (96.248)   Prec@5 100.000 (99.977)   [2019-11-22 00:46:18]
  Epoch: [097][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.1051 (0.1105)   Prec@1 96.094 (96.125)   Prec@5 100.000 (99.984)   [2019-11-22 00:46:22]
  Epoch: [097][300/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.1481 (0.1116)   Prec@1 94.531 (96.151)   Prec@5 100.000 (99.974)   [2019-11-22 00:46:27]
  **Train** Prec@1 96.086 Prec@5 99.970 Error@1 3.914
  **Test** Prec@1 90.490 Prec@5 99.570 Error@1 9.510

==>>[2019-11-22 00:46:33] [Epoch=098/200] [Need: 00:34:08] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [098][000/391]   Time 0.230 (0.230)   Data 0.174 (0.174)   Loss 0.0898 (0.0898)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:46:33]
  Epoch: [098][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.1114 (0.1070)   Prec@1 96.875 (96.140)   Prec@5 100.000 (99.954)   [2019-11-22 00:46:38]
  Epoch: [098][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.1669 (0.1094)   Prec@1 96.094 (96.051)   Prec@5 100.000 (99.965)   [2019-11-22 00:46:43]
  Epoch: [098][300/391]   Time 0.049 (0.049)   Data 0.000 (0.001)   Loss 0.1086 (0.1106)   Prec@1 95.312 (96.018)   Prec@5 100.000 (99.964)   [2019-11-22 00:46:48]
  **Train** Prec@1 96.074 Prec@5 99.960 Error@1 3.926
  **Test** Prec@1 90.460 Prec@5 99.650 Error@1 9.540

==>>[2019-11-22 00:46:54] [Epoch=099/200] [Need: 00:33:48] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [099][000/391]   Time 0.214 (0.214)   Data 0.146 (0.146)   Loss 0.1463 (0.1463)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:46:54]
  Epoch: [099][100/391]   Time 0.038 (0.051)   Data 0.000 (0.002)   Loss 0.1476 (0.1060)   Prec@1 96.094 (96.364)   Prec@5 100.000 (99.961)   [2019-11-22 00:46:59]
  Epoch: [099][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.1346 (0.1075)   Prec@1 92.969 (96.284)   Prec@5 100.000 (99.973)   [2019-11-22 00:47:03]
  Epoch: [099][300/391]   Time 0.036 (0.046)   Data 0.000 (0.001)   Loss 0.0981 (0.1089)   Prec@1 95.312 (96.208)   Prec@5 100.000 (99.971)   [2019-11-22 00:47:08]
  **Train** Prec@1 96.122 Prec@5 99.970 Error@1 3.878
  **Test** Prec@1 90.410 Prec@5 99.640 Error@1 9.590

==>>[2019-11-22 00:47:13] [Epoch=100/200] [Need: 00:33:28] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [100][000/391]   Time 0.214 (0.214)   Data 0.157 (0.157)   Loss 0.1135 (0.1135)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:47:14]
  Epoch: [100][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.0948 (0.1017)   Prec@1 96.094 (96.411)   Prec@5 100.000 (99.946)   [2019-11-22 00:47:18]
  Epoch: [100][200/391]   Time 0.051 (0.047)   Data 0.000 (0.001)   Loss 0.0948 (0.1046)   Prec@1 96.875 (96.358)   Prec@5 99.219 (99.953)   [2019-11-22 00:47:23]
  Epoch: [100][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.1164 (0.1057)   Prec@1 95.312 (96.353)   Prec@5 100.000 (99.951)   [2019-11-22 00:47:27]
  **Train** Prec@1 96.336 Prec@5 99.948 Error@1 3.664
  **Test** Prec@1 90.300 Prec@5 99.690 Error@1 9.700

==>>[2019-11-22 00:47:33] [Epoch=101/200] [Need: 00:33:07] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [101][000/391]   Time 0.211 (0.211)   Data 0.143 (0.143)   Loss 0.0812 (0.0812)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:47:33]
  Epoch: [101][100/391]   Time 0.046 (0.049)   Data 0.000 (0.002)   Loss 0.0461 (0.0983)   Prec@1 97.656 (96.566)   Prec@5 100.000 (99.985)   [2019-11-22 00:47:38]
  Epoch: [101][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1463 (0.0995)   Prec@1 94.531 (96.560)   Prec@5 100.000 (99.984)   [2019-11-22 00:47:43]
  Epoch: [101][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.1467 (0.1005)   Prec@1 94.531 (96.519)   Prec@5 100.000 (99.990)   [2019-11-22 00:47:48]
  **Train** Prec@1 96.414 Prec@5 99.982 Error@1 3.586
  **Test** Prec@1 90.380 Prec@5 99.640 Error@1 9.620

==>>[2019-11-22 00:47:54] [Epoch=102/200] [Need: 00:32:48] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [102][000/391]   Time 0.221 (0.221)   Data 0.166 (0.166)   Loss 0.1137 (0.1137)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:47:55]
  Epoch: [102][100/391]   Time 0.040 (0.051)   Data 0.000 (0.002)   Loss 0.0771 (0.0932)   Prec@1 97.656 (96.666)   Prec@5 100.000 (99.977)   [2019-11-22 00:48:00]
  Epoch: [102][200/391]   Time 0.055 (0.047)   Data 0.000 (0.001)   Loss 0.1119 (0.0951)   Prec@1 95.312 (96.661)   Prec@5 100.000 (99.984)   [2019-11-22 00:48:04]
  Epoch: [102][300/391]   Time 0.071 (0.048)   Data 0.000 (0.001)   Loss 0.1276 (0.0999)   Prec@1 95.312 (96.470)   Prec@5 100.000 (99.979)   [2019-11-22 00:48:09]
  **Train** Prec@1 96.444 Prec@5 99.976 Error@1 3.556
  **Test** Prec@1 90.070 Prec@5 99.620 Error@1 9.930

==>>[2019-11-22 00:48:15] [Epoch=103/200] [Need: 00:32:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [103][000/391]   Time 0.222 (0.222)   Data 0.155 (0.155)   Loss 0.0564 (0.0564)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:48:15]
  Epoch: [103][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.0867 (0.0967)   Prec@1 96.875 (96.357)   Prec@5 100.000 (99.992)   [2019-11-22 00:48:20]
  Epoch: [103][200/391]   Time 0.081 (0.046)   Data 0.000 (0.001)   Loss 0.1134 (0.0974)   Prec@1 97.656 (96.479)   Prec@5 100.000 (99.984)   [2019-11-22 00:48:24]
  Epoch: [103][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.1042 (0.0978)   Prec@1 96.094 (96.548)   Prec@5 100.000 (99.974)   [2019-11-22 00:48:29]
  **Train** Prec@1 96.498 Prec@5 99.974 Error@1 3.502
  **Test** Prec@1 90.430 Prec@5 99.610 Error@1 9.570

==>>[2019-11-22 00:48:35] [Epoch=104/200] [Need: 00:32:08] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [104][000/391]   Time 0.220 (0.220)   Data 0.174 (0.174)   Loss 0.0391 (0.0391)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 00:48:35]
  Epoch: [104][100/391]   Time 0.077 (0.048)   Data 0.000 (0.002)   Loss 0.0695 (0.0993)   Prec@1 97.656 (96.457)   Prec@5 100.000 (99.946)   [2019-11-22 00:48:40]
  Epoch: [104][200/391]   Time 0.071 (0.049)   Data 0.000 (0.001)   Loss 0.1529 (0.0980)   Prec@1 96.875 (96.479)   Prec@5 100.000 (99.969)   [2019-11-22 00:48:45]
  Epoch: [104][300/391]   Time 0.059 (0.049)   Data 0.000 (0.001)   Loss 0.1629 (0.0989)   Prec@1 94.531 (96.470)   Prec@5 100.000 (99.974)   [2019-11-22 00:48:50]
  **Train** Prec@1 96.428 Prec@5 99.968 Error@1 3.572
  **Test** Prec@1 90.350 Prec@5 99.640 Error@1 9.650

==>>[2019-11-22 00:48:56] [Epoch=105/200] [Need: 00:31:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.57, Error=9.43]
  Epoch: [105][000/391]   Time 0.232 (0.232)   Data 0.145 (0.145)   Loss 0.1497 (0.1497)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:48:56]
  Epoch: [105][100/391]   Time 0.046 (0.049)   Data 0.000 (0.002)   Loss 0.0950 (0.0991)   Prec@1 96.875 (96.442)   Prec@5 100.000 (99.954)   [2019-11-22 00:49:01]
  Epoch: [105][200/391]   Time 0.072 (0.050)   Data 0.000 (0.001)   Loss 0.0788 (0.0981)   Prec@1 98.438 (96.510)   Prec@5 100.000 (99.969)   [2019-11-22 00:49:06]
  Epoch: [105][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0769 (0.0976)   Prec@1 97.656 (96.553)   Prec@5 100.000 (99.964)   [2019-11-22 00:49:10]
  **Train** Prec@1 96.516 Prec@5 99.960 Error@1 3.484
  **Test** Prec@1 90.600 Prec@5 99.670 Error@1 9.400
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:49:16] [Epoch=106/200] [Need: 00:31:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [106][000/391]   Time 0.229 (0.229)   Data 0.162 (0.162)   Loss 0.1025 (0.1025)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:49:17]
  Epoch: [106][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.1024 (0.0938)   Prec@1 96.875 (96.674)   Prec@5 100.000 (99.961)   [2019-11-22 00:49:21]
  Epoch: [106][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0600 (0.0933)   Prec@1 98.438 (96.789)   Prec@5 100.000 (99.957)   [2019-11-22 00:49:26]
  Epoch: [106][300/391]   Time 0.071 (0.047)   Data 0.000 (0.001)   Loss 0.0824 (0.0937)   Prec@1 96.875 (96.743)   Prec@5 100.000 (99.958)   [2019-11-22 00:49:31]
  **Train** Prec@1 96.630 Prec@5 99.966 Error@1 3.370
  **Test** Prec@1 90.500 Prec@5 99.640 Error@1 9.500

==>>[2019-11-22 00:49:37] [Epoch=107/200] [Need: 00:31:10] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [107][000/391]   Time 0.228 (0.228)   Data 0.175 (0.175)   Loss 0.0822 (0.0822)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:49:37]
  Epoch: [107][100/391]   Time 0.038 (0.048)   Data 0.000 (0.002)   Loss 0.1408 (0.0863)   Prec@1 95.312 (96.999)   Prec@5 100.000 (99.985)   [2019-11-22 00:49:42]
  Epoch: [107][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0799 (0.0875)   Prec@1 96.094 (96.926)   Prec@5 100.000 (99.988)   [2019-11-22 00:49:47]
  Epoch: [107][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.1043 (0.0908)   Prec@1 97.656 (96.846)   Prec@5 100.000 (99.984)   [2019-11-22 00:49:51]
  **Train** Prec@1 96.760 Prec@5 99.988 Error@1 3.240
  **Test** Prec@1 90.560 Prec@5 99.590 Error@1 9.440

==>>[2019-11-22 00:49:58] [Epoch=108/200] [Need: 00:30:50] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [108][000/391]   Time 0.228 (0.228)   Data 0.169 (0.169)   Loss 0.0941 (0.0941)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:49:58]
  Epoch: [108][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.0734 (0.0900)   Prec@1 96.875 (96.744)   Prec@5 100.000 (99.969)   [2019-11-22 00:50:02]
  Epoch: [108][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0643 (0.0928)   Prec@1 97.656 (96.653)   Prec@5 100.000 (99.973)   [2019-11-22 00:50:07]
  Epoch: [108][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.1108 (0.0934)   Prec@1 95.312 (96.561)   Prec@5 100.000 (99.982)   [2019-11-22 00:50:11]
  **Train** Prec@1 96.590 Prec@5 99.972 Error@1 3.410
  **Test** Prec@1 90.080 Prec@5 99.730 Error@1 9.920

==>>[2019-11-22 00:50:17] [Epoch=109/200] [Need: 00:30:30] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [109][000/391]   Time 0.247 (0.247)   Data 0.192 (0.192)   Loss 0.0699 (0.0699)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:50:17]
  Epoch: [109][100/391]   Time 0.046 (0.048)   Data 0.000 (0.002)   Loss 0.0874 (0.0922)   Prec@1 96.875 (96.736)   Prec@5 100.000 (99.977)   [2019-11-22 00:50:22]
  Epoch: [109][200/391]   Time 0.079 (0.046)   Data 0.000 (0.001)   Loss 0.0863 (0.0927)   Prec@1 96.094 (96.688)   Prec@5 100.000 (99.973)   [2019-11-22 00:50:27]
  Epoch: [109][300/391]   Time 0.045 (0.047)   Data 0.000 (0.001)   Loss 0.1247 (0.0939)   Prec@1 96.094 (96.660)   Prec@5 100.000 (99.969)   [2019-11-22 00:50:31]
  **Train** Prec@1 96.648 Prec@5 99.972 Error@1 3.352
  **Test** Prec@1 90.440 Prec@5 99.660 Error@1 9.560

==>>[2019-11-22 00:50:37] [Epoch=110/200] [Need: 00:30:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [110][000/391]   Time 0.202 (0.202)   Data 0.144 (0.144)   Loss 0.0854 (0.0854)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:50:37]
  Epoch: [110][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.0861 (0.0857)   Prec@1 97.656 (96.976)   Prec@5 100.000 (99.969)   [2019-11-22 00:50:42]
  Epoch: [110][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0757 (0.0892)   Prec@1 97.656 (96.867)   Prec@5 100.000 (99.981)   [2019-11-22 00:50:47]
  Epoch: [110][300/391]   Time 0.065 (0.048)   Data 0.000 (0.001)   Loss 0.0511 (0.0899)   Prec@1 97.656 (96.849)   Prec@5 100.000 (99.982)   [2019-11-22 00:50:52]
  **Train** Prec@1 96.818 Prec@5 99.978 Error@1 3.182
  **Test** Prec@1 90.160 Prec@5 99.680 Error@1 9.840

==>>[2019-11-22 00:50:57] [Epoch=111/200] [Need: 00:29:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [111][000/391]   Time 0.210 (0.210)   Data 0.149 (0.149)   Loss 0.1428 (0.1428)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-22 00:50:58]
  Epoch: [111][100/391]   Time 0.041 (0.050)   Data 0.000 (0.002)   Loss 0.1074 (0.0883)   Prec@1 94.531 (96.813)   Prec@5 100.000 (99.977)   [2019-11-22 00:51:03]
  Epoch: [111][200/391]   Time 0.039 (0.047)   Data 0.000 (0.001)   Loss 0.1447 (0.0880)   Prec@1 95.312 (96.836)   Prec@5 100.000 (99.988)   [2019-11-22 00:51:07]
  Epoch: [111][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0908 (0.0902)   Prec@1 96.094 (96.779)   Prec@5 100.000 (99.987)   [2019-11-22 00:51:12]
  **Train** Prec@1 96.742 Prec@5 99.984 Error@1 3.258
  **Test** Prec@1 90.520 Prec@5 99.690 Error@1 9.480

==>>[2019-11-22 00:51:17] [Epoch=112/200] [Need: 00:29:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [112][000/391]   Time 0.241 (0.241)   Data 0.174 (0.174)   Loss 0.0682 (0.0682)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:51:18]
  Epoch: [112][100/391]   Time 0.056 (0.049)   Data 0.000 (0.002)   Loss 0.1393 (0.0852)   Prec@1 94.531 (97.014)   Prec@5 100.000 (99.985)   [2019-11-22 00:51:22]
  Epoch: [112][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0997 (0.0888)   Prec@1 96.094 (96.883)   Prec@5 100.000 (99.984)   [2019-11-22 00:51:27]
  Epoch: [112][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0944 (0.0884)   Prec@1 96.875 (96.891)   Prec@5 100.000 (99.987)   [2019-11-22 00:51:32]
  **Train** Prec@1 96.852 Prec@5 99.980 Error@1 3.148
  **Test** Prec@1 90.390 Prec@5 99.660 Error@1 9.610

==>>[2019-11-22 00:51:38] [Epoch=113/200] [Need: 00:29:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [113][000/391]   Time 0.219 (0.219)   Data 0.154 (0.154)   Loss 0.0791 (0.0791)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:51:38]
  Epoch: [113][100/391]   Time 0.057 (0.049)   Data 0.000 (0.002)   Loss 0.0708 (0.0859)   Prec@1 96.094 (96.744)   Prec@5 100.000 (99.992)   [2019-11-22 00:51:43]
  Epoch: [113][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0489 (0.0830)   Prec@1 97.656 (96.961)   Prec@5 100.000 (99.992)   [2019-11-22 00:51:47]
  Epoch: [113][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0701 (0.0851)   Prec@1 97.656 (96.927)   Prec@5 100.000 (99.990)   [2019-11-22 00:51:52]
  **Train** Prec@1 96.890 Prec@5 99.984 Error@1 3.110
  **Test** Prec@1 90.280 Prec@5 99.710 Error@1 9.720

==>>[2019-11-22 00:51:58] [Epoch=114/200] [Need: 00:28:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [114][000/391]   Time 0.219 (0.219)   Data 0.146 (0.146)   Loss 0.1292 (0.1292)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 00:51:58]
  Epoch: [114][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.1320 (0.0906)   Prec@1 95.312 (96.736)   Prec@5 100.000 (99.985)   [2019-11-22 00:52:03]
  Epoch: [114][200/391]   Time 0.050 (0.047)   Data 0.000 (0.001)   Loss 0.1140 (0.0896)   Prec@1 96.094 (96.852)   Prec@5 100.000 (99.992)   [2019-11-22 00:52:07]
  Epoch: [114][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.1602 (0.0894)   Prec@1 95.312 (96.846)   Prec@5 100.000 (99.982)   [2019-11-22 00:52:12]
  **Train** Prec@1 96.840 Prec@5 99.982 Error@1 3.160
  **Test** Prec@1 90.330 Prec@5 99.650 Error@1 9.670

==>>[2019-11-22 00:52:18] [Epoch=115/200] [Need: 00:28:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [115][000/391]   Time 0.214 (0.214)   Data 0.159 (0.159)   Loss 0.0660 (0.0660)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:52:19]
  Epoch: [115][100/391]   Time 0.057 (0.048)   Data 0.000 (0.002)   Loss 0.0845 (0.0892)   Prec@1 96.875 (96.705)   Prec@5 100.000 (99.992)   [2019-11-22 00:52:23]
  Epoch: [115][200/391]   Time 0.039 (0.049)   Data 0.000 (0.001)   Loss 0.0976 (0.0864)   Prec@1 96.094 (96.871)   Prec@5 100.000 (99.984)   [2019-11-22 00:52:28]
  Epoch: [115][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0391 (0.0854)   Prec@1 99.219 (96.950)   Prec@5 100.000 (99.982)   [2019-11-22 00:52:33]
  **Train** Prec@1 96.950 Prec@5 99.982 Error@1 3.050
  **Test** Prec@1 90.430 Prec@5 99.720 Error@1 9.570

==>>[2019-11-22 00:52:39] [Epoch=116/200] [Need: 00:28:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [116][000/391]   Time 0.226 (0.226)   Data 0.156 (0.156)   Loss 0.1561 (0.1561)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-22 00:52:39]
  Epoch: [116][100/391]   Time 0.040 (0.051)   Data 0.000 (0.002)   Loss 0.1228 (0.0827)   Prec@1 96.094 (97.076)   Prec@5 100.000 (99.985)   [2019-11-22 00:52:44]
  Epoch: [116][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0829 (0.0840)   Prec@1 96.875 (96.999)   Prec@5 100.000 (99.981)   [2019-11-22 00:52:48]
  Epoch: [116][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0784 (0.0841)   Prec@1 96.875 (97.018)   Prec@5 100.000 (99.984)   [2019-11-22 00:52:53]
  **Train** Prec@1 96.962 Prec@5 99.982 Error@1 3.038
  **Test** Prec@1 90.350 Prec@5 99.700 Error@1 9.650

==>>[2019-11-22 00:53:00] [Epoch=117/200] [Need: 00:27:50] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [117][000/391]   Time 0.208 (0.208)   Data 0.142 (0.142)   Loss 0.1124 (0.1124)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:53:00]
  Epoch: [117][100/391]   Time 0.051 (0.048)   Data 0.000 (0.002)   Loss 0.0648 (0.0788)   Prec@1 96.875 (97.262)   Prec@5 100.000 (99.992)   [2019-11-22 00:53:04]
  Epoch: [117][200/391]   Time 0.051 (0.047)   Data 0.000 (0.001)   Loss 0.0591 (0.0825)   Prec@1 97.656 (97.065)   Prec@5 100.000 (99.992)   [2019-11-22 00:53:09]
  Epoch: [117][300/391]   Time 0.043 (0.047)   Data 0.000 (0.001)   Loss 0.1109 (0.0831)   Prec@1 95.312 (97.028)   Prec@5 100.000 (99.990)   [2019-11-22 00:53:14]
  **Train** Prec@1 96.992 Prec@5 99.992 Error@1 3.008
  **Test** Prec@1 90.200 Prec@5 99.730 Error@1 9.800

==>>[2019-11-22 00:53:19] [Epoch=118/200] [Need: 00:27:29] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [118][000/391]   Time 0.225 (0.225)   Data 0.170 (0.170)   Loss 0.0652 (0.0652)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 00:53:20]
  Epoch: [118][100/391]   Time 0.039 (0.050)   Data 0.000 (0.002)   Loss 0.0943 (0.0814)   Prec@1 96.094 (97.107)   Prec@5 100.000 (99.969)   [2019-11-22 00:53:24]
  Epoch: [118][200/391]   Time 0.049 (0.048)   Data 0.000 (0.001)   Loss 0.0345 (0.0832)   Prec@1 99.219 (97.073)   Prec@5 100.000 (99.977)   [2019-11-22 00:53:29]
  Epoch: [118][300/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.0342 (0.0837)   Prec@1 100.000 (97.049)   Prec@5 100.000 (99.982)   [2019-11-22 00:53:34]
  **Train** Prec@1 97.118 Prec@5 99.986 Error@1 2.882
  **Test** Prec@1 89.970 Prec@5 99.630 Error@1 10.030

==>>[2019-11-22 00:53:40] [Epoch=119/200] [Need: 00:27:09] [LR=0.0010][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [119][000/391]   Time 0.227 (0.227)   Data 0.172 (0.172)   Loss 0.0704 (0.0704)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:53:40]
  Epoch: [119][100/391]   Time 0.044 (0.047)   Data 0.000 (0.002)   Loss 0.1384 (0.0846)   Prec@1 95.312 (96.914)   Prec@5 99.219 (99.969)   [2019-11-22 00:53:44]
  Epoch: [119][200/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.0777 (0.0824)   Prec@1 97.656 (97.007)   Prec@5 100.000 (99.984)   [2019-11-22 00:53:49]
  Epoch: [119][300/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.0449 (0.0819)   Prec@1 98.438 (97.054)   Prec@5 100.000 (99.990)   [2019-11-22 00:53:53]
  **Train** Prec@1 97.084 Prec@5 99.988 Error@1 2.916
  **Test** Prec@1 90.240 Prec@5 99.670 Error@1 9.760

==>>[2019-11-22 00:53:59] [Epoch=120/200] [Need: 00:26:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.60, Error=9.40]
  Epoch: [120][000/391]   Time 0.225 (0.225)   Data 0.157 (0.157)   Loss 0.1465 (0.1465)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 00:53:59]
  Epoch: [120][100/391]   Time 0.071 (0.046)   Data 0.000 (0.002)   Loss 0.0882 (0.0781)   Prec@1 97.656 (97.347)   Prec@5 100.000 (99.977)   [2019-11-22 00:54:03]
  Epoch: [120][200/391]   Time 0.065 (0.047)   Data 0.000 (0.001)   Loss 0.0666 (0.0761)   Prec@1 97.656 (97.361)   Prec@5 100.000 (99.981)   [2019-11-22 00:54:08]
  Epoch: [120][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0544 (0.0748)   Prec@1 98.438 (97.433)   Prec@5 100.000 (99.982)   [2019-11-22 00:54:13]
  **Train** Prec@1 97.488 Prec@5 99.982 Error@1 2.512
  **Test** Prec@1 90.630 Prec@5 99.700 Error@1 9.370
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:54:19] [Epoch=121/200] [Need: 00:26:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.63, Error=9.37]
  Epoch: [121][000/391]   Time 0.227 (0.227)   Data 0.171 (0.171)   Loss 0.0578 (0.0578)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:54:19]
  Epoch: [121][100/391]   Time 0.039 (0.047)   Data 0.000 (0.002)   Loss 0.0442 (0.0701)   Prec@1 99.219 (97.517)   Prec@5 100.000 (99.969)   [2019-11-22 00:54:24]
  Epoch: [121][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0572 (0.0678)   Prec@1 97.656 (97.598)   Prec@5 100.000 (99.984)   [2019-11-22 00:54:28]
  Epoch: [121][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.0864 (0.0683)   Prec@1 96.875 (97.625)   Prec@5 100.000 (99.987)   [2019-11-22 00:54:33]
  **Train** Prec@1 97.610 Prec@5 99.982 Error@1 2.390
  **Test** Prec@1 90.740 Prec@5 99.650 Error@1 9.260
=> Obtain best accuracy, and update the best model

==>>[2019-11-22 00:54:38] [Epoch=122/200] [Need: 00:26:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [122][000/391]   Time 0.225 (0.225)   Data 0.160 (0.160)   Loss 0.0753 (0.0753)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:54:39]
  Epoch: [122][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.1152 (0.0684)   Prec@1 96.094 (97.571)   Prec@5 100.000 (99.992)   [2019-11-22 00:54:43]
  Epoch: [122][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0855 (0.0703)   Prec@1 97.656 (97.555)   Prec@5 100.000 (99.992)   [2019-11-22 00:54:48]
  Epoch: [122][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0609 (0.0672)   Prec@1 98.438 (97.672)   Prec@5 100.000 (99.995)   [2019-11-22 00:54:53]
  **Train** Prec@1 97.662 Prec@5 99.994 Error@1 2.338
  **Test** Prec@1 90.620 Prec@5 99.680 Error@1 9.380

==>>[2019-11-22 00:54:59] [Epoch=123/200] [Need: 00:25:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [123][000/391]   Time 0.219 (0.219)   Data 0.157 (0.157)   Loss 0.0875 (0.0875)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:55:00]
  Epoch: [123][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0404 (0.0675)   Prec@1 99.219 (97.641)   Prec@5 100.000 (99.992)   [2019-11-22 00:55:04]
  Epoch: [123][200/391]   Time 0.048 (0.049)   Data 0.000 (0.001)   Loss 0.0554 (0.0667)   Prec@1 97.656 (97.648)   Prec@5 100.000 (99.996)   [2019-11-22 00:55:09]
  Epoch: [123][300/391]   Time 0.078 (0.049)   Data 0.000 (0.001)   Loss 0.0496 (0.0665)   Prec@1 98.438 (97.659)   Prec@5 100.000 (99.992)   [2019-11-22 00:55:14]
  **Train** Prec@1 97.672 Prec@5 99.990 Error@1 2.328
  **Test** Prec@1 90.690 Prec@5 99.680 Error@1 9.310

==>>[2019-11-22 00:55:20] [Epoch=124/200] [Need: 00:25:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [124][000/391]   Time 0.213 (0.213)   Data 0.146 (0.146)   Loss 0.0599 (0.0599)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:55:20]
  Epoch: [124][100/391]   Time 0.039 (0.046)   Data 0.000 (0.002)   Loss 0.0280 (0.0625)   Prec@1 99.219 (97.857)   Prec@5 100.000 (99.992)   [2019-11-22 00:55:25]
  Epoch: [124][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0755 (0.0662)   Prec@1 97.656 (97.726)   Prec@5 100.000 (99.981)   [2019-11-22 00:55:29]
  Epoch: [124][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0560 (0.0663)   Prec@1 96.875 (97.669)   Prec@5 100.000 (99.982)   [2019-11-22 00:55:34]
  **Train** Prec@1 97.712 Prec@5 99.986 Error@1 2.288
  **Test** Prec@1 90.700 Prec@5 99.690 Error@1 9.300

==>>[2019-11-22 00:55:40] [Epoch=125/200] [Need: 00:25:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [125][000/391]   Time 0.209 (0.209)   Data 0.157 (0.157)   Loss 0.0279 (0.0279)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 00:55:40]
  Epoch: [125][100/391]   Time 0.041 (0.047)   Data 0.000 (0.002)   Loss 0.0327 (0.0635)   Prec@1 99.219 (97.919)   Prec@5 100.000 (100.000)   [2019-11-22 00:55:45]
  Epoch: [125][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0641 (0.0636)   Prec@1 97.656 (97.905)   Prec@5 100.000 (100.000)   [2019-11-22 00:55:50]
  Epoch: [125][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.0921 (0.0648)   Prec@1 96.094 (97.828)   Prec@5 100.000 (99.997)   [2019-11-22 00:55:55]
  **Train** Prec@1 97.786 Prec@5 99.994 Error@1 2.214
  **Test** Prec@1 90.630 Prec@5 99.670 Error@1 9.370

==>>[2019-11-22 00:56:00] [Epoch=126/200] [Need: 00:24:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [126][000/391]   Time 0.228 (0.228)   Data 0.144 (0.144)   Loss 0.0593 (0.0593)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:56:01]
  Epoch: [126][100/391]   Time 0.076 (0.048)   Data 0.000 (0.002)   Loss 0.0570 (0.0605)   Prec@1 97.656 (98.144)   Prec@5 100.000 (99.992)   [2019-11-22 00:56:05]
  Epoch: [126][200/391]   Time 0.049 (0.046)   Data 0.000 (0.001)   Loss 0.0688 (0.0634)   Prec@1 98.438 (97.963)   Prec@5 100.000 (99.984)   [2019-11-22 00:56:10]
  Epoch: [126][300/391]   Time 0.050 (0.047)   Data 0.000 (0.001)   Loss 0.0733 (0.0642)   Prec@1 95.312 (97.856)   Prec@5 100.000 (99.987)   [2019-11-22 00:56:14]
  **Train** Prec@1 97.898 Prec@5 99.990 Error@1 2.102
  **Test** Prec@1 90.680 Prec@5 99.670 Error@1 9.320

==>>[2019-11-22 00:56:21] [Epoch=127/200] [Need: 00:24:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [127][000/391]   Time 0.212 (0.212)   Data 0.155 (0.155)   Loss 0.0741 (0.0741)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:56:21]
  Epoch: [127][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.0529 (0.0624)   Prec@1 96.094 (97.679)   Prec@5 100.000 (100.000)   [2019-11-22 00:56:25]
  Epoch: [127][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0651 (0.0633)   Prec@1 98.438 (97.769)   Prec@5 100.000 (99.992)   [2019-11-22 00:56:30]
  Epoch: [127][300/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0603 (0.0621)   Prec@1 98.438 (97.882)   Prec@5 100.000 (99.995)   [2019-11-22 00:56:35]
  **Train** Prec@1 97.852 Prec@5 99.996 Error@1 2.148
  **Test** Prec@1 90.590 Prec@5 99.670 Error@1 9.410

==>>[2019-11-22 00:56:41] [Epoch=128/200] [Need: 00:24:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [128][000/391]   Time 0.220 (0.220)   Data 0.164 (0.164)   Loss 0.0404 (0.0404)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 00:56:41]
  Epoch: [128][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0887 (0.0657)   Prec@1 95.312 (97.672)   Prec@5 100.000 (99.992)   [2019-11-22 00:56:46]
  Epoch: [128][200/391]   Time 0.061 (0.050)   Data 0.000 (0.001)   Loss 0.0930 (0.0645)   Prec@1 96.875 (97.734)   Prec@5 100.000 (99.992)   [2019-11-22 00:56:51]
  Epoch: [128][300/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0680 (0.0637)   Prec@1 96.875 (97.781)   Prec@5 99.219 (99.992)   [2019-11-22 00:56:56]
  **Train** Prec@1 97.826 Prec@5 99.994 Error@1 2.174
  **Test** Prec@1 90.630 Prec@5 99.710 Error@1 9.370

==>>[2019-11-22 00:57:02] [Epoch=129/200] [Need: 00:23:49] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [129][000/391]   Time 0.230 (0.230)   Data 0.149 (0.149)   Loss 0.0599 (0.0599)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:02]
  Epoch: [129][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.0515 (0.0592)   Prec@1 97.656 (97.973)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:06]
  Epoch: [129][200/391]   Time 0.039 (0.046)   Data 0.000 (0.001)   Loss 0.0214 (0.0603)   Prec@1 100.000 (97.956)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:11]
  Epoch: [129][300/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.0358 (0.0596)   Prec@1 98.438 (97.996)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:15]
  **Train** Prec@1 97.948 Prec@5 99.990 Error@1 2.052
  **Test** Prec@1 90.490 Prec@5 99.700 Error@1 9.510

==>>[2019-11-22 00:57:21] [Epoch=130/200] [Need: 00:23:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [130][000/391]   Time 0.213 (0.213)   Data 0.157 (0.157)   Loss 0.0793 (0.0793)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:21]
  Epoch: [130][100/391]   Time 0.049 (0.050)   Data 0.000 (0.002)   Loss 0.0771 (0.0604)   Prec@1 96.875 (98.051)   Prec@5 100.000 (99.977)   [2019-11-22 00:57:26]
  Epoch: [130][200/391]   Time 0.061 (0.048)   Data 0.000 (0.001)   Loss 0.1244 (0.0603)   Prec@1 96.875 (98.022)   Prec@5 100.000 (99.981)   [2019-11-22 00:57:31]
  Epoch: [130][300/391]   Time 0.049 (0.047)   Data 0.000 (0.001)   Loss 0.0642 (0.0614)   Prec@1 97.656 (97.939)   Prec@5 100.000 (99.987)   [2019-11-22 00:57:35]
  **Train** Prec@1 97.886 Prec@5 99.988 Error@1 2.114
  **Test** Prec@1 90.550 Prec@5 99.660 Error@1 9.450

==>>[2019-11-22 00:57:41] [Epoch=131/200] [Need: 00:23:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [131][000/391]   Time 0.222 (0.222)   Data 0.146 (0.146)   Loss 0.0581 (0.0581)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:57:42]
  Epoch: [131][100/391]   Time 0.048 (0.045)   Data 0.000 (0.002)   Loss 0.0698 (0.0611)   Prec@1 97.656 (97.888)   Prec@5 100.000 (99.985)   [2019-11-22 00:57:46]
  Epoch: [131][200/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.0836 (0.0599)   Prec@1 95.312 (97.975)   Prec@5 100.000 (99.988)   [2019-11-22 00:57:51]
  Epoch: [131][300/391]   Time 0.043 (0.046)   Data 0.000 (0.001)   Loss 0.0638 (0.0593)   Prec@1 97.656 (97.963)   Prec@5 100.000 (99.990)   [2019-11-22 00:57:55]
  **Train** Prec@1 97.962 Prec@5 99.988 Error@1 2.038
  **Test** Prec@1 90.480 Prec@5 99.690 Error@1 9.520

==>>[2019-11-22 00:58:01] [Epoch=132/200] [Need: 00:22:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [132][000/391]   Time 0.220 (0.220)   Data 0.150 (0.150)   Loss 0.0476 (0.0476)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:02]
  Epoch: [132][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0625 (0.0655)   Prec@1 97.656 (97.649)   Prec@5 100.000 (99.977)   [2019-11-22 00:58:06]
  Epoch: [132][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0952 (0.0641)   Prec@1 96.094 (97.769)   Prec@5 100.000 (99.984)   [2019-11-22 00:58:11]
  Epoch: [132][300/391]   Time 0.042 (0.047)   Data 0.002 (0.001)   Loss 0.0574 (0.0626)   Prec@1 98.438 (97.838)   Prec@5 100.000 (99.987)   [2019-11-22 00:58:15]
  **Train** Prec@1 97.848 Prec@5 99.984 Error@1 2.152
  **Test** Prec@1 90.610 Prec@5 99.670 Error@1 9.390

==>>[2019-11-22 00:58:22] [Epoch=133/200] [Need: 00:22:28] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [133][000/391]   Time 0.237 (0.237)   Data 0.170 (0.170)   Loss 0.0515 (0.0515)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:22]
  Epoch: [133][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.0269 (0.0584)   Prec@1 100.000 (98.058)   Prec@5 100.000 (99.985)   [2019-11-22 00:58:27]
  Epoch: [133][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0372 (0.0596)   Prec@1 99.219 (97.963)   Prec@5 100.000 (99.992)   [2019-11-22 00:58:31]
  Epoch: [133][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.0256 (0.0598)   Prec@1 99.219 (97.988)   Prec@5 100.000 (99.990)   [2019-11-22 00:58:36]
  **Train** Prec@1 97.962 Prec@5 99.990 Error@1 2.038
  **Test** Prec@1 90.630 Prec@5 99.670 Error@1 9.370

==>>[2019-11-22 00:58:42] [Epoch=134/200] [Need: 00:22:08] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [134][000/391]   Time 0.218 (0.218)   Data 0.162 (0.162)   Loss 0.0287 (0.0287)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:42]
  Epoch: [134][100/391]   Time 0.040 (0.046)   Data 0.000 (0.002)   Loss 0.0472 (0.0571)   Prec@1 98.438 (98.151)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:47]
  Epoch: [134][200/391]   Time 0.058 (0.047)   Data 0.000 (0.001)   Loss 0.0582 (0.0596)   Prec@1 97.656 (98.076)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:52]
  Epoch: [134][300/391]   Time 0.039 (0.047)   Data 0.000 (0.001)   Loss 0.0346 (0.0591)   Prec@1 98.438 (98.007)   Prec@5 100.000 (100.000)   [2019-11-22 00:58:56]
  **Train** Prec@1 97.964 Prec@5 99.998 Error@1 2.036
  **Test** Prec@1 90.570 Prec@5 99.650 Error@1 9.430

==>>[2019-11-22 00:59:02] [Epoch=135/200] [Need: 00:21:48] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [135][000/391]   Time 0.225 (0.225)   Data 0.161 (0.161)   Loss 0.0185 (0.0185)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 00:59:03]
  Epoch: [135][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.0544 (0.0589)   Prec@1 98.438 (97.935)   Prec@5 100.000 (100.000)   [2019-11-22 00:59:07]
  Epoch: [135][200/391]   Time 0.047 (0.048)   Data 0.000 (0.001)   Loss 0.0599 (0.0591)   Prec@1 98.438 (98.002)   Prec@5 100.000 (99.996)   [2019-11-22 00:59:12]
  Epoch: [135][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0582 (0.0591)   Prec@1 98.438 (97.963)   Prec@5 100.000 (99.995)   [2019-11-22 00:59:17]
  **Train** Prec@1 97.960 Prec@5 99.994 Error@1 2.040
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-22 00:59:22] [Epoch=136/200] [Need: 00:21:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [136][000/391]   Time 0.217 (0.217)   Data 0.146 (0.146)   Loss 0.0557 (0.0557)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 00:59:22]
  Epoch: [136][100/391]   Time 0.047 (0.047)   Data 0.000 (0.002)   Loss 0.0491 (0.0584)   Prec@1 97.656 (97.780)   Prec@5 100.000 (99.992)   [2019-11-22 00:59:27]
  Epoch: [136][200/391]   Time 0.056 (0.048)   Data 0.000 (0.001)   Loss 0.0282 (0.0577)   Prec@1 98.438 (97.924)   Prec@5 100.000 (99.988)   [2019-11-22 00:59:32]
  Epoch: [136][300/391]   Time 0.048 (0.047)   Data 0.000 (0.001)   Loss 0.0441 (0.0578)   Prec@1 99.219 (97.968)   Prec@5 100.000 (99.990)   [2019-11-22 00:59:36]
  **Train** Prec@1 97.980 Prec@5 99.992 Error@1 2.020
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-22 00:59:42] [Epoch=137/200] [Need: 00:21:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [137][000/391]   Time 0.216 (0.216)   Data 0.162 (0.162)   Loss 0.0864 (0.0864)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 00:59:42]
  Epoch: [137][100/391]   Time 0.049 (0.052)   Data 0.000 (0.002)   Loss 0.0727 (0.0611)   Prec@1 97.656 (97.834)   Prec@5 100.000 (99.992)   [2019-11-22 00:59:47]
  Epoch: [137][200/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.0701 (0.0590)   Prec@1 97.656 (97.940)   Prec@5 100.000 (99.992)   [2019-11-22 00:59:52]
  Epoch: [137][300/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.0539 (0.0605)   Prec@1 98.438 (97.879)   Prec@5 100.000 (99.992)   [2019-11-22 00:59:57]
  **Train** Prec@1 97.910 Prec@5 99.994 Error@1 2.090
  **Test** Prec@1 90.560 Prec@5 99.720 Error@1 9.440

==>>[2019-11-22 01:00:03] [Epoch=138/200] [Need: 00:20:47] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [138][000/391]   Time 0.225 (0.225)   Data 0.164 (0.164)   Loss 0.0754 (0.0754)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:00:03]
  Epoch: [138][100/391]   Time 0.040 (0.049)   Data 0.000 (0.002)   Loss 0.0510 (0.0634)   Prec@1 96.875 (97.687)   Prec@5 100.000 (99.992)   [2019-11-22 01:00:07]
  Epoch: [138][200/391]   Time 0.047 (0.047)   Data 0.000 (0.001)   Loss 0.0414 (0.0599)   Prec@1 96.875 (97.882)   Prec@5 100.000 (99.992)   [2019-11-22 01:00:12]
  Epoch: [138][300/391]   Time 0.051 (0.047)   Data 0.000 (0.001)   Loss 0.0978 (0.0584)   Prec@1 96.875 (97.991)   Prec@5 100.000 (99.992)   [2019-11-22 01:00:17]
  **Train** Prec@1 97.976 Prec@5 99.992 Error@1 2.024
  **Test** Prec@1 90.720 Prec@5 99.670 Error@1 9.280

==>>[2019-11-22 01:00:23] [Epoch=139/200] [Need: 00:20:27] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [139][000/391]   Time 0.221 (0.221)   Data 0.161 (0.161)   Loss 0.0500 (0.0500)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:00:23]
  Epoch: [139][100/391]   Time 0.049 (0.047)   Data 0.000 (0.002)   Loss 0.0378 (0.0563)   Prec@1 98.438 (98.128)   Prec@5 100.000 (99.977)   [2019-11-22 01:00:28]
  Epoch: [139][200/391]   Time 0.041 (0.045)   Data 0.000 (0.001)   Loss 0.0225 (0.0583)   Prec@1 99.219 (97.979)   Prec@5 100.000 (99.981)   [2019-11-22 01:00:32]
  Epoch: [139][300/391]   Time 0.056 (0.044)   Data 0.000 (0.001)   Loss 0.0400 (0.0584)   Prec@1 98.438 (97.973)   Prec@5 100.000 (99.984)   [2019-11-22 01:00:36]
  **Train** Prec@1 97.984 Prec@5 99.982 Error@1 2.016
  **Test** Prec@1 90.680 Prec@5 99.680 Error@1 9.320

==>>[2019-11-22 01:00:42] [Epoch=140/200] [Need: 00:20:07] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [140][000/391]   Time 0.213 (0.213)   Data 0.146 (0.146)   Loss 0.0629 (0.0629)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:00:42]
  Epoch: [140][100/391]   Time 0.048 (0.050)   Data 0.000 (0.002)   Loss 0.0767 (0.0578)   Prec@1 96.094 (97.997)   Prec@5 100.000 (99.985)   [2019-11-22 01:00:47]
  Epoch: [140][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0479 (0.0582)   Prec@1 98.438 (97.940)   Prec@5 100.000 (99.992)   [2019-11-22 01:00:52]
  Epoch: [140][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0168 (0.0583)   Prec@1 99.219 (97.968)   Prec@5 100.000 (99.987)   [2019-11-22 01:00:56]
  **Train** Prec@1 97.964 Prec@5 99.986 Error@1 2.036
  **Test** Prec@1 90.590 Prec@5 99.650 Error@1 9.410

==>>[2019-11-22 01:01:02] [Epoch=141/200] [Need: 00:19:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [141][000/391]   Time 0.216 (0.216)   Data 0.145 (0.145)   Loss 0.0546 (0.0546)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:02]
  Epoch: [141][100/391]   Time 0.065 (0.052)   Data 0.000 (0.002)   Loss 0.0767 (0.0572)   Prec@1 96.875 (98.043)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:07]
  Epoch: [141][200/391]   Time 0.039 (0.049)   Data 0.000 (0.001)   Loss 0.0469 (0.0577)   Prec@1 98.438 (98.041)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:12]
  Epoch: [141][300/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0189 (0.0577)   Prec@1 100.000 (98.061)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:16]
  **Train** Prec@1 98.026 Prec@5 99.998 Error@1 1.974
  **Test** Prec@1 90.670 Prec@5 99.690 Error@1 9.330

==>>[2019-11-22 01:01:22] [Epoch=142/200] [Need: 00:19:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [142][000/391]   Time 0.229 (0.229)   Data 0.146 (0.146)   Loss 0.0687 (0.0687)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:22]
  Epoch: [142][100/391]   Time 0.042 (0.048)   Data 0.000 (0.002)   Loss 0.0803 (0.0576)   Prec@1 96.094 (98.128)   Prec@5 100.000 (99.985)   [2019-11-22 01:01:27]
  Epoch: [142][200/391]   Time 0.062 (0.048)   Data 0.000 (0.001)   Loss 0.0313 (0.0569)   Prec@1 99.219 (98.138)   Prec@5 100.000 (99.988)   [2019-11-22 01:01:31]
  Epoch: [142][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.0609 (0.0571)   Prec@1 99.219 (98.108)   Prec@5 100.000 (99.990)   [2019-11-22 01:01:36]
  **Train** Prec@1 98.032 Prec@5 99.984 Error@1 1.968
  **Test** Prec@1 90.650 Prec@5 99.680 Error@1 9.350

==>>[2019-11-22 01:01:42] [Epoch=143/200] [Need: 00:19:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [143][000/391]   Time 0.215 (0.215)   Data 0.161 (0.161)   Loss 0.0217 (0.0217)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:01:42]
  Epoch: [143][100/391]   Time 0.055 (0.049)   Data 0.000 (0.002)   Loss 0.0744 (0.0552)   Prec@1 97.656 (98.229)   Prec@5 100.000 (99.992)   [2019-11-22 01:01:47]
  Epoch: [143][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.0604 (0.0572)   Prec@1 97.656 (98.138)   Prec@5 100.000 (99.992)   [2019-11-22 01:01:51]
  Epoch: [143][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.0905 (0.0575)   Prec@1 96.094 (98.129)   Prec@5 100.000 (99.995)   [2019-11-22 01:01:56]
  **Train** Prec@1 98.098 Prec@5 99.992 Error@1 1.902
  **Test** Prec@1 90.570 Prec@5 99.640 Error@1 9.430

==>>[2019-11-22 01:02:02] [Epoch=144/200] [Need: 00:18:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [144][000/391]   Time 0.226 (0.226)   Data 0.158 (0.158)   Loss 0.0290 (0.0290)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:02:02]
  Epoch: [144][100/391]   Time 0.038 (0.050)   Data 0.000 (0.002)   Loss 0.0553 (0.0566)   Prec@1 98.438 (98.097)   Prec@5 100.000 (99.985)   [2019-11-22 01:02:07]
  Epoch: [144][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0864 (0.0568)   Prec@1 97.656 (98.111)   Prec@5 100.000 (99.984)   [2019-11-22 01:02:11]
  Epoch: [144][300/391]   Time 0.046 (0.047)   Data 0.000 (0.001)   Loss 0.0807 (0.0578)   Prec@1 96.875 (98.056)   Prec@5 100.000 (99.990)   [2019-11-22 01:02:16]
  **Train** Prec@1 97.994 Prec@5 99.990 Error@1 2.006
  **Test** Prec@1 90.550 Prec@5 99.690 Error@1 9.450

==>>[2019-11-22 01:02:22] [Epoch=145/200] [Need: 00:18:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [145][000/391]   Time 0.229 (0.229)   Data 0.174 (0.174)   Loss 0.0437 (0.0437)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:02:23]
  Epoch: [145][100/391]   Time 0.042 (0.048)   Data 0.000 (0.002)   Loss 0.0674 (0.0568)   Prec@1 96.094 (98.082)   Prec@5 100.000 (99.992)   [2019-11-22 01:02:27]
  Epoch: [145][200/391]   Time 0.049 (0.047)   Data 0.000 (0.001)   Loss 0.0729 (0.0576)   Prec@1 97.656 (98.010)   Prec@5 100.000 (99.988)   [2019-11-22 01:02:32]
  Epoch: [145][300/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.0479 (0.0571)   Prec@1 98.438 (98.014)   Prec@5 100.000 (99.987)   [2019-11-22 01:02:36]
  **Train** Prec@1 97.984 Prec@5 99.990 Error@1 2.016
  **Test** Prec@1 90.570 Prec@5 99.680 Error@1 9.430

==>>[2019-11-22 01:02:42] [Epoch=146/200] [Need: 00:18:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [146][000/391]   Time 0.217 (0.217)   Data 0.147 (0.147)   Loss 0.0411 (0.0411)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:02:43]
  Epoch: [146][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.0446 (0.0576)   Prec@1 98.438 (98.128)   Prec@5 100.000 (99.992)   [2019-11-22 01:02:47]
  Epoch: [146][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0752 (0.0575)   Prec@1 99.219 (98.142)   Prec@5 100.000 (99.996)   [2019-11-22 01:02:52]
  Epoch: [146][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.0999 (0.0587)   Prec@1 94.531 (98.043)   Prec@5 100.000 (99.995)   [2019-11-22 01:02:56]
  **Train** Prec@1 98.040 Prec@5 99.996 Error@1 1.960
  **Test** Prec@1 90.400 Prec@5 99.640 Error@1 9.600

==>>[2019-11-22 01:03:02] [Epoch=147/200] [Need: 00:17:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [147][000/391]   Time 0.229 (0.229)   Data 0.176 (0.176)   Loss 0.0625 (0.0625)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:02]
  Epoch: [147][100/391]   Time 0.037 (0.047)   Data 0.000 (0.002)   Loss 0.0620 (0.0587)   Prec@1 96.875 (98.004)   Prec@5 100.000 (99.992)   [2019-11-22 01:03:07]
  Epoch: [147][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0410 (0.0564)   Prec@1 98.438 (98.057)   Prec@5 100.000 (99.996)   [2019-11-22 01:03:12]
  Epoch: [147][300/391]   Time 0.041 (0.046)   Data 0.002 (0.001)   Loss 0.0412 (0.0564)   Prec@1 97.656 (98.074)   Prec@5 100.000 (99.997)   [2019-11-22 01:03:16]
  **Train** Prec@1 98.042 Prec@5 99.996 Error@1 1.958
  **Test** Prec@1 90.540 Prec@5 99.680 Error@1 9.460

==>>[2019-11-22 01:03:22] [Epoch=148/200] [Need: 00:17:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [148][000/391]   Time 0.223 (0.223)   Data 0.168 (0.168)   Loss 0.0425 (0.0425)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:22]
  Epoch: [148][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0541 (0.0566)   Prec@1 98.438 (98.028)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:28]
  Epoch: [148][200/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.0196 (0.0576)   Prec@1 99.219 (98.018)   Prec@5 100.000 (99.996)   [2019-11-22 01:03:32]
  Epoch: [148][300/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.0538 (0.0572)   Prec@1 97.656 (98.022)   Prec@5 100.000 (99.995)   [2019-11-22 01:03:37]
  **Train** Prec@1 98.034 Prec@5 99.994 Error@1 1.966
  **Test** Prec@1 90.470 Prec@5 99.650 Error@1 9.530

==>>[2019-11-22 01:03:43] [Epoch=149/200] [Need: 00:17:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [149][000/391]   Time 0.206 (0.206)   Data 0.153 (0.153)   Loss 0.0422 (0.0422)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:43]
  Epoch: [149][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0348 (0.0586)   Prec@1 99.219 (97.950)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:48]
  Epoch: [149][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0489 (0.0579)   Prec@1 97.656 (98.033)   Prec@5 100.000 (100.000)   [2019-11-22 01:03:53]
  Epoch: [149][300/391]   Time 0.046 (0.048)   Data 0.000 (0.001)   Loss 0.0600 (0.0574)   Prec@1 97.656 (98.053)   Prec@5 100.000 (99.997)   [2019-11-22 01:03:57]
  **Train** Prec@1 98.092 Prec@5 99.998 Error@1 1.908
  **Test** Prec@1 90.500 Prec@5 99.690 Error@1 9.500

==>>[2019-11-22 01:04:04] [Epoch=150/200] [Need: 00:16:46] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [150][000/391]   Time 0.214 (0.214)   Data 0.149 (0.149)   Loss 0.0338 (0.0338)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:04:04]
  Epoch: [150][100/391]   Time 0.038 (0.049)   Data 0.000 (0.002)   Loss 0.0438 (0.0568)   Prec@1 98.438 (97.997)   Prec@5 100.000 (100.000)   [2019-11-22 01:04:08]
  Epoch: [150][200/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0475 (0.0571)   Prec@1 98.438 (97.975)   Prec@5 100.000 (99.996)   [2019-11-22 01:04:13]
  Epoch: [150][300/391]   Time 0.046 (0.048)   Data 0.000 (0.001)   Loss 0.0503 (0.0579)   Prec@1 98.438 (97.931)   Prec@5 100.000 (99.995)   [2019-11-22 01:04:18]
  **Train** Prec@1 97.920 Prec@5 99.996 Error@1 2.080
  **Test** Prec@1 90.400 Prec@5 99.690 Error@1 9.600

==>>[2019-11-22 01:04:24] [Epoch=151/200] [Need: 00:16:26] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [151][000/391]   Time 0.231 (0.231)   Data 0.158 (0.158)   Loss 0.0833 (0.0833)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-22 01:04:24]
  Epoch: [151][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.0696 (0.0581)   Prec@1 96.875 (98.097)   Prec@5 100.000 (99.992)   [2019-11-22 01:04:29]
  Epoch: [151][200/391]   Time 0.050 (0.048)   Data 0.000 (0.001)   Loss 0.0386 (0.0561)   Prec@1 97.656 (98.088)   Prec@5 100.000 (99.992)   [2019-11-22 01:04:34]
  Epoch: [151][300/391]   Time 0.051 (0.048)   Data 0.000 (0.001)   Loss 0.0498 (0.0563)   Prec@1 97.656 (98.108)   Prec@5 100.000 (99.987)   [2019-11-22 01:04:38]
  **Train** Prec@1 98.080 Prec@5 99.988 Error@1 1.920
  **Test** Prec@1 90.560 Prec@5 99.660 Error@1 9.440

==>>[2019-11-22 01:04:45] [Epoch=152/200] [Need: 00:16:06] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [152][000/391]   Time 0.210 (0.210)   Data 0.153 (0.153)   Loss 0.0500 (0.0500)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:04:45]
  Epoch: [152][100/391]   Time 0.044 (0.046)   Data 0.000 (0.002)   Loss 0.0806 (0.0548)   Prec@1 96.094 (98.190)   Prec@5 100.000 (99.992)   [2019-11-22 01:04:50]
  Epoch: [152][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0678 (0.0545)   Prec@1 97.656 (98.150)   Prec@5 100.000 (99.996)   [2019-11-22 01:04:54]
  Epoch: [152][300/391]   Time 0.078 (0.047)   Data 0.000 (0.001)   Loss 0.0306 (0.0561)   Prec@1 98.438 (98.087)   Prec@5 100.000 (99.992)   [2019-11-22 01:04:59]
  **Train** Prec@1 98.126 Prec@5 99.988 Error@1 1.874
  **Test** Prec@1 90.560 Prec@5 99.660 Error@1 9.440

==>>[2019-11-22 01:05:05] [Epoch=153/200] [Need: 00:15:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [153][000/391]   Time 0.217 (0.217)   Data 0.167 (0.167)   Loss 0.0377 (0.0377)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:05:05]
  Epoch: [153][100/391]   Time 0.034 (0.047)   Data 0.000 (0.002)   Loss 0.0366 (0.0519)   Prec@1 98.438 (98.283)   Prec@5 100.000 (99.992)   [2019-11-22 01:05:09]
  Epoch: [153][200/391]   Time 0.066 (0.047)   Data 0.000 (0.001)   Loss 0.0793 (0.0532)   Prec@1 96.875 (98.204)   Prec@5 100.000 (99.996)   [2019-11-22 01:05:14]
  Epoch: [153][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0344 (0.0538)   Prec@1 99.219 (98.196)   Prec@5 100.000 (99.995)   [2019-11-22 01:05:19]
  **Train** Prec@1 98.226 Prec@5 99.996 Error@1 1.774
  **Test** Prec@1 90.610 Prec@5 99.700 Error@1 9.390

==>>[2019-11-22 01:05:25] [Epoch=154/200] [Need: 00:15:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [154][000/391]   Time 0.230 (0.230)   Data 0.167 (0.167)   Loss 0.0207 (0.0207)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:05:25]
  Epoch: [154][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.1225 (0.0588)   Prec@1 97.656 (98.004)   Prec@5 100.000 (99.985)   [2019-11-22 01:05:30]
  Epoch: [154][200/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.0956 (0.0575)   Prec@1 96.875 (98.025)   Prec@5 100.000 (99.992)   [2019-11-22 01:05:35]
  Epoch: [154][300/391]   Time 0.065 (0.049)   Data 0.000 (0.001)   Loss 0.0620 (0.0564)   Prec@1 98.438 (98.087)   Prec@5 100.000 (99.995)   [2019-11-22 01:05:39]
  **Train** Prec@1 98.104 Prec@5 99.994 Error@1 1.896
  **Test** Prec@1 90.560 Prec@5 99.660 Error@1 9.440

==>>[2019-11-22 01:05:45] [Epoch=155/200] [Need: 00:15:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [155][000/391]   Time 0.231 (0.231)   Data 0.175 (0.175)   Loss 0.0462 (0.0462)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:05:46]
  Epoch: [155][100/391]   Time 0.040 (0.048)   Data 0.000 (0.002)   Loss 0.0702 (0.0515)   Prec@1 97.656 (98.329)   Prec@5 100.000 (100.000)   [2019-11-22 01:05:50]
  Epoch: [155][200/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.0507 (0.0529)   Prec@1 99.219 (98.309)   Prec@5 100.000 (99.996)   [2019-11-22 01:05:55]
  Epoch: [155][300/391]   Time 0.056 (0.047)   Data 0.000 (0.001)   Loss 0.0515 (0.0544)   Prec@1 97.656 (98.222)   Prec@5 100.000 (99.992)   [2019-11-22 01:05:59]
  **Train** Prec@1 98.172 Prec@5 99.990 Error@1 1.828
  **Test** Prec@1 90.480 Prec@5 99.660 Error@1 9.520

==>>[2019-11-22 01:06:06] [Epoch=156/200] [Need: 00:14:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [156][000/391]   Time 0.210 (0.210)   Data 0.145 (0.145)   Loss 0.0251 (0.0251)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:06:06]
  Epoch: [156][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0741 (0.0513)   Prec@1 96.094 (98.252)   Prec@5 100.000 (99.992)   [2019-11-22 01:06:11]
  Epoch: [156][200/391]   Time 0.061 (0.047)   Data 0.000 (0.001)   Loss 0.0196 (0.0534)   Prec@1 100.000 (98.123)   Prec@5 100.000 (99.996)   [2019-11-22 01:06:15]
  Epoch: [156][300/391]   Time 0.071 (0.048)   Data 0.000 (0.001)   Loss 0.0474 (0.0534)   Prec@1 97.656 (98.162)   Prec@5 100.000 (99.995)   [2019-11-22 01:06:20]
  **Train** Prec@1 98.146 Prec@5 99.994 Error@1 1.854
  **Test** Prec@1 90.520 Prec@5 99.630 Error@1 9.480

==>>[2019-11-22 01:06:26] [Epoch=157/200] [Need: 00:14:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [157][000/391]   Time 0.225 (0.225)   Data 0.151 (0.151)   Loss 0.0368 (0.0368)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:06:27]
  Epoch: [157][100/391]   Time 0.041 (0.050)   Data 0.000 (0.002)   Loss 0.0480 (0.0548)   Prec@1 98.438 (98.120)   Prec@5 100.000 (100.000)   [2019-11-22 01:06:31]
  Epoch: [157][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0288 (0.0555)   Prec@1 100.000 (97.991)   Prec@5 100.000 (99.992)   [2019-11-22 01:06:36]
  Epoch: [157][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0391 (0.0554)   Prec@1 99.219 (98.017)   Prec@5 100.000 (99.992)   [2019-11-22 01:06:41]
  **Train** Prec@1 98.062 Prec@5 99.992 Error@1 1.938
  **Test** Prec@1 90.450 Prec@5 99.690 Error@1 9.550

==>>[2019-11-22 01:06:47] [Epoch=158/200] [Need: 00:14:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [158][000/391]   Time 0.222 (0.222)   Data 0.158 (0.158)   Loss 0.0533 (0.0533)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:06:48]
  Epoch: [158][100/391]   Time 0.078 (0.050)   Data 0.000 (0.002)   Loss 0.0532 (0.0554)   Prec@1 97.656 (98.066)   Prec@5 100.000 (99.992)   [2019-11-22 01:06:52]
  Epoch: [158][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0563 (0.0541)   Prec@1 96.875 (98.095)   Prec@5 100.000 (99.992)   [2019-11-22 01:06:57]
  Epoch: [158][300/391]   Time 0.037 (0.049)   Data 0.000 (0.001)   Loss 0.0838 (0.0532)   Prec@1 95.312 (98.160)   Prec@5 100.000 (99.992)   [2019-11-22 01:07:02]
  **Train** Prec@1 98.178 Prec@5 99.994 Error@1 1.822
  **Test** Prec@1 90.510 Prec@5 99.670 Error@1 9.490

==>>[2019-11-22 01:07:08] [Epoch=159/200] [Need: 00:13:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [159][000/391]   Time 0.211 (0.211)   Data 0.151 (0.151)   Loss 0.0410 (0.0410)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:08]
  Epoch: [159][100/391]   Time 0.041 (0.045)   Data 0.000 (0.002)   Loss 0.0741 (0.0541)   Prec@1 97.656 (98.058)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:12]
  Epoch: [159][200/391]   Time 0.074 (0.046)   Data 0.000 (0.001)   Loss 0.0563 (0.0558)   Prec@1 96.875 (98.057)   Prec@5 100.000 (99.996)   [2019-11-22 01:07:17]
  Epoch: [159][300/391]   Time 0.047 (0.047)   Data 0.000 (0.001)   Loss 0.0294 (0.0564)   Prec@1 99.219 (98.064)   Prec@5 100.000 (99.992)   [2019-11-22 01:07:22]
  **Train** Prec@1 98.104 Prec@5 99.994 Error@1 1.896
  **Test** Prec@1 90.610 Prec@5 99.650 Error@1 9.390

==>>[2019-11-22 01:07:28] [Epoch=160/200] [Need: 00:13:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [160][000/391]   Time 0.210 (0.210)   Data 0.138 (0.138)   Loss 0.0577 (0.0577)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:28]
  Epoch: [160][100/391]   Time 0.080 (0.051)   Data 0.000 (0.001)   Loss 0.0433 (0.0517)   Prec@1 98.438 (98.329)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:33]
  Epoch: [160][200/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.0511 (0.0532)   Prec@1 99.219 (98.228)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:38]
  Epoch: [160][300/391]   Time 0.076 (0.048)   Data 0.000 (0.001)   Loss 0.0449 (0.0516)   Prec@1 98.438 (98.303)   Prec@5 100.000 (99.997)   [2019-11-22 01:07:42]
  **Train** Prec@1 98.298 Prec@5 99.996 Error@1 1.702
  **Test** Prec@1 90.490 Prec@5 99.650 Error@1 9.510

==>>[2019-11-22 01:07:49] [Epoch=161/200] [Need: 00:13:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [161][000/391]   Time 0.213 (0.213)   Data 0.160 (0.160)   Loss 0.0899 (0.0899)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:07:49]
  Epoch: [161][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0728 (0.0592)   Prec@1 97.656 (97.981)   Prec@5 100.000 (99.992)   [2019-11-22 01:07:54]
  Epoch: [161][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0407 (0.0562)   Prec@1 98.438 (98.080)   Prec@5 100.000 (99.992)   [2019-11-22 01:07:58]
  Epoch: [161][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0193 (0.0547)   Prec@1 100.000 (98.144)   Prec@5 100.000 (99.990)   [2019-11-22 01:08:03]
  **Train** Prec@1 98.130 Prec@5 99.984 Error@1 1.870
  **Test** Prec@1 90.470 Prec@5 99.630 Error@1 9.530

==>>[2019-11-22 01:08:09] [Epoch=162/200] [Need: 00:12:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [162][000/391]   Time 0.211 (0.211)   Data 0.158 (0.158)   Loss 0.0683 (0.0683)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:10]
  Epoch: [162][100/391]   Time 0.042 (0.048)   Data 0.000 (0.002)   Loss 0.0326 (0.0545)   Prec@1 99.219 (98.105)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:14]
  Epoch: [162][200/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0250 (0.0547)   Prec@1 100.000 (98.084)   Prec@5 100.000 (99.988)   [2019-11-22 01:08:19]
  Epoch: [162][300/391]   Time 0.048 (0.047)   Data 0.000 (0.001)   Loss 0.0389 (0.0539)   Prec@1 98.438 (98.162)   Prec@5 100.000 (99.992)   [2019-11-22 01:08:23]
  **Train** Prec@1 98.198 Prec@5 99.994 Error@1 1.802
  **Test** Prec@1 90.510 Prec@5 99.680 Error@1 9.490

==>>[2019-11-22 01:08:30] [Epoch=163/200] [Need: 00:12:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [163][000/391]   Time 0.215 (0.215)   Data 0.147 (0.147)   Loss 0.0460 (0.0460)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:30]
  Epoch: [163][100/391]   Time 0.079 (0.052)   Data 0.000 (0.002)   Loss 0.0360 (0.0498)   Prec@1 99.219 (98.399)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:35]
  Epoch: [163][200/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.0670 (0.0513)   Prec@1 98.438 (98.290)   Prec@5 99.219 (99.992)   [2019-11-22 01:08:40]
  Epoch: [163][300/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.0802 (0.0512)   Prec@1 96.875 (98.318)   Prec@5 100.000 (99.995)   [2019-11-22 01:08:45]
  **Train** Prec@1 98.256 Prec@5 99.994 Error@1 1.744
  **Test** Prec@1 90.540 Prec@5 99.650 Error@1 9.460

==>>[2019-11-22 01:08:51] [Epoch=164/200] [Need: 00:12:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [164][000/391]   Time 0.234 (0.234)   Data 0.182 (0.182)   Loss 0.0431 (0.0431)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:51]
  Epoch: [164][100/391]   Time 0.041 (0.050)   Data 0.000 (0.002)   Loss 0.0286 (0.0538)   Prec@1 99.219 (98.213)   Prec@5 100.000 (100.000)   [2019-11-22 01:08:56]
  Epoch: [164][200/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.0578 (0.0526)   Prec@1 98.438 (98.239)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:00]
  Epoch: [164][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0620 (0.0527)   Prec@1 96.875 (98.212)   Prec@5 100.000 (99.997)   [2019-11-22 01:09:05]
  **Train** Prec@1 98.220 Prec@5 99.998 Error@1 1.780
  **Test** Prec@1 90.590 Prec@5 99.660 Error@1 9.410

==>>[2019-11-22 01:09:11] [Epoch=165/200] [Need: 00:11:45] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [165][000/391]   Time 0.226 (0.226)   Data 0.173 (0.173)   Loss 0.0521 (0.0521)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:11]
  Epoch: [165][100/391]   Time 0.077 (0.049)   Data 0.000 (0.002)   Loss 0.0654 (0.0511)   Prec@1 97.656 (98.275)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:16]
  Epoch: [165][200/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0317 (0.0496)   Prec@1 99.219 (98.360)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:21]
  Epoch: [165][300/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.0643 (0.0494)   Prec@1 97.656 (98.344)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:25]
  **Train** Prec@1 98.348 Prec@5 100.000 Error@1 1.652
  **Test** Prec@1 90.530 Prec@5 99.650 Error@1 9.470

==>>[2019-11-22 01:09:32] [Epoch=166/200] [Need: 00:11:25] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [166][000/391]   Time 0.220 (0.220)   Data 0.150 (0.150)   Loss 0.0117 (0.0117)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:32]
  Epoch: [166][100/391]   Time 0.040 (0.046)   Data 0.000 (0.002)   Loss 0.0276 (0.0523)   Prec@1 99.219 (98.298)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:36]
  Epoch: [166][200/391]   Time 0.042 (0.045)   Data 0.000 (0.001)   Loss 0.0195 (0.0527)   Prec@1 100.000 (98.208)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:41]
  Epoch: [166][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0152 (0.0532)   Prec@1 100.000 (98.186)   Prec@5 100.000 (99.997)   [2019-11-22 01:09:45]
  **Train** Prec@1 98.198 Prec@5 99.998 Error@1 1.802
  **Test** Prec@1 90.480 Prec@5 99.660 Error@1 9.520

==>>[2019-11-22 01:09:52] [Epoch=167/200] [Need: 00:11:05] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [167][000/391]   Time 0.227 (0.227)   Data 0.170 (0.170)   Loss 0.0195 (0.0195)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:52]
  Epoch: [167][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.0172 (0.0523)   Prec@1 100.000 (98.097)   Prec@5 100.000 (100.000)   [2019-11-22 01:09:56]
  Epoch: [167][200/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.0370 (0.0527)   Prec@1 100.000 (98.189)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:01]
  Epoch: [167][300/391]   Time 0.052 (0.046)   Data 0.000 (0.001)   Loss 0.0359 (0.0527)   Prec@1 99.219 (98.191)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:05]
  **Train** Prec@1 98.178 Prec@5 100.000 Error@1 1.822
  **Test** Prec@1 90.620 Prec@5 99.660 Error@1 9.380

==>>[2019-11-22 01:10:11] [Epoch=168/200] [Need: 00:10:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [168][000/391]   Time 0.214 (0.214)   Data 0.158 (0.158)   Loss 0.0989 (0.0989)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:11]
  Epoch: [168][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.0719 (0.0527)   Prec@1 96.094 (98.190)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:16]
  Epoch: [168][200/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.0359 (0.0529)   Prec@1 99.219 (98.197)   Prec@5 100.000 (99.996)   [2019-11-22 01:10:21]
  Epoch: [168][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0399 (0.0531)   Prec@1 97.656 (98.136)   Prec@5 100.000 (99.997)   [2019-11-22 01:10:25]
  **Train** Prec@1 98.152 Prec@5 99.994 Error@1 1.848
  **Test** Prec@1 90.430 Prec@5 99.670 Error@1 9.570

==>>[2019-11-22 01:10:31] [Epoch=169/200] [Need: 00:10:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [169][000/391]   Time 0.230 (0.230)   Data 0.178 (0.178)   Loss 0.0805 (0.0805)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:31]
  Epoch: [169][100/391]   Time 0.056 (0.052)   Data 0.000 (0.002)   Loss 0.0478 (0.0502)   Prec@1 98.438 (98.329)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:36]
  Epoch: [169][200/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.0302 (0.0500)   Prec@1 100.000 (98.317)   Prec@5 100.000 (99.992)   [2019-11-22 01:10:40]
  Epoch: [169][300/391]   Time 0.042 (0.046)   Data 0.000 (0.001)   Loss 0.0500 (0.0511)   Prec@1 98.438 (98.295)   Prec@5 100.000 (99.990)   [2019-11-22 01:10:45]
  **Train** Prec@1 98.266 Prec@5 99.992 Error@1 1.734
  **Test** Prec@1 90.540 Prec@5 99.700 Error@1 9.460

==>>[2019-11-22 01:10:51] [Epoch=170/200] [Need: 00:10:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [170][000/391]   Time 0.224 (0.224)   Data 0.146 (0.146)   Loss 0.0486 (0.0486)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:10:51]
  Epoch: [170][100/391]   Time 0.050 (0.049)   Data 0.000 (0.002)   Loss 0.0328 (0.0492)   Prec@1 99.219 (98.267)   Prec@5 100.000 (99.992)   [2019-11-22 01:10:56]
  Epoch: [170][200/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.0421 (0.0524)   Prec@1 98.438 (98.200)   Prec@5 100.000 (99.996)   [2019-11-22 01:11:00]
  Epoch: [170][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0567 (0.0521)   Prec@1 97.656 (98.251)   Prec@5 100.000 (99.995)   [2019-11-22 01:11:05]
  **Train** Prec@1 98.232 Prec@5 99.996 Error@1 1.768
  **Test** Prec@1 90.510 Prec@5 99.670 Error@1 9.490

==>>[2019-11-22 01:11:11] [Epoch=171/200] [Need: 00:09:44] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [171][000/391]   Time 0.224 (0.224)   Data 0.172 (0.172)   Loss 0.0352 (0.0352)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:11:11]
  Epoch: [171][100/391]   Time 0.048 (0.047)   Data 0.000 (0.002)   Loss 0.0845 (0.0551)   Prec@1 96.094 (98.144)   Prec@5 100.000 (99.985)   [2019-11-22 01:11:16]
  Epoch: [171][200/391]   Time 0.044 (0.047)   Data 0.000 (0.001)   Loss 0.0601 (0.0535)   Prec@1 98.438 (98.228)   Prec@5 100.000 (99.992)   [2019-11-22 01:11:20]
  Epoch: [171][300/391]   Time 0.047 (0.047)   Data 0.000 (0.001)   Loss 0.0502 (0.0531)   Prec@1 98.438 (98.201)   Prec@5 100.000 (99.995)   [2019-11-22 01:11:25]
  **Train** Prec@1 98.170 Prec@5 99.996 Error@1 1.830
  **Test** Prec@1 90.660 Prec@5 99.680 Error@1 9.340

==>>[2019-11-22 01:11:31] [Epoch=172/200] [Need: 00:09:24] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [172][000/391]   Time 0.226 (0.226)   Data 0.172 (0.172)   Loss 0.0664 (0.0664)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:11:31]
  Epoch: [172][100/391]   Time 0.040 (0.046)   Data 0.000 (0.002)   Loss 0.0609 (0.0542)   Prec@1 96.875 (98.151)   Prec@5 100.000 (100.000)   [2019-11-22 01:11:36]
  Epoch: [172][200/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.0638 (0.0521)   Prec@1 97.656 (98.193)   Prec@5 100.000 (99.996)   [2019-11-22 01:11:40]
  Epoch: [172][300/391]   Time 0.048 (0.046)   Data 0.000 (0.001)   Loss 0.0745 (0.0511)   Prec@1 96.875 (98.274)   Prec@5 100.000 (99.992)   [2019-11-22 01:11:45]
  **Train** Prec@1 98.252 Prec@5 99.994 Error@1 1.748
  **Test** Prec@1 90.460 Prec@5 99.670 Error@1 9.540

==>>[2019-11-22 01:11:51] [Epoch=173/200] [Need: 00:09:04] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [173][000/391]   Time 0.233 (0.233)   Data 0.178 (0.178)   Loss 0.0712 (0.0712)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:11:52]
  Epoch: [173][100/391]   Time 0.043 (0.048)   Data 0.000 (0.002)   Loss 0.0258 (0.0494)   Prec@1 100.000 (98.376)   Prec@5 100.000 (100.000)   [2019-11-22 01:11:56]
  Epoch: [173][200/391]   Time 0.039 (0.047)   Data 0.000 (0.001)   Loss 0.0530 (0.0523)   Prec@1 98.438 (98.224)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:01]
  Epoch: [173][300/391]   Time 0.036 (0.047)   Data 0.000 (0.001)   Loss 0.0368 (0.0521)   Prec@1 98.438 (98.235)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:06]
  **Train** Prec@1 98.266 Prec@5 100.000 Error@1 1.734
  **Test** Prec@1 90.540 Prec@5 99.670 Error@1 9.460

==>>[2019-11-22 01:12:11] [Epoch=174/200] [Need: 00:08:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [174][000/391]   Time 0.222 (0.222)   Data 0.166 (0.166)   Loss 0.0380 (0.0380)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:11]
  Epoch: [174][100/391]   Time 0.041 (0.051)   Data 0.000 (0.002)   Loss 0.0303 (0.0513)   Prec@1 99.219 (98.113)   Prec@5 100.000 (99.992)   [2019-11-22 01:12:16]
  Epoch: [174][200/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0409 (0.0513)   Prec@1 98.438 (98.208)   Prec@5 100.000 (99.984)   [2019-11-22 01:12:21]
  Epoch: [174][300/391]   Time 0.081 (0.047)   Data 0.000 (0.001)   Loss 0.0298 (0.0514)   Prec@1 99.219 (98.230)   Prec@5 100.000 (99.990)   [2019-11-22 01:12:25]
  **Train** Prec@1 98.208 Prec@5 99.992 Error@1 1.792
  **Test** Prec@1 90.540 Prec@5 99.710 Error@1 9.460

==>>[2019-11-22 01:12:31] [Epoch=175/200] [Need: 00:08:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [175][000/391]   Time 0.230 (0.230)   Data 0.176 (0.176)   Loss 0.0536 (0.0536)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:32]
  Epoch: [175][100/391]   Time 0.050 (0.048)   Data 0.000 (0.002)   Loss 0.0357 (0.0533)   Prec@1 98.438 (98.260)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:36]
  Epoch: [175][200/391]   Time 0.052 (0.047)   Data 0.000 (0.001)   Loss 0.0486 (0.0535)   Prec@1 97.656 (98.162)   Prec@5 100.000 (99.996)   [2019-11-22 01:12:41]
  Epoch: [175][300/391]   Time 0.059 (0.047)   Data 0.000 (0.001)   Loss 0.0943 (0.0533)   Prec@1 96.875 (98.183)   Prec@5 99.219 (99.992)   [2019-11-22 01:12:45]
  **Train** Prec@1 98.176 Prec@5 99.994 Error@1 1.824
  **Test** Prec@1 90.510 Prec@5 99.670 Error@1 9.490

==>>[2019-11-22 01:12:52] [Epoch=176/200] [Need: 00:08:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [176][000/391]   Time 0.231 (0.231)   Data 0.162 (0.162)   Loss 0.0601 (0.0601)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:52]
  Epoch: [176][100/391]   Time 0.051 (0.049)   Data 0.000 (0.002)   Loss 0.0674 (0.0510)   Prec@1 96.875 (98.345)   Prec@5 100.000 (100.000)   [2019-11-22 01:12:56]
  Epoch: [176][200/391]   Time 0.045 (0.047)   Data 0.000 (0.001)   Loss 0.0188 (0.0510)   Prec@1 99.219 (98.282)   Prec@5 100.000 (99.996)   [2019-11-22 01:13:01]
  Epoch: [176][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0463 (0.0524)   Prec@1 97.656 (98.230)   Prec@5 100.000 (99.997)   [2019-11-22 01:13:06]
  **Train** Prec@1 98.270 Prec@5 99.996 Error@1 1.730
  **Test** Prec@1 90.580 Prec@5 99.700 Error@1 9.420

==>>[2019-11-22 01:13:11] [Epoch=177/200] [Need: 00:07:43] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [177][000/391]   Time 0.214 (0.214)   Data 0.147 (0.147)   Loss 0.0485 (0.0485)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:13:12]
  Epoch: [177][100/391]   Time 0.040 (0.045)   Data 0.000 (0.002)   Loss 0.0707 (0.0534)   Prec@1 97.656 (98.144)   Prec@5 100.000 (99.992)   [2019-11-22 01:13:16]
  Epoch: [177][200/391]   Time 0.039 (0.044)   Data 0.000 (0.001)   Loss 0.1148 (0.0538)   Prec@1 96.094 (98.154)   Prec@5 100.000 (99.996)   [2019-11-22 01:13:20]
  Epoch: [177][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0280 (0.0516)   Prec@1 100.000 (98.256)   Prec@5 100.000 (99.995)   [2019-11-22 01:13:25]
  **Train** Prec@1 98.216 Prec@5 99.994 Error@1 1.784
  **Test** Prec@1 90.390 Prec@5 99.670 Error@1 9.610

==>>[2019-11-22 01:13:32] [Epoch=178/200] [Need: 00:07:23] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [178][000/391]   Time 0.219 (0.219)   Data 0.165 (0.165)   Loss 0.0525 (0.0525)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:13:32]
  Epoch: [178][100/391]   Time 0.046 (0.048)   Data 0.000 (0.002)   Loss 0.0692 (0.0498)   Prec@1 97.656 (98.321)   Prec@5 100.000 (100.000)   [2019-11-22 01:13:36]
  Epoch: [178][200/391]   Time 0.076 (0.048)   Data 0.000 (0.001)   Loss 0.0256 (0.0506)   Prec@1 99.219 (98.301)   Prec@5 100.000 (99.996)   [2019-11-22 01:13:41]
  Epoch: [178][300/391]   Time 0.041 (0.046)   Data 0.000 (0.001)   Loss 0.0293 (0.0506)   Prec@1 99.219 (98.310)   Prec@5 100.000 (99.997)   [2019-11-22 01:13:45]
  **Train** Prec@1 98.288 Prec@5 99.996 Error@1 1.712
  **Test** Prec@1 90.550 Prec@5 99.660 Error@1 9.450

==>>[2019-11-22 01:13:51] [Epoch=179/200] [Need: 00:07:03] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [179][000/391]   Time 0.219 (0.219)   Data 0.157 (0.157)   Loss 0.0753 (0.0753)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-11-22 01:13:51]
  Epoch: [179][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0362 (0.0520)   Prec@1 99.219 (98.229)   Prec@5 100.000 (99.992)   [2019-11-22 01:13:56]
  Epoch: [179][200/391]   Time 0.044 (0.048)   Data 0.000 (0.001)   Loss 0.0467 (0.0518)   Prec@1 98.438 (98.231)   Prec@5 100.000 (99.996)   [2019-11-22 01:14:01]
  Epoch: [179][300/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.0793 (0.0532)   Prec@1 96.875 (98.175)   Prec@5 99.219 (99.995)   [2019-11-22 01:14:05]
  **Train** Prec@1 98.210 Prec@5 99.994 Error@1 1.790
  **Test** Prec@1 90.580 Prec@5 99.640 Error@1 9.420

==>>[2019-11-22 01:14:12] [Epoch=180/200] [Need: 00:06:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [180][000/391]   Time 0.227 (0.227)   Data 0.146 (0.146)   Loss 0.0316 (0.0316)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:14:12]
  Epoch: [180][100/391]   Time 0.059 (0.050)   Data 0.000 (0.002)   Loss 0.0301 (0.0494)   Prec@1 98.438 (98.252)   Prec@5 100.000 (99.992)   [2019-11-22 01:14:17]
  Epoch: [180][200/391]   Time 0.047 (0.047)   Data 0.000 (0.001)   Loss 0.0348 (0.0507)   Prec@1 99.219 (98.290)   Prec@5 100.000 (99.996)   [2019-11-22 01:14:21]
  Epoch: [180][300/391]   Time 0.038 (0.047)   Data 0.000 (0.001)   Loss 0.0413 (0.0515)   Prec@1 98.438 (98.264)   Prec@5 100.000 (99.997)   [2019-11-22 01:14:26]
  **Train** Prec@1 98.278 Prec@5 99.992 Error@1 1.722
  **Test** Prec@1 90.530 Prec@5 99.660 Error@1 9.470

==>>[2019-11-22 01:14:31] [Epoch=181/200] [Need: 00:06:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [181][000/391]   Time 0.211 (0.211)   Data 0.139 (0.139)   Loss 0.0337 (0.0337)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:14:32]
  Epoch: [181][100/391]   Time 0.040 (0.049)   Data 0.000 (0.002)   Loss 0.0248 (0.0468)   Prec@1 99.219 (98.461)   Prec@5 100.000 (100.000)   [2019-11-22 01:14:36]
  Epoch: [181][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0363 (0.0480)   Prec@1 98.438 (98.406)   Prec@5 100.000 (100.000)   [2019-11-22 01:14:41]
  Epoch: [181][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0560 (0.0498)   Prec@1 96.875 (98.328)   Prec@5 100.000 (99.997)   [2019-11-22 01:14:46]
  **Train** Prec@1 98.304 Prec@5 99.998 Error@1 1.696
  **Test** Prec@1 90.400 Prec@5 99.680 Error@1 9.600

==>>[2019-11-22 01:14:52] [Epoch=182/200] [Need: 00:06:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [182][000/391]   Time 0.217 (0.217)   Data 0.164 (0.164)   Loss 0.0577 (0.0577)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:14:52]
  Epoch: [182][100/391]   Time 0.041 (0.049)   Data 0.000 (0.002)   Loss 0.0419 (0.0500)   Prec@1 99.219 (98.360)   Prec@5 100.000 (99.992)   [2019-11-22 01:14:57]
  Epoch: [182][200/391]   Time 0.056 (0.049)   Data 0.000 (0.001)   Loss 0.0480 (0.0519)   Prec@1 99.219 (98.286)   Prec@5 100.000 (99.992)   [2019-11-22 01:15:02]
  Epoch: [182][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0514 (0.0515)   Prec@1 97.656 (98.287)   Prec@5 100.000 (99.992)   [2019-11-22 01:15:06]
  **Train** Prec@1 98.276 Prec@5 99.992 Error@1 1.724
  **Test** Prec@1 90.600 Prec@5 99.670 Error@1 9.400

==>>[2019-11-22 01:15:12] [Epoch=183/200] [Need: 00:05:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [183][000/391]   Time 0.226 (0.226)   Data 0.149 (0.149)   Loss 0.0548 (0.0548)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:15:13]
  Epoch: [183][100/391]   Time 0.048 (0.049)   Data 0.000 (0.002)   Loss 0.0278 (0.0493)   Prec@1 99.219 (98.461)   Prec@5 100.000 (100.000)   [2019-11-22 01:15:17]
  Epoch: [183][200/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0110 (0.0535)   Prec@1 100.000 (98.251)   Prec@5 100.000 (99.992)   [2019-11-22 01:15:22]
  Epoch: [183][300/391]   Time 0.040 (0.045)   Data 0.000 (0.001)   Loss 0.0208 (0.0522)   Prec@1 100.000 (98.243)   Prec@5 100.000 (99.992)   [2019-11-22 01:15:26]
  **Train** Prec@1 98.280 Prec@5 99.992 Error@1 1.720
  **Test** Prec@1 90.480 Prec@5 99.660 Error@1 9.520

==>>[2019-11-22 01:15:32] [Epoch=184/200] [Need: 00:05:22] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [184][000/391]   Time 0.226 (0.226)   Data 0.145 (0.145)   Loss 0.0652 (0.0652)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:15:32]
  Epoch: [184][100/391]   Time 0.060 (0.050)   Data 0.000 (0.002)   Loss 0.0977 (0.0478)   Prec@1 96.094 (98.438)   Prec@5 100.000 (99.985)   [2019-11-22 01:15:37]
  Epoch: [184][200/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.1142 (0.0488)   Prec@1 96.094 (98.371)   Prec@5 100.000 (99.988)   [2019-11-22 01:15:42]
  Epoch: [184][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0307 (0.0488)   Prec@1 99.219 (98.367)   Prec@5 100.000 (99.992)   [2019-11-22 01:15:46]
  **Train** Prec@1 98.354 Prec@5 99.990 Error@1 1.646
  **Test** Prec@1 90.470 Prec@5 99.690 Error@1 9.530

==>>[2019-11-22 01:15:52] [Epoch=185/200] [Need: 00:05:02] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [185][000/391]   Time 0.221 (0.221)   Data 0.167 (0.167)   Loss 0.0452 (0.0452)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:15:52]
  Epoch: [185][100/391]   Time 0.045 (0.046)   Data 0.000 (0.002)   Loss 0.0509 (0.0490)   Prec@1 98.438 (98.337)   Prec@5 100.000 (100.000)   [2019-11-22 01:15:57]
  Epoch: [185][200/391]   Time 0.042 (0.047)   Data 0.000 (0.001)   Loss 0.0698 (0.0517)   Prec@1 96.875 (98.197)   Prec@5 100.000 (99.996)   [2019-11-22 01:16:02]
  Epoch: [185][300/391]   Time 0.036 (0.047)   Data 0.000 (0.001)   Loss 0.0504 (0.0517)   Prec@1 98.438 (98.232)   Prec@5 100.000 (99.997)   [2019-11-22 01:16:06]
  **Train** Prec@1 98.182 Prec@5 99.998 Error@1 1.818
  **Test** Prec@1 90.560 Prec@5 99.660 Error@1 9.440

==>>[2019-11-22 01:16:13] [Epoch=186/200] [Need: 00:04:42] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [186][000/391]   Time 0.230 (0.230)   Data 0.174 (0.174)   Loss 0.0689 (0.0689)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:16:13]
  Epoch: [186][100/391]   Time 0.041 (0.048)   Data 0.000 (0.002)   Loss 0.0512 (0.0483)   Prec@1 98.438 (98.507)   Prec@5 100.000 (100.000)   [2019-11-22 01:16:17]
  Epoch: [186][200/391]   Time 0.046 (0.047)   Data 0.000 (0.001)   Loss 0.0377 (0.0505)   Prec@1 98.438 (98.356)   Prec@5 100.000 (99.996)   [2019-11-22 01:16:22]
  Epoch: [186][300/391]   Time 0.045 (0.048)   Data 0.000 (0.001)   Loss 0.0500 (0.0507)   Prec@1 98.438 (98.308)   Prec@5 100.000 (99.997)   [2019-11-22 01:16:27]
  **Train** Prec@1 98.308 Prec@5 99.998 Error@1 1.692
  **Test** Prec@1 90.530 Prec@5 99.650 Error@1 9.470

==>>[2019-11-22 01:16:33] [Epoch=187/200] [Need: 00:04:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [187][000/391]   Time 0.234 (0.234)   Data 0.179 (0.179)   Loss 0.0456 (0.0456)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:16:33]
  Epoch: [187][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0870 (0.0475)   Prec@1 96.094 (98.546)   Prec@5 100.000 (99.992)   [2019-11-22 01:16:38]
  Epoch: [187][200/391]   Time 0.041 (0.048)   Data 0.000 (0.001)   Loss 0.0358 (0.0505)   Prec@1 99.219 (98.360)   Prec@5 100.000 (99.992)   [2019-11-22 01:16:42]
  Epoch: [187][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0348 (0.0504)   Prec@1 99.219 (98.316)   Prec@5 100.000 (99.995)   [2019-11-22 01:16:47]
  **Train** Prec@1 98.324 Prec@5 99.996 Error@1 1.676
  **Test** Prec@1 90.450 Prec@5 99.680 Error@1 9.550

==>>[2019-11-22 01:16:53] [Epoch=188/200] [Need: 00:04:01] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [188][000/391]   Time 0.217 (0.217)   Data 0.157 (0.157)   Loss 0.0237 (0.0237)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:16:54]
  Epoch: [188][100/391]   Time 0.039 (0.053)   Data 0.000 (0.002)   Loss 0.0278 (0.0485)   Prec@1 98.438 (98.345)   Prec@5 100.000 (100.000)   [2019-11-22 01:16:59]
  Epoch: [188][200/391]   Time 0.046 (0.049)   Data 0.000 (0.001)   Loss 0.0227 (0.0520)   Prec@1 100.000 (98.200)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:03]
  Epoch: [188][300/391]   Time 0.078 (0.047)   Data 0.000 (0.001)   Loss 0.0513 (0.0509)   Prec@1 98.438 (98.243)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:08]
  **Train** Prec@1 98.248 Prec@5 99.998 Error@1 1.752
  **Test** Prec@1 90.560 Prec@5 99.670 Error@1 9.440

==>>[2019-11-22 01:17:14] [Epoch=189/200] [Need: 00:03:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [189][000/391]   Time 0.231 (0.231)   Data 0.178 (0.178)   Loss 0.0418 (0.0418)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:14]
  Epoch: [189][100/391]   Time 0.047 (0.051)   Data 0.001 (0.002)   Loss 0.0470 (0.0476)   Prec@1 97.656 (98.383)   Prec@5 100.000 (99.992)   [2019-11-22 01:17:19]
  Epoch: [189][200/391]   Time 0.039 (0.048)   Data 0.000 (0.001)   Loss 0.0891 (0.0487)   Prec@1 97.656 (98.305)   Prec@5 100.000 (99.996)   [2019-11-22 01:17:23]
  Epoch: [189][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0318 (0.0495)   Prec@1 99.219 (98.313)   Prec@5 100.000 (99.995)   [2019-11-22 01:17:28]
  **Train** Prec@1 98.294 Prec@5 99.996 Error@1 1.706
  **Test** Prec@1 90.570 Prec@5 99.690 Error@1 9.430

==>>[2019-11-22 01:17:34] [Epoch=190/200] [Need: 00:03:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [190][000/391]   Time 0.215 (0.215)   Data 0.137 (0.137)   Loss 0.0392 (0.0392)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:34]
  Epoch: [190][100/391]   Time 0.058 (0.049)   Data 0.000 (0.002)   Loss 0.0374 (0.0556)   Prec@1 98.438 (98.082)   Prec@5 100.000 (99.992)   [2019-11-22 01:17:39]
  Epoch: [190][200/391]   Time 0.038 (0.049)   Data 0.000 (0.001)   Loss 0.1009 (0.0526)   Prec@1 98.438 (98.239)   Prec@5 100.000 (99.996)   [2019-11-22 01:17:43]
  Epoch: [190][300/391]   Time 0.060 (0.048)   Data 0.000 (0.001)   Loss 0.0654 (0.0513)   Prec@1 97.656 (98.303)   Prec@5 100.000 (99.997)   [2019-11-22 01:17:48]
  **Train** Prec@1 98.270 Prec@5 99.998 Error@1 1.730
  **Test** Prec@1 90.520 Prec@5 99.660 Error@1 9.480

==>>[2019-11-22 01:17:54] [Epoch=191/200] [Need: 00:03:01] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [191][000/391]   Time 0.215 (0.215)   Data 0.159 (0.159)   Loss 0.0349 (0.0349)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:54]
  Epoch: [191][100/391]   Time 0.041 (0.052)   Data 0.000 (0.002)   Loss 0.0745 (0.0455)   Prec@1 96.094 (98.492)   Prec@5 100.000 (100.000)   [2019-11-22 01:17:59]
  Epoch: [191][200/391]   Time 0.040 (0.050)   Data 0.000 (0.001)   Loss 0.0371 (0.0492)   Prec@1 99.219 (98.325)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:04]
  Epoch: [191][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0466 (0.0502)   Prec@1 98.438 (98.277)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:08]
  **Train** Prec@1 98.294 Prec@5 100.000 Error@1 1.706
  **Test** Prec@1 90.530 Prec@5 99.660 Error@1 9.470

==>>[2019-11-22 01:18:14] [Epoch=192/200] [Need: 00:02:41] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [192][000/391]   Time 0.228 (0.228)   Data 0.148 (0.148)   Loss 0.0486 (0.0486)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:14]
  Epoch: [192][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.0474 (0.0480)   Prec@1 97.656 (98.399)   Prec@5 100.000 (99.992)   [2019-11-22 01:18:19]
  Epoch: [192][200/391]   Time 0.037 (0.050)   Data 0.000 (0.001)   Loss 0.0753 (0.0493)   Prec@1 97.656 (98.356)   Prec@5 100.000 (99.996)   [2019-11-22 01:18:24]
  Epoch: [192][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0585 (0.0505)   Prec@1 97.656 (98.341)   Prec@5 100.000 (99.997)   [2019-11-22 01:18:28]
  **Train** Prec@1 98.346 Prec@5 99.996 Error@1 1.654
  **Test** Prec@1 90.480 Prec@5 99.690 Error@1 9.520

==>>[2019-11-22 01:18:34] [Epoch=193/200] [Need: 00:02:21] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [193][000/391]   Time 0.218 (0.218)   Data 0.162 (0.162)   Loss 0.0632 (0.0632)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:34]
  Epoch: [193][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.0673 (0.0505)   Prec@1 97.656 (98.221)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:39]
  Epoch: [193][200/391]   Time 0.050 (0.047)   Data 0.000 (0.001)   Loss 0.0477 (0.0511)   Prec@1 98.438 (98.216)   Prec@5 100.000 (99.992)   [2019-11-22 01:18:44]
  Epoch: [193][300/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0476 (0.0506)   Prec@1 98.438 (98.256)   Prec@5 100.000 (99.990)   [2019-11-22 01:18:48]
  **Train** Prec@1 98.254 Prec@5 99.992 Error@1 1.746
  **Test** Prec@1 90.500 Prec@5 99.670 Error@1 9.500

==>>[2019-11-22 01:18:55] [Epoch=194/200] [Need: 00:02:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [194][000/391]   Time 0.226 (0.226)   Data 0.173 (0.173)   Loss 0.0230 (0.0230)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-22 01:18:55]
  Epoch: [194][100/391]   Time 0.041 (0.047)   Data 0.000 (0.002)   Loss 0.0639 (0.0511)   Prec@1 97.656 (98.175)   Prec@5 100.000 (99.992)   [2019-11-22 01:18:59]
  Epoch: [194][200/391]   Time 0.063 (0.046)   Data 0.000 (0.001)   Loss 0.0498 (0.0508)   Prec@1 98.438 (98.255)   Prec@5 100.000 (99.996)   [2019-11-22 01:19:04]
  Epoch: [194][300/391]   Time 0.051 (0.045)   Data 0.000 (0.001)   Loss 0.0397 (0.0504)   Prec@1 98.438 (98.251)   Prec@5 100.000 (99.995)   [2019-11-22 01:19:08]
  **Train** Prec@1 98.222 Prec@5 99.994 Error@1 1.778
  **Test** Prec@1 90.450 Prec@5 99.690 Error@1 9.550

==>>[2019-11-22 01:19:14] [Epoch=195/200] [Need: 00:01:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [195][000/391]   Time 0.228 (0.228)   Data 0.159 (0.159)   Loss 0.0803 (0.0803)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:19:15]
  Epoch: [195][100/391]   Time 0.040 (0.052)   Data 0.000 (0.002)   Loss 0.0476 (0.0513)   Prec@1 99.219 (98.244)   Prec@5 100.000 (99.985)   [2019-11-22 01:19:20]
  Epoch: [195][200/391]   Time 0.041 (0.047)   Data 0.000 (0.001)   Loss 0.0469 (0.0502)   Prec@1 97.656 (98.298)   Prec@5 100.000 (99.988)   [2019-11-22 01:19:24]
  Epoch: [195][300/391]   Time 0.040 (0.048)   Data 0.000 (0.001)   Loss 0.0737 (0.0510)   Prec@1 97.656 (98.305)   Prec@5 100.000 (99.990)   [2019-11-22 01:19:29]
  **Train** Prec@1 98.290 Prec@5 99.992 Error@1 1.710
  **Test** Prec@1 90.550 Prec@5 99.670 Error@1 9.450

==>>[2019-11-22 01:19:35] [Epoch=196/200] [Need: 00:01:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [196][000/391]   Time 0.204 (0.204)   Data 0.144 (0.144)   Loss 0.0948 (0.0948)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-22 01:19:35]
  Epoch: [196][100/391]   Time 0.041 (0.046)   Data 0.000 (0.002)   Loss 0.0490 (0.0467)   Prec@1 97.656 (98.453)   Prec@5 100.000 (99.992)   [2019-11-22 01:19:39]
  Epoch: [196][200/391]   Time 0.052 (0.046)   Data 0.000 (0.001)   Loss 0.0866 (0.0469)   Prec@1 95.312 (98.461)   Prec@5 100.000 (99.996)   [2019-11-22 01:19:44]
  Epoch: [196][300/391]   Time 0.040 (0.046)   Data 0.000 (0.001)   Loss 0.0814 (0.0480)   Prec@1 96.875 (98.404)   Prec@5 100.000 (99.997)   [2019-11-22 01:19:49]
  **Train** Prec@1 98.434 Prec@5 99.998 Error@1 1.566
  **Test** Prec@1 90.370 Prec@5 99.710 Error@1 9.630

==>>[2019-11-22 01:19:54] [Epoch=197/200] [Need: 00:01:00] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [197][000/391]   Time 0.226 (0.226)   Data 0.160 (0.160)   Loss 0.0229 (0.0229)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-22 01:19:55]
  Epoch: [197][100/391]   Time 0.050 (0.050)   Data 0.000 (0.002)   Loss 0.0380 (0.0471)   Prec@1 99.219 (98.352)   Prec@5 100.000 (100.000)   [2019-11-22 01:19:59]
  Epoch: [197][200/391]   Time 0.059 (0.049)   Data 0.000 (0.001)   Loss 0.0387 (0.0478)   Prec@1 99.219 (98.356)   Prec@5 100.000 (100.000)   [2019-11-22 01:20:04]
  Epoch: [197][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0442 (0.0494)   Prec@1 99.219 (98.308)   Prec@5 100.000 (99.997)   [2019-11-22 01:20:09]
  **Train** Prec@1 98.308 Prec@5 99.998 Error@1 1.692
  **Test** Prec@1 90.480 Prec@5 99.670 Error@1 9.520

==>>[2019-11-22 01:20:15] [Epoch=198/200] [Need: 00:00:40] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [198][000/391]   Time 0.225 (0.225)   Data 0.169 (0.169)   Loss 0.0729 (0.0729)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-22 01:20:15]
  Epoch: [198][100/391]   Time 0.040 (0.047)   Data 0.000 (0.002)   Loss 0.0562 (0.0494)   Prec@1 98.438 (98.345)   Prec@5 100.000 (99.992)   [2019-11-22 01:20:20]
  Epoch: [198][200/391]   Time 0.051 (0.047)   Data 0.000 (0.001)   Loss 0.0274 (0.0489)   Prec@1 99.219 (98.336)   Prec@5 100.000 (99.992)   [2019-11-22 01:20:25]
  Epoch: [198][300/391]   Time 0.040 (0.047)   Data 0.000 (0.001)   Loss 0.0366 (0.0489)   Prec@1 99.219 (98.360)   Prec@5 100.000 (99.992)   [2019-11-22 01:20:29]
  **Train** Prec@1 98.348 Prec@5 99.992 Error@1 1.652
  **Test** Prec@1 90.490 Prec@5 99.660 Error@1 9.510

==>>[2019-11-22 01:20:36] [Epoch=199/200] [Need: 00:00:20] [LR=0.0001][M=0.90] [Best : Accuracy=90.74, Error=9.26]
  Epoch: [199][000/391]   Time 0.240 (0.240)   Data 0.156 (0.156)   Loss 0.0588 (0.0588)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-22 01:20:36]
  Epoch: [199][100/391]   Time 0.059 (0.054)   Data 0.000 (0.002)   Loss 0.0312 (0.0473)   Prec@1 98.438 (98.484)   Prec@5 100.000 (100.000)   [2019-11-22 01:20:41]
  Epoch: [199][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0291 (0.0481)   Prec@1 100.000 (98.414)   Prec@5 100.000 (99.996)   [2019-11-22 01:20:46]
  Epoch: [199][300/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0608 (0.0486)   Prec@1 98.438 (98.383)   Prec@5 100.000 (99.997)   [2019-11-22 01:20:50]
  **Train** Prec@1 98.366 Prec@5 99.996 Error@1 1.634
  **Test** Prec@1 90.590 Prec@5 99.680 Error@1 9.410
