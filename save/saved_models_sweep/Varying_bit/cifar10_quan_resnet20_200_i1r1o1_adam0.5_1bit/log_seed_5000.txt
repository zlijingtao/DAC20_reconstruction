save path : ./save/2019-11-23/cifar10_quan_resnet20_200_i1r1o1_adam0.5_1bit
{'AD_sigma': 0.0, 'DA_sigma': 0.0, 'arch': 'quan_resnet20', 'attack_sample_size': 128, 'batch_size': 128, 'data_path': './dataset/', 'dataset': 'cifar10', 'decay': 1e-05, 'enable_bfa': False, 'epochs': 200, 'evaluate': False, 'fine_tune': False, 'gammas': [0.1, 0.1, 0.5], 'gpu_id': 0, 'input_M2D': 0.5, 'input_grain_size': [1, 1], 'input_num_bits': 1, 'k_top': 10, 'learning_rate': 0.01, 'manualSeed': 5000, 'model_only': False, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimize_step': False, 'optimizer': 'Adam', 'output_M2D': 0.5, 'output_grain_size': [1, 1], 'output_num_bits': 1, 'print_freq': 100, 'regular_factor': 0.0, 'res_M2D': 0.5, 'res_grain_size': [1, 1], 'res_num_bits': 1, 'reset_weight': False, 'resume': '', 'save_path': './save/2019-11-23/cifar10_quan_resnet20_200_i1r1o1_adam0.5_1bit', 'schedule': [80, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'workers': 4}
Random Seed: 5000
python version : 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7600
=> creating model 'quan_resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): quan_Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): quan_Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for quan_resnet20 model

==>>[2019-11-24 13:14:42] [Epoch=000/200] [Need: 00:00:00] [LR=0.0100][M=0.90] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 1.649 (1.649)   Data 0.167 (0.167)   Loss 4.0999 (4.0999)   Prec@1 10.156 (10.156)   Prec@5 50.781 (50.781)   [2019-11-24 13:14:43]
  Epoch: [000][100/391]   Time 0.054 (0.068)   Data 0.000 (0.002)   Loss 1.8291 (1.9497)   Prec@1 35.156 (28.032)   Prec@5 85.156 (81.892)   [2019-11-24 13:14:49]
  Epoch: [000][200/391]   Time 0.044 (0.060)   Data 0.000 (0.001)   Loss 1.5675 (1.7688)   Prec@1 41.406 (34.394)   Prec@5 89.844 (86.237)   [2019-11-24 13:14:54]
  Epoch: [000][300/391]   Time 0.081 (0.059)   Data 0.000 (0.001)   Loss 1.2822 (1.6381)   Prec@1 54.688 (39.447)   Prec@5 93.750 (88.577)   [2019-11-24 13:14:59]
  **Train** Prec@1 43.014 Prec@5 89.918 Error@1 56.986
  **Test** Prec@1 53.870 Prec@5 94.880 Error@1 46.130
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:15:05] [Epoch=001/200] [Need: 01:18:03] [LR=0.0100][M=0.90] [Best : Accuracy=53.87, Error=46.13]
  Epoch: [001][000/391]   Time 0.285 (0.285)   Data 0.213 (0.213)   Loss 1.1446 (1.1446)   Prec@1 60.156 (60.156)   Prec@5 96.875 (96.875)   [2019-11-24 13:15:06]
  Epoch: [001][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 1.1735 (1.1445)   Prec@1 60.938 (58.632)   Prec@5 96.094 (95.552)   [2019-11-24 13:15:11]
  Epoch: [001][200/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.9843 (1.0946)   Prec@1 64.062 (60.553)   Prec@5 96.875 (95.923)   [2019-11-24 13:15:16]
  Epoch: [001][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.9269 (1.0704)   Prec@1 64.062 (61.651)   Prec@5 97.656 (96.042)   [2019-11-24 13:15:21]
  **Train** Prec@1 62.758 Prec@5 96.296 Error@1 37.242
  **Test** Prec@1 63.300 Prec@5 97.360 Error@1 36.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:15:27] [Epoch=002/200] [Need: 01:13:40] [LR=0.0100][M=0.90] [Best : Accuracy=63.30, Error=36.70]
  Epoch: [002][000/391]   Time 0.265 (0.265)   Data 0.212 (0.212)   Loss 0.8592 (0.8592)   Prec@1 72.656 (72.656)   Prec@5 96.875 (96.875)   [2019-11-24 13:15:27]
  Epoch: [002][100/391]   Time 0.074 (0.054)   Data 0.000 (0.002)   Loss 1.0238 (0.8938)   Prec@1 66.406 (68.410)   Prec@5 95.312 (97.440)   [2019-11-24 13:15:32]
  Epoch: [002][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 1.0209 (0.8601)   Prec@1 67.188 (69.601)   Prec@5 96.875 (97.738)   [2019-11-24 13:15:37]
  Epoch: [002][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.7960 (0.8473)   Prec@1 75.000 (70.100)   Prec@5 96.875 (97.763)   [2019-11-24 13:15:42]
  **Train** Prec@1 70.752 Prec@5 97.832 Error@1 29.248
  **Test** Prec@1 70.710 Prec@5 97.420 Error@1 29.290
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:15:49] [Epoch=003/200] [Need: 01:13:09] [LR=0.0100][M=0.90] [Best : Accuracy=70.71, Error=29.29]
  Epoch: [003][000/391]   Time 0.266 (0.266)   Data 0.205 (0.205)   Loss 0.9476 (0.9476)   Prec@1 68.750 (68.750)   Prec@5 93.750 (93.750)   [2019-11-24 13:15:49]
  Epoch: [003][100/391]   Time 0.059 (0.053)   Data 0.000 (0.002)   Loss 0.6650 (0.7460)   Prec@1 74.219 (74.087)   Prec@5 98.438 (98.205)   [2019-11-24 13:15:54]
  Epoch: [003][200/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.7746 (0.7370)   Prec@1 67.969 (74.234)   Prec@5 98.438 (98.274)   [2019-11-24 13:15:59]
  Epoch: [003][300/391]   Time 0.067 (0.051)   Data 0.000 (0.001)   Loss 0.4909 (0.7304)   Prec@1 85.156 (74.582)   Prec@5 99.219 (98.271)   [2019-11-24 13:16:04]
  **Train** Prec@1 74.942 Prec@5 98.326 Error@1 25.058
  **Test** Prec@1 75.930 Prec@5 98.470 Error@1 24.070
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:16:11] [Epoch=004/200] [Need: 01:12:23] [LR=0.0100][M=0.90] [Best : Accuracy=75.93, Error=24.07]
  Epoch: [004][000/391]   Time 0.266 (0.266)   Data 0.200 (0.200)   Loss 0.6146 (0.6146)   Prec@1 80.469 (80.469)   Prec@5 100.000 (100.000)   [2019-11-24 13:16:11]
  Epoch: [004][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.4128 (0.6677)   Prec@1 88.281 (77.174)   Prec@5 99.219 (98.453)   [2019-11-24 13:16:16]
  Epoch: [004][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.6348 (0.6664)   Prec@1 78.906 (77.006)   Prec@5 100.000 (98.558)   [2019-11-24 13:16:21]
  Epoch: [004][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.6651 (0.6591)   Prec@1 79.688 (77.118)   Prec@5 96.875 (98.656)   [2019-11-24 13:16:26]
  **Train** Prec@1 77.418 Prec@5 98.726 Error@1 22.582
  **Test** Prec@1 75.850 Prec@5 98.530 Error@1 24.150

==>>[2019-11-24 13:16:33] [Epoch=005/200] [Need: 01:12:01] [LR=0.0100][M=0.90] [Best : Accuracy=75.93, Error=24.07]
  Epoch: [005][000/391]   Time 0.276 (0.276)   Data 0.216 (0.216)   Loss 0.6395 (0.6395)   Prec@1 76.562 (76.562)   Prec@5 100.000 (100.000)   [2019-11-24 13:16:33]
  Epoch: [005][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.4883 (0.6124)   Prec@1 82.812 (78.434)   Prec@5 98.438 (98.762)   [2019-11-24 13:16:38]
  Epoch: [005][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.6255 (0.6164)   Prec@1 82.031 (78.486)   Prec@5 96.875 (98.741)   [2019-11-24 13:16:43]
  Epoch: [005][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.6773 (0.6081)   Prec@1 80.469 (78.844)   Prec@5 98.438 (98.775)   [2019-11-24 13:16:48]
  **Train** Prec@1 79.130 Prec@5 98.786 Error@1 20.870
  **Test** Prec@1 78.560 Prec@5 98.750 Error@1 21.440
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:16:55] [Epoch=006/200] [Need: 01:11:31] [LR=0.0100][M=0.90] [Best : Accuracy=78.56, Error=21.44]
  Epoch: [006][000/391]   Time 0.289 (0.289)   Data 0.199 (0.199)   Loss 0.5317 (0.5317)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-24 13:16:55]
  Epoch: [006][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.5972 (0.5726)   Prec@1 75.781 (80.368)   Prec@5 98.438 (98.971)   [2019-11-24 13:17:00]
  Epoch: [006][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.6002 (0.5644)   Prec@1 76.562 (80.508)   Prec@5 99.219 (99.005)   [2019-11-24 13:17:05]
  Epoch: [006][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.6151 (0.5696)   Prec@1 77.344 (80.287)   Prec@5 99.219 (98.990)   [2019-11-24 13:17:10]
  **Train** Prec@1 80.516 Prec@5 98.992 Error@1 19.484
  **Test** Prec@1 75.570 Prec@5 98.590 Error@1 24.430

==>>[2019-11-24 13:17:16] [Epoch=007/200] [Need: 01:10:57] [LR=0.0100][M=0.90] [Best : Accuracy=78.56, Error=21.44]
  Epoch: [007][000/391]   Time 0.282 (0.282)   Data 0.227 (0.227)   Loss 0.6421 (0.6421)   Prec@1 81.250 (81.250)   Prec@5 96.094 (96.094)   [2019-11-24 13:17:17]
  Epoch: [007][100/391]   Time 0.075 (0.051)   Data 0.000 (0.002)   Loss 0.6468 (0.5369)   Prec@1 78.125 (81.513)   Prec@5 98.438 (99.087)   [2019-11-24 13:17:22]
  Epoch: [007][200/391]   Time 0.046 (0.052)   Data 0.002 (0.001)   Loss 0.6262 (0.5306)   Prec@1 75.781 (81.580)   Prec@5 99.219 (99.114)   [2019-11-24 13:17:27]
  Epoch: [007][300/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.6255 (0.5313)   Prec@1 74.219 (81.572)   Prec@5 99.219 (99.105)   [2019-11-24 13:17:32]
  **Train** Prec@1 81.564 Prec@5 99.094 Error@1 18.436
  **Test** Prec@1 80.340 Prec@5 98.750 Error@1 19.660
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:17:38] [Epoch=008/200] [Need: 01:10:34] [LR=0.0100][M=0.90] [Best : Accuracy=80.34, Error=19.66]
  Epoch: [008][000/391]   Time 0.292 (0.292)   Data 0.225 (0.225)   Loss 0.5333 (0.5333)   Prec@1 77.344 (77.344)   Prec@5 99.219 (99.219)   [2019-11-24 13:17:39]
  Epoch: [008][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.4619 (0.5217)   Prec@1 84.375 (82.163)   Prec@5 100.000 (99.211)   [2019-11-24 13:17:44]
  Epoch: [008][200/391]   Time 0.038 (0.052)   Data 0.000 (0.001)   Loss 0.5508 (0.5221)   Prec@1 82.812 (82.121)   Prec@5 100.000 (99.223)   [2019-11-24 13:17:49]
  Epoch: [008][300/391]   Time 0.079 (0.051)   Data 0.000 (0.001)   Loss 0.5475 (0.5177)   Prec@1 82.812 (82.179)   Prec@5 100.000 (99.247)   [2019-11-24 13:17:54]
  **Train** Prec@1 82.272 Prec@5 99.214 Error@1 17.728
  **Test** Prec@1 77.760 Prec@5 98.770 Error@1 22.240

==>>[2019-11-24 13:18:00] [Epoch=009/200] [Need: 01:10:09] [LR=0.0100][M=0.90] [Best : Accuracy=80.34, Error=19.66]
  Epoch: [009][000/391]   Time 0.285 (0.285)   Data 0.226 (0.226)   Loss 0.6624 (0.6624)   Prec@1 76.562 (76.562)   Prec@5 100.000 (100.000)   [2019-11-24 13:18:01]
  Epoch: [009][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.4061 (0.4875)   Prec@1 87.500 (83.153)   Prec@5 100.000 (99.257)   [2019-11-24 13:18:06]
  Epoch: [009][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.4939 (0.4920)   Prec@1 85.156 (82.980)   Prec@5 98.438 (99.269)   [2019-11-24 13:18:10]
  Epoch: [009][300/391]   Time 0.081 (0.050)   Data 0.000 (0.001)   Loss 0.5097 (0.4940)   Prec@1 82.031 (82.919)   Prec@5 99.219 (99.286)   [2019-11-24 13:18:15]
  **Train** Prec@1 82.826 Prec@5 99.246 Error@1 17.174
  **Test** Prec@1 80.430 Prec@5 98.880 Error@1 19.570
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:18:22] [Epoch=010/200] [Need: 01:09:40] [LR=0.0100][M=0.90] [Best : Accuracy=80.43, Error=19.57]
  Epoch: [010][000/391]   Time 0.276 (0.276)   Data 0.219 (0.219)   Loss 0.5278 (0.5278)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2019-11-24 13:18:22]
  Epoch: [010][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.3847 (0.4683)   Prec@1 84.375 (83.632)   Prec@5 98.438 (99.343)   [2019-11-24 13:18:27]
  Epoch: [010][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4425 (0.4782)   Prec@1 85.938 (83.384)   Prec@5 99.219 (99.238)   [2019-11-24 13:18:32]
  Epoch: [010][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2888 (0.4780)   Prec@1 89.062 (83.524)   Prec@5 98.438 (99.252)   [2019-11-24 13:18:37]
  **Train** Prec@1 83.520 Prec@5 99.288 Error@1 16.480
  **Test** Prec@1 79.900 Prec@5 98.790 Error@1 20.100

==>>[2019-11-24 13:18:44] [Epoch=011/200] [Need: 01:09:15] [LR=0.0100][M=0.90] [Best : Accuracy=80.43, Error=19.57]
  Epoch: [011][000/391]   Time 0.272 (0.272)   Data 0.207 (0.207)   Loss 0.3283 (0.3283)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-24 13:18:44]
  Epoch: [011][100/391]   Time 0.040 (0.057)   Data 0.000 (0.002)   Loss 0.5011 (0.4581)   Prec@1 78.125 (84.298)   Prec@5 100.000 (99.273)   [2019-11-24 13:18:49]
  Epoch: [011][200/391]   Time 0.059 (0.055)   Data 0.000 (0.001)   Loss 0.4844 (0.4603)   Prec@1 82.031 (84.157)   Prec@5 100.000 (99.331)   [2019-11-24 13:18:55]
  Epoch: [011][300/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.4047 (0.4654)   Prec@1 84.375 (83.975)   Prec@5 100.000 (99.276)   [2019-11-24 13:19:00]
  **Train** Prec@1 83.960 Prec@5 99.244 Error@1 16.040
  **Test** Prec@1 81.100 Prec@5 98.920 Error@1 18.900
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:19:07] [Epoch=012/200] [Need: 01:09:08] [LR=0.0100][M=0.90] [Best : Accuracy=81.10, Error=18.90]
  Epoch: [012][000/391]   Time 0.286 (0.286)   Data 0.228 (0.228)   Loss 0.4409 (0.4409)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-24 13:19:07]
  Epoch: [012][100/391]   Time 0.038 (0.053)   Data 0.000 (0.002)   Loss 0.4855 (0.4384)   Prec@1 82.031 (84.886)   Prec@5 99.219 (99.420)   [2019-11-24 13:19:12]
  Epoch: [012][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4982 (0.4462)   Prec@1 79.688 (84.457)   Prec@5 99.219 (99.409)   [2019-11-24 13:19:17]
  Epoch: [012][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.3700 (0.4507)   Prec@1 89.844 (84.424)   Prec@5 100.000 (99.364)   [2019-11-24 13:19:22]
  **Train** Prec@1 84.382 Prec@5 99.334 Error@1 15.618
  **Test** Prec@1 77.480 Prec@5 98.280 Error@1 22.520

==>>[2019-11-24 13:19:28] [Epoch=013/200] [Need: 01:08:32] [LR=0.0100][M=0.90] [Best : Accuracy=81.10, Error=18.90]
  Epoch: [013][000/391]   Time 0.265 (0.265)   Data 0.197 (0.197)   Loss 0.5111 (0.5111)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2019-11-24 13:19:28]
  Epoch: [013][100/391]   Time 0.060 (0.052)   Data 0.000 (0.002)   Loss 0.4413 (0.4304)   Prec@1 85.156 (85.002)   Prec@5 99.219 (99.412)   [2019-11-24 13:19:33]
  Epoch: [013][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.4892 (0.4351)   Prec@1 82.031 (84.826)   Prec@5 99.219 (99.448)   [2019-11-24 13:19:38]
  Epoch: [013][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.5313 (0.4442)   Prec@1 82.812 (84.692)   Prec@5 100.000 (99.369)   [2019-11-24 13:19:43]
  **Train** Prec@1 84.752 Prec@5 99.364 Error@1 15.248
  **Test** Prec@1 82.710 Prec@5 99.110 Error@1 17.290
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:19:50] [Epoch=014/200] [Need: 01:08:09] [LR=0.0100][M=0.90] [Best : Accuracy=82.71, Error=17.29]
  Epoch: [014][000/391]   Time 0.286 (0.286)   Data 0.229 (0.229)   Loss 0.4667 (0.4667)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-24 13:19:50]
  Epoch: [014][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.4400 (0.4250)   Prec@1 82.812 (85.574)   Prec@5 99.219 (99.412)   [2019-11-24 13:19:55]
  Epoch: [014][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.3733 (0.4326)   Prec@1 85.938 (85.261)   Prec@5 100.000 (99.409)   [2019-11-24 13:20:00]
  Epoch: [014][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.5004 (0.4326)   Prec@1 85.938 (85.159)   Prec@5 99.219 (99.413)   [2019-11-24 13:20:05]
  **Train** Prec@1 85.086 Prec@5 99.400 Error@1 14.914
  **Test** Prec@1 81.000 Prec@5 99.110 Error@1 19.000

==>>[2019-11-24 13:20:12] [Epoch=015/200] [Need: 01:07:52] [LR=0.0100][M=0.90] [Best : Accuracy=82.71, Error=17.29]
  Epoch: [015][000/391]   Time 0.269 (0.269)   Data 0.207 (0.207)   Loss 0.5919 (0.5919)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2019-11-24 13:20:12]
  Epoch: [015][100/391]   Time 0.073 (0.055)   Data 0.000 (0.002)   Loss 0.3627 (0.4161)   Prec@1 88.281 (85.868)   Prec@5 98.438 (99.536)   [2019-11-24 13:20:18]
  Epoch: [015][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.5534 (0.4232)   Prec@1 82.031 (85.463)   Prec@5 100.000 (99.471)   [2019-11-24 13:20:22]
  Epoch: [015][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.4052 (0.4250)   Prec@1 90.625 (85.361)   Prec@5 99.219 (99.499)   [2019-11-24 13:20:27]
  **Train** Prec@1 85.266 Prec@5 99.460 Error@1 14.734
  **Test** Prec@1 82.130 Prec@5 99.180 Error@1 17.870

==>>[2019-11-24 13:20:33] [Epoch=016/200] [Need: 01:07:22] [LR=0.0100][M=0.90] [Best : Accuracy=82.71, Error=17.29]
  Epoch: [016][000/391]   Time 0.276 (0.276)   Data 0.197 (0.197)   Loss 0.3856 (0.3856)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-24 13:20:34]
  Epoch: [016][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.2879 (0.4097)   Prec@1 92.188 (86.046)   Prec@5 100.000 (99.373)   [2019-11-24 13:20:39]
  Epoch: [016][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.5784 (0.4166)   Prec@1 79.688 (85.673)   Prec@5 97.656 (99.398)   [2019-11-24 13:20:44]
  Epoch: [016][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.3620 (0.4203)   Prec@1 85.156 (85.582)   Prec@5 99.219 (99.408)   [2019-11-24 13:20:49]
  **Train** Prec@1 85.614 Prec@5 99.402 Error@1 14.386
  **Test** Prec@1 81.460 Prec@5 98.870 Error@1 18.540

==>>[2019-11-24 13:20:55] [Epoch=017/200] [Need: 01:06:56] [LR=0.0100][M=0.90] [Best : Accuracy=82.71, Error=17.29]
  Epoch: [017][000/391]   Time 0.275 (0.275)   Data 0.209 (0.209)   Loss 0.3304 (0.3304)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-24 13:20:55]
  Epoch: [017][100/391]   Time 0.050 (0.054)   Data 0.000 (0.002)   Loss 0.4764 (0.4126)   Prec@1 84.375 (85.760)   Prec@5 98.438 (99.373)   [2019-11-24 13:21:00]
  Epoch: [017][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.5688 (0.4087)   Prec@1 79.688 (85.805)   Prec@5 98.438 (99.405)   [2019-11-24 13:21:06]
  Epoch: [017][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4872 (0.4118)   Prec@1 82.812 (85.784)   Prec@5 99.219 (99.426)   [2019-11-24 13:21:10]
  **Train** Prec@1 85.798 Prec@5 99.426 Error@1 14.202
  **Test** Prec@1 82.850 Prec@5 99.230 Error@1 17.150
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:21:17] [Epoch=018/200] [Need: 01:06:31] [LR=0.0100][M=0.90] [Best : Accuracy=82.85, Error=17.15]
  Epoch: [018][000/391]   Time 0.269 (0.269)   Data 0.202 (0.202)   Loss 0.3213 (0.3213)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-24 13:21:17]
  Epoch: [018][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.4509 (0.3894)   Prec@1 85.938 (86.672)   Prec@5 99.219 (99.443)   [2019-11-24 13:21:22]
  Epoch: [018][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.3485 (0.3942)   Prec@1 88.281 (86.489)   Prec@5 100.000 (99.483)   [2019-11-24 13:21:27]
  Epoch: [018][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.4771 (0.3978)   Prec@1 85.156 (86.405)   Prec@5 100.000 (99.494)   [2019-11-24 13:21:32]
  **Train** Prec@1 86.206 Prec@5 99.492 Error@1 13.794
  **Test** Prec@1 83.400 Prec@5 99.290 Error@1 16.600
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:21:39] [Epoch=019/200] [Need: 01:06:09] [LR=0.0100][M=0.90] [Best : Accuracy=83.40, Error=16.60]
  Epoch: [019][000/391]   Time 0.288 (0.288)   Data 0.230 (0.230)   Loss 0.5259 (0.5259)   Prec@1 82.812 (82.812)   Prec@5 100.000 (100.000)   [2019-11-24 13:21:39]
  Epoch: [019][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3527 (0.3957)   Prec@1 87.500 (86.100)   Prec@5 99.219 (99.536)   [2019-11-24 13:21:44]
  Epoch: [019][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.4376 (0.3946)   Prec@1 84.375 (86.388)   Prec@5 100.000 (99.514)   [2019-11-24 13:21:49]
  Epoch: [019][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.4798 (0.3979)   Prec@1 84.375 (86.296)   Prec@5 100.000 (99.502)   [2019-11-24 13:21:54]
  **Train** Prec@1 86.174 Prec@5 99.470 Error@1 13.826
  **Test** Prec@1 82.630 Prec@5 99.040 Error@1 17.370

==>>[2019-11-24 13:22:00] [Epoch=020/200] [Need: 01:05:45] [LR=0.0100][M=0.90] [Best : Accuracy=83.40, Error=16.60]
  Epoch: [020][000/391]   Time 0.268 (0.268)   Data 0.206 (0.206)   Loss 0.4188 (0.4188)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-24 13:22:01]
  Epoch: [020][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.3149 (0.3837)   Prec@1 88.281 (86.433)   Prec@5 99.219 (99.459)   [2019-11-24 13:22:06]
  Epoch: [020][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.4283 (0.3864)   Prec@1 85.938 (86.466)   Prec@5 100.000 (99.444)   [2019-11-24 13:22:11]
  Epoch: [020][300/391]   Time 0.082 (0.051)   Data 0.000 (0.001)   Loss 0.4475 (0.3924)   Prec@1 82.812 (86.340)   Prec@5 98.438 (99.445)   [2019-11-24 13:22:16]
  **Train** Prec@1 86.356 Prec@5 99.460 Error@1 13.644
  **Test** Prec@1 82.480 Prec@5 99.160 Error@1 17.520

==>>[2019-11-24 13:22:23] [Epoch=021/200] [Need: 01:05:28] [LR=0.0100][M=0.90] [Best : Accuracy=83.40, Error=16.60]
  Epoch: [021][000/391]   Time 0.258 (0.258)   Data 0.205 (0.205)   Loss 0.4709 (0.4709)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-24 13:22:23]
  Epoch: [021][100/391]   Time 0.080 (0.056)   Data 0.000 (0.002)   Loss 0.4559 (0.3781)   Prec@1 84.375 (86.835)   Prec@5 100.000 (99.528)   [2019-11-24 13:22:28]
  Epoch: [021][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.4115 (0.3838)   Prec@1 89.062 (86.863)   Prec@5 99.219 (99.518)   [2019-11-24 13:22:34]
  Epoch: [021][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4584 (0.3881)   Prec@1 79.688 (86.714)   Prec@5 100.000 (99.481)   [2019-11-24 13:22:39]
  **Train** Prec@1 86.612 Prec@5 99.484 Error@1 13.388
  **Test** Prec@1 83.560 Prec@5 99.320 Error@1 16.440
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:22:45] [Epoch=022/200] [Need: 01:05:11] [LR=0.0100][M=0.90] [Best : Accuracy=83.56, Error=16.44]
  Epoch: [022][000/391]   Time 0.244 (0.244)   Data 0.186 (0.186)   Loss 0.3592 (0.3592)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-24 13:22:46]
  Epoch: [022][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3844 (0.3764)   Prec@1 86.719 (86.742)   Prec@5 100.000 (99.482)   [2019-11-24 13:22:51]
  Epoch: [022][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.4508 (0.3784)   Prec@1 82.031 (86.773)   Prec@5 100.000 (99.530)   [2019-11-24 13:22:56]
  Epoch: [022][300/391]   Time 0.037 (0.051)   Data 0.000 (0.001)   Loss 0.3234 (0.3771)   Prec@1 87.500 (86.856)   Prec@5 100.000 (99.525)   [2019-11-24 13:23:01]
  **Train** Prec@1 86.672 Prec@5 99.516 Error@1 13.328
  **Test** Prec@1 81.110 Prec@5 99.040 Error@1 18.890

==>>[2019-11-24 13:23:07] [Epoch=023/200] [Need: 01:04:49] [LR=0.0100][M=0.90] [Best : Accuracy=83.56, Error=16.44]
  Epoch: [023][000/391]   Time 0.279 (0.279)   Data 0.204 (0.204)   Loss 0.3476 (0.3476)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-24 13:23:08]
  Epoch: [023][100/391]   Time 0.044 (0.051)   Data 0.000 (0.002)   Loss 0.4040 (0.3579)   Prec@1 86.719 (87.631)   Prec@5 100.000 (99.575)   [2019-11-24 13:23:13]
  Epoch: [023][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.2903 (0.3680)   Prec@1 90.625 (87.352)   Prec@5 100.000 (99.553)   [2019-11-24 13:23:18]
  Epoch: [023][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.4911 (0.3726)   Prec@1 85.938 (87.170)   Prec@5 97.656 (99.525)   [2019-11-24 13:23:23]
  **Train** Prec@1 87.008 Prec@5 99.526 Error@1 12.992
  **Test** Prec@1 82.160 Prec@5 99.140 Error@1 17.840

==>>[2019-11-24 13:23:29] [Epoch=024/200] [Need: 01:04:25] [LR=0.0100][M=0.90] [Best : Accuracy=83.56, Error=16.44]
  Epoch: [024][000/391]   Time 0.306 (0.306)   Data 0.247 (0.247)   Loss 0.3489 (0.3489)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-24 13:23:29]
  Epoch: [024][100/391]   Time 0.043 (0.049)   Data 0.000 (0.003)   Loss 0.4396 (0.3682)   Prec@1 87.500 (87.384)   Prec@5 100.000 (99.428)   [2019-11-24 13:23:34]
  Epoch: [024][200/391]   Time 0.046 (0.048)   Data 0.000 (0.001)   Loss 0.4580 (0.3704)   Prec@1 83.594 (87.158)   Prec@5 100.000 (99.518)   [2019-11-24 13:23:39]
  Epoch: [024][300/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.5429 (0.3770)   Prec@1 79.688 (86.869)   Prec@5 99.219 (99.507)   [2019-11-24 13:23:44]
  **Train** Prec@1 86.924 Prec@5 99.516 Error@1 13.076
  **Test** Prec@1 81.310 Prec@5 99.190 Error@1 18.690

==>>[2019-11-24 13:23:51] [Epoch=025/200] [Need: 01:04:01] [LR=0.0100][M=0.90] [Best : Accuracy=83.56, Error=16.44]
  Epoch: [025][000/391]   Time 0.283 (0.283)   Data 0.201 (0.201)   Loss 0.3595 (0.3595)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-24 13:23:51]
  Epoch: [025][100/391]   Time 0.055 (0.054)   Data 0.000 (0.002)   Loss 0.3159 (0.3553)   Prec@1 90.625 (87.330)   Prec@5 99.219 (99.598)   [2019-11-24 13:23:56]
  Epoch: [025][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3508 (0.3639)   Prec@1 89.062 (87.212)   Prec@5 100.000 (99.549)   [2019-11-24 13:24:02]
  Epoch: [025][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.2779 (0.3665)   Prec@1 88.281 (87.222)   Prec@5 100.000 (99.559)   [2019-11-24 13:24:07]
  **Train** Prec@1 87.214 Prec@5 99.546 Error@1 12.786
  **Test** Prec@1 83.810 Prec@5 99.240 Error@1 16.190
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:24:13] [Epoch=026/200] [Need: 01:03:42] [LR=0.0100][M=0.90] [Best : Accuracy=83.81, Error=16.19]
  Epoch: [026][000/391]   Time 0.273 (0.273)   Data 0.216 (0.216)   Loss 0.2375 (0.2375)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-11-24 13:24:13]
  Epoch: [026][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.3514 (0.3439)   Prec@1 89.062 (88.088)   Prec@5 100.000 (99.698)   [2019-11-24 13:24:18]
  Epoch: [026][200/391]   Time 0.065 (0.051)   Data 0.000 (0.001)   Loss 0.3365 (0.3593)   Prec@1 89.062 (87.376)   Prec@5 100.000 (99.596)   [2019-11-24 13:24:23]
  Epoch: [026][300/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.2605 (0.3635)   Prec@1 89.844 (87.222)   Prec@5 100.000 (99.582)   [2019-11-24 13:24:28]
  **Train** Prec@1 87.124 Prec@5 99.552 Error@1 12.876
  **Test** Prec@1 82.370 Prec@5 99.110 Error@1 17.630

==>>[2019-11-24 13:24:35] [Epoch=027/200] [Need: 01:03:19] [LR=0.0100][M=0.90] [Best : Accuracy=83.81, Error=16.19]
  Epoch: [027][000/391]   Time 0.284 (0.284)   Data 0.192 (0.192)   Loss 0.4995 (0.4995)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2019-11-24 13:24:35]
  Epoch: [027][100/391]   Time 0.042 (0.049)   Data 0.000 (0.002)   Loss 0.3519 (0.3444)   Prec@1 90.625 (88.134)   Prec@5 100.000 (99.629)   [2019-11-24 13:24:40]
  Epoch: [027][200/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.4058 (0.3542)   Prec@1 84.375 (87.710)   Prec@5 100.000 (99.662)   [2019-11-24 13:24:45]
  Epoch: [027][300/391]   Time 0.083 (0.051)   Data 0.000 (0.001)   Loss 0.3069 (0.3627)   Prec@1 90.625 (87.425)   Prec@5 100.000 (99.582)   [2019-11-24 13:24:50]
  **Train** Prec@1 87.386 Prec@5 99.576 Error@1 12.614
  **Test** Prec@1 82.780 Prec@5 99.170 Error@1 17.220

==>>[2019-11-24 13:24:56] [Epoch=028/200] [Need: 01:02:54] [LR=0.0100][M=0.90] [Best : Accuracy=83.81, Error=16.19]
  Epoch: [028][000/391]   Time 0.265 (0.265)   Data 0.205 (0.205)   Loss 0.4524 (0.4524)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2019-11-24 13:24:57]
  Epoch: [028][100/391]   Time 0.067 (0.054)   Data 0.000 (0.002)   Loss 0.2981 (0.3459)   Prec@1 89.844 (88.072)   Prec@5 100.000 (99.621)   [2019-11-24 13:25:02]
  Epoch: [028][200/391]   Time 0.080 (0.052)   Data 0.000 (0.001)   Loss 0.4217 (0.3522)   Prec@1 83.594 (87.823)   Prec@5 99.219 (99.631)   [2019-11-24 13:25:07]
  Epoch: [028][300/391]   Time 0.083 (0.051)   Data 0.000 (0.001)   Loss 0.3253 (0.3570)   Prec@1 89.844 (87.726)   Prec@5 100.000 (99.567)   [2019-11-24 13:25:12]
  **Train** Prec@1 87.534 Prec@5 99.546 Error@1 12.466
  **Test** Prec@1 84.270 Prec@5 99.250 Error@1 15.730
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:25:18] [Epoch=029/200] [Need: 01:02:31] [LR=0.0100][M=0.90] [Best : Accuracy=84.27, Error=15.73]
  Epoch: [029][000/391]   Time 0.281 (0.281)   Data 0.201 (0.201)   Loss 0.3762 (0.3762)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-24 13:25:19]
  Epoch: [029][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.3484 (0.3377)   Prec@1 85.156 (88.374)   Prec@5 100.000 (99.683)   [2019-11-24 13:25:24]
  Epoch: [029][200/391]   Time 0.054 (0.053)   Data 0.000 (0.001)   Loss 0.5046 (0.3467)   Prec@1 82.812 (88.099)   Prec@5 100.000 (99.627)   [2019-11-24 13:25:29]
  Epoch: [029][300/391]   Time 0.037 (0.052)   Data 0.000 (0.001)   Loss 0.4306 (0.3527)   Prec@1 85.156 (87.869)   Prec@5 99.219 (99.626)   [2019-11-24 13:25:34]
  **Train** Prec@1 87.792 Prec@5 99.602 Error@1 12.208
  **Test** Prec@1 83.090 Prec@5 99.170 Error@1 16.910

==>>[2019-11-24 13:25:40] [Epoch=030/200] [Need: 01:02:10] [LR=0.0100][M=0.90] [Best : Accuracy=84.27, Error=15.73]
  Epoch: [030][000/391]   Time 0.290 (0.290)   Data 0.226 (0.226)   Loss 0.3674 (0.3674)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-24 13:25:41]
  Epoch: [030][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.3891 (0.3427)   Prec@1 85.938 (88.049)   Prec@5 100.000 (99.652)   [2019-11-24 13:25:46]
  Epoch: [030][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.3412 (0.3559)   Prec@1 87.500 (87.663)   Prec@5 99.219 (99.545)   [2019-11-24 13:25:51]
  Epoch: [030][300/391]   Time 0.057 (0.050)   Data 0.000 (0.001)   Loss 0.4294 (0.3543)   Prec@1 85.156 (87.731)   Prec@5 99.219 (99.574)   [2019-11-24 13:25:55]
  **Train** Prec@1 87.662 Prec@5 99.556 Error@1 12.338
  **Test** Prec@1 83.760 Prec@5 99.220 Error@1 16.240

==>>[2019-11-24 13:26:02] [Epoch=031/200] [Need: 01:01:46] [LR=0.0100][M=0.90] [Best : Accuracy=84.27, Error=15.73]
  Epoch: [031][000/391]   Time 0.267 (0.267)   Data 0.208 (0.208)   Loss 0.3378 (0.3378)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-24 13:26:02]
  Epoch: [031][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.2716 (0.3424)   Prec@1 91.406 (88.103)   Prec@5 100.000 (99.606)   [2019-11-24 13:26:07]
  Epoch: [031][200/391]   Time 0.076 (0.054)   Data 0.000 (0.001)   Loss 0.3356 (0.3556)   Prec@1 89.062 (87.811)   Prec@5 100.000 (99.522)   [2019-11-24 13:26:13]
  Epoch: [031][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.4508 (0.3542)   Prec@1 85.938 (87.817)   Prec@5 100.000 (99.543)   [2019-11-24 13:26:18]
  **Train** Prec@1 87.698 Prec@5 99.558 Error@1 12.302
  **Test** Prec@1 83.920 Prec@5 99.110 Error@1 16.080

==>>[2019-11-24 13:26:24] [Epoch=032/200] [Need: 01:01:28] [LR=0.0100][M=0.90] [Best : Accuracy=84.27, Error=15.73]
  Epoch: [032][000/391]   Time 0.270 (0.270)   Data 0.207 (0.207)   Loss 0.3880 (0.3880)   Prec@1 85.156 (85.156)   Prec@5 100.000 (100.000)   [2019-11-24 13:26:25]
  Epoch: [032][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3254 (0.3277)   Prec@1 89.062 (88.769)   Prec@5 100.000 (99.706)   [2019-11-24 13:26:30]
  Epoch: [032][200/391]   Time 0.041 (0.053)   Data 0.000 (0.001)   Loss 0.4138 (0.3380)   Prec@1 85.938 (88.258)   Prec@5 99.219 (99.642)   [2019-11-24 13:26:35]
  Epoch: [032][300/391]   Time 0.063 (0.053)   Data 0.000 (0.001)   Loss 0.3260 (0.3436)   Prec@1 87.500 (88.092)   Prec@5 100.000 (99.598)   [2019-11-24 13:26:40]
  **Train** Prec@1 87.950 Prec@5 99.608 Error@1 12.050
  **Test** Prec@1 83.910 Prec@5 99.100 Error@1 16.090

==>>[2019-11-24 13:26:47] [Epoch=033/200] [Need: 01:01:09] [LR=0.0100][M=0.90] [Best : Accuracy=84.27, Error=15.73]
  Epoch: [033][000/391]   Time 0.284 (0.284)   Data 0.226 (0.226)   Loss 0.3396 (0.3396)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-24 13:26:47]
  Epoch: [033][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.3648 (0.3354)   Prec@1 84.375 (88.343)   Prec@5 100.000 (99.621)   [2019-11-24 13:26:52]
  Epoch: [033][200/391]   Time 0.080 (0.050)   Data 0.000 (0.001)   Loss 0.4583 (0.3409)   Prec@1 86.719 (88.215)   Prec@5 99.219 (99.619)   [2019-11-24 13:26:57]
  Epoch: [033][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2992 (0.3405)   Prec@1 88.281 (88.201)   Prec@5 99.219 (99.634)   [2019-11-24 13:27:02]
  **Train** Prec@1 87.970 Prec@5 99.610 Error@1 12.030
  **Test** Prec@1 85.000 Prec@5 99.400 Error@1 15.000
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:27:09] [Epoch=034/200] [Need: 01:00:46] [LR=0.0100][M=0.90] [Best : Accuracy=85.00, Error=15.00]
  Epoch: [034][000/391]   Time 0.280 (0.280)   Data 0.225 (0.225)   Loss 0.2566 (0.2566)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:27:09]
  Epoch: [034][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.4576 (0.3372)   Prec@1 86.719 (88.181)   Prec@5 99.219 (99.644)   [2019-11-24 13:27:14]
  Epoch: [034][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.4041 (0.3389)   Prec@1 82.812 (88.211)   Prec@5 99.219 (99.623)   [2019-11-24 13:27:20]
  Epoch: [034][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.3988 (0.3404)   Prec@1 85.938 (88.094)   Prec@5 100.000 (99.634)   [2019-11-24 13:27:25]
  **Train** Prec@1 88.034 Prec@5 99.628 Error@1 11.966
  **Test** Prec@1 82.580 Prec@5 99.200 Error@1 17.420

==>>[2019-11-24 13:27:31] [Epoch=035/200] [Need: 01:00:26] [LR=0.0100][M=0.90] [Best : Accuracy=85.00, Error=15.00]
  Epoch: [035][000/391]   Time 0.274 (0.274)   Data 0.207 (0.207)   Loss 0.2440 (0.2440)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-24 13:27:31]
  Epoch: [035][100/391]   Time 0.083 (0.054)   Data 0.000 (0.002)   Loss 0.2114 (0.3311)   Prec@1 90.625 (88.521)   Prec@5 100.000 (99.675)   [2019-11-24 13:27:37]
  Epoch: [035][200/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.3403 (0.3426)   Prec@1 85.938 (88.126)   Prec@5 97.656 (99.611)   [2019-11-24 13:27:42]
  Epoch: [035][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.5101 (0.3370)   Prec@1 89.062 (88.367)   Prec@5 97.656 (99.626)   [2019-11-24 13:27:46]
  **Train** Prec@1 88.194 Prec@5 99.594 Error@1 11.806
  **Test** Prec@1 83.260 Prec@5 99.120 Error@1 16.740

==>>[2019-11-24 13:27:53] [Epoch=036/200] [Need: 01:00:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.00, Error=15.00]
  Epoch: [036][000/391]   Time 0.281 (0.281)   Data 0.214 (0.214)   Loss 0.3654 (0.3654)   Prec@1 89.062 (89.062)   Prec@5 99.219 (99.219)   [2019-11-24 13:27:53]
  Epoch: [036][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.4260 (0.3416)   Prec@1 85.156 (87.925)   Prec@5 100.000 (99.575)   [2019-11-24 13:27:59]
  Epoch: [036][200/391]   Time 0.066 (0.051)   Data 0.000 (0.001)   Loss 0.2982 (0.3321)   Prec@1 86.719 (88.487)   Prec@5 100.000 (99.639)   [2019-11-24 13:28:03]
  Epoch: [036][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.2876 (0.3406)   Prec@1 89.062 (88.198)   Prec@5 99.219 (99.618)   [2019-11-24 13:28:08]
  **Train** Prec@1 88.170 Prec@5 99.620 Error@1 11.830
  **Test** Prec@1 85.070 Prec@5 99.340 Error@1 14.930
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:28:15] [Epoch=037/200] [Need: 00:59:41] [LR=0.0100][M=0.90] [Best : Accuracy=85.07, Error=14.93]
  Epoch: [037][000/391]   Time 0.271 (0.271)   Data 0.203 (0.203)   Loss 0.3114 (0.3114)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-24 13:28:15]
  Epoch: [037][100/391]   Time 0.046 (0.052)   Data 0.000 (0.002)   Loss 0.2598 (0.3232)   Prec@1 90.625 (88.954)   Prec@5 100.000 (99.683)   [2019-11-24 13:28:20]
  Epoch: [037][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.2666 (0.3268)   Prec@1 91.406 (88.682)   Prec@5 100.000 (99.654)   [2019-11-24 13:28:25]
  Epoch: [037][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.3661 (0.3347)   Prec@1 89.844 (88.406)   Prec@5 100.000 (99.629)   [2019-11-24 13:28:30]
  **Train** Prec@1 88.372 Prec@5 99.626 Error@1 11.628
  **Test** Prec@1 83.290 Prec@5 99.070 Error@1 16.710

==>>[2019-11-24 13:28:36] [Epoch=038/200] [Need: 00:59:17] [LR=0.0100][M=0.90] [Best : Accuracy=85.07, Error=14.93]
  Epoch: [038][000/391]   Time 0.281 (0.281)   Data 0.212 (0.212)   Loss 0.2257 (0.2257)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:28:37]
  Epoch: [038][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3159 (0.3101)   Prec@1 87.500 (89.279)   Prec@5 100.000 (99.698)   [2019-11-24 13:28:42]
  Epoch: [038][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.3056 (0.3249)   Prec@1 91.406 (88.728)   Prec@5 100.000 (99.670)   [2019-11-24 13:28:47]
  Epoch: [038][300/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.4376 (0.3309)   Prec@1 84.375 (88.572)   Prec@5 99.219 (99.644)   [2019-11-24 13:28:52]
  **Train** Prec@1 88.440 Prec@5 99.628 Error@1 11.560
  **Test** Prec@1 85.540 Prec@5 99.440 Error@1 14.460
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:28:59] [Epoch=039/200] [Need: 00:58:57] [LR=0.0100][M=0.90] [Best : Accuracy=85.54, Error=14.46]
  Epoch: [039][000/391]   Time 0.277 (0.277)   Data 0.220 (0.220)   Loss 0.3096 (0.3096)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2019-11-24 13:28:59]
  Epoch: [039][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.3676 (0.3140)   Prec@1 88.281 (89.349)   Prec@5 100.000 (99.606)   [2019-11-24 13:29:04]
  Epoch: [039][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2471 (0.3277)   Prec@1 90.625 (88.853)   Prec@5 99.219 (99.619)   [2019-11-24 13:29:09]
  Epoch: [039][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.2797 (0.3314)   Prec@1 89.844 (88.600)   Prec@5 99.219 (99.626)   [2019-11-24 13:29:14]
  **Train** Prec@1 88.528 Prec@5 99.626 Error@1 11.472
  **Test** Prec@1 84.480 Prec@5 99.360 Error@1 15.520

==>>[2019-11-24 13:29:20] [Epoch=040/200] [Need: 00:58:32] [LR=0.0100][M=0.90] [Best : Accuracy=85.54, Error=14.46]
  Epoch: [040][000/391]   Time 0.270 (0.270)   Data 0.205 (0.205)   Loss 0.2643 (0.2643)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2019-11-24 13:29:20]
  Epoch: [040][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.2011 (0.3164)   Prec@1 93.750 (88.807)   Prec@5 100.000 (99.745)   [2019-11-24 13:29:25]
  Epoch: [040][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.4045 (0.3286)   Prec@1 87.500 (88.472)   Prec@5 98.438 (99.662)   [2019-11-24 13:29:30]
  Epoch: [040][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3893 (0.3299)   Prec@1 86.719 (88.546)   Prec@5 98.438 (99.660)   [2019-11-24 13:29:35]
  **Train** Prec@1 88.634 Prec@5 99.650 Error@1 11.366
  **Test** Prec@1 85.400 Prec@5 99.280 Error@1 14.600

==>>[2019-11-24 13:29:42] [Epoch=041/200] [Need: 00:58:09] [LR=0.0100][M=0.90] [Best : Accuracy=85.54, Error=14.46]
  Epoch: [041][000/391]   Time 0.289 (0.289)   Data 0.211 (0.211)   Loss 0.3679 (0.3679)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2019-11-24 13:29:42]
  Epoch: [041][100/391]   Time 0.082 (0.053)   Data 0.000 (0.002)   Loss 0.3417 (0.3294)   Prec@1 88.281 (88.482)   Prec@5 99.219 (99.691)   [2019-11-24 13:29:47]
  Epoch: [041][200/391]   Time 0.059 (0.051)   Data 0.000 (0.001)   Loss 0.3019 (0.3284)   Prec@1 86.719 (88.612)   Prec@5 100.000 (99.674)   [2019-11-24 13:29:52]
  Epoch: [041][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.3425 (0.3300)   Prec@1 89.062 (88.551)   Prec@5 100.000 (99.678)   [2019-11-24 13:29:57]
  **Train** Prec@1 88.518 Prec@5 99.678 Error@1 11.482
  **Test** Prec@1 84.380 Prec@5 99.310 Error@1 15.620

==>>[2019-11-24 13:30:03] [Epoch=042/200] [Need: 00:57:46] [LR=0.0100][M=0.90] [Best : Accuracy=85.54, Error=14.46]
  Epoch: [042][000/391]   Time 0.287 (0.287)   Data 0.200 (0.200)   Loss 0.3066 (0.3066)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2019-11-24 13:30:04]
  Epoch: [042][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.4593 (0.3123)   Prec@1 85.938 (89.519)   Prec@5 99.219 (99.667)   [2019-11-24 13:30:09]
  Epoch: [042][200/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3046 (0.3111)   Prec@1 89.844 (89.366)   Prec@5 99.219 (99.681)   [2019-11-24 13:30:14]
  Epoch: [042][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.2801 (0.3189)   Prec@1 90.625 (89.018)   Prec@5 100.000 (99.678)   [2019-11-24 13:30:19]
  **Train** Prec@1 88.888 Prec@5 99.686 Error@1 11.112
  **Test** Prec@1 85.800 Prec@5 99.310 Error@1 14.200
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:30:25] [Epoch=043/200] [Need: 00:57:24] [LR=0.0100][M=0.90] [Best : Accuracy=85.80, Error=14.20]
  Epoch: [043][000/391]   Time 0.277 (0.277)   Data 0.208 (0.208)   Loss 0.3050 (0.3050)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2019-11-24 13:30:26]
  Epoch: [043][100/391]   Time 0.052 (0.057)   Data 0.000 (0.002)   Loss 0.1575 (0.3088)   Prec@1 93.750 (89.109)   Prec@5 100.000 (99.729)   [2019-11-24 13:30:31]
  Epoch: [043][200/391]   Time 0.079 (0.053)   Data 0.000 (0.001)   Loss 0.3389 (0.3142)   Prec@1 87.500 (88.849)   Prec@5 100.000 (99.697)   [2019-11-24 13:30:36]
  Epoch: [043][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.3220 (0.3148)   Prec@1 87.500 (89.008)   Prec@5 100.000 (99.694)   [2019-11-24 13:30:41]
  **Train** Prec@1 88.750 Prec@5 99.670 Error@1 11.250
  **Test** Prec@1 80.580 Prec@5 98.990 Error@1 19.420

==>>[2019-11-24 13:30:48] [Epoch=044/200] [Need: 00:57:04] [LR=0.0100][M=0.90] [Best : Accuracy=85.80, Error=14.20]
  Epoch: [044][000/391]   Time 0.275 (0.275)   Data 0.209 (0.209)   Loss 0.3117 (0.3117)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:30:48]
  Epoch: [044][100/391]   Time 0.059 (0.051)   Data 0.000 (0.002)   Loss 0.3283 (0.3265)   Prec@1 87.500 (88.977)   Prec@5 100.000 (99.667)   [2019-11-24 13:30:53]
  Epoch: [044][200/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.2526 (0.3281)   Prec@1 91.406 (88.903)   Prec@5 99.219 (99.627)   [2019-11-24 13:30:59]
  Epoch: [044][300/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.4365 (0.3285)   Prec@1 86.719 (88.959)   Prec@5 100.000 (99.660)   [2019-11-24 13:31:04]
  **Train** Prec@1 88.960 Prec@5 99.658 Error@1 11.040
  **Test** Prec@1 84.880 Prec@5 99.330 Error@1 15.120

==>>[2019-11-24 13:31:10] [Epoch=045/200] [Need: 00:56:43] [LR=0.0100][M=0.90] [Best : Accuracy=85.80, Error=14.20]
  Epoch: [045][000/391]   Time 0.279 (0.279)   Data 0.215 (0.215)   Loss 0.2800 (0.2800)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2019-11-24 13:31:10]
  Epoch: [045][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.4437 (0.3211)   Prec@1 83.594 (88.645)   Prec@5 100.000 (99.606)   [2019-11-24 13:31:16]
  Epoch: [045][200/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.3207 (0.3232)   Prec@1 88.281 (88.565)   Prec@5 99.219 (99.674)   [2019-11-24 13:31:20]
  Epoch: [045][300/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.3484 (0.3232)   Prec@1 82.812 (88.569)   Prec@5 99.219 (99.657)   [2019-11-24 13:31:25]
  **Train** Prec@1 88.530 Prec@5 99.646 Error@1 11.470
  **Test** Prec@1 84.720 Prec@5 99.300 Error@1 15.280

==>>[2019-11-24 13:31:32] [Epoch=046/200] [Need: 00:56:20] [LR=0.0100][M=0.90] [Best : Accuracy=85.80, Error=14.20]
  Epoch: [046][000/391]   Time 0.271 (0.271)   Data 0.211 (0.211)   Loss 0.4135 (0.4135)   Prec@1 84.375 (84.375)   Prec@5 100.000 (100.000)   [2019-11-24 13:31:32]
  Epoch: [046][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.2892 (0.3048)   Prec@1 89.062 (89.496)   Prec@5 100.000 (99.768)   [2019-11-24 13:31:37]
  Epoch: [046][200/391]   Time 0.052 (0.050)   Data 0.000 (0.001)   Loss 0.3976 (0.3214)   Prec@1 86.719 (89.051)   Prec@5 98.438 (99.670)   [2019-11-24 13:31:42]
  Epoch: [046][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.4103 (0.3190)   Prec@1 84.375 (89.021)   Prec@5 99.219 (99.678)   [2019-11-24 13:31:47]
  **Train** Prec@1 89.006 Prec@5 99.678 Error@1 10.994
  **Test** Prec@1 82.600 Prec@5 98.990 Error@1 17.400

==>>[2019-11-24 13:31:54] [Epoch=047/200] [Need: 00:55:58] [LR=0.0100][M=0.90] [Best : Accuracy=85.80, Error=14.20]
  Epoch: [047][000/391]   Time 0.271 (0.271)   Data 0.198 (0.198)   Loss 0.1894 (0.1894)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-24 13:31:54]
  Epoch: [047][100/391]   Time 0.048 (0.057)   Data 0.000 (0.002)   Loss 0.1944 (0.2980)   Prec@1 93.750 (89.728)   Prec@5 100.000 (99.675)   [2019-11-24 13:31:59]
  Epoch: [047][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.3310 (0.3175)   Prec@1 87.500 (89.035)   Prec@5 100.000 (99.674)   [2019-11-24 13:32:04]
  Epoch: [047][300/391]   Time 0.082 (0.052)   Data 0.000 (0.001)   Loss 0.3373 (0.3193)   Prec@1 87.500 (88.972)   Prec@5 100.000 (99.678)   [2019-11-24 13:32:09]
  **Train** Prec@1 88.876 Prec@5 99.684 Error@1 11.124
  **Test** Prec@1 85.900 Prec@5 99.420 Error@1 14.100
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:32:16] [Epoch=048/200] [Need: 00:55:38] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [048][000/391]   Time 0.278 (0.278)   Data 0.195 (0.195)   Loss 0.2063 (0.2063)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:32:17]
  Epoch: [048][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.3048 (0.3135)   Prec@1 89.844 (89.287)   Prec@5 100.000 (99.644)   [2019-11-24 13:32:22]
  Epoch: [048][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.3273 (0.3197)   Prec@1 88.281 (88.977)   Prec@5 100.000 (99.693)   [2019-11-24 13:32:27]
  Epoch: [048][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.4510 (0.3198)   Prec@1 85.938 (88.956)   Prec@5 100.000 (99.683)   [2019-11-24 13:32:32]
  **Train** Prec@1 88.838 Prec@5 99.656 Error@1 11.162
  **Test** Prec@1 85.770 Prec@5 99.490 Error@1 14.230

==>>[2019-11-24 13:32:38] [Epoch=049/200] [Need: 00:55:17] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [049][000/391]   Time 0.271 (0.271)   Data 0.211 (0.211)   Loss 0.3447 (0.3447)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2019-11-24 13:32:39]
  Epoch: [049][100/391]   Time 0.075 (0.054)   Data 0.000 (0.002)   Loss 0.2866 (0.3102)   Prec@1 88.281 (89.225)   Prec@5 100.000 (99.714)   [2019-11-24 13:32:44]
  Epoch: [049][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.4131 (0.3054)   Prec@1 89.062 (89.276)   Prec@5 98.438 (99.705)   [2019-11-24 13:32:49]
  Epoch: [049][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.2982 (0.3108)   Prec@1 89.062 (89.148)   Prec@5 100.000 (99.694)   [2019-11-24 13:32:53]
  **Train** Prec@1 89.082 Prec@5 99.694 Error@1 10.918
  **Test** Prec@1 85.610 Prec@5 99.410 Error@1 14.390

==>>[2019-11-24 13:33:00] [Epoch=050/200] [Need: 00:54:54] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [050][000/391]   Time 0.264 (0.264)   Data 0.211 (0.211)   Loss 0.2495 (0.2495)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:33:00]
  Epoch: [050][100/391]   Time 0.057 (0.054)   Data 0.000 (0.002)   Loss 0.2604 (0.3067)   Prec@1 92.188 (89.325)   Prec@5 99.219 (99.636)   [2019-11-24 13:33:05]
  Epoch: [050][200/391]   Time 0.079 (0.053)   Data 0.000 (0.001)   Loss 0.2191 (0.3169)   Prec@1 90.625 (89.039)   Prec@5 100.000 (99.646)   [2019-11-24 13:33:11]
  Epoch: [050][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.3936 (0.3154)   Prec@1 86.719 (89.101)   Prec@5 100.000 (99.657)   [2019-11-24 13:33:15]
  **Train** Prec@1 89.024 Prec@5 99.654 Error@1 10.976
  **Test** Prec@1 84.910 Prec@5 99.200 Error@1 15.090

==>>[2019-11-24 13:33:21] [Epoch=051/200] [Need: 00:54:29] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [051][000/391]   Time 0.280 (0.280)   Data 0.203 (0.203)   Loss 0.2085 (0.2085)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-24 13:33:21]
  Epoch: [051][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.3271 (0.2979)   Prec@1 85.938 (89.488)   Prec@5 100.000 (99.737)   [2019-11-24 13:33:27]
  Epoch: [051][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.2315 (0.3080)   Prec@1 91.406 (89.222)   Prec@5 100.000 (99.712)   [2019-11-24 13:33:31]
  Epoch: [051][300/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.2804 (0.3126)   Prec@1 91.406 (89.172)   Prec@5 100.000 (99.696)   [2019-11-24 13:33:36]
  **Train** Prec@1 89.122 Prec@5 99.672 Error@1 10.878
  **Test** Prec@1 85.170 Prec@5 99.230 Error@1 14.830

==>>[2019-11-24 13:33:42] [Epoch=052/200] [Need: 00:54:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [052][000/391]   Time 0.281 (0.281)   Data 0.222 (0.222)   Loss 0.3273 (0.3273)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-24 13:33:42]
  Epoch: [052][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.3374 (0.3044)   Prec@1 88.281 (89.782)   Prec@5 100.000 (99.582)   [2019-11-24 13:33:47]
  Epoch: [052][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3825 (0.3146)   Prec@1 87.500 (89.167)   Prec@5 99.219 (99.607)   [2019-11-24 13:33:52]
  Epoch: [052][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.2679 (0.3109)   Prec@1 89.844 (89.242)   Prec@5 99.219 (99.644)   [2019-11-24 13:33:57]
  **Train** Prec@1 89.164 Prec@5 99.644 Error@1 10.836
  **Test** Prec@1 82.710 Prec@5 99.160 Error@1 17.290

==>>[2019-11-24 13:34:04] [Epoch=053/200] [Need: 00:53:42] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [053][000/391]   Time 0.269 (0.269)   Data 0.199 (0.199)   Loss 0.2648 (0.2648)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-24 13:34:04]
  Epoch: [053][100/391]   Time 0.045 (0.050)   Data 0.000 (0.002)   Loss 0.2603 (0.2999)   Prec@1 93.750 (89.805)   Prec@5 100.000 (99.667)   [2019-11-24 13:34:09]
  Epoch: [053][200/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.2456 (0.3035)   Prec@1 92.969 (89.498)   Prec@5 100.000 (99.681)   [2019-11-24 13:34:14]
  Epoch: [053][300/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.3644 (0.3093)   Prec@1 91.406 (89.294)   Prec@5 100.000 (99.663)   [2019-11-24 13:34:19]
  **Train** Prec@1 89.136 Prec@5 99.656 Error@1 10.864
  **Test** Prec@1 85.130 Prec@5 99.440 Error@1 14.870

==>>[2019-11-24 13:34:26] [Epoch=054/200] [Need: 00:53:21] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [054][000/391]   Time 0.274 (0.274)   Data 0.214 (0.214)   Loss 0.2712 (0.2712)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-24 13:34:26]
  Epoch: [054][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.2315 (0.3081)   Prec@1 92.188 (89.635)   Prec@5 100.000 (99.652)   [2019-11-24 13:34:32]
  Epoch: [054][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.2924 (0.3015)   Prec@1 85.938 (89.855)   Prec@5 100.000 (99.666)   [2019-11-24 13:34:37]
  Epoch: [054][300/391]   Time 0.049 (0.051)   Data 0.000 (0.001)   Loss 0.4249 (0.3121)   Prec@1 82.031 (89.335)   Prec@5 98.438 (99.655)   [2019-11-24 13:34:41]
  **Train** Prec@1 89.278 Prec@5 99.664 Error@1 10.722
  **Test** Prec@1 84.940 Prec@5 99.080 Error@1 15.060

==>>[2019-11-24 13:34:48] [Epoch=055/200] [Need: 00:52:59] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [055][000/391]   Time 0.273 (0.273)   Data 0.218 (0.218)   Loss 0.4168 (0.4168)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2019-11-24 13:34:48]
  Epoch: [055][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.4307 (0.2994)   Prec@1 87.500 (89.488)   Prec@5 100.000 (99.783)   [2019-11-24 13:34:53]
  Epoch: [055][200/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.2456 (0.2990)   Prec@1 92.188 (89.630)   Prec@5 99.219 (99.740)   [2019-11-24 13:34:58]
  Epoch: [055][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.3091 (0.3056)   Prec@1 89.062 (89.358)   Prec@5 100.000 (99.704)   [2019-11-24 13:35:03]
  **Train** Prec@1 89.286 Prec@5 99.676 Error@1 10.714
  **Test** Prec@1 85.280 Prec@5 99.260 Error@1 14.720

==>>[2019-11-24 13:35:10] [Epoch=056/200] [Need: 00:52:37] [LR=0.0100][M=0.90] [Best : Accuracy=85.90, Error=14.10]
  Epoch: [056][000/391]   Time 0.287 (0.287)   Data 0.229 (0.229)   Loss 0.3095 (0.3095)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2019-11-24 13:35:10]
  Epoch: [056][100/391]   Time 0.044 (0.057)   Data 0.000 (0.002)   Loss 0.2570 (0.2955)   Prec@1 89.062 (89.735)   Prec@5 100.000 (99.698)   [2019-11-24 13:35:16]
  Epoch: [056][200/391]   Time 0.076 (0.054)   Data 0.000 (0.001)   Loss 0.2611 (0.3015)   Prec@1 89.062 (89.381)   Prec@5 100.000 (99.743)   [2019-11-24 13:35:21]
  Epoch: [056][300/391]   Time 0.047 (0.054)   Data 0.000 (0.001)   Loss 0.2727 (0.3109)   Prec@1 91.406 (89.029)   Prec@5 99.219 (99.725)   [2019-11-24 13:35:26]
  **Train** Prec@1 89.122 Prec@5 99.706 Error@1 10.878
  **Test** Prec@1 85.950 Prec@5 99.360 Error@1 14.050
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:35:33] [Epoch=057/200] [Need: 00:52:18] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [057][000/391]   Time 0.290 (0.290)   Data 0.204 (0.204)   Loss 0.2268 (0.2268)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2019-11-24 13:35:33]
  Epoch: [057][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.4309 (0.2933)   Prec@1 85.938 (89.519)   Prec@5 98.438 (99.675)   [2019-11-24 13:35:38]
  Epoch: [057][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2358 (0.2942)   Prec@1 92.188 (89.595)   Prec@5 99.219 (99.732)   [2019-11-24 13:35:43]
  Epoch: [057][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.3754 (0.3031)   Prec@1 83.594 (89.325)   Prec@5 100.000 (99.714)   [2019-11-24 13:35:48]
  **Train** Prec@1 89.254 Prec@5 99.698 Error@1 10.746
  **Test** Prec@1 85.780 Prec@5 99.520 Error@1 14.220

==>>[2019-11-24 13:35:54] [Epoch=058/200] [Need: 00:51:54] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [058][000/391]   Time 0.283 (0.283)   Data 0.208 (0.208)   Loss 0.3051 (0.3051)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-24 13:35:54]
  Epoch: [058][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.2076 (0.2837)   Prec@1 92.188 (90.161)   Prec@5 100.000 (99.783)   [2019-11-24 13:35:59]
  Epoch: [058][200/391]   Time 0.073 (0.055)   Data 0.000 (0.001)   Loss 0.3010 (0.2900)   Prec@1 91.406 (89.797)   Prec@5 99.219 (99.724)   [2019-11-24 13:36:05]
  Epoch: [058][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.2372 (0.2972)   Prec@1 91.406 (89.563)   Prec@5 99.219 (99.714)   [2019-11-24 13:36:10]
  **Train** Prec@1 89.416 Prec@5 99.714 Error@1 10.584
  **Test** Prec@1 79.720 Prec@5 99.320 Error@1 20.280

==>>[2019-11-24 13:36:16] [Epoch=059/200] [Need: 00:51:33] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [059][000/391]   Time 0.288 (0.288)   Data 0.206 (0.206)   Loss 0.3285 (0.3285)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:36:17]
  Epoch: [059][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.3490 (0.2960)   Prec@1 89.844 (89.550)   Prec@5 100.000 (99.799)   [2019-11-24 13:36:22]
  Epoch: [059][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.4046 (0.2955)   Prec@1 84.375 (89.634)   Prec@5 100.000 (99.775)   [2019-11-24 13:36:26]
  Epoch: [059][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.3092 (0.3077)   Prec@1 89.844 (89.358)   Prec@5 100.000 (99.702)   [2019-11-24 13:36:31]
  **Train** Prec@1 89.340 Prec@5 99.708 Error@1 10.660
  **Test** Prec@1 82.180 Prec@5 99.300 Error@1 17.820

==>>[2019-11-24 13:36:38] [Epoch=060/200] [Need: 00:51:11] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [060][000/391]   Time 0.275 (0.275)   Data 0.215 (0.215)   Loss 0.1849 (0.1849)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-24 13:36:38]
  Epoch: [060][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.5310 (0.2964)   Prec@1 82.812 (89.735)   Prec@5 99.219 (99.714)   [2019-11-24 13:36:43]
  Epoch: [060][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2966 (0.2996)   Prec@1 89.062 (89.614)   Prec@5 100.000 (99.697)   [2019-11-24 13:36:49]
  Epoch: [060][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.2806 (0.3020)   Prec@1 90.625 (89.517)   Prec@5 100.000 (99.712)   [2019-11-24 13:36:53]
  **Train** Prec@1 89.418 Prec@5 99.700 Error@1 10.582
  **Test** Prec@1 85.160 Prec@5 99.430 Error@1 14.840

==>>[2019-11-24 13:37:00] [Epoch=061/200] [Need: 00:50:48] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [061][000/391]   Time 0.270 (0.270)   Data 0.201 (0.201)   Loss 0.2182 (0.2182)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-24 13:37:00]
  Epoch: [061][100/391]   Time 0.044 (0.055)   Data 0.000 (0.002)   Loss 0.2327 (0.2923)   Prec@1 89.844 (89.782)   Prec@5 100.000 (99.768)   [2019-11-24 13:37:05]
  Epoch: [061][200/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.3508 (0.2952)   Prec@1 86.719 (89.681)   Prec@5 99.219 (99.701)   [2019-11-24 13:37:10]
  Epoch: [061][300/391]   Time 0.047 (0.052)   Data 0.000 (0.001)   Loss 0.2902 (0.2997)   Prec@1 89.062 (89.602)   Prec@5 99.219 (99.689)   [2019-11-24 13:37:15]
  **Train** Prec@1 89.406 Prec@5 99.680 Error@1 10.594
  **Test** Prec@1 85.550 Prec@5 99.380 Error@1 14.450

==>>[2019-11-24 13:37:22] [Epoch=062/200] [Need: 00:50:27] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [062][000/391]   Time 0.263 (0.263)   Data 0.205 (0.205)   Loss 0.2926 (0.2926)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2019-11-24 13:37:22]
  Epoch: [062][100/391]   Time 0.059 (0.053)   Data 0.000 (0.002)   Loss 0.4154 (0.2872)   Prec@1 85.938 (90.099)   Prec@5 100.000 (99.737)   [2019-11-24 13:37:27]
  Epoch: [062][200/391]   Time 0.055 (0.052)   Data 0.000 (0.001)   Loss 0.2555 (0.2978)   Prec@1 90.625 (89.440)   Prec@5 100.000 (99.751)   [2019-11-24 13:37:32]
  Epoch: [062][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.2839 (0.2985)   Prec@1 89.844 (89.532)   Prec@5 100.000 (99.746)   [2019-11-24 13:37:38]
  **Train** Prec@1 89.418 Prec@5 99.720 Error@1 10.582
  **Test** Prec@1 85.870 Prec@5 99.390 Error@1 14.130

==>>[2019-11-24 13:37:44] [Epoch=063/200] [Need: 00:50:05] [LR=0.0100][M=0.90] [Best : Accuracy=85.95, Error=14.05]
  Epoch: [063][000/391]   Time 0.277 (0.277)   Data 0.217 (0.217)   Loss 0.2564 (0.2564)   Prec@1 90.625 (90.625)   Prec@5 98.438 (98.438)   [2019-11-24 13:37:44]
  Epoch: [063][100/391]   Time 0.061 (0.055)   Data 0.000 (0.002)   Loss 0.2710 (0.2778)   Prec@1 89.062 (90.122)   Prec@5 100.000 (99.752)   [2019-11-24 13:37:49]
  Epoch: [063][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.4198 (0.2968)   Prec@1 84.375 (89.747)   Prec@5 100.000 (99.740)   [2019-11-24 13:37:54]
  Epoch: [063][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3871 (0.3002)   Prec@1 83.594 (89.569)   Prec@5 99.219 (99.735)   [2019-11-24 13:38:00]
  **Train** Prec@1 89.428 Prec@5 99.710 Error@1 10.572
  **Test** Prec@1 86.440 Prec@5 99.490 Error@1 13.560
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:38:06] [Epoch=064/200] [Need: 00:49:44] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [064][000/391]   Time 0.270 (0.270)   Data 0.205 (0.205)   Loss 0.2409 (0.2409)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:38:07]
  Epoch: [064][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.3781 (0.2932)   Prec@1 88.281 (90.122)   Prec@5 100.000 (99.745)   [2019-11-24 13:38:12]
  Epoch: [064][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2811 (0.2970)   Prec@1 87.500 (89.801)   Prec@5 100.000 (99.716)   [2019-11-24 13:38:17]
  Epoch: [064][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.4462 (0.3064)   Prec@1 84.375 (89.483)   Prec@5 99.219 (99.676)   [2019-11-24 13:38:22]
  **Train** Prec@1 89.538 Prec@5 99.684 Error@1 10.462
  **Test** Prec@1 86.070 Prec@5 99.400 Error@1 13.930

==>>[2019-11-24 13:38:28] [Epoch=065/200] [Need: 00:49:22] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [065][000/391]   Time 0.270 (0.270)   Data 0.214 (0.214)   Loss 0.2938 (0.2938)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:38:28]
  Epoch: [065][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.2751 (0.2916)   Prec@1 89.062 (90.153)   Prec@5 100.000 (99.629)   [2019-11-24 13:38:33]
  Epoch: [065][200/391]   Time 0.081 (0.053)   Data 0.000 (0.001)   Loss 0.3081 (0.2904)   Prec@1 89.062 (90.019)   Prec@5 99.219 (99.701)   [2019-11-24 13:38:39]
  Epoch: [065][300/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.2929 (0.2968)   Prec@1 90.625 (89.792)   Prec@5 100.000 (99.704)   [2019-11-24 13:38:44]
  **Train** Prec@1 89.738 Prec@5 99.700 Error@1 10.262
  **Test** Prec@1 85.010 Prec@5 99.400 Error@1 14.990

==>>[2019-11-24 13:38:50] [Epoch=066/200] [Need: 00:49:00] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [066][000/391]   Time 0.280 (0.280)   Data 0.213 (0.213)   Loss 0.3101 (0.3101)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:38:51]
  Epoch: [066][100/391]   Time 0.066 (0.055)   Data 0.000 (0.002)   Loss 0.3356 (0.2913)   Prec@1 89.844 (90.215)   Prec@5 99.219 (99.776)   [2019-11-24 13:38:56]
  Epoch: [066][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.3077 (0.3013)   Prec@1 90.625 (89.708)   Prec@5 98.438 (99.724)   [2019-11-24 13:39:01]
  Epoch: [066][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1933 (0.3007)   Prec@1 94.531 (89.722)   Prec@5 100.000 (99.707)   [2019-11-24 13:39:06]
  **Train** Prec@1 89.624 Prec@5 99.702 Error@1 10.376
  **Test** Prec@1 86.190 Prec@5 99.300 Error@1 13.810

==>>[2019-11-24 13:39:13] [Epoch=067/200] [Need: 00:48:39] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [067][000/391]   Time 0.295 (0.295)   Data 0.240 (0.240)   Loss 0.3078 (0.3078)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2019-11-24 13:39:13]
  Epoch: [067][100/391]   Time 0.060 (0.055)   Data 0.000 (0.003)   Loss 0.2304 (0.2764)   Prec@1 92.188 (90.548)   Prec@5 100.000 (99.714)   [2019-11-24 13:39:18]
  Epoch: [067][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.2584 (0.2890)   Prec@1 89.062 (90.050)   Prec@5 100.000 (99.716)   [2019-11-24 13:39:23]
  Epoch: [067][300/391]   Time 0.056 (0.052)   Data 0.000 (0.001)   Loss 0.2825 (0.2919)   Prec@1 89.062 (89.893)   Prec@5 100.000 (99.720)   [2019-11-24 13:39:28]
  **Train** Prec@1 89.692 Prec@5 99.686 Error@1 10.308
  **Test** Prec@1 85.200 Prec@5 99.190 Error@1 14.800

==>>[2019-11-24 13:39:35] [Epoch=068/200] [Need: 00:48:18] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [068][000/391]   Time 0.267 (0.267)   Data 0.206 (0.206)   Loss 0.2454 (0.2454)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:39:35]
  Epoch: [068][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.3199 (0.2935)   Prec@1 89.844 (90.045)   Prec@5 100.000 (99.776)   [2019-11-24 13:39:41]
  Epoch: [068][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.3615 (0.2977)   Prec@1 90.625 (89.840)   Prec@5 98.438 (99.716)   [2019-11-24 13:39:46]
  Epoch: [068][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1737 (0.2971)   Prec@1 96.094 (89.756)   Prec@5 99.219 (99.727)   [2019-11-24 13:39:51]
  **Train** Prec@1 89.750 Prec@5 99.736 Error@1 10.250
  **Test** Prec@1 84.810 Prec@5 99.240 Error@1 15.190

==>>[2019-11-24 13:39:57] [Epoch=069/200] [Need: 00:47:56] [LR=0.0100][M=0.90] [Best : Accuracy=86.44, Error=13.56]
  Epoch: [069][000/391]   Time 0.259 (0.259)   Data 0.209 (0.209)   Loss 0.1658 (0.1658)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2019-11-24 13:39:57]
  Epoch: [069][100/391]   Time 0.051 (0.055)   Data 0.000 (0.002)   Loss 0.2882 (0.2983)   Prec@1 90.625 (89.712)   Prec@5 99.219 (99.760)   [2019-11-24 13:40:03]
  Epoch: [069][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.3277 (0.2966)   Prec@1 88.281 (89.747)   Prec@5 99.219 (99.755)   [2019-11-24 13:40:07]
  Epoch: [069][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.2510 (0.2971)   Prec@1 92.969 (89.569)   Prec@5 99.219 (99.727)   [2019-11-24 13:40:12]
  **Train** Prec@1 89.480 Prec@5 99.714 Error@1 10.520
  **Test** Prec@1 86.500 Prec@5 99.390 Error@1 13.500
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:40:19] [Epoch=070/200] [Need: 00:47:34] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [070][000/391]   Time 0.276 (0.276)   Data 0.216 (0.216)   Loss 0.2632 (0.2632)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-24 13:40:19]
  Epoch: [070][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.2564 (0.2743)   Prec@1 89.844 (90.579)   Prec@5 100.000 (99.776)   [2019-11-24 13:40:24]
  Epoch: [070][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.2347 (0.2929)   Prec@1 92.188 (89.805)   Prec@5 100.000 (99.740)   [2019-11-24 13:40:29]
  Epoch: [070][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.4582 (0.2961)   Prec@1 82.812 (89.743)   Prec@5 100.000 (99.720)   [2019-11-24 13:40:35]
  **Train** Prec@1 89.606 Prec@5 99.728 Error@1 10.394
  **Test** Prec@1 85.720 Prec@5 99.510 Error@1 14.280

==>>[2019-11-24 13:40:41] [Epoch=071/200] [Need: 00:47:12] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [071][000/391]   Time 0.278 (0.278)   Data 0.219 (0.219)   Loss 0.2222 (0.2222)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-11-24 13:40:41]
  Epoch: [071][100/391]   Time 0.045 (0.051)   Data 0.000 (0.002)   Loss 0.3236 (0.2879)   Prec@1 85.938 (89.929)   Prec@5 100.000 (99.745)   [2019-11-24 13:40:46]
  Epoch: [071][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.2507 (0.2877)   Prec@1 89.062 (89.824)   Prec@5 100.000 (99.767)   [2019-11-24 13:40:51]
  Epoch: [071][300/391]   Time 0.073 (0.052)   Data 0.000 (0.001)   Loss 0.2185 (0.2918)   Prec@1 92.188 (89.735)   Prec@5 100.000 (99.746)   [2019-11-24 13:40:57]
  **Train** Prec@1 89.712 Prec@5 99.746 Error@1 10.288
  **Test** Prec@1 86.250 Prec@5 99.520 Error@1 13.750

==>>[2019-11-24 13:41:03] [Epoch=072/200] [Need: 00:46:50] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [072][000/391]   Time 0.278 (0.278)   Data 0.201 (0.201)   Loss 0.2452 (0.2452)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-24 13:41:03]
  Epoch: [072][100/391]   Time 0.043 (0.057)   Data 0.000 (0.002)   Loss 0.3776 (0.2770)   Prec@1 85.156 (90.331)   Prec@5 99.219 (99.760)   [2019-11-24 13:41:08]
  Epoch: [072][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.2281 (0.2805)   Prec@1 92.188 (90.252)   Prec@5 99.219 (99.751)   [2019-11-24 13:41:14]
  Epoch: [072][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3119 (0.2916)   Prec@1 89.062 (89.883)   Prec@5 100.000 (99.746)   [2019-11-24 13:41:18]
  **Train** Prec@1 89.702 Prec@5 99.738 Error@1 10.298
  **Test** Prec@1 82.790 Prec@5 98.610 Error@1 17.210

==>>[2019-11-24 13:41:25] [Epoch=073/200] [Need: 00:46:28] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [073][000/391]   Time 0.278 (0.278)   Data 0.212 (0.212)   Loss 0.2404 (0.2404)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-24 13:41:25]
  Epoch: [073][100/391]   Time 0.050 (0.051)   Data 0.000 (0.002)   Loss 0.3252 (0.2809)   Prec@1 88.281 (90.184)   Prec@5 100.000 (99.691)   [2019-11-24 13:41:30]
  Epoch: [073][200/391]   Time 0.050 (0.050)   Data 0.000 (0.001)   Loss 0.2653 (0.2908)   Prec@1 91.406 (89.739)   Prec@5 100.000 (99.646)   [2019-11-24 13:41:35]
  Epoch: [073][300/391]   Time 0.077 (0.051)   Data 0.000 (0.001)   Loss 0.2435 (0.2926)   Prec@1 89.844 (89.709)   Prec@5 100.000 (99.694)   [2019-11-24 13:41:40]
  **Train** Prec@1 89.612 Prec@5 99.678 Error@1 10.388
  **Test** Prec@1 85.830 Prec@5 99.500 Error@1 14.170

==>>[2019-11-24 13:41:47] [Epoch=074/200] [Need: 00:46:07] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [074][000/391]   Time 0.274 (0.274)   Data 0.216 (0.216)   Loss 0.3174 (0.3174)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:41:47]
  Epoch: [074][100/391]   Time 0.043 (0.057)   Data 0.000 (0.002)   Loss 0.2891 (0.2759)   Prec@1 90.625 (90.540)   Prec@5 99.219 (99.714)   [2019-11-24 13:41:53]
  Epoch: [074][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.3694 (0.2788)   Prec@1 89.062 (90.435)   Prec@5 98.438 (99.743)   [2019-11-24 13:41:58]
  Epoch: [074][300/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.3089 (0.2878)   Prec@1 90.625 (90.080)   Prec@5 100.000 (99.727)   [2019-11-24 13:42:03]
  **Train** Prec@1 90.070 Prec@5 99.720 Error@1 9.930
  **Test** Prec@1 86.470 Prec@5 99.380 Error@1 13.530

==>>[2019-11-24 13:42:10] [Epoch=075/200] [Need: 00:45:46] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [075][000/391]   Time 0.270 (0.270)   Data 0.206 (0.206)   Loss 0.2925 (0.2925)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-24 13:42:10]
  Epoch: [075][100/391]   Time 0.074 (0.052)   Data 0.000 (0.002)   Loss 0.2996 (0.2721)   Prec@1 88.281 (90.563)   Prec@5 100.000 (99.799)   [2019-11-24 13:42:15]
  Epoch: [075][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2267 (0.2810)   Prec@1 92.188 (90.275)   Prec@5 100.000 (99.771)   [2019-11-24 13:42:20]
  Epoch: [075][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.3372 (0.2898)   Prec@1 88.281 (90.018)   Prec@5 100.000 (99.743)   [2019-11-24 13:42:26]
  **Train** Prec@1 89.930 Prec@5 99.746 Error@1 10.070
  **Test** Prec@1 85.310 Prec@5 99.250 Error@1 14.690

==>>[2019-11-24 13:42:32] [Epoch=076/200] [Need: 00:45:25] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [076][000/391]   Time 0.274 (0.274)   Data 0.197 (0.197)   Loss 0.2848 (0.2848)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-11-24 13:42:32]
  Epoch: [076][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.2002 (0.2829)   Prec@1 92.969 (90.029)   Prec@5 99.219 (99.667)   [2019-11-24 13:42:37]
  Epoch: [076][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.2774 (0.2925)   Prec@1 91.406 (89.634)   Prec@5 99.219 (99.689)   [2019-11-24 13:42:42]
  Epoch: [076][300/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.3908 (0.2931)   Prec@1 87.500 (89.644)   Prec@5 99.219 (99.686)   [2019-11-24 13:42:47]
  **Train** Prec@1 89.592 Prec@5 99.710 Error@1 10.408
  **Test** Prec@1 80.090 Prec@5 99.100 Error@1 19.910

==>>[2019-11-24 13:42:54] [Epoch=077/200] [Need: 00:45:02] [LR=0.0100][M=0.90] [Best : Accuracy=86.50, Error=13.50]
  Epoch: [077][000/391]   Time 0.275 (0.275)   Data 0.201 (0.201)   Loss 0.2149 (0.2149)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-24 13:42:54]
  Epoch: [077][100/391]   Time 0.048 (0.052)   Data 0.000 (0.002)   Loss 0.3265 (0.2871)   Prec@1 86.719 (89.890)   Prec@5 100.000 (99.745)   [2019-11-24 13:42:59]
  Epoch: [077][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.2857 (0.2856)   Prec@1 89.844 (90.069)   Prec@5 99.219 (99.740)   [2019-11-24 13:43:04]
  Epoch: [077][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.3188 (0.2909)   Prec@1 87.500 (89.781)   Prec@5 100.000 (99.753)   [2019-11-24 13:43:09]
  **Train** Prec@1 89.788 Prec@5 99.724 Error@1 10.212
  **Test** Prec@1 86.530 Prec@5 99.380 Error@1 13.470
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:43:15] [Epoch=078/200] [Need: 00:44:40] [LR=0.0100][M=0.90] [Best : Accuracy=86.53, Error=13.47]
  Epoch: [078][000/391]   Time 0.275 (0.275)   Data 0.210 (0.210)   Loss 0.2450 (0.2450)   Prec@1 91.406 (91.406)   Prec@5 97.656 (97.656)   [2019-11-24 13:43:16]
  Epoch: [078][100/391]   Time 0.055 (0.055)   Data 0.000 (0.002)   Loss 0.3502 (0.2707)   Prec@1 84.375 (90.664)   Prec@5 100.000 (99.760)   [2019-11-24 13:43:21]
  Epoch: [078][200/391]   Time 0.049 (0.053)   Data 0.000 (0.001)   Loss 0.2939 (0.2848)   Prec@1 92.188 (90.124)   Prec@5 98.438 (99.771)   [2019-11-24 13:43:26]
  Epoch: [078][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.3103 (0.2871)   Prec@1 89.062 (89.997)   Prec@5 100.000 (99.743)   [2019-11-24 13:43:31]
  **Train** Prec@1 89.908 Prec@5 99.746 Error@1 10.092
  **Test** Prec@1 85.720 Prec@5 99.340 Error@1 14.280

==>>[2019-11-24 13:43:38] [Epoch=079/200] [Need: 00:44:18] [LR=0.0100][M=0.90] [Best : Accuracy=86.53, Error=13.47]
  Epoch: [079][000/391]   Time 0.288 (0.288)   Data 0.201 (0.201)   Loss 0.2859 (0.2859)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2019-11-24 13:43:38]
  Epoch: [079][100/391]   Time 0.061 (0.056)   Data 0.000 (0.002)   Loss 0.3194 (0.2757)   Prec@1 87.500 (90.408)   Prec@5 99.219 (99.722)   [2019-11-24 13:43:43]
  Epoch: [079][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.2920 (0.2790)   Prec@1 92.969 (90.345)   Prec@5 99.219 (99.724)   [2019-11-24 13:43:48]
  Epoch: [079][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1849 (0.2894)   Prec@1 92.969 (89.940)   Prec@5 100.000 (99.725)   [2019-11-24 13:43:53]
  **Train** Prec@1 89.824 Prec@5 99.708 Error@1 10.176
  **Test** Prec@1 85.890 Prec@5 99.500 Error@1 14.110

==>>[2019-11-24 13:43:59] [Epoch=080/200] [Need: 00:43:55] [LR=0.0010][M=0.90] [Best : Accuracy=86.53, Error=13.47]
  Epoch: [080][000/391]   Time 0.277 (0.277)   Data 0.211 (0.211)   Loss 0.3874 (0.3874)   Prec@1 85.156 (85.156)   Prec@5 98.438 (98.438)   [2019-11-24 13:43:59]
  Epoch: [080][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.2502 (0.2263)   Prec@1 92.969 (92.334)   Prec@5 100.000 (99.838)   [2019-11-24 13:44:04]
  Epoch: [080][200/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.2129 (0.2121)   Prec@1 92.188 (92.736)   Prec@5 100.000 (99.872)   [2019-11-24 13:44:10]
  Epoch: [080][300/391]   Time 0.035 (0.052)   Data 0.000 (0.001)   Loss 0.2289 (0.2061)   Prec@1 91.406 (92.948)   Prec@5 100.000 (99.860)   [2019-11-24 13:44:15]
  **Train** Prec@1 93.094 Prec@5 99.854 Error@1 6.906
  **Test** Prec@1 90.250 Prec@5 99.750 Error@1 9.750
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:44:21] [Epoch=081/200] [Need: 00:43:34] [LR=0.0010][M=0.90] [Best : Accuracy=90.25, Error=9.75]
  Epoch: [081][000/391]   Time 0.268 (0.268)   Data 0.203 (0.203)   Loss 0.1695 (0.1695)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-11-24 13:44:22]
  Epoch: [081][100/391]   Time 0.051 (0.057)   Data 0.000 (0.002)   Loss 0.1755 (0.1690)   Prec@1 92.188 (94.322)   Prec@5 99.219 (99.876)   [2019-11-24 13:44:27]
  Epoch: [081][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.2678 (0.1692)   Prec@1 94.531 (94.349)   Prec@5 100.000 (99.891)   [2019-11-24 13:44:32]
  Epoch: [081][300/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.1447 (0.1686)   Prec@1 95.312 (94.272)   Prec@5 100.000 (99.891)   [2019-11-24 13:44:37]
  **Train** Prec@1 94.208 Prec@5 99.888 Error@1 5.792
  **Test** Prec@1 90.530 Prec@5 99.690 Error@1 9.470
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:44:43] [Epoch=082/200] [Need: 00:43:12] [LR=0.0010][M=0.90] [Best : Accuracy=90.53, Error=9.47]
  Epoch: [082][000/391]   Time 0.265 (0.265)   Data 0.208 (0.208)   Loss 0.2001 (0.2001)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2019-11-24 13:44:44]
  Epoch: [082][100/391]   Time 0.049 (0.054)   Data 0.000 (0.002)   Loss 0.2674 (0.1511)   Prec@1 90.625 (95.034)   Prec@5 99.219 (99.869)   [2019-11-24 13:44:49]
  Epoch: [082][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.1488 (0.1574)   Prec@1 94.531 (94.663)   Prec@5 100.000 (99.868)   [2019-11-24 13:44:54]
  Epoch: [082][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.1762 (0.1586)   Prec@1 92.969 (94.625)   Prec@5 100.000 (99.881)   [2019-11-24 13:44:58]
  **Train** Prec@1 94.602 Prec@5 99.898 Error@1 5.398
  **Test** Prec@1 90.810 Prec@5 99.690 Error@1 9.190
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:45:05] [Epoch=083/200] [Need: 00:42:49] [LR=0.0010][M=0.90] [Best : Accuracy=90.81, Error=9.19]
  Epoch: [083][000/391]   Time 0.286 (0.286)   Data 0.217 (0.217)   Loss 0.1099 (0.1099)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:45:05]
  Epoch: [083][100/391]   Time 0.047 (0.054)   Data 0.000 (0.002)   Loss 0.1173 (0.1475)   Prec@1 96.094 (94.949)   Prec@5 100.000 (99.923)   [2019-11-24 13:45:10]
  Epoch: [083][200/391]   Time 0.056 (0.050)   Data 0.000 (0.001)   Loss 0.1661 (0.1483)   Prec@1 93.750 (94.939)   Prec@5 100.000 (99.922)   [2019-11-24 13:45:15]
  Epoch: [083][300/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.1988 (0.1479)   Prec@1 92.969 (94.923)   Prec@5 99.219 (99.920)   [2019-11-24 13:45:20]
  **Train** Prec@1 94.854 Prec@5 99.912 Error@1 5.146
  **Test** Prec@1 90.870 Prec@5 99.700 Error@1 9.130
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:45:27] [Epoch=084/200] [Need: 00:42:27] [LR=0.0010][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [084][000/391]   Time 0.265 (0.265)   Data 0.204 (0.204)   Loss 0.1306 (0.1306)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:45:27]
  Epoch: [084][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.1240 (0.1397)   Prec@1 96.094 (95.088)   Prec@5 99.219 (99.930)   [2019-11-24 13:45:32]
  Epoch: [084][200/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.1128 (0.1419)   Prec@1 95.312 (95.079)   Prec@5 100.000 (99.918)   [2019-11-24 13:45:37]
  Epoch: [084][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1358 (0.1420)   Prec@1 96.094 (95.123)   Prec@5 100.000 (99.909)   [2019-11-24 13:45:42]
  **Train** Prec@1 95.040 Prec@5 99.908 Error@1 4.960
  **Test** Prec@1 90.690 Prec@5 99.760 Error@1 9.310

==>>[2019-11-24 13:45:49] [Epoch=085/200] [Need: 00:42:05] [LR=0.0010][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [085][000/391]   Time 0.269 (0.269)   Data 0.214 (0.214)   Loss 0.1364 (0.1364)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:45:49]
  Epoch: [085][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.1468 (0.1370)   Prec@1 95.312 (95.065)   Prec@5 100.000 (99.969)   [2019-11-24 13:45:54]
  Epoch: [085][200/391]   Time 0.053 (0.053)   Data 0.000 (0.001)   Loss 0.1165 (0.1353)   Prec@1 95.312 (95.122)   Prec@5 100.000 (99.961)   [2019-11-24 13:45:59]
  Epoch: [085][300/391]   Time 0.074 (0.052)   Data 0.000 (0.001)   Loss 0.1190 (0.1366)   Prec@1 96.875 (95.097)   Prec@5 99.219 (99.930)   [2019-11-24 13:46:04]
  **Train** Prec@1 95.072 Prec@5 99.930 Error@1 4.928
  **Test** Prec@1 90.790 Prec@5 99.760 Error@1 9.210

==>>[2019-11-24 13:46:11] [Epoch=086/200] [Need: 00:41:44] [LR=0.0010][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [086][000/391]   Time 0.281 (0.281)   Data 0.212 (0.212)   Loss 0.1465 (0.1465)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:46:11]
  Epoch: [086][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.1362 (0.1269)   Prec@1 95.312 (95.831)   Prec@5 100.000 (99.938)   [2019-11-24 13:46:17]
  Epoch: [086][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1258 (0.1325)   Prec@1 94.531 (95.449)   Prec@5 100.000 (99.918)   [2019-11-24 13:46:22]
  Epoch: [086][300/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.2011 (0.1356)   Prec@1 93.750 (95.336)   Prec@5 100.000 (99.927)   [2019-11-24 13:46:26]
  **Train** Prec@1 95.280 Prec@5 99.930 Error@1 4.720
  **Test** Prec@1 90.760 Prec@5 99.780 Error@1 9.240

==>>[2019-11-24 13:46:33] [Epoch=087/200] [Need: 00:41:21] [LR=0.0010][M=0.90] [Best : Accuracy=90.87, Error=9.13]
  Epoch: [087][000/391]   Time 0.276 (0.276)   Data 0.217 (0.217)   Loss 0.0753 (0.0753)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 13:46:33]
  Epoch: [087][100/391]   Time 0.049 (0.054)   Data 0.000 (0.002)   Loss 0.1406 (0.1266)   Prec@1 96.875 (95.591)   Prec@5 100.000 (99.892)   [2019-11-24 13:46:38]
  Epoch: [087][200/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.1156 (0.1283)   Prec@1 96.094 (95.522)   Prec@5 100.000 (99.926)   [2019-11-24 13:46:43]
  Epoch: [087][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0976 (0.1286)   Prec@1 96.875 (95.497)   Prec@5 100.000 (99.938)   [2019-11-24 13:46:48]
  **Train** Prec@1 95.480 Prec@5 99.938 Error@1 4.520
  **Test** Prec@1 90.970 Prec@5 99.750 Error@1 9.030
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:46:55] [Epoch=088/200] [Need: 00:41:00] [LR=0.0010][M=0.90] [Best : Accuracy=90.97, Error=9.03]
  Epoch: [088][000/391]   Time 0.282 (0.282)   Data 0.199 (0.199)   Loss 0.1574 (0.1574)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:46:56]
  Epoch: [088][100/391]   Time 0.053 (0.052)   Data 0.000 (0.002)   Loss 0.1807 (0.1216)   Prec@1 96.094 (95.815)   Prec@5 100.000 (99.977)   [2019-11-24 13:47:01]
  Epoch: [088][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.0948 (0.1185)   Prec@1 96.094 (95.791)   Prec@5 100.000 (99.965)   [2019-11-24 13:47:05]
  Epoch: [088][300/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0881 (0.1197)   Prec@1 96.875 (95.754)   Prec@5 100.000 (99.958)   [2019-11-24 13:47:10]
  **Train** Prec@1 95.628 Prec@5 99.950 Error@1 4.372
  **Test** Prec@1 90.930 Prec@5 99.740 Error@1 9.070

==>>[2019-11-24 13:47:17] [Epoch=089/200] [Need: 00:40:37] [LR=0.0010][M=0.90] [Best : Accuracy=90.97, Error=9.03]
  Epoch: [089][000/391]   Time 0.292 (0.292)   Data 0.228 (0.228)   Loss 0.0865 (0.0865)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:47:17]
  Epoch: [089][100/391]   Time 0.055 (0.050)   Data 0.000 (0.002)   Loss 0.1988 (0.1234)   Prec@1 92.969 (95.753)   Prec@5 100.000 (99.954)   [2019-11-24 13:47:22]
  Epoch: [089][200/391]   Time 0.054 (0.050)   Data 0.000 (0.001)   Loss 0.1510 (0.1206)   Prec@1 95.312 (95.857)   Prec@5 100.000 (99.965)   [2019-11-24 13:47:27]
  Epoch: [089][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0785 (0.1177)   Prec@1 97.656 (95.959)   Prec@5 100.000 (99.961)   [2019-11-24 13:47:32]
  **Train** Prec@1 95.940 Prec@5 99.962 Error@1 4.060
  **Test** Prec@1 90.900 Prec@5 99.760 Error@1 9.100

==>>[2019-11-24 13:47:39] [Epoch=090/200] [Need: 00:40:16] [LR=0.0010][M=0.90] [Best : Accuracy=90.97, Error=9.03]
  Epoch: [090][000/391]   Time 0.286 (0.286)   Data 0.230 (0.230)   Loss 0.1436 (0.1436)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:47:39]
  Epoch: [090][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0586 (0.1090)   Prec@1 98.438 (96.179)   Prec@5 100.000 (99.969)   [2019-11-24 13:47:44]
  Epoch: [090][200/391]   Time 0.058 (0.054)   Data 0.000 (0.001)   Loss 0.1540 (0.1103)   Prec@1 94.531 (96.152)   Prec@5 98.438 (99.949)   [2019-11-24 13:47:49]
  Epoch: [090][300/391]   Time 0.063 (0.053)   Data 0.000 (0.001)   Loss 0.1166 (0.1137)   Prec@1 95.312 (96.112)   Prec@5 100.000 (99.938)   [2019-11-24 13:47:55]
  **Train** Prec@1 96.006 Prec@5 99.936 Error@1 3.994
  **Test** Prec@1 90.850 Prec@5 99.760 Error@1 9.150

==>>[2019-11-24 13:48:01] [Epoch=091/200] [Need: 00:39:54] [LR=0.0010][M=0.90] [Best : Accuracy=90.97, Error=9.03]
  Epoch: [091][000/391]   Time 0.273 (0.273)   Data 0.207 (0.207)   Loss 0.1151 (0.1151)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-11-24 13:48:01]
  Epoch: [091][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.1060 (0.1136)   Prec@1 95.312 (95.877)   Prec@5 100.000 (99.961)   [2019-11-24 13:48:07]
  Epoch: [091][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1022 (0.1128)   Prec@1 94.531 (95.958)   Prec@5 100.000 (99.965)   [2019-11-24 13:48:11]
  Epoch: [091][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.2176 (0.1125)   Prec@1 92.188 (95.961)   Prec@5 99.219 (99.966)   [2019-11-24 13:48:16]
  **Train** Prec@1 96.004 Prec@5 99.960 Error@1 3.996
  **Test** Prec@1 91.300 Prec@5 99.750 Error@1 8.700
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:48:23] [Epoch=092/200] [Need: 00:39:32] [LR=0.0010][M=0.90] [Best : Accuracy=91.30, Error=8.70]
  Epoch: [092][000/391]   Time 0.278 (0.278)   Data 0.212 (0.212)   Loss 0.1089 (0.1089)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:48:23]
  Epoch: [092][100/391]   Time 0.047 (0.054)   Data 0.000 (0.002)   Loss 0.1197 (0.1070)   Prec@1 96.094 (96.194)   Prec@5 100.000 (99.961)   [2019-11-24 13:48:28]
  Epoch: [092][200/391]   Time 0.050 (0.053)   Data 0.000 (0.001)   Loss 0.1318 (0.1097)   Prec@1 96.094 (96.125)   Prec@5 100.000 (99.953)   [2019-11-24 13:48:33]
  Epoch: [092][300/391]   Time 0.060 (0.053)   Data 0.000 (0.001)   Loss 0.0716 (0.1089)   Prec@1 98.438 (96.192)   Prec@5 100.000 (99.948)   [2019-11-24 13:48:39]
  **Train** Prec@1 96.112 Prec@5 99.940 Error@1 3.888
  **Test** Prec@1 91.040 Prec@5 99.770 Error@1 8.960

==>>[2019-11-24 13:48:45] [Epoch=093/200] [Need: 00:39:10] [LR=0.0010][M=0.90] [Best : Accuracy=91.30, Error=8.70]
  Epoch: [093][000/391]   Time 0.268 (0.268)   Data 0.198 (0.198)   Loss 0.0487 (0.0487)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:48:45]
  Epoch: [093][100/391]   Time 0.080 (0.053)   Data 0.000 (0.002)   Loss 0.0723 (0.1053)   Prec@1 96.094 (96.140)   Prec@5 100.000 (99.961)   [2019-11-24 13:48:50]
  Epoch: [093][200/391]   Time 0.075 (0.054)   Data 0.000 (0.001)   Loss 0.1260 (0.1083)   Prec@1 96.875 (96.028)   Prec@5 99.219 (99.953)   [2019-11-24 13:48:56]
  Epoch: [093][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0979 (0.1088)   Prec@1 96.094 (96.115)   Prec@5 100.000 (99.953)   [2019-11-24 13:49:01]
  **Train** Prec@1 96.138 Prec@5 99.950 Error@1 3.862
  **Test** Prec@1 91.160 Prec@5 99.730 Error@1 8.840

==>>[2019-11-24 13:49:08] [Epoch=094/200] [Need: 00:38:49] [LR=0.0010][M=0.90] [Best : Accuracy=91.30, Error=8.70]
  Epoch: [094][000/391]   Time 0.273 (0.273)   Data 0.200 (0.200)   Loss 0.1126 (0.1126)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:49:08]
  Epoch: [094][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.1552 (0.0961)   Prec@1 96.094 (96.744)   Prec@5 100.000 (99.969)   [2019-11-24 13:49:13]
  Epoch: [094][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0706 (0.1000)   Prec@1 98.438 (96.607)   Prec@5 100.000 (99.961)   [2019-11-24 13:49:18]
  Epoch: [094][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0752 (0.1011)   Prec@1 96.875 (96.444)   Prec@5 100.000 (99.969)   [2019-11-24 13:49:23]
  **Train** Prec@1 96.324 Prec@5 99.968 Error@1 3.676
  **Test** Prec@1 91.240 Prec@5 99.670 Error@1 8.760

==>>[2019-11-24 13:49:30] [Epoch=095/200] [Need: 00:38:27] [LR=0.0010][M=0.90] [Best : Accuracy=91.30, Error=8.70]
  Epoch: [095][000/391]   Time 0.283 (0.283)   Data 0.220 (0.220)   Loss 0.0526 (0.0526)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:49:30]
  Epoch: [095][100/391]   Time 0.045 (0.055)   Data 0.000 (0.002)   Loss 0.0987 (0.0891)   Prec@1 96.875 (96.921)   Prec@5 100.000 (99.954)   [2019-11-24 13:49:35]
  Epoch: [095][200/391]   Time 0.080 (0.053)   Data 0.000 (0.001)   Loss 0.1080 (0.0947)   Prec@1 96.094 (96.673)   Prec@5 100.000 (99.961)   [2019-11-24 13:49:41]
  Epoch: [095][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.1401 (0.0969)   Prec@1 95.312 (96.569)   Prec@5 100.000 (99.971)   [2019-11-24 13:49:46]
  **Train** Prec@1 96.580 Prec@5 99.966 Error@1 3.420
  **Test** Prec@1 91.330 Prec@5 99.700 Error@1 8.670
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:49:53] [Epoch=096/200] [Need: 00:38:06] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [096][000/391]   Time 0.275 (0.275)   Data 0.210 (0.210)   Loss 0.0426 (0.0426)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:49:53]
  Epoch: [096][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0559 (0.0961)   Prec@1 96.875 (96.612)   Prec@5 100.000 (99.961)   [2019-11-24 13:49:58]
  Epoch: [096][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0626 (0.0984)   Prec@1 99.219 (96.533)   Prec@5 100.000 (99.977)   [2019-11-24 13:50:03]
  Epoch: [096][300/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.1373 (0.1000)   Prec@1 95.312 (96.442)   Prec@5 100.000 (99.977)   [2019-11-24 13:50:08]
  **Train** Prec@1 96.520 Prec@5 99.970 Error@1 3.480
  **Test** Prec@1 91.010 Prec@5 99.780 Error@1 8.990

==>>[2019-11-24 13:50:15] [Epoch=097/200] [Need: 00:37:45] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [097][000/391]   Time 0.277 (0.277)   Data 0.217 (0.217)   Loss 0.1149 (0.1149)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:50:15]
  Epoch: [097][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.1155 (0.0904)   Prec@1 96.094 (96.759)   Prec@5 100.000 (99.969)   [2019-11-24 13:50:20]
  Epoch: [097][200/391]   Time 0.062 (0.051)   Data 0.000 (0.001)   Loss 0.0851 (0.0930)   Prec@1 96.875 (96.723)   Prec@5 100.000 (99.977)   [2019-11-24 13:50:25]
  Epoch: [097][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.1049 (0.0949)   Prec@1 96.875 (96.704)   Prec@5 100.000 (99.982)   [2019-11-24 13:50:30]
  **Train** Prec@1 96.724 Prec@5 99.978 Error@1 3.276
  **Test** Prec@1 91.160 Prec@5 99.710 Error@1 8.840

==>>[2019-11-24 13:50:36] [Epoch=098/200] [Need: 00:37:22] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [098][000/391]   Time 0.272 (0.272)   Data 0.212 (0.212)   Loss 0.1301 (0.1301)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 13:50:37]
  Epoch: [098][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.0830 (0.0910)   Prec@1 98.438 (96.813)   Prec@5 100.000 (99.969)   [2019-11-24 13:50:42]
  Epoch: [098][200/391]   Time 0.082 (0.053)   Data 0.000 (0.001)   Loss 0.1193 (0.0928)   Prec@1 97.656 (96.879)   Prec@5 100.000 (99.969)   [2019-11-24 13:50:47]
  Epoch: [098][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.1230 (0.0956)   Prec@1 93.750 (96.686)   Prec@5 100.000 (99.977)   [2019-11-24 13:50:52]
  **Train** Prec@1 96.750 Prec@5 99.972 Error@1 3.250
  **Test** Prec@1 90.990 Prec@5 99.700 Error@1 9.010

==>>[2019-11-24 13:50:58] [Epoch=099/200] [Need: 00:37:00] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [099][000/391]   Time 0.287 (0.287)   Data 0.230 (0.230)   Loss 0.0824 (0.0824)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 13:50:59]
  Epoch: [099][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.1244 (0.0879)   Prec@1 95.312 (97.061)   Prec@5 100.000 (99.985)   [2019-11-24 13:51:04]
  Epoch: [099][200/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.0552 (0.0873)   Prec@1 99.219 (97.050)   Prec@5 100.000 (99.988)   [2019-11-24 13:51:08]
  Epoch: [099][300/391]   Time 0.055 (0.050)   Data 0.000 (0.001)   Loss 0.0998 (0.0899)   Prec@1 96.094 (96.849)   Prec@5 100.000 (99.992)   [2019-11-24 13:51:13]
  **Train** Prec@1 96.844 Prec@5 99.986 Error@1 3.156
  **Test** Prec@1 90.690 Prec@5 99.680 Error@1 9.310

==>>[2019-11-24 13:51:20] [Epoch=100/200] [Need: 00:36:38] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [100][000/391]   Time 0.269 (0.269)   Data 0.204 (0.204)   Loss 0.1008 (0.1008)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:51:20]
  Epoch: [100][100/391]   Time 0.071 (0.052)   Data 0.000 (0.002)   Loss 0.1134 (0.0894)   Prec@1 95.312 (96.774)   Prec@5 100.000 (99.961)   [2019-11-24 13:51:25]
  Epoch: [100][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.1255 (0.0898)   Prec@1 96.094 (96.801)   Prec@5 100.000 (99.957)   [2019-11-24 13:51:30]
  Epoch: [100][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.1164 (0.0905)   Prec@1 95.312 (96.792)   Prec@5 100.000 (99.956)   [2019-11-24 13:51:35]
  **Train** Prec@1 96.774 Prec@5 99.960 Error@1 3.226
  **Test** Prec@1 90.990 Prec@5 99.750 Error@1 9.010

==>>[2019-11-24 13:51:42] [Epoch=101/200] [Need: 00:36:15] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [101][000/391]   Time 0.261 (0.261)   Data 0.200 (0.200)   Loss 0.0711 (0.0711)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:51:42]
  Epoch: [101][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0528 (0.0881)   Prec@1 98.438 (96.883)   Prec@5 100.000 (99.977)   [2019-11-24 13:51:47]
  Epoch: [101][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.1186 (0.0890)   Prec@1 96.875 (96.953)   Prec@5 100.000 (99.953)   [2019-11-24 13:51:52]
  Epoch: [101][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0913 (0.0885)   Prec@1 95.312 (96.958)   Prec@5 100.000 (99.966)   [2019-11-24 13:51:57]
  **Train** Prec@1 96.822 Prec@5 99.964 Error@1 3.178
  **Test** Prec@1 91.140 Prec@5 99.680 Error@1 8.860

==>>[2019-11-24 13:52:03] [Epoch=102/200] [Need: 00:35:53] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [102][000/391]   Time 0.274 (0.274)   Data 0.222 (0.222)   Loss 0.0599 (0.0599)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:52:03]
  Epoch: [102][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0546 (0.0861)   Prec@1 97.656 (97.053)   Prec@5 100.000 (99.977)   [2019-11-24 13:52:08]
  Epoch: [102][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.1463 (0.0866)   Prec@1 95.312 (96.980)   Prec@5 100.000 (99.977)   [2019-11-24 13:52:14]
  Epoch: [102][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0707 (0.0854)   Prec@1 96.875 (97.000)   Prec@5 100.000 (99.979)   [2019-11-24 13:52:19]
  **Train** Prec@1 96.974 Prec@5 99.984 Error@1 3.026
  **Test** Prec@1 90.900 Prec@5 99.660 Error@1 9.100

==>>[2019-11-24 13:52:25] [Epoch=103/200] [Need: 00:35:31] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [103][000/391]   Time 0.278 (0.278)   Data 0.222 (0.222)   Loss 0.0446 (0.0446)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:52:25]
  Epoch: [103][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0713 (0.0841)   Prec@1 98.438 (96.937)   Prec@5 100.000 (99.992)   [2019-11-24 13:52:30]
  Epoch: [103][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0771 (0.0828)   Prec@1 98.438 (97.027)   Prec@5 100.000 (99.992)   [2019-11-24 13:52:35]
  Epoch: [103][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0383 (0.0831)   Prec@1 98.438 (97.051)   Prec@5 100.000 (99.982)   [2019-11-24 13:52:40]
  **Train** Prec@1 97.034 Prec@5 99.982 Error@1 2.966
  **Test** Prec@1 91.010 Prec@5 99.720 Error@1 8.990

==>>[2019-11-24 13:52:47] [Epoch=104/200] [Need: 00:35:09] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [104][000/391]   Time 0.284 (0.284)   Data 0.197 (0.197)   Loss 0.0536 (0.0536)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:52:47]
  Epoch: [104][100/391]   Time 0.071 (0.052)   Data 0.000 (0.002)   Loss 0.0702 (0.0788)   Prec@1 99.219 (97.269)   Prec@5 100.000 (99.992)   [2019-11-24 13:52:52]
  Epoch: [104][200/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.1142 (0.0794)   Prec@1 96.875 (97.240)   Prec@5 100.000 (99.996)   [2019-11-24 13:52:57]
  Epoch: [104][300/391]   Time 0.046 (0.052)   Data 0.000 (0.001)   Loss 0.0851 (0.0800)   Prec@1 96.875 (97.241)   Prec@5 100.000 (99.995)   [2019-11-24 13:53:03]
  **Train** Prec@1 97.202 Prec@5 99.992 Error@1 2.798
  **Test** Prec@1 90.910 Prec@5 99.720 Error@1 9.090

==>>[2019-11-24 13:53:09] [Epoch=105/200] [Need: 00:34:47] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [105][000/391]   Time 0.274 (0.274)   Data 0.219 (0.219)   Loss 0.0996 (0.0996)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:53:10]
  Epoch: [105][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0598 (0.0805)   Prec@1 97.656 (97.092)   Prec@5 100.000 (99.985)   [2019-11-24 13:53:15]
  Epoch: [105][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.1078 (0.0817)   Prec@1 97.656 (97.073)   Prec@5 100.000 (99.992)   [2019-11-24 13:53:20]
  Epoch: [105][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0812 (0.0830)   Prec@1 96.875 (97.046)   Prec@5 100.000 (99.979)   [2019-11-24 13:53:25]
  **Train** Prec@1 97.030 Prec@5 99.976 Error@1 2.970
  **Test** Prec@1 90.890 Prec@5 99.750 Error@1 9.110

==>>[2019-11-24 13:53:32] [Epoch=106/200] [Need: 00:34:25] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [106][000/391]   Time 0.275 (0.275)   Data 0.212 (0.212)   Loss 0.0267 (0.0267)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 13:53:32]
  Epoch: [106][100/391]   Time 0.051 (0.053)   Data 0.000 (0.002)   Loss 0.0599 (0.0754)   Prec@1 96.875 (97.293)   Prec@5 100.000 (99.992)   [2019-11-24 13:53:37]
  Epoch: [106][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0481 (0.0779)   Prec@1 98.438 (97.167)   Prec@5 100.000 (99.984)   [2019-11-24 13:53:42]
  Epoch: [106][300/391]   Time 0.045 (0.051)   Data 0.002 (0.001)   Loss 0.0852 (0.0805)   Prec@1 97.656 (97.064)   Prec@5 100.000 (99.984)   [2019-11-24 13:53:47]
  **Train** Prec@1 97.054 Prec@5 99.986 Error@1 2.946
  **Test** Prec@1 90.970 Prec@5 99.780 Error@1 9.030

==>>[2019-11-24 13:53:54] [Epoch=107/200] [Need: 00:34:03] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [107][000/391]   Time 0.272 (0.272)   Data 0.199 (0.199)   Loss 0.0258 (0.0258)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 13:53:54]
  Epoch: [107][100/391]   Time 0.081 (0.052)   Data 0.000 (0.002)   Loss 0.1249 (0.0727)   Prec@1 96.875 (97.602)   Prec@5 100.000 (99.985)   [2019-11-24 13:53:59]
  Epoch: [107][200/391]   Time 0.073 (0.050)   Data 0.000 (0.001)   Loss 0.1039 (0.0762)   Prec@1 96.875 (97.400)   Prec@5 100.000 (99.992)   [2019-11-24 13:54:04]
  Epoch: [107][300/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0734 (0.0781)   Prec@1 96.875 (97.303)   Prec@5 100.000 (99.990)   [2019-11-24 13:54:08]
  **Train** Prec@1 97.238 Prec@5 99.990 Error@1 2.762
  **Test** Prec@1 90.770 Prec@5 99.690 Error@1 9.230

==>>[2019-11-24 13:54:15] [Epoch=108/200] [Need: 00:33:41] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [108][000/391]   Time 0.285 (0.285)   Data 0.201 (0.201)   Loss 0.1640 (0.1640)   Prec@1 95.312 (95.312)   Prec@5 99.219 (99.219)   [2019-11-24 13:54:15]
  Epoch: [108][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.0505 (0.0764)   Prec@1 98.438 (97.308)   Prec@5 100.000 (99.985)   [2019-11-24 13:54:20]
  Epoch: [108][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.0972 (0.0763)   Prec@1 96.094 (97.341)   Prec@5 100.000 (99.984)   [2019-11-24 13:54:25]
  Epoch: [108][300/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.1014 (0.0758)   Prec@1 96.094 (97.321)   Prec@5 100.000 (99.990)   [2019-11-24 13:54:30]
  **Train** Prec@1 97.280 Prec@5 99.986 Error@1 2.720
  **Test** Prec@1 90.990 Prec@5 99.750 Error@1 9.010

==>>[2019-11-24 13:54:37] [Epoch=109/200] [Need: 00:33:19] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [109][000/391]   Time 0.289 (0.289)   Data 0.225 (0.225)   Loss 0.0822 (0.0822)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:54:37]
  Epoch: [109][100/391]   Time 0.045 (0.052)   Data 0.000 (0.002)   Loss 0.0915 (0.0729)   Prec@1 96.875 (97.540)   Prec@5 100.000 (99.985)   [2019-11-24 13:54:42]
  Epoch: [109][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0663 (0.0775)   Prec@1 97.656 (97.291)   Prec@5 100.000 (99.981)   [2019-11-24 13:54:47]
  Epoch: [109][300/391]   Time 0.053 (0.050)   Data 0.000 (0.001)   Loss 0.0592 (0.0765)   Prec@1 97.656 (97.267)   Prec@5 100.000 (99.982)   [2019-11-24 13:54:52]
  **Train** Prec@1 97.256 Prec@5 99.982 Error@1 2.744
  **Test** Prec@1 90.940 Prec@5 99.640 Error@1 9.060

==>>[2019-11-24 13:54:58] [Epoch=110/200] [Need: 00:32:56] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [110][000/391]   Time 0.255 (0.255)   Data 0.199 (0.199)   Loss 0.0821 (0.0821)   Prec@1 98.438 (98.438)   Prec@5 99.219 (99.219)   [2019-11-24 13:54:58]
  Epoch: [110][100/391]   Time 0.044 (0.053)   Data 0.000 (0.002)   Loss 0.0464 (0.0700)   Prec@1 98.438 (97.579)   Prec@5 100.000 (99.985)   [2019-11-24 13:55:04]
  Epoch: [110][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0557 (0.0743)   Prec@1 98.438 (97.376)   Prec@5 100.000 (99.977)   [2019-11-24 13:55:09]
  Epoch: [110][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0521 (0.0743)   Prec@1 98.438 (97.410)   Prec@5 100.000 (99.982)   [2019-11-24 13:55:14]
  **Train** Prec@1 97.366 Prec@5 99.980 Error@1 2.634
  **Test** Prec@1 90.860 Prec@5 99.780 Error@1 9.140

==>>[2019-11-24 13:55:20] [Epoch=111/200] [Need: 00:32:35] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [111][000/391]   Time 0.275 (0.275)   Data 0.216 (0.216)   Loss 0.0580 (0.0580)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 13:55:20]
  Epoch: [111][100/391]   Time 0.076 (0.053)   Data 0.000 (0.002)   Loss 0.0585 (0.0775)   Prec@1 97.656 (97.370)   Prec@5 100.000 (99.992)   [2019-11-24 13:55:25]
  Epoch: [111][200/391]   Time 0.041 (0.051)   Data 0.000 (0.001)   Loss 0.1095 (0.0747)   Prec@1 97.656 (97.458)   Prec@5 100.000 (99.992)   [2019-11-24 13:55:30]
  Epoch: [111][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0563 (0.0752)   Prec@1 96.875 (97.407)   Prec@5 100.000 (99.992)   [2019-11-24 13:55:35]
  **Train** Prec@1 97.398 Prec@5 99.992 Error@1 2.602
  **Test** Prec@1 90.790 Prec@5 99.710 Error@1 9.210

==>>[2019-11-24 13:55:42] [Epoch=112/200] [Need: 00:32:12] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [112][000/391]   Time 0.281 (0.281)   Data 0.215 (0.215)   Loss 0.0268 (0.0268)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:55:42]
  Epoch: [112][100/391]   Time 0.055 (0.056)   Data 0.000 (0.002)   Loss 0.0682 (0.0723)   Prec@1 97.656 (97.401)   Prec@5 100.000 (100.000)   [2019-11-24 13:55:48]
  Epoch: [112][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0452 (0.0730)   Prec@1 98.438 (97.423)   Prec@5 100.000 (99.988)   [2019-11-24 13:55:53]
  Epoch: [112][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0817 (0.0733)   Prec@1 97.656 (97.430)   Prec@5 100.000 (99.982)   [2019-11-24 13:55:58]
  **Train** Prec@1 97.342 Prec@5 99.980 Error@1 2.658
  **Test** Prec@1 91.040 Prec@5 99.750 Error@1 8.960

==>>[2019-11-24 13:56:04] [Epoch=113/200] [Need: 00:31:50] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [113][000/391]   Time 0.286 (0.286)   Data 0.229 (0.229)   Loss 0.0868 (0.0868)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-11-24 13:56:04]
  Epoch: [113][100/391]   Time 0.053 (0.051)   Data 0.000 (0.002)   Loss 0.1127 (0.0715)   Prec@1 96.094 (97.471)   Prec@5 100.000 (99.992)   [2019-11-24 13:56:09]
  Epoch: [113][200/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0522 (0.0735)   Prec@1 98.438 (97.407)   Prec@5 100.000 (99.996)   [2019-11-24 13:56:14]
  Epoch: [113][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0731 (0.0722)   Prec@1 98.438 (97.441)   Prec@5 100.000 (99.992)   [2019-11-24 13:56:19]
  **Train** Prec@1 97.368 Prec@5 99.992 Error@1 2.632
  **Test** Prec@1 91.090 Prec@5 99.770 Error@1 8.910

==>>[2019-11-24 13:56:26] [Epoch=114/200] [Need: 00:31:28] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [114][000/391]   Time 0.279 (0.279)   Data 0.223 (0.223)   Loss 0.0445 (0.0445)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:56:26]
  Epoch: [114][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0480 (0.0652)   Prec@1 98.438 (97.795)   Prec@5 100.000 (99.992)   [2019-11-24 13:56:31]
  Epoch: [114][200/391]   Time 0.077 (0.052)   Data 0.000 (0.001)   Loss 0.0763 (0.0669)   Prec@1 96.875 (97.637)   Prec@5 100.000 (99.992)   [2019-11-24 13:56:36]
  Epoch: [114][300/391]   Time 0.057 (0.051)   Data 0.000 (0.001)   Loss 0.0718 (0.0671)   Prec@1 96.875 (97.630)   Prec@5 100.000 (99.992)   [2019-11-24 13:56:41]
  **Train** Prec@1 97.584 Prec@5 99.990 Error@1 2.416
  **Test** Prec@1 90.700 Prec@5 99.730 Error@1 9.300

==>>[2019-11-24 13:56:48] [Epoch=115/200] [Need: 00:31:06] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [115][000/391]   Time 0.270 (0.270)   Data 0.200 (0.200)   Loss 0.0267 (0.0267)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 13:56:48]
  Epoch: [115][100/391]   Time 0.059 (0.054)   Data 0.000 (0.002)   Loss 0.0968 (0.0713)   Prec@1 96.094 (97.463)   Prec@5 100.000 (100.000)   [2019-11-24 13:56:53]
  Epoch: [115][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0841 (0.0726)   Prec@1 97.656 (97.446)   Prec@5 100.000 (99.996)   [2019-11-24 13:56:58]
  Epoch: [115][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0581 (0.0739)   Prec@1 97.656 (97.334)   Prec@5 100.000 (99.990)   [2019-11-24 13:57:03]
  **Train** Prec@1 97.408 Prec@5 99.990 Error@1 2.592
  **Test** Prec@1 90.450 Prec@5 99.780 Error@1 9.550

==>>[2019-11-24 13:57:09] [Epoch=116/200] [Need: 00:30:44] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [116][000/391]   Time 0.269 (0.269)   Data 0.198 (0.198)   Loss 0.1236 (0.1236)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 13:57:10]
  Epoch: [116][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.0658 (0.0669)   Prec@1 96.875 (97.664)   Prec@5 100.000 (99.977)   [2019-11-24 13:57:15]
  Epoch: [116][200/391]   Time 0.048 (0.053)   Data 0.000 (0.001)   Loss 0.0347 (0.0646)   Prec@1 99.219 (97.753)   Prec@5 100.000 (99.988)   [2019-11-24 13:57:20]
  Epoch: [116][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0769 (0.0659)   Prec@1 98.438 (97.693)   Prec@5 100.000 (99.992)   [2019-11-24 13:57:25]
  **Train** Prec@1 97.686 Prec@5 99.992 Error@1 2.314
  **Test** Prec@1 90.850 Prec@5 99.720 Error@1 9.150

==>>[2019-11-24 13:57:32] [Epoch=117/200] [Need: 00:30:22] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [117][000/391]   Time 0.292 (0.292)   Data 0.228 (0.228)   Loss 0.0374 (0.0374)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:57:32]
  Epoch: [117][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.0429 (0.0659)   Prec@1 97.656 (97.679)   Prec@5 100.000 (99.992)   [2019-11-24 13:57:37]
  Epoch: [117][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.1144 (0.0667)   Prec@1 95.312 (97.586)   Prec@5 100.000 (99.996)   [2019-11-24 13:57:42]
  Epoch: [117][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.1314 (0.0687)   Prec@1 96.094 (97.519)   Prec@5 99.219 (99.990)   [2019-11-24 13:57:46]
  **Train** Prec@1 97.480 Prec@5 99.988 Error@1 2.520
  **Test** Prec@1 90.520 Prec@5 99.740 Error@1 9.480

==>>[2019-11-24 13:57:53] [Epoch=118/200] [Need: 00:30:00] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [118][000/391]   Time 0.267 (0.267)   Data 0.197 (0.197)   Loss 0.0553 (0.0553)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:57:53]
  Epoch: [118][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0667 (0.0648)   Prec@1 99.219 (97.672)   Prec@5 100.000 (99.977)   [2019-11-24 13:57:58]
  Epoch: [118][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0760 (0.0660)   Prec@1 95.312 (97.602)   Prec@5 100.000 (99.988)   [2019-11-24 13:58:03]
  Epoch: [118][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0177 (0.0653)   Prec@1 99.219 (97.610)   Prec@5 100.000 (99.990)   [2019-11-24 13:58:08]
  **Train** Prec@1 97.660 Prec@5 99.992 Error@1 2.340
  **Test** Prec@1 90.950 Prec@5 99.720 Error@1 9.050

==>>[2019-11-24 13:58:15] [Epoch=119/200] [Need: 00:29:38] [LR=0.0010][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [119][000/391]   Time 0.282 (0.282)   Data 0.226 (0.226)   Loss 0.0879 (0.0879)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 13:58:15]
  Epoch: [119][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0887 (0.0577)   Prec@1 96.875 (97.888)   Prec@5 100.000 (99.992)   [2019-11-24 13:58:20]
  Epoch: [119][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0418 (0.0605)   Prec@1 98.438 (97.847)   Prec@5 100.000 (99.996)   [2019-11-24 13:58:25]
  Epoch: [119][300/391]   Time 0.065 (0.050)   Data 0.000 (0.001)   Loss 0.0342 (0.0630)   Prec@1 98.438 (97.721)   Prec@5 100.000 (99.995)   [2019-11-24 13:58:30]
  **Train** Prec@1 97.658 Prec@5 99.994 Error@1 2.342
  **Test** Prec@1 90.820 Prec@5 99.740 Error@1 9.180

==>>[2019-11-24 13:58:36] [Epoch=120/200] [Need: 00:29:15] [LR=0.0001][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [120][000/391]   Time 0.285 (0.285)   Data 0.230 (0.230)   Loss 0.0673 (0.0673)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 13:58:36]
  Epoch: [120][100/391]   Time 0.054 (0.059)   Data 0.000 (0.002)   Loss 0.0746 (0.0601)   Prec@1 96.875 (97.888)   Prec@5 100.000 (99.992)   [2019-11-24 13:58:42]
  Epoch: [120][200/391]   Time 0.042 (0.055)   Data 0.000 (0.001)   Loss 0.0313 (0.0584)   Prec@1 98.438 (97.975)   Prec@5 100.000 (99.996)   [2019-11-24 13:58:47]
  Epoch: [120][300/391]   Time 0.043 (0.054)   Data 0.000 (0.001)   Loss 0.0458 (0.0582)   Prec@1 97.656 (97.957)   Prec@5 100.000 (99.992)   [2019-11-24 13:58:52]
  **Train** Prec@1 98.036 Prec@5 99.994 Error@1 1.964
  **Test** Prec@1 91.240 Prec@5 99.780 Error@1 8.760

==>>[2019-11-24 13:58:59] [Epoch=121/200] [Need: 00:28:54] [LR=0.0001][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [121][000/391]   Time 0.271 (0.271)   Data 0.200 (0.200)   Loss 0.0334 (0.0334)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 13:58:59]
  Epoch: [121][100/391]   Time 0.058 (0.059)   Data 0.000 (0.002)   Loss 0.0484 (0.0503)   Prec@1 99.219 (98.399)   Prec@5 100.000 (99.992)   [2019-11-24 13:59:05]
  Epoch: [121][200/391]   Time 0.070 (0.054)   Data 0.000 (0.001)   Loss 0.1011 (0.0529)   Prec@1 96.875 (98.239)   Prec@5 100.000 (99.984)   [2019-11-24 13:59:10]
  Epoch: [121][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.1064 (0.0532)   Prec@1 96.094 (98.212)   Prec@5 99.219 (99.984)   [2019-11-24 13:59:14]
  **Train** Prec@1 98.190 Prec@5 99.986 Error@1 1.810
  **Test** Prec@1 91.320 Prec@5 99.740 Error@1 8.680

==>>[2019-11-24 13:59:21] [Epoch=122/200] [Need: 00:28:32] [LR=0.0001][M=0.90] [Best : Accuracy=91.33, Error=8.67]
  Epoch: [122][000/391]   Time 0.273 (0.273)   Data 0.218 (0.218)   Loss 0.0605 (0.0605)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:59:21]
  Epoch: [122][100/391]   Time 0.051 (0.056)   Data 0.000 (0.002)   Loss 0.0640 (0.0506)   Prec@1 98.438 (98.298)   Prec@5 100.000 (100.000)   [2019-11-24 13:59:27]
  Epoch: [122][200/391]   Time 0.043 (0.055)   Data 0.000 (0.001)   Loss 0.0461 (0.0513)   Prec@1 98.438 (98.208)   Prec@5 100.000 (99.992)   [2019-11-24 13:59:32]
  Epoch: [122][300/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0110 (0.0495)   Prec@1 100.000 (98.264)   Prec@5 100.000 (99.992)   [2019-11-24 13:59:37]
  **Train** Prec@1 98.294 Prec@5 99.992 Error@1 1.706
  **Test** Prec@1 91.490 Prec@5 99.800 Error@1 8.510
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 13:59:44] [Epoch=123/200] [Need: 00:28:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [123][000/391]   Time 0.285 (0.285)   Data 0.228 (0.228)   Loss 0.0708 (0.0708)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 13:59:44]
  Epoch: [123][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0452 (0.0492)   Prec@1 100.000 (98.453)   Prec@5 100.000 (99.992)   [2019-11-24 13:59:49]
  Epoch: [123][200/391]   Time 0.060 (0.052)   Data 0.000 (0.001)   Loss 0.0460 (0.0473)   Prec@1 99.219 (98.496)   Prec@5 100.000 (99.988)   [2019-11-24 13:59:54]
  Epoch: [123][300/391]   Time 0.081 (0.051)   Data 0.000 (0.001)   Loss 0.0642 (0.0462)   Prec@1 97.656 (98.492)   Prec@5 100.000 (99.992)   [2019-11-24 13:59:59]
  **Train** Prec@1 98.492 Prec@5 99.988 Error@1 1.508
  **Test** Prec@1 91.310 Prec@5 99.770 Error@1 8.690

==>>[2019-11-24 14:00:06] [Epoch=124/200] [Need: 00:27:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [124][000/391]   Time 0.290 (0.290)   Data 0.235 (0.235)   Loss 0.0199 (0.0199)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:06]
  Epoch: [124][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0578 (0.0448)   Prec@1 99.219 (98.600)   Prec@5 100.000 (99.992)   [2019-11-24 14:00:11]
  Epoch: [124][200/391]   Time 0.075 (0.050)   Data 0.000 (0.001)   Loss 0.0102 (0.0448)   Prec@1 100.000 (98.558)   Prec@5 100.000 (99.992)   [2019-11-24 14:00:16]
  Epoch: [124][300/391]   Time 0.050 (0.049)   Data 0.000 (0.001)   Loss 0.0292 (0.0459)   Prec@1 99.219 (98.471)   Prec@5 100.000 (99.995)   [2019-11-24 14:00:20]
  **Train** Prec@1 98.498 Prec@5 99.996 Error@1 1.502
  **Test** Prec@1 91.370 Prec@5 99.730 Error@1 8.630

==>>[2019-11-24 14:00:27] [Epoch=125/200] [Need: 00:27:26] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [125][000/391]   Time 0.271 (0.271)   Data 0.208 (0.208)   Loss 0.0148 (0.0148)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:27]
  Epoch: [125][100/391]   Time 0.055 (0.052)   Data 0.000 (0.002)   Loss 0.0498 (0.0446)   Prec@1 98.438 (98.561)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:32]
  Epoch: [125][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0631 (0.0458)   Prec@1 97.656 (98.511)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:37]
  Epoch: [125][300/391]   Time 0.073 (0.051)   Data 0.000 (0.001)   Loss 0.0696 (0.0454)   Prec@1 97.656 (98.500)   Prec@5 100.000 (99.997)   [2019-11-24 14:00:42]
  **Train** Prec@1 98.428 Prec@5 99.998 Error@1 1.572
  **Test** Prec@1 91.410 Prec@5 99.760 Error@1 8.590

==>>[2019-11-24 14:00:48] [Epoch=126/200] [Need: 00:27:04] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [126][000/391]   Time 0.272 (0.272)   Data 0.213 (0.213)   Loss 0.0346 (0.0346)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:49]
  Epoch: [126][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0245 (0.0435)   Prec@1 99.219 (98.561)   Prec@5 100.000 (100.000)   [2019-11-24 14:00:54]
  Epoch: [126][200/391]   Time 0.048 (0.051)   Data 0.000 (0.001)   Loss 0.0927 (0.0440)   Prec@1 97.656 (98.527)   Prec@5 100.000 (99.996)   [2019-11-24 14:00:59]
  Epoch: [126][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0749 (0.0447)   Prec@1 96.875 (98.502)   Prec@5 100.000 (99.995)   [2019-11-24 14:01:04]
  **Train** Prec@1 98.514 Prec@5 99.996 Error@1 1.486
  **Test** Prec@1 91.360 Prec@5 99.770 Error@1 8.640

==>>[2019-11-24 14:01:10] [Epoch=127/200] [Need: 00:26:42] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [127][000/391]   Time 0.285 (0.285)   Data 0.199 (0.199)   Loss 0.0610 (0.0610)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:11]
  Epoch: [127][100/391]   Time 0.076 (0.053)   Data 0.000 (0.002)   Loss 0.0148 (0.0440)   Prec@1 100.000 (98.530)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:16]
  Epoch: [127][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0288 (0.0449)   Prec@1 98.438 (98.484)   Prec@5 100.000 (99.992)   [2019-11-24 14:01:21]
  Epoch: [127][300/391]   Time 0.049 (0.052)   Data 0.000 (0.001)   Loss 0.0600 (0.0455)   Prec@1 98.438 (98.482)   Prec@5 100.000 (99.995)   [2019-11-24 14:01:26]
  **Train** Prec@1 98.470 Prec@5 99.996 Error@1 1.530
  **Test** Prec@1 91.420 Prec@5 99.760 Error@1 8.580

==>>[2019-11-24 14:01:33] [Epoch=128/200] [Need: 00:26:20] [LR=0.0001][M=0.90] [Best : Accuracy=91.49, Error=8.51]
  Epoch: [128][000/391]   Time 0.270 (0.270)   Data 0.216 (0.216)   Loss 0.0504 (0.0504)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:33]
  Epoch: [128][100/391]   Time 0.057 (0.052)   Data 0.000 (0.002)   Loss 0.0447 (0.0463)   Prec@1 97.656 (98.298)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:38]
  Epoch: [128][200/391]   Time 0.062 (0.050)   Data 0.000 (0.001)   Loss 0.0505 (0.0438)   Prec@1 97.656 (98.461)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:43]
  Epoch: [128][300/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0217 (0.0437)   Prec@1 99.219 (98.531)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:48]
  **Train** Prec@1 98.538 Prec@5 100.000 Error@1 1.462
  **Test** Prec@1 91.520 Prec@5 99.790 Error@1 8.480
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 14:01:54] [Epoch=129/200] [Need: 00:25:58] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [129][000/391]   Time 0.244 (0.244)   Data 0.188 (0.188)   Loss 0.0261 (0.0261)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:01:54]
  Epoch: [129][100/391]   Time 0.042 (0.052)   Data 0.000 (0.002)   Loss 0.0147 (0.0435)   Prec@1 100.000 (98.577)   Prec@5 100.000 (99.992)   [2019-11-24 14:01:59]
  Epoch: [129][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0102 (0.0450)   Prec@1 100.000 (98.492)   Prec@5 100.000 (99.996)   [2019-11-24 14:02:04]
  Epoch: [129][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0314 (0.0445)   Prec@1 99.219 (98.508)   Prec@5 100.000 (99.995)   [2019-11-24 14:02:09]
  **Train** Prec@1 98.542 Prec@5 99.996 Error@1 1.458
  **Test** Prec@1 91.500 Prec@5 99.780 Error@1 8.500

==>>[2019-11-24 14:02:16] [Epoch=130/200] [Need: 00:25:36] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [130][000/391]   Time 0.290 (0.290)   Data 0.235 (0.235)   Loss 0.0388 (0.0388)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:02:16]
  Epoch: [130][100/391]   Time 0.083 (0.052)   Data 0.000 (0.002)   Loss 0.0228 (0.0409)   Prec@1 99.219 (98.662)   Prec@5 100.000 (99.985)   [2019-11-24 14:02:21]
  Epoch: [130][200/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0557 (0.0421)   Prec@1 98.438 (98.628)   Prec@5 100.000 (99.988)   [2019-11-24 14:02:26]
  Epoch: [130][300/391]   Time 0.058 (0.051)   Data 0.000 (0.001)   Loss 0.0248 (0.0420)   Prec@1 100.000 (98.609)   Prec@5 100.000 (99.992)   [2019-11-24 14:02:31]
  **Train** Prec@1 98.560 Prec@5 99.992 Error@1 1.440
  **Test** Prec@1 91.410 Prec@5 99.780 Error@1 8.590

==>>[2019-11-24 14:02:38] [Epoch=131/200] [Need: 00:25:14] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [131][000/391]   Time 0.277 (0.277)   Data 0.221 (0.221)   Loss 0.0207 (0.0207)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:02:38]
  Epoch: [131][100/391]   Time 0.073 (0.050)   Data 0.000 (0.002)   Loss 0.0799 (0.0416)   Prec@1 96.875 (98.577)   Prec@5 100.000 (100.000)   [2019-11-24 14:02:43]
  Epoch: [131][200/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.0669 (0.0416)   Prec@1 97.656 (98.628)   Prec@5 100.000 (99.996)   [2019-11-24 14:02:48]
  Epoch: [131][300/391]   Time 0.058 (0.050)   Data 0.000 (0.001)   Loss 0.0426 (0.0415)   Prec@1 96.875 (98.627)   Prec@5 100.000 (99.997)   [2019-11-24 14:02:53]
  **Train** Prec@1 98.624 Prec@5 99.998 Error@1 1.376
  **Test** Prec@1 91.440 Prec@5 99.740 Error@1 8.560

==>>[2019-11-24 14:02:59] [Epoch=132/200] [Need: 00:24:52] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [132][000/391]   Time 0.275 (0.275)   Data 0.214 (0.214)   Loss 0.0296 (0.0296)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:02:59]
  Epoch: [132][100/391]   Time 0.049 (0.051)   Data 0.000 (0.002)   Loss 0.0542 (0.0424)   Prec@1 98.438 (98.577)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:04]
  Epoch: [132][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0862 (0.0418)   Prec@1 97.656 (98.609)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:09]
  Epoch: [132][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0161 (0.0415)   Prec@1 100.000 (98.611)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:14]
  **Train** Prec@1 98.592 Prec@5 100.000 Error@1 1.408
  **Test** Prec@1 91.410 Prec@5 99.730 Error@1 8.590

==>>[2019-11-24 14:03:21] [Epoch=133/200] [Need: 00:24:30] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [133][000/391]   Time 0.277 (0.277)   Data 0.215 (0.215)   Loss 0.0573 (0.0573)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:21]
  Epoch: [133][100/391]   Time 0.044 (0.052)   Data 0.000 (0.002)   Loss 0.0262 (0.0388)   Prec@1 99.219 (98.724)   Prec@5 100.000 (99.992)   [2019-11-24 14:03:26]
  Epoch: [133][200/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0130 (0.0403)   Prec@1 100.000 (98.678)   Prec@5 100.000 (99.996)   [2019-11-24 14:03:31]
  Epoch: [133][300/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0640 (0.0421)   Prec@1 96.875 (98.572)   Prec@5 100.000 (99.995)   [2019-11-24 14:03:37]
  **Train** Prec@1 98.574 Prec@5 99.990 Error@1 1.426
  **Test** Prec@1 91.390 Prec@5 99.750 Error@1 8.610

==>>[2019-11-24 14:03:44] [Epoch=134/200] [Need: 00:24:08] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [134][000/391]   Time 0.281 (0.281)   Data 0.199 (0.199)   Loss 0.0382 (0.0382)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:44]
  Epoch: [134][100/391]   Time 0.052 (0.053)   Data 0.000 (0.002)   Loss 0.0484 (0.0434)   Prec@1 98.438 (98.499)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:49]
  Epoch: [134][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0328 (0.0434)   Prec@1 99.219 (98.492)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:54]
  Epoch: [134][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0636 (0.0423)   Prec@1 97.656 (98.593)   Prec@5 100.000 (100.000)   [2019-11-24 14:03:59]
  **Train** Prec@1 98.576 Prec@5 100.000 Error@1 1.424
  **Test** Prec@1 91.350 Prec@5 99.760 Error@1 8.650

==>>[2019-11-24 14:04:05] [Epoch=135/200] [Need: 00:23:46] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [135][000/391]   Time 0.270 (0.270)   Data 0.214 (0.214)   Loss 0.0221 (0.0221)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:05]
  Epoch: [135][100/391]   Time 0.052 (0.051)   Data 0.000 (0.002)   Loss 0.0438 (0.0404)   Prec@1 98.438 (98.708)   Prec@5 100.000 (99.992)   [2019-11-24 14:04:10]
  Epoch: [135][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0812 (0.0400)   Prec@1 96.875 (98.745)   Prec@5 100.000 (99.996)   [2019-11-24 14:04:15]
  Epoch: [135][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0318 (0.0399)   Prec@1 99.219 (98.687)   Prec@5 100.000 (99.997)   [2019-11-24 14:04:20]
  **Train** Prec@1 98.652 Prec@5 99.996 Error@1 1.348
  **Test** Prec@1 91.480 Prec@5 99.740 Error@1 8.520

==>>[2019-11-24 14:04:26] [Epoch=136/200] [Need: 00:23:24] [LR=0.0001][M=0.90] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [136][000/391]   Time 0.275 (0.275)   Data 0.212 (0.212)   Loss 0.0693 (0.0693)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:26]
  Epoch: [136][100/391]   Time 0.044 (0.056)   Data 0.000 (0.002)   Loss 0.0506 (0.0389)   Prec@1 97.656 (98.762)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:32]
  Epoch: [136][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0090 (0.0394)   Prec@1 100.000 (98.737)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:37]
  Epoch: [136][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0231 (0.0399)   Prec@1 99.219 (98.718)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:42]
  **Train** Prec@1 98.672 Prec@5 100.000 Error@1 1.328
  **Test** Prec@1 91.540 Prec@5 99.740 Error@1 8.460
=> Obtain best accuracy, and update the best model

==>>[2019-11-24 14:04:48] [Epoch=137/200] [Need: 00:23:02] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [137][000/391]   Time 0.282 (0.282)   Data 0.227 (0.227)   Loss 0.0510 (0.0510)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:04:48]
  Epoch: [137][100/391]   Time 0.070 (0.052)   Data 0.000 (0.002)   Loss 0.0304 (0.0441)   Prec@1 98.438 (98.476)   Prec@5 100.000 (99.992)   [2019-11-24 14:04:53]
  Epoch: [137][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0364 (0.0419)   Prec@1 99.219 (98.597)   Prec@5 100.000 (99.996)   [2019-11-24 14:04:58]
  Epoch: [137][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0616 (0.0429)   Prec@1 97.656 (98.549)   Prec@5 100.000 (99.995)   [2019-11-24 14:05:03]
  **Train** Prec@1 98.576 Prec@5 99.996 Error@1 1.424
  **Test** Prec@1 91.410 Prec@5 99.770 Error@1 8.590

==>>[2019-11-24 14:05:09] [Epoch=138/200] [Need: 00:22:40] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [138][000/391]   Time 0.283 (0.283)   Data 0.228 (0.228)   Loss 0.0484 (0.0484)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:10]
  Epoch: [138][100/391]   Time 0.083 (0.057)   Data 0.000 (0.002)   Loss 0.0591 (0.0408)   Prec@1 97.656 (98.584)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:15]
  Epoch: [138][200/391]   Time 0.045 (0.053)   Data 0.000 (0.001)   Loss 0.0309 (0.0422)   Prec@1 98.438 (98.562)   Prec@5 100.000 (99.996)   [2019-11-24 14:05:20]
  Epoch: [138][300/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0490 (0.0407)   Prec@1 98.438 (98.663)   Prec@5 100.000 (99.995)   [2019-11-24 14:05:25]
  **Train** Prec@1 98.626 Prec@5 99.996 Error@1 1.374
  **Test** Prec@1 91.390 Prec@5 99.760 Error@1 8.610

==>>[2019-11-24 14:05:31] [Epoch=139/200] [Need: 00:22:18] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [139][000/391]   Time 0.285 (0.285)   Data 0.224 (0.224)   Loss 0.0231 (0.0231)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:32]
  Epoch: [139][100/391]   Time 0.045 (0.056)   Data 0.000 (0.002)   Loss 0.0215 (0.0390)   Prec@1 98.438 (98.685)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:37]
  Epoch: [139][200/391]   Time 0.052 (0.053)   Data 0.000 (0.001)   Loss 0.0097 (0.0408)   Prec@1 100.000 (98.640)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:42]
  Epoch: [139][300/391]   Time 0.058 (0.052)   Data 0.000 (0.001)   Loss 0.0154 (0.0403)   Prec@1 100.000 (98.624)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:47]
  **Train** Prec@1 98.650 Prec@5 100.000 Error@1 1.350
  **Test** Prec@1 91.270 Prec@5 99.750 Error@1 8.730

==>>[2019-11-24 14:05:54] [Epoch=140/200] [Need: 00:21:56] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [140][000/391]   Time 0.278 (0.278)   Data 0.221 (0.221)   Loss 0.0572 (0.0572)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:54]
  Epoch: [140][100/391]   Time 0.045 (0.054)   Data 0.000 (0.002)   Loss 0.0421 (0.0380)   Prec@1 98.438 (98.762)   Prec@5 100.000 (100.000)   [2019-11-24 14:05:59]
  Epoch: [140][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0431 (0.0391)   Prec@1 98.438 (98.667)   Prec@5 100.000 (99.996)   [2019-11-24 14:06:04]
  Epoch: [140][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0186 (0.0382)   Prec@1 99.219 (98.689)   Prec@5 100.000 (99.997)   [2019-11-24 14:06:08]
  **Train** Prec@1 98.652 Prec@5 99.998 Error@1 1.348
  **Test** Prec@1 91.210 Prec@5 99.750 Error@1 8.790

==>>[2019-11-24 14:06:15] [Epoch=141/200] [Need: 00:21:34] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [141][000/391]   Time 0.272 (0.272)   Data 0.217 (0.217)   Loss 0.0505 (0.0505)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:15]
  Epoch: [141][100/391]   Time 0.061 (0.055)   Data 0.000 (0.002)   Loss 0.0796 (0.0412)   Prec@1 96.875 (98.700)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:20]
  Epoch: [141][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0280 (0.0418)   Prec@1 99.219 (98.589)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:25]
  Epoch: [141][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0271 (0.0411)   Prec@1 99.219 (98.580)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:30]
  **Train** Prec@1 98.602 Prec@5 100.000 Error@1 1.398
  **Test** Prec@1 91.330 Prec@5 99.770 Error@1 8.670

==>>[2019-11-24 14:06:37] [Epoch=142/200] [Need: 00:21:12] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [142][000/391]   Time 0.287 (0.287)   Data 0.214 (0.214)   Loss 0.0456 (0.0456)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:37]
  Epoch: [142][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0544 (0.0366)   Prec@1 97.656 (98.894)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:42]
  Epoch: [142][200/391]   Time 0.056 (0.051)   Data 0.000 (0.001)   Loss 0.0396 (0.0363)   Prec@1 97.656 (98.838)   Prec@5 100.000 (99.996)   [2019-11-24 14:06:47]
  Epoch: [142][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0905 (0.0370)   Prec@1 96.875 (98.809)   Prec@5 100.000 (99.997)   [2019-11-24 14:06:52]
  **Train** Prec@1 98.794 Prec@5 99.996 Error@1 1.206
  **Test** Prec@1 91.180 Prec@5 99.720 Error@1 8.820

==>>[2019-11-24 14:06:58] [Epoch=143/200] [Need: 00:20:50] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [143][000/391]   Time 0.276 (0.276)   Data 0.219 (0.219)   Loss 0.0446 (0.0446)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:06:58]
  Epoch: [143][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0248 (0.0390)   Prec@1 100.000 (98.739)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:03]
  Epoch: [143][200/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0693 (0.0391)   Prec@1 98.438 (98.655)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:08]
  Epoch: [143][300/391]   Time 0.042 (0.048)   Data 0.000 (0.001)   Loss 0.0370 (0.0389)   Prec@1 98.438 (98.671)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:12]
  **Train** Prec@1 98.666 Prec@5 100.000 Error@1 1.334
  **Test** Prec@1 91.290 Prec@5 99.780 Error@1 8.710

==>>[2019-11-24 14:07:19] [Epoch=144/200] [Need: 00:20:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [144][000/391]   Time 0.273 (0.273)   Data 0.213 (0.213)   Loss 0.0190 (0.0190)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:19]
  Epoch: [144][100/391]   Time 0.043 (0.052)   Data 0.000 (0.002)   Loss 0.0346 (0.0368)   Prec@1 98.438 (98.716)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:24]
  Epoch: [144][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0444 (0.0390)   Prec@1 98.438 (98.616)   Prec@5 100.000 (99.996)   [2019-11-24 14:07:29]
  Epoch: [144][300/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0139 (0.0405)   Prec@1 100.000 (98.567)   Prec@5 100.000 (99.997)   [2019-11-24 14:07:34]
  **Train** Prec@1 98.618 Prec@5 99.998 Error@1 1.382
  **Test** Prec@1 91.390 Prec@5 99.730 Error@1 8.610

==>>[2019-11-24 14:07:41] [Epoch=145/200] [Need: 00:20:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [145][000/391]   Time 0.276 (0.276)   Data 0.219 (0.219)   Loss 0.0464 (0.0464)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:07:41]
  Epoch: [145][100/391]   Time 0.065 (0.051)   Data 0.000 (0.002)   Loss 0.0520 (0.0375)   Prec@1 97.656 (98.762)   Prec@5 100.000 (99.992)   [2019-11-24 14:07:46]
  Epoch: [145][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0159 (0.0379)   Prec@1 100.000 (98.733)   Prec@5 100.000 (99.992)   [2019-11-24 14:07:51]
  Epoch: [145][300/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0158 (0.0375)   Prec@1 100.000 (98.762)   Prec@5 100.000 (99.995)   [2019-11-24 14:07:56]
  **Train** Prec@1 98.750 Prec@5 99.996 Error@1 1.250
  **Test** Prec@1 91.400 Prec@5 99.770 Error@1 8.600

==>>[2019-11-24 14:08:02] [Epoch=146/200] [Need: 00:19:43] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [146][000/391]   Time 0.268 (0.268)   Data 0.214 (0.214)   Loss 0.0226 (0.0226)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:03]
  Epoch: [146][100/391]   Time 0.040 (0.050)   Data 0.000 (0.002)   Loss 0.0105 (0.0397)   Prec@1 100.000 (98.569)   Prec@5 100.000 (99.985)   [2019-11-24 14:08:08]
  Epoch: [146][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0508 (0.0379)   Prec@1 97.656 (98.698)   Prec@5 100.000 (99.992)   [2019-11-24 14:08:12]
  Epoch: [146][300/391]   Time 0.053 (0.049)   Data 0.000 (0.001)   Loss 0.0850 (0.0381)   Prec@1 96.875 (98.715)   Prec@5 100.000 (99.990)   [2019-11-24 14:08:17]
  **Train** Prec@1 98.708 Prec@5 99.992 Error@1 1.292
  **Test** Prec@1 91.330 Prec@5 99.750 Error@1 8.670

==>>[2019-11-24 14:08:24] [Epoch=147/200] [Need: 00:19:21] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [147][000/391]   Time 0.278 (0.278)   Data 0.199 (0.199)   Loss 0.0467 (0.0467)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:24]
  Epoch: [147][100/391]   Time 0.043 (0.050)   Data 0.000 (0.002)   Loss 0.0343 (0.0372)   Prec@1 100.000 (98.793)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:29]
  Epoch: [147][200/391]   Time 0.051 (0.049)   Data 0.000 (0.001)   Loss 0.0152 (0.0368)   Prec@1 99.219 (98.799)   Prec@5 100.000 (99.996)   [2019-11-24 14:08:34]
  Epoch: [147][300/391]   Time 0.043 (0.048)   Data 0.000 (0.001)   Loss 0.0444 (0.0368)   Prec@1 98.438 (98.785)   Prec@5 100.000 (99.997)   [2019-11-24 14:08:38]
  **Train** Prec@1 98.740 Prec@5 99.996 Error@1 1.260
  **Test** Prec@1 91.430 Prec@5 99.750 Error@1 8.570

==>>[2019-11-24 14:08:44] [Epoch=148/200] [Need: 00:18:59] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [148][000/391]   Time 0.279 (0.279)   Data 0.211 (0.211)   Loss 0.0245 (0.0245)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:45]
  Epoch: [148][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.0445 (0.0395)   Prec@1 99.219 (98.639)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:50]
  Epoch: [148][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0200 (0.0394)   Prec@1 99.219 (98.624)   Prec@5 100.000 (100.000)   [2019-11-24 14:08:55]
  Epoch: [148][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0333 (0.0390)   Prec@1 99.219 (98.661)   Prec@5 100.000 (99.997)   [2019-11-24 14:09:00]
  **Train** Prec@1 98.688 Prec@5 99.998 Error@1 1.312
  **Test** Prec@1 91.340 Prec@5 99.750 Error@1 8.660

==>>[2019-11-24 14:09:06] [Epoch=149/200] [Need: 00:18:37] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [149][000/391]   Time 0.279 (0.279)   Data 0.210 (0.210)   Loss 0.0235 (0.0235)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:07]
  Epoch: [149][100/391]   Time 0.064 (0.052)   Data 0.000 (0.002)   Loss 0.0258 (0.0348)   Prec@1 99.219 (98.956)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:12]
  Epoch: [149][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0179 (0.0361)   Prec@1 100.000 (98.830)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:16]
  Epoch: [149][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0411 (0.0376)   Prec@1 99.219 (98.778)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:21]
  **Train** Prec@1 98.778 Prec@5 100.000 Error@1 1.222
  **Test** Prec@1 91.240 Prec@5 99.770 Error@1 8.760

==>>[2019-11-24 14:09:28] [Epoch=150/200] [Need: 00:18:15] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [150][000/391]   Time 0.288 (0.288)   Data 0.201 (0.201)   Loss 0.0177 (0.0177)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:28]
  Epoch: [150][100/391]   Time 0.054 (0.053)   Data 0.000 (0.002)   Loss 0.0468 (0.0372)   Prec@1 98.438 (98.639)   Prec@5 100.000 (99.992)   [2019-11-24 14:09:33]
  Epoch: [150][200/391]   Time 0.054 (0.052)   Data 0.000 (0.001)   Loss 0.0279 (0.0381)   Prec@1 98.438 (98.690)   Prec@5 100.000 (99.992)   [2019-11-24 14:09:38]
  Epoch: [150][300/391]   Time 0.080 (0.051)   Data 0.000 (0.001)   Loss 0.0531 (0.0381)   Prec@1 99.219 (98.710)   Prec@5 100.000 (99.992)   [2019-11-24 14:09:43]
  **Train** Prec@1 98.718 Prec@5 99.994 Error@1 1.282
  **Test** Prec@1 91.270 Prec@5 99.760 Error@1 8.730

==>>[2019-11-24 14:09:50] [Epoch=151/200] [Need: 00:17:53] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [151][000/391]   Time 0.276 (0.276)   Data 0.199 (0.199)   Loss 0.0454 (0.0454)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:50]
  Epoch: [151][100/391]   Time 0.046 (0.053)   Data 0.000 (0.002)   Loss 0.0406 (0.0365)   Prec@1 99.219 (98.801)   Prec@5 100.000 (100.000)   [2019-11-24 14:09:55]
  Epoch: [151][200/391]   Time 0.042 (0.052)   Data 0.000 (0.001)   Loss 0.0322 (0.0365)   Prec@1 98.438 (98.752)   Prec@5 100.000 (99.996)   [2019-11-24 14:10:00]
  Epoch: [151][300/391]   Time 0.046 (0.051)   Data 0.000 (0.001)   Loss 0.0206 (0.0375)   Prec@1 100.000 (98.749)   Prec@5 100.000 (99.997)   [2019-11-24 14:10:05]
  **Train** Prec@1 98.708 Prec@5 99.998 Error@1 1.292
  **Test** Prec@1 91.370 Prec@5 99.770 Error@1 8.630

==>>[2019-11-24 14:10:12] [Epoch=152/200] [Need: 00:17:31] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [152][000/391]   Time 0.263 (0.263)   Data 0.198 (0.198)   Loss 0.0492 (0.0492)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:12]
  Epoch: [152][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.0688 (0.0391)   Prec@1 98.438 (98.662)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:17]
  Epoch: [152][200/391]   Time 0.046 (0.050)   Data 0.000 (0.001)   Loss 0.0521 (0.0373)   Prec@1 97.656 (98.748)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:22]
  Epoch: [152][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0280 (0.0371)   Prec@1 99.219 (98.780)   Prec@5 100.000 (99.995)   [2019-11-24 14:10:27]
  **Train** Prec@1 98.788 Prec@5 99.996 Error@1 1.212
  **Test** Prec@1 91.410 Prec@5 99.760 Error@1 8.590

==>>[2019-11-24 14:10:34] [Epoch=153/200] [Need: 00:17:09] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [153][000/391]   Time 0.268 (0.268)   Data 0.203 (0.203)   Loss 0.0564 (0.0564)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:34]
  Epoch: [153][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.0180 (0.0354)   Prec@1 99.219 (98.755)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:39]
  Epoch: [153][200/391]   Time 0.066 (0.052)   Data 0.000 (0.001)   Loss 0.0240 (0.0364)   Prec@1 99.219 (98.772)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:44]
  Epoch: [153][300/391]   Time 0.081 (0.050)   Data 0.000 (0.001)   Loss 0.0359 (0.0368)   Prec@1 98.438 (98.757)   Prec@5 100.000 (99.997)   [2019-11-24 14:10:49]
  **Train** Prec@1 98.776 Prec@5 99.998 Error@1 1.224
  **Test** Prec@1 91.300 Prec@5 99.780 Error@1 8.700

==>>[2019-11-24 14:10:55] [Epoch=154/200] [Need: 00:16:47] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [154][000/391]   Time 0.278 (0.278)   Data 0.199 (0.199)   Loss 0.0252 (0.0252)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:10:55]
  Epoch: [154][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0473 (0.0360)   Prec@1 98.438 (98.809)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:00]
  Epoch: [154][200/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0206 (0.0372)   Prec@1 100.000 (98.733)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:05]
  Epoch: [154][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0336 (0.0372)   Prec@1 99.219 (98.744)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:10]
  **Train** Prec@1 98.714 Prec@5 99.996 Error@1 1.286
  **Test** Prec@1 91.300 Prec@5 99.760 Error@1 8.700

==>>[2019-11-24 14:11:17] [Epoch=155/200] [Need: 00:16:25] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [155][000/391]   Time 0.285 (0.285)   Data 0.206 (0.206)   Loss 0.0486 (0.0486)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:17]
  Epoch: [155][100/391]   Time 0.048 (0.053)   Data 0.000 (0.002)   Loss 0.0386 (0.0367)   Prec@1 99.219 (98.755)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:22]
  Epoch: [155][200/391]   Time 0.059 (0.052)   Data 0.000 (0.001)   Loss 0.0515 (0.0361)   Prec@1 99.219 (98.811)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:27]
  Epoch: [155][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0453 (0.0367)   Prec@1 98.438 (98.762)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:32]
  **Train** Prec@1 98.786 Prec@5 100.000 Error@1 1.214
  **Test** Prec@1 91.280 Prec@5 99.750 Error@1 8.720

==>>[2019-11-24 14:11:39] [Epoch=156/200] [Need: 00:16:03] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [156][000/391]   Time 0.274 (0.274)   Data 0.204 (0.204)   Loss 0.0529 (0.0529)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:39]
  Epoch: [156][100/391]   Time 0.060 (0.054)   Data 0.000 (0.002)   Loss 0.0385 (0.0336)   Prec@1 99.219 (98.956)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:44]
  Epoch: [156][200/391]   Time 0.042 (0.051)   Data 0.000 (0.001)   Loss 0.0678 (0.0331)   Prec@1 97.656 (98.970)   Prec@5 100.000 (100.000)   [2019-11-24 14:11:49]
  Epoch: [156][300/391]   Time 0.082 (0.051)   Data 0.000 (0.001)   Loss 0.0641 (0.0336)   Prec@1 98.438 (98.951)   Prec@5 100.000 (99.997)   [2019-11-24 14:11:54]
  **Train** Prec@1 98.920 Prec@5 99.998 Error@1 1.080
  **Test** Prec@1 91.330 Prec@5 99.750 Error@1 8.670

==>>[2019-11-24 14:12:01] [Epoch=157/200] [Need: 00:15:41] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [157][000/391]   Time 0.271 (0.271)   Data 0.209 (0.209)   Loss 0.0259 (0.0259)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:01]
  Epoch: [157][100/391]   Time 0.046 (0.054)   Data 0.000 (0.002)   Loss 0.0464 (0.0397)   Prec@1 98.438 (98.654)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:06]
  Epoch: [157][200/391]   Time 0.044 (0.053)   Data 0.000 (0.001)   Loss 0.0232 (0.0394)   Prec@1 99.219 (98.640)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:11]
  Epoch: [157][300/391]   Time 0.050 (0.052)   Data 0.000 (0.001)   Loss 0.0316 (0.0375)   Prec@1 99.219 (98.700)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:16]
  **Train** Prec@1 98.726 Prec@5 99.998 Error@1 1.274
  **Test** Prec@1 91.240 Prec@5 99.730 Error@1 8.760

==>>[2019-11-24 14:12:23] [Epoch=158/200] [Need: 00:15:20] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [158][000/391]   Time 0.261 (0.261)   Data 0.203 (0.203)   Loss 0.0679 (0.0679)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:23]
  Epoch: [158][100/391]   Time 0.056 (0.051)   Data 0.000 (0.002)   Loss 0.0507 (0.0370)   Prec@1 98.438 (98.731)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:28]
  Epoch: [158][200/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0189 (0.0359)   Prec@1 100.000 (98.795)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:33]
  Epoch: [158][300/391]   Time 0.051 (0.049)   Data 0.000 (0.001)   Loss 0.0401 (0.0366)   Prec@1 98.438 (98.759)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:38]
  **Train** Prec@1 98.762 Prec@5 99.998 Error@1 1.238
  **Test** Prec@1 91.260 Prec@5 99.760 Error@1 8.740

==>>[2019-11-24 14:12:44] [Epoch=159/200] [Need: 00:14:57] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [159][000/391]   Time 0.270 (0.270)   Data 0.220 (0.220)   Loss 0.0208 (0.0208)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:45]
  Epoch: [159][100/391]   Time 0.058 (0.052)   Data 0.000 (0.002)   Loss 0.0282 (0.0318)   Prec@1 99.219 (98.963)   Prec@5 100.000 (100.000)   [2019-11-24 14:12:50]
  Epoch: [159][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0378 (0.0336)   Prec@1 97.656 (98.912)   Prec@5 100.000 (99.996)   [2019-11-24 14:12:55]
  Epoch: [159][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0160 (0.0345)   Prec@1 100.000 (98.871)   Prec@5 100.000 (99.997)   [2019-11-24 14:13:00]
  **Train** Prec@1 98.846 Prec@5 99.996 Error@1 1.154
  **Test** Prec@1 91.410 Prec@5 99.750 Error@1 8.590

==>>[2019-11-24 14:13:06] [Epoch=160/200] [Need: 00:14:36] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [160][000/391]   Time 0.274 (0.274)   Data 0.201 (0.201)   Loss 0.0193 (0.0193)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:13:07]
  Epoch: [160][100/391]   Time 0.043 (0.053)   Data 0.000 (0.002)   Loss 0.0139 (0.0341)   Prec@1 100.000 (98.863)   Prec@5 100.000 (99.992)   [2019-11-24 14:13:12]
  Epoch: [160][200/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0242 (0.0347)   Prec@1 99.219 (98.780)   Prec@5 100.000 (99.996)   [2019-11-24 14:13:16]
  Epoch: [160][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0206 (0.0335)   Prec@1 100.000 (98.840)   Prec@5 100.000 (99.997)   [2019-11-24 14:13:21]
  **Train** Prec@1 98.814 Prec@5 99.998 Error@1 1.186
  **Test** Prec@1 91.180 Prec@5 99.730 Error@1 8.820

==>>[2019-11-24 14:13:28] [Epoch=161/200] [Need: 00:14:14] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [161][000/391]   Time 0.293 (0.293)   Data 0.234 (0.234)   Loss 0.0693 (0.0693)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-11-24 14:13:28]
  Epoch: [161][100/391]   Time 0.042 (0.050)   Data 0.000 (0.002)   Loss 0.0272 (0.0373)   Prec@1 99.219 (98.700)   Prec@5 100.000 (99.992)   [2019-11-24 14:13:33]
  Epoch: [161][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0173 (0.0365)   Prec@1 99.219 (98.772)   Prec@5 100.000 (99.996)   [2019-11-24 14:13:38]
  Epoch: [161][300/391]   Time 0.060 (0.050)   Data 0.000 (0.001)   Loss 0.0226 (0.0362)   Prec@1 99.219 (98.775)   Prec@5 100.000 (99.992)   [2019-11-24 14:13:43]
  **Train** Prec@1 98.770 Prec@5 99.994 Error@1 1.230
  **Test** Prec@1 91.170 Prec@5 99.770 Error@1 8.830

==>>[2019-11-24 14:13:49] [Epoch=162/200] [Need: 00:13:52] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [162][000/391]   Time 0.288 (0.288)   Data 0.208 (0.208)   Loss 0.0222 (0.0222)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:13:49]
  Epoch: [162][100/391]   Time 0.054 (0.051)   Data 0.000 (0.002)   Loss 0.0269 (0.0354)   Prec@1 99.219 (98.847)   Prec@5 100.000 (100.000)   [2019-11-24 14:13:54]
  Epoch: [162][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0260 (0.0339)   Prec@1 99.219 (98.892)   Prec@5 100.000 (100.000)   [2019-11-24 14:13:59]
  Epoch: [162][300/391]   Time 0.041 (0.049)   Data 0.000 (0.001)   Loss 0.0056 (0.0336)   Prec@1 100.000 (98.918)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:04]
  **Train** Prec@1 98.932 Prec@5 100.000 Error@1 1.068
  **Test** Prec@1 91.290 Prec@5 99.740 Error@1 8.710

==>>[2019-11-24 14:14:10] [Epoch=163/200] [Need: 00:13:29] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [163][000/391]   Time 0.300 (0.300)   Data 0.236 (0.236)   Loss 0.0416 (0.0416)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:10]
  Epoch: [163][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0178 (0.0354)   Prec@1 100.000 (98.700)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:15]
  Epoch: [163][200/391]   Time 0.071 (0.052)   Data 0.000 (0.001)   Loss 0.0336 (0.0356)   Prec@1 98.438 (98.737)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:20]
  Epoch: [163][300/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0355 (0.0355)   Prec@1 99.219 (98.770)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:25]
  **Train** Prec@1 98.752 Prec@5 100.000 Error@1 1.248
  **Test** Prec@1 91.350 Prec@5 99.740 Error@1 8.650

==>>[2019-11-24 14:14:32] [Epoch=164/200] [Need: 00:13:08] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [164][000/391]   Time 0.259 (0.259)   Data 0.207 (0.207)   Loss 0.0226 (0.0226)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:32]
  Epoch: [164][100/391]   Time 0.081 (0.054)   Data 0.000 (0.002)   Loss 0.0246 (0.0348)   Prec@1 98.438 (98.786)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:38]
  Epoch: [164][200/391]   Time 0.043 (0.052)   Data 0.000 (0.001)   Loss 0.0419 (0.0349)   Prec@1 99.219 (98.815)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:43]
  Epoch: [164][300/391]   Time 0.064 (0.051)   Data 0.000 (0.001)   Loss 0.0226 (0.0346)   Prec@1 100.000 (98.850)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:47]
  **Train** Prec@1 98.868 Prec@5 100.000 Error@1 1.132
  **Test** Prec@1 91.330 Prec@5 99.730 Error@1 8.670

==>>[2019-11-24 14:14:54] [Epoch=165/200] [Need: 00:12:46] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [165][000/391]   Time 0.264 (0.264)   Data 0.192 (0.192)   Loss 0.0563 (0.0563)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:54]
  Epoch: [165][100/391]   Time 0.045 (0.058)   Data 0.000 (0.002)   Loss 0.0979 (0.0362)   Prec@1 96.094 (98.739)   Prec@5 100.000 (100.000)   [2019-11-24 14:14:59]
  Epoch: [165][200/391]   Time 0.042 (0.053)   Data 0.000 (0.001)   Loss 0.0287 (0.0344)   Prec@1 99.219 (98.830)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:04]
  Epoch: [165][300/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0464 (0.0340)   Prec@1 97.656 (98.887)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:09]
  **Train** Prec@1 98.892 Prec@5 100.000 Error@1 1.108
  **Test** Prec@1 91.450 Prec@5 99.710 Error@1 8.550

==>>[2019-11-24 14:15:16] [Epoch=166/200] [Need: 00:12:24] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [166][000/391]   Time 0.274 (0.274)   Data 0.215 (0.215)   Loss 0.0166 (0.0166)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:16]
  Epoch: [166][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0114 (0.0319)   Prec@1 100.000 (99.087)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:21]
  Epoch: [166][200/391]   Time 0.052 (0.051)   Data 0.000 (0.001)   Loss 0.0147 (0.0315)   Prec@1 100.000 (99.067)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:26]
  Epoch: [166][300/391]   Time 0.053 (0.051)   Data 0.000 (0.001)   Loss 0.0048 (0.0337)   Prec@1 100.000 (98.923)   Prec@5 100.000 (99.995)   [2019-11-24 14:15:31]
  **Train** Prec@1 98.934 Prec@5 99.996 Error@1 1.066
  **Test** Prec@1 91.300 Prec@5 99.720 Error@1 8.700

==>>[2019-11-24 14:15:37] [Epoch=167/200] [Need: 00:12:02] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [167][000/391]   Time 0.273 (0.273)   Data 0.213 (0.213)   Loss 0.0160 (0.0160)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:37]
  Epoch: [167][100/391]   Time 0.049 (0.053)   Data 0.000 (0.002)   Loss 0.0499 (0.0359)   Prec@1 98.438 (98.793)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:43]
  Epoch: [167][200/391]   Time 0.065 (0.052)   Data 0.000 (0.001)   Loss 0.0549 (0.0346)   Prec@1 98.438 (98.834)   Prec@5 100.000 (99.996)   [2019-11-24 14:15:48]
  Epoch: [167][300/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.0452 (0.0341)   Prec@1 98.438 (98.858)   Prec@5 100.000 (99.997)   [2019-11-24 14:15:52]
  **Train** Prec@1 98.846 Prec@5 99.996 Error@1 1.154
  **Test** Prec@1 91.350 Prec@5 99.730 Error@1 8.650

==>>[2019-11-24 14:15:59] [Epoch=168/200] [Need: 00:11:40] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [168][000/391]   Time 0.271 (0.271)   Data 0.205 (0.205)   Loss 0.0163 (0.0163)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:15:59]
  Epoch: [168][100/391]   Time 0.042 (0.054)   Data 0.000 (0.002)   Loss 0.0532 (0.0322)   Prec@1 97.656 (98.987)   Prec@5 100.000 (99.992)   [2019-11-24 14:16:04]
  Epoch: [168][200/391]   Time 0.041 (0.052)   Data 0.000 (0.001)   Loss 0.0230 (0.0329)   Prec@1 99.219 (98.974)   Prec@5 100.000 (99.992)   [2019-11-24 14:16:09]
  Epoch: [168][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0161 (0.0332)   Prec@1 100.000 (98.954)   Prec@5 100.000 (99.995)   [2019-11-24 14:16:14]
  **Train** Prec@1 98.950 Prec@5 99.996 Error@1 1.050
  **Test** Prec@1 91.420 Prec@5 99.750 Error@1 8.580

==>>[2019-11-24 14:16:20] [Epoch=169/200] [Need: 00:11:18] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [169][000/391]   Time 0.278 (0.278)   Data 0.203 (0.203)   Loss 0.0240 (0.0240)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:16:20]
  Epoch: [169][100/391]   Time 0.069 (0.053)   Data 0.000 (0.002)   Loss 0.0091 (0.0328)   Prec@1 100.000 (98.855)   Prec@5 100.000 (100.000)   [2019-11-24 14:16:26]
  Epoch: [169][200/391]   Time 0.047 (0.051)   Data 0.000 (0.001)   Loss 0.0612 (0.0328)   Prec@1 97.656 (98.877)   Prec@5 100.000 (100.000)   [2019-11-24 14:16:31]
  Epoch: [169][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0128 (0.0345)   Prec@1 100.000 (98.798)   Prec@5 100.000 (100.000)   [2019-11-24 14:16:35]
  **Train** Prec@1 98.816 Prec@5 100.000 Error@1 1.184
  **Test** Prec@1 91.400 Prec@5 99.780 Error@1 8.600

==>>[2019-11-24 14:16:42] [Epoch=170/200] [Need: 00:10:56] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [170][000/391]   Time 0.287 (0.287)   Data 0.218 (0.218)   Loss 0.0523 (0.0523)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:16:42]
  Epoch: [170][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.0502 (0.0316)   Prec@1 98.438 (98.971)   Prec@5 100.000 (99.992)   [2019-11-24 14:16:47]
  Epoch: [170][200/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0370 (0.0330)   Prec@1 99.219 (98.978)   Prec@5 100.000 (99.996)   [2019-11-24 14:16:51]
  Epoch: [170][300/391]   Time 0.075 (0.049)   Data 0.000 (0.001)   Loss 0.0508 (0.0329)   Prec@1 98.438 (98.944)   Prec@5 100.000 (99.997)   [2019-11-24 14:16:56]
  **Train** Prec@1 98.930 Prec@5 99.998 Error@1 1.070
  **Test** Prec@1 91.390 Prec@5 99.730 Error@1 8.610

==>>[2019-11-24 14:17:03] [Epoch=171/200] [Need: 00:10:34] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [171][000/391]   Time 0.280 (0.280)   Data 0.203 (0.203)   Loss 0.0438 (0.0438)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:03]
  Epoch: [171][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.0311 (0.0368)   Prec@1 99.219 (98.739)   Prec@5 100.000 (99.992)   [2019-11-24 14:17:08]
  Epoch: [171][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0370 (0.0347)   Prec@1 98.438 (98.846)   Prec@5 100.000 (99.996)   [2019-11-24 14:17:13]
  Epoch: [171][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0517 (0.0332)   Prec@1 99.219 (98.912)   Prec@5 100.000 (99.997)   [2019-11-24 14:17:19]
  **Train** Prec@1 98.896 Prec@5 99.996 Error@1 1.104
  **Test** Prec@1 91.220 Prec@5 99.750 Error@1 8.780

==>>[2019-11-24 14:17:25] [Epoch=172/200] [Need: 00:10:12] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [172][000/391]   Time 0.287 (0.287)   Data 0.232 (0.232)   Loss 0.0187 (0.0187)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:25]
  Epoch: [172][100/391]   Time 0.080 (0.051)   Data 0.000 (0.002)   Loss 0.0089 (0.0334)   Prec@1 100.000 (98.894)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:30]
  Epoch: [172][200/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0256 (0.0331)   Prec@1 100.000 (98.900)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:35]
  Epoch: [172][300/391]   Time 0.076 (0.051)   Data 0.000 (0.001)   Loss 0.0167 (0.0321)   Prec@1 100.000 (98.941)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:40]
  **Train** Prec@1 98.944 Prec@5 99.994 Error@1 1.056
  **Test** Prec@1 91.260 Prec@5 99.740 Error@1 8.740

==>>[2019-11-24 14:17:46] [Epoch=173/200] [Need: 00:09:50] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [173][000/391]   Time 0.272 (0.272)   Data 0.201 (0.201)   Loss 0.0268 (0.0268)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:17:47]
  Epoch: [173][100/391]   Time 0.051 (0.051)   Data 0.000 (0.002)   Loss 0.0158 (0.0319)   Prec@1 100.000 (98.940)   Prec@5 100.000 (99.992)   [2019-11-24 14:17:51]
  Epoch: [173][200/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.0222 (0.0325)   Prec@1 99.219 (98.951)   Prec@5 100.000 (99.996)   [2019-11-24 14:17:56]
  Epoch: [173][300/391]   Time 0.043 (0.049)   Data 0.000 (0.001)   Loss 0.0158 (0.0333)   Prec@1 100.000 (98.925)   Prec@5 100.000 (99.997)   [2019-11-24 14:18:01]
  **Train** Prec@1 98.924 Prec@5 99.998 Error@1 1.076
  **Test** Prec@1 91.430 Prec@5 99.740 Error@1 8.570

==>>[2019-11-24 14:18:07] [Epoch=174/200] [Need: 00:09:28] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [174][000/391]   Time 0.292 (0.292)   Data 0.229 (0.229)   Loss 0.0551 (0.0551)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:18:07]
  Epoch: [174][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0159 (0.0304)   Prec@1 100.000 (99.072)   Prec@5 100.000 (100.000)   [2019-11-24 14:18:12]
  Epoch: [174][200/391]   Time 0.040 (0.049)   Data 0.000 (0.001)   Loss 0.0374 (0.0341)   Prec@1 98.438 (98.861)   Prec@5 100.000 (100.000)   [2019-11-24 14:18:17]
  Epoch: [174][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0060 (0.0335)   Prec@1 100.000 (98.894)   Prec@5 100.000 (99.997)   [2019-11-24 14:18:22]
  **Train** Prec@1 98.890 Prec@5 99.998 Error@1 1.110
  **Test** Prec@1 91.310 Prec@5 99.740 Error@1 8.690

==>>[2019-11-24 14:18:28] [Epoch=175/200] [Need: 00:09:06] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [175][000/391]   Time 0.286 (0.286)   Data 0.223 (0.223)   Loss 0.0276 (0.0276)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:18:29]
  Epoch: [175][100/391]   Time 0.043 (0.057)   Data 0.000 (0.002)   Loss 0.0073 (0.0340)   Prec@1 100.000 (98.917)   Prec@5 100.000 (99.992)   [2019-11-24 14:18:34]
  Epoch: [175][200/391]   Time 0.053 (0.054)   Data 0.000 (0.001)   Loss 0.0163 (0.0344)   Prec@1 100.000 (98.896)   Prec@5 100.000 (99.996)   [2019-11-24 14:18:39]
  Epoch: [175][300/391]   Time 0.046 (0.053)   Data 0.000 (0.001)   Loss 0.0318 (0.0340)   Prec@1 98.438 (98.889)   Prec@5 100.000 (99.997)   [2019-11-24 14:18:44]
  **Train** Prec@1 98.870 Prec@5 99.998 Error@1 1.130
  **Test** Prec@1 91.400 Prec@5 99.750 Error@1 8.600

==>>[2019-11-24 14:18:51] [Epoch=176/200] [Need: 00:08:44] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [176][000/391]   Time 0.292 (0.292)   Data 0.230 (0.230)   Loss 0.0800 (0.0800)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-11-24 14:18:51]
  Epoch: [176][100/391]   Time 0.045 (0.053)   Data 0.000 (0.002)   Loss 0.0292 (0.0305)   Prec@1 99.219 (99.041)   Prec@5 100.000 (99.985)   [2019-11-24 14:18:56]
  Epoch: [176][200/391]   Time 0.065 (0.051)   Data 0.000 (0.001)   Loss 0.0281 (0.0315)   Prec@1 99.219 (99.017)   Prec@5 100.000 (99.992)   [2019-11-24 14:19:01]
  Epoch: [176][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0144 (0.0329)   Prec@1 100.000 (98.923)   Prec@5 100.000 (99.995)   [2019-11-24 14:19:06]
  **Train** Prec@1 98.892 Prec@5 99.996 Error@1 1.108
  **Test** Prec@1 91.320 Prec@5 99.740 Error@1 8.680

==>>[2019-11-24 14:19:12] [Epoch=177/200] [Need: 00:08:22] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [177][000/391]   Time 0.271 (0.271)   Data 0.199 (0.199)   Loss 0.0312 (0.0312)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:13]
  Epoch: [177][100/391]   Time 0.052 (0.054)   Data 0.000 (0.002)   Loss 0.0283 (0.0326)   Prec@1 99.219 (98.933)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:18]
  Epoch: [177][200/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0493 (0.0336)   Prec@1 97.656 (98.881)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:23]
  Epoch: [177][300/391]   Time 0.081 (0.052)   Data 0.000 (0.001)   Loss 0.0137 (0.0326)   Prec@1 99.219 (98.928)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:28]
  **Train** Prec@1 98.912 Prec@5 99.998 Error@1 1.088
  **Test** Prec@1 91.290 Prec@5 99.760 Error@1 8.710

==>>[2019-11-24 14:19:35] [Epoch=178/200] [Need: 00:08:01] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [178][000/391]   Time 0.270 (0.270)   Data 0.216 (0.216)   Loss 0.0190 (0.0190)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:35]
  Epoch: [178][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0371 (0.0357)   Prec@1 98.438 (98.693)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:40]
  Epoch: [178][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0147 (0.0324)   Prec@1 100.000 (98.881)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:45]
  Epoch: [178][300/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0186 (0.0327)   Prec@1 100.000 (98.868)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:50]
  **Train** Prec@1 98.852 Prec@5 100.000 Error@1 1.148
  **Test** Prec@1 91.290 Prec@5 99.750 Error@1 8.710

==>>[2019-11-24 14:19:56] [Epoch=179/200] [Need: 00:07:39] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [179][000/391]   Time 0.278 (0.278)   Data 0.220 (0.220)   Loss 0.0388 (0.0388)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:19:56]
  Epoch: [179][100/391]   Time 0.044 (0.054)   Data 0.000 (0.002)   Loss 0.0237 (0.0346)   Prec@1 99.219 (98.902)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:02]
  Epoch: [179][200/391]   Time 0.051 (0.050)   Data 0.000 (0.001)   Loss 0.0262 (0.0331)   Prec@1 99.219 (98.916)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:06]
  Epoch: [179][300/391]   Time 0.041 (0.050)   Data 0.000 (0.001)   Loss 0.0305 (0.0335)   Prec@1 99.219 (98.879)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:11]
  **Train** Prec@1 98.924 Prec@5 100.000 Error@1 1.076
  **Test** Prec@1 91.190 Prec@5 99.730 Error@1 8.810

==>>[2019-11-24 14:20:17] [Epoch=180/200] [Need: 00:07:17] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [180][000/391]   Time 0.279 (0.279)   Data 0.209 (0.209)   Loss 0.0401 (0.0401)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:17]
  Epoch: [180][100/391]   Time 0.040 (0.052)   Data 0.000 (0.002)   Loss 0.0107 (0.0323)   Prec@1 100.000 (98.971)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:22]
  Epoch: [180][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0334 (0.0329)   Prec@1 99.219 (98.958)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:27]
  Epoch: [180][300/391]   Time 0.050 (0.051)   Data 0.000 (0.001)   Loss 0.0107 (0.0339)   Prec@1 100.000 (98.855)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:32]
  **Train** Prec@1 98.886 Prec@5 100.000 Error@1 1.114
  **Test** Prec@1 91.180 Prec@5 99.720 Error@1 8.820

==>>[2019-11-24 14:20:39] [Epoch=181/200] [Need: 00:06:55] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [181][000/391]   Time 0.265 (0.265)   Data 0.205 (0.205)   Loss 0.0313 (0.0313)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:39]
  Epoch: [181][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0167 (0.0308)   Prec@1 99.219 (98.956)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:44]
  Epoch: [181][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0150 (0.0302)   Prec@1 99.219 (98.997)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:49]
  Epoch: [181][300/391]   Time 0.047 (0.050)   Data 0.000 (0.001)   Loss 0.0249 (0.0313)   Prec@1 100.000 (98.967)   Prec@5 100.000 (100.000)   [2019-11-24 14:20:54]
  **Train** Prec@1 98.982 Prec@5 100.000 Error@1 1.018
  **Test** Prec@1 91.320 Prec@5 99.730 Error@1 8.680

==>>[2019-11-24 14:21:00] [Epoch=182/200] [Need: 00:06:33] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [182][000/391]   Time 0.275 (0.275)   Data 0.218 (0.218)   Loss 0.0557 (0.0557)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:01]
  Epoch: [182][100/391]   Time 0.042 (0.051)   Data 0.000 (0.002)   Loss 0.0156 (0.0321)   Prec@1 100.000 (98.925)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:06]
  Epoch: [182][200/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0457 (0.0331)   Prec@1 98.438 (98.919)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:10]
  Epoch: [182][300/391]   Time 0.042 (0.049)   Data 0.000 (0.001)   Loss 0.0249 (0.0322)   Prec@1 99.219 (98.944)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:15]
  **Train** Prec@1 98.886 Prec@5 99.998 Error@1 1.114
  **Test** Prec@1 91.260 Prec@5 99.710 Error@1 8.740

==>>[2019-11-24 14:21:22] [Epoch=183/200] [Need: 00:06:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [183][000/391]   Time 0.269 (0.269)   Data 0.218 (0.218)   Loss 0.0176 (0.0176)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:22]
  Epoch: [183][100/391]   Time 0.050 (0.053)   Data 0.000 (0.002)   Loss 0.0450 (0.0317)   Prec@1 98.438 (98.933)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:27]
  Epoch: [183][200/391]   Time 0.045 (0.052)   Data 0.000 (0.001)   Loss 0.0508 (0.0334)   Prec@1 97.656 (98.857)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:32]
  Epoch: [183][300/391]   Time 0.043 (0.051)   Data 0.000 (0.001)   Loss 0.0482 (0.0336)   Prec@1 98.438 (98.829)   Prec@5 100.000 (99.997)   [2019-11-24 14:21:37]
  **Train** Prec@1 98.874 Prec@5 99.998 Error@1 1.126
  **Test** Prec@1 91.340 Prec@5 99.750 Error@1 8.660

==>>[2019-11-24 14:21:43] [Epoch=184/200] [Need: 00:05:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [184][000/391]   Time 0.271 (0.271)   Data 0.201 (0.201)   Loss 0.0520 (0.0520)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:44]
  Epoch: [184][100/391]   Time 0.043 (0.054)   Data 0.000 (0.002)   Loss 0.0718 (0.0333)   Prec@1 97.656 (98.886)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:49]
  Epoch: [184][200/391]   Time 0.085 (0.052)   Data 0.000 (0.001)   Loss 0.0299 (0.0324)   Prec@1 99.219 (98.927)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:54]
  Epoch: [184][300/391]   Time 0.044 (0.051)   Data 0.000 (0.001)   Loss 0.0450 (0.0325)   Prec@1 97.656 (98.907)   Prec@5 100.000 (100.000)   [2019-11-24 14:21:59]
  **Train** Prec@1 98.928 Prec@5 100.000 Error@1 1.072
  **Test** Prec@1 91.240 Prec@5 99.750 Error@1 8.760

==>>[2019-11-24 14:22:05] [Epoch=185/200] [Need: 00:05:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [185][000/391]   Time 0.287 (0.287)   Data 0.226 (0.226)   Loss 0.0358 (0.0358)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:05]
  Epoch: [185][100/391]   Time 0.042 (0.053)   Data 0.000 (0.002)   Loss 0.0307 (0.0308)   Prec@1 99.219 (98.979)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:10]
  Epoch: [185][200/391]   Time 0.054 (0.051)   Data 0.000 (0.001)   Loss 0.0328 (0.0329)   Prec@1 99.219 (98.927)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:15]
  Epoch: [185][300/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0447 (0.0322)   Prec@1 98.438 (98.941)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:20]
  **Train** Prec@1 98.948 Prec@5 100.000 Error@1 1.052
  **Test** Prec@1 91.260 Prec@5 99.720 Error@1 8.740

==>>[2019-11-24 14:22:26] [Epoch=186/200] [Need: 00:05:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [186][000/391]   Time 0.271 (0.271)   Data 0.217 (0.217)   Loss 0.0173 (0.0173)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:26]
  Epoch: [186][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0164 (0.0294)   Prec@1 100.000 (99.103)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:31]
  Epoch: [186][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0202 (0.0327)   Prec@1 99.219 (98.927)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:37]
  Epoch: [186][300/391]   Time 0.051 (0.052)   Data 0.000 (0.001)   Loss 0.0224 (0.0320)   Prec@1 100.000 (98.957)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:42]
  **Train** Prec@1 98.976 Prec@5 100.000 Error@1 1.024
  **Test** Prec@1 91.310 Prec@5 99.740 Error@1 8.690

==>>[2019-11-24 14:22:49] [Epoch=187/200] [Need: 00:04:44] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [187][000/391]   Time 0.270 (0.270)   Data 0.203 (0.203)   Loss 0.0517 (0.0517)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:49]
  Epoch: [187][100/391]   Time 0.042 (0.055)   Data 0.000 (0.002)   Loss 0.0490 (0.0303)   Prec@1 99.219 (99.056)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:54]
  Epoch: [187][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0680 (0.0328)   Prec@1 98.438 (98.989)   Prec@5 100.000 (100.000)   [2019-11-24 14:22:59]
  Epoch: [187][300/391]   Time 0.051 (0.053)   Data 0.000 (0.001)   Loss 0.0148 (0.0320)   Prec@1 99.219 (99.006)   Prec@5 100.000 (99.997)   [2019-11-24 14:23:05]
  **Train** Prec@1 98.970 Prec@5 99.998 Error@1 1.030
  **Test** Prec@1 91.360 Prec@5 99.750 Error@1 8.640

==>>[2019-11-24 14:23:12] [Epoch=188/200] [Need: 00:04:22] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [188][000/391]   Time 0.288 (0.288)   Data 0.212 (0.212)   Loss 0.0391 (0.0391)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:12]
  Epoch: [188][100/391]   Time 0.046 (0.051)   Data 0.000 (0.002)   Loss 0.0455 (0.0337)   Prec@1 97.656 (98.832)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:17]
  Epoch: [188][200/391]   Time 0.045 (0.049)   Data 0.000 (0.001)   Loss 0.0263 (0.0330)   Prec@1 98.438 (98.892)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:22]
  Epoch: [188][300/391]   Time 0.061 (0.049)   Data 0.000 (0.001)   Loss 0.0513 (0.0332)   Prec@1 98.438 (98.892)   Prec@5 100.000 (99.997)   [2019-11-24 14:23:26]
  **Train** Prec@1 98.914 Prec@5 99.998 Error@1 1.086
  **Test** Prec@1 91.280 Prec@5 99.750 Error@1 8.720

==>>[2019-11-24 14:23:33] [Epoch=189/200] [Need: 00:04:00] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [189][000/391]   Time 0.276 (0.276)   Data 0.199 (0.199)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:33]
  Epoch: [189][100/391]   Time 0.043 (0.056)   Data 0.000 (0.002)   Loss 0.0206 (0.0294)   Prec@1 99.219 (99.033)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:38]
  Epoch: [189][200/391]   Time 0.044 (0.054)   Data 0.000 (0.001)   Loss 0.0210 (0.0291)   Prec@1 100.000 (99.044)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:44]
  Epoch: [189][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0294 (0.0298)   Prec@1 99.219 (99.032)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:49]
  **Train** Prec@1 99.028 Prec@5 100.000 Error@1 0.972
  **Test** Prec@1 91.270 Prec@5 99.720 Error@1 8.730

==>>[2019-11-24 14:23:55] [Epoch=190/200] [Need: 00:03:38] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [190][000/391]   Time 0.273 (0.273)   Data 0.215 (0.215)   Loss 0.0182 (0.0182)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-11-24 14:23:55]
  Epoch: [190][100/391]   Time 0.058 (0.053)   Data 0.000 (0.002)   Loss 0.0306 (0.0328)   Prec@1 98.438 (98.855)   Prec@5 100.000 (99.992)   [2019-11-24 14:24:00]
  Epoch: [190][200/391]   Time 0.063 (0.052)   Data 0.000 (0.001)   Loss 0.0809 (0.0327)   Prec@1 97.656 (98.888)   Prec@5 100.000 (99.996)   [2019-11-24 14:24:05]
  Epoch: [190][300/391]   Time 0.053 (0.052)   Data 0.000 (0.001)   Loss 0.0464 (0.0320)   Prec@1 98.438 (98.957)   Prec@5 100.000 (99.997)   [2019-11-24 14:24:11]
  **Train** Prec@1 98.978 Prec@5 99.998 Error@1 1.022
  **Test** Prec@1 91.330 Prec@5 99.740 Error@1 8.670

==>>[2019-11-24 14:24:17] [Epoch=191/200] [Need: 00:03:16] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [191][000/391]   Time 0.269 (0.269)   Data 0.199 (0.199)   Loss 0.0379 (0.0379)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:17]
  Epoch: [191][100/391]   Time 0.041 (0.053)   Data 0.000 (0.002)   Loss 0.0365 (0.0296)   Prec@1 98.438 (98.948)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:22]
  Epoch: [191][200/391]   Time 0.056 (0.054)   Data 0.000 (0.001)   Loss 0.0176 (0.0291)   Prec@1 100.000 (98.986)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:28]
  Epoch: [191][300/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0279 (0.0296)   Prec@1 98.438 (98.990)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:33]
  **Train** Prec@1 99.002 Prec@5 100.000 Error@1 0.998
  **Test** Prec@1 91.210 Prec@5 99.710 Error@1 8.790

==>>[2019-11-24 14:24:39] [Epoch=192/200] [Need: 00:02:54] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [192][000/391]   Time 0.275 (0.275)   Data 0.201 (0.201)   Loss 0.0336 (0.0336)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:39]
  Epoch: [192][100/391]   Time 0.036 (0.053)   Data 0.000 (0.002)   Loss 0.0104 (0.0305)   Prec@1 100.000 (98.994)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:44]
  Epoch: [192][200/391]   Time 0.040 (0.051)   Data 0.000 (0.001)   Loss 0.0269 (0.0310)   Prec@1 99.219 (98.986)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:49]
  Epoch: [192][300/391]   Time 0.044 (0.050)   Data 0.000 (0.001)   Loss 0.0416 (0.0315)   Prec@1 98.438 (99.014)   Prec@5 100.000 (100.000)   [2019-11-24 14:24:54]
  **Train** Prec@1 99.014 Prec@5 100.000 Error@1 0.986
  **Test** Prec@1 91.370 Prec@5 99.720 Error@1 8.630

==>>[2019-11-24 14:25:00] [Epoch=193/200] [Need: 00:02:32] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [193][000/391]   Time 0.279 (0.279)   Data 0.210 (0.210)   Loss 0.0350 (0.0350)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:00]
  Epoch: [193][100/391]   Time 0.052 (0.055)   Data 0.000 (0.002)   Loss 0.0321 (0.0310)   Prec@1 97.656 (98.971)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:05]
  Epoch: [193][200/391]   Time 0.043 (0.053)   Data 0.000 (0.001)   Loss 0.0162 (0.0324)   Prec@1 100.000 (98.919)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:11]
  Epoch: [193][300/391]   Time 0.045 (0.051)   Data 0.000 (0.001)   Loss 0.0220 (0.0315)   Prec@1 100.000 (98.949)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:15]
  **Train** Prec@1 98.946 Prec@5 100.000 Error@1 1.054
  **Test** Prec@1 91.310 Prec@5 99.730 Error@1 8.690

==>>[2019-11-24 14:25:22] [Epoch=194/200] [Need: 00:02:11] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [194][000/391]   Time 0.265 (0.265)   Data 0.205 (0.205)   Loss 0.0230 (0.0230)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:22]
  Epoch: [194][100/391]   Time 0.057 (0.053)   Data 0.000 (0.002)   Loss 0.0195 (0.0306)   Prec@1 99.219 (98.956)   Prec@5 100.000 (99.992)   [2019-11-24 14:25:27]
  Epoch: [194][200/391]   Time 0.051 (0.051)   Data 0.000 (0.001)   Loss 0.0141 (0.0318)   Prec@1 100.000 (98.935)   Prec@5 100.000 (99.996)   [2019-11-24 14:25:32]
  Epoch: [194][300/391]   Time 0.049 (0.050)   Data 0.000 (0.001)   Loss 0.0112 (0.0317)   Prec@1 100.000 (98.928)   Prec@5 100.000 (99.995)   [2019-11-24 14:25:37]
  **Train** Prec@1 98.924 Prec@5 99.994 Error@1 1.076
  **Test** Prec@1 91.420 Prec@5 99.720 Error@1 8.580

==>>[2019-11-24 14:25:43] [Epoch=195/200] [Need: 00:01:49] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [195][000/391]   Time 0.281 (0.281)   Data 0.216 (0.216)   Loss 0.0293 (0.0293)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:43]
  Epoch: [195][100/391]   Time 0.052 (0.052)   Data 0.000 (0.002)   Loss 0.0653 (0.0327)   Prec@1 98.438 (98.894)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:48]
  Epoch: [195][200/391]   Time 0.045 (0.050)   Data 0.000 (0.001)   Loss 0.0195 (0.0303)   Prec@1 100.000 (99.013)   Prec@5 100.000 (100.000)   [2019-11-24 14:25:53]
  Epoch: [195][300/391]   Time 0.082 (0.050)   Data 0.000 (0.001)   Loss 0.0433 (0.0299)   Prec@1 98.438 (99.071)   Prec@5 100.000 (99.997)   [2019-11-24 14:25:58]
  **Train** Prec@1 99.044 Prec@5 99.998 Error@1 0.956
  **Test** Prec@1 91.210 Prec@5 99.700 Error@1 8.790

==>>[2019-11-24 14:26:05] [Epoch=196/200] [Need: 00:01:27] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [196][000/391]   Time 0.287 (0.287)   Data 0.232 (0.232)   Loss 0.0291 (0.0291)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-11-24 14:26:05]
  Epoch: [196][100/391]   Time 0.055 (0.051)   Data 0.000 (0.002)   Loss 0.0391 (0.0269)   Prec@1 99.219 (99.157)   Prec@5 100.000 (100.000)   [2019-11-24 14:26:10]
  Epoch: [196][200/391]   Time 0.048 (0.050)   Data 0.000 (0.001)   Loss 0.0524 (0.0291)   Prec@1 98.438 (99.024)   Prec@5 100.000 (100.000)   [2019-11-24 14:26:15]
  Epoch: [196][300/391]   Time 0.043 (0.050)   Data 0.000 (0.001)   Loss 0.0180 (0.0307)   Prec@1 99.219 (98.975)   Prec@5 100.000 (99.997)   [2019-11-24 14:26:20]
  **Train** Prec@1 98.940 Prec@5 99.996 Error@1 1.060
  **Test** Prec@1 91.420 Prec@5 99.730 Error@1 8.580

==>>[2019-11-24 14:26:26] [Epoch=197/200] [Need: 00:01:05] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [197][000/391]   Time 0.284 (0.284)   Data 0.224 (0.224)   Loss 0.0350 (0.0350)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:26:27]
  Epoch: [197][100/391]   Time 0.051 (0.052)   Data 0.000 (0.002)   Loss 0.0116 (0.0301)   Prec@1 100.000 (99.002)   Prec@5 100.000 (99.992)   [2019-11-24 14:26:32]
  Epoch: [197][200/391]   Time 0.044 (0.052)   Data 0.000 (0.001)   Loss 0.0624 (0.0310)   Prec@1 97.656 (98.958)   Prec@5 100.000 (99.996)   [2019-11-24 14:26:37]
  Epoch: [197][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0284 (0.0315)   Prec@1 98.438 (98.949)   Prec@5 100.000 (99.997)   [2019-11-24 14:26:41]
  **Train** Prec@1 98.928 Prec@5 99.998 Error@1 1.072
  **Test** Prec@1 91.390 Prec@5 99.730 Error@1 8.610

==>>[2019-11-24 14:26:48] [Epoch=198/200] [Need: 00:00:43] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [198][000/391]   Time 0.276 (0.276)   Data 0.206 (0.206)   Loss 0.0427 (0.0427)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-11-24 14:26:48]
  Epoch: [198][100/391]   Time 0.043 (0.051)   Data 0.000 (0.002)   Loss 0.0988 (0.0285)   Prec@1 96.094 (99.118)   Prec@5 99.219 (99.992)   [2019-11-24 14:26:53]
  Epoch: [198][200/391]   Time 0.052 (0.049)   Data 0.000 (0.001)   Loss 0.0335 (0.0300)   Prec@1 98.438 (99.001)   Prec@5 100.000 (99.992)   [2019-11-24 14:26:58]
  Epoch: [198][300/391]   Time 0.042 (0.050)   Data 0.000 (0.001)   Loss 0.0534 (0.0304)   Prec@1 98.438 (98.988)   Prec@5 100.000 (99.992)   [2019-11-24 14:27:03]
  **Train** Prec@1 98.962 Prec@5 99.992 Error@1 1.038
  **Test** Prec@1 91.230 Prec@5 99.740 Error@1 8.770

==>>[2019-11-24 14:27:10] [Epoch=199/200] [Need: 00:00:21] [LR=0.0001][M=0.90] [Best : Accuracy=91.54, Error=8.46]
  Epoch: [199][000/391]   Time 0.266 (0.266)   Data 0.214 (0.214)   Loss 0.0640 (0.0640)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-11-24 14:27:10]
  Epoch: [199][100/391]   Time 0.043 (0.049)   Data 0.000 (0.002)   Loss 0.0067 (0.0310)   Prec@1 100.000 (98.925)   Prec@5 100.000 (100.000)   [2019-11-24 14:27:15]
  Epoch: [199][200/391]   Time 0.044 (0.049)   Data 0.000 (0.001)   Loss 0.0221 (0.0320)   Prec@1 98.438 (98.904)   Prec@5 100.000 (99.992)   [2019-11-24 14:27:19]
  Epoch: [199][300/391]   Time 0.051 (0.048)   Data 0.000 (0.001)   Loss 0.0314 (0.0320)   Prec@1 99.219 (98.900)   Prec@5 100.000 (99.995)   [2019-11-24 14:27:24]
  **Train** Prec@1 98.920 Prec@5 99.996 Error@1 1.080
  **Test** Prec@1 91.390 Prec@5 99.710 Error@1 8.610
